---
title: Evals.do - AI Component Evaluation Platform
description: Evaluate the performance of your AI functions, workflows, and agents with Evals.do, the comprehensive evaluation platform
headline: Evaluate AI That Actually Works
subhead: Measure the performance of your AI components against objective criteria. Make data-driven decisions about which components to deploy in production environments.
badge: 'AI without Complexity'
codeExample: "import { Evaluation } from 'evals.do';\n\nconst agentEvaluation = new Evaluation({\n  name: 'Customer Support Agent Evaluation',\n  description: 'Evaluate the performance of customer support agent responses',\n  target: 'customer-support-agent',\n  metrics: [\n    {\n      name: 'accuracy',\n      description: 'Correctness of information provided',\n      scale: [0, 5],\n      threshold: 4.0\n    },\n    {\n      name: 'helpfulness',\n      description: 'How well the response addresses the customer need',\n      scale: [0, 5],\n      threshold: 4.2\n    },\n    {\n      name: 'tone',\n      description: 'Appropriateness of language and tone',\n      scale: [0, 5],\n      threshold: 4.5\n    }\n  ],\n  dataset: 'customer-support-queries',\n  evaluators: ['human-review', 'automated-metrics']\n});"
---

# Evals.do

Evaluate Functions, Workflows, and Agents
