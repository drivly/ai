# Experiments

Experiments allow you to test different configurations, models, and prompts to optimize your AI applications.

## Overview

The Experiments collection provides a structured way to define, run, and analyze experiments in your AI applications. Experiments can:

- Test different models and configurations
- Compare prompt variations
- Measure performance metrics
- Help you make data-driven decisions

## Key Features

- **A/B Testing**: Compare different configurations side by side
- **Metrics Tracking**: Measure and analyze performance metrics
- **Versioning**: Track changes and iterations
- **Reproducibility**: Ensure experiments can be reproduced

## Defining Experiments

Experiments can be defined using the Experiments.do API or through the dashboard interface.

```typescript
// Example experiment definition
const SummarizationExperiment = {
  name: 'SummarizationExperiment',
  description: 'Compare different models and prompts for text summarization',
  variants: [
    {
      id: 'baseline',
      description: 'Current production configuration',
      config: {
        model: 'gpt-3.5-turbo',
        prompt: 'summarize-v1',
        temperature: 0.7,
        maxTokens: 150
      }
    },
    {
      id: 'new-model',
      description: 'Testing newer model',
      config: {
        model: 'gpt-4',
        prompt: 'summarize-v1',
        temperature: 0.7,
        maxTokens: 150
      }
    },
    {
      id: 'new-prompt',
      description: 'Testing improved prompt',
      config: {
        model: 'gpt-3.5-turbo',
        prompt: 'summarize-v2',
        temperature: 0.7,
        maxTokens: 150
      }
    },
    {
      id: 'combined',
      description: 'New model with new prompt',
      config: {
        model: 'gpt-4',
        prompt: 'summarize-v2',
        temperature: 0.7,
        maxTokens: 150
      }
    }
  ],
  metrics: [
    {
      name: 'rouge-1',
      description: 'ROUGE-1 score against reference summaries',
      higherIsBetter: true
    },
    {
      name: 'rouge-l',
      description: 'ROUGE-L score against reference summaries',
      higherIsBetter: true
    },
    {
      name: 'human-rating',
      description: 'Human-rated quality score (1-5)',
      higherIsBetter: true
    },
    {
      name: 'latency',
      description: 'Response time in milliseconds',
      higherIsBetter: false
    },
    {
      name: 'cost',
      description: 'Cost per request in USD',
      higherIsBetter: false
    }
  ],
  dataset: {
    id: 'summarization-test-set',
    size: 100
  },
  trafficAllocation: {
    type: 'percentage',
    values: {
      'baseline': 40,
      'new-model': 20,
      'new-prompt': 20,
      'combined': 20
    }
  },
  duration: {
    startDate: '2023-06-01T00:00:00Z',
    endDate: '2023-06-15T23:59:59Z'
  }
}
```

## Running Experiments

Experiments can be run and monitored through your AI applications:

```typescript
// Start an experiment
await experiments.start('SummarizationExperiment')

// Get a variant for a specific request
const variant = await experiments.getVariant('SummarizationExperiment', {
  userId: 'user-123',
  sessionId: 'session-456'
})

// Use the variant in your application
const summary = await llm.generate({
  model: variant.config.model,
  prompt: prompts.get(variant.config.prompt),
  temperature: variant.config.temperature,
  maxTokens: variant.config.maxTokens,
  input: {
    text: articleText
  }
})

// Record metrics for the variant
await experiments.recordMetrics('SummarizationExperiment', variant.id, {
  'rouge-1': 0.78,
  'rouge-l': 0.65,
  'latency': 450,
  'cost': 0.02
})
```

## Analyzing Results

Experiment results can be analyzed through the dashboard or API:

```typescript
// Get experiment results
const results = await experiments.getResults('SummarizationExperiment')

// Compare variants
const comparison = await experiments.compareVariants('SummarizationExperiment', [
  'baseline',
  'combined'
])

// Get recommendations
const recommendations = await experiments.getRecommendations('SummarizationExperiment')
```

## Next Steps

- [Create your first experiment](/experiments/experiments/create)
- [Explore experiment templates](/experiments/experiments/templates)
- [Learn about statistical analysis](/experiments/experiments/analysis)