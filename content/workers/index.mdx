# Workers

Welcome to the Workers documentation for the AI Primitives platform. This section provides information about the Cloudflare Workers that power various components of the platform.

## Overview

The AI Primitives platform uses Cloudflare Workers to provide scalable, serverless computing at the edge. These workers handle various tasks, including API requests, data processing, and more.

## Available Workers

- **LLM Worker**: Handles requests to language models
- **Function Worker**: Executes AI functions
- **Workflow Worker**: Manages workflow execution
- **Agent Worker**: Coordinates agent activities

## Worker Architecture

Workers are deployed to Cloudflare's global network and are designed to be fast, reliable, and secure. They are written in TypeScript and use the Hono framework for routing and request handling.

## Deployment

Workers are deployed using Wrangler, Cloudflare's command-line tool for managing Workers. For more information about deploying workers, see the [Deployment](/code/deployments) documentation.

## Development

For information about developing workers for the AI Primitives platform, see the [Development](/code/modules) documentation.
