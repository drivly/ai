export default {
  "models": [
    {
      "slug": "openai/gpt-4o-mini",
      "hfSlug": null,
      "updatedAt": "2025-04-23T22:07:10.809212+00:00",
      "createdAt": "2024-07-18T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4o-mini",
      "shortName": "GPT-4o-mini",
      "author": "openai",
      "description": "GPT-4o mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting both text and image inputs with text outputs.\n\nAs their most advanced small model, it is many multiples more affordable than other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo). It maintains SOTA intelligence, while being significantly more cost-effective.\n\nGPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on chat preferences [common leaderboards](https://arena.lmsys.org/).\n\nCheck out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) to learn more.\n\n#multimodal",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4o-mini",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "77e40332-6f2a-4c48-bc14-e44596b30ce2",
        "name": "OpenAI | openai/gpt-4o-mini",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4o-mini",
          "hfSlug": null,
          "updatedAt": "2025-04-23T22:07:10.809212+00:00",
          "createdAt": "2024-07-18T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4o-mini",
          "shortName": "GPT-4o-mini",
          "author": "openai",
          "description": "GPT-4o mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting both text and image inputs with text outputs.\n\nAs their most advanced small model, it is many multiples more affordable than other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo). It maintains SOTA intelligence, while being significantly more cost-effective.\n\nGPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on chat preferences [common leaderboards](https://arena.lmsys.org/).\n\nCheck out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) to learn more.\n\n#multimodal",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4o-mini",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4o-mini",
        "modelVariantPermaslug": "openai/gpt-4o-mini",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4o-mini",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "web_search_options",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000006",
          "image": "0.000217",
          "request": "0",
          "inputCacheRead": "0.000000075",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.03"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.0275"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.025"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 0,
        "newest": 236,
        "throughputHighToLow": 128,
        "latencyLowToHigh": 55,
        "pricingLowToHigh": 143,
        "pricingHighToLow": 176
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o-mini",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0.000217",
            "request": "0",
            "inputCacheRead": "0.000000075",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 60.699,
          "latency": 439
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "openai/gpt-4o-mini",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 155.2135,
          "latency": 1508
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.7-sonnet",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-24T18:35:10.00008+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.7 Sonnet",
      "shortName": "Claude 3.7 Sonnet",
      "author": "anthropic",
      "description": "Claude 3.7 Sonnet is an advanced large language model with improved reasoning, coding, and problem-solving capabilities. It introduces a hybrid reasoning approach, allowing users to choose between rapid responses and extended, step-by-step processing for complex tasks. The model demonstrates notable improvements in coding, particularly in front-end development and full-stack updates, and excels in agentic workflows, where it can autonomously navigate multi-step processes. \n\nClaude 3.7 Sonnet maintains performance parity with its predecessor in standard mode while offering an extended reasoning mode for enhanced accuracy in math, coding, and instruction-following tasks.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-3-7-sonnet)",
      "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-7-sonnet-20250219",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "1c9b8776-e266-4efb-b5ba-19a6753e7736",
        "name": "Google | anthropic/claude-3-7-sonnet-20250219",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.7-sonnet",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-24T18:35:10.00008+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.7 Sonnet",
          "shortName": "Claude 3.7 Sonnet",
          "author": "anthropic",
          "description": "Claude 3.7 Sonnet is an advanced large language model with improved reasoning, coding, and problem-solving capabilities. It introduces a hybrid reasoning approach, allowing users to choose between rapid responses and extended, step-by-step processing for complex tasks. The model demonstrates notable improvements in coding, particularly in front-end development and full-stack updates, and excels in agentic workflows, where it can autonomously navigate multi-step processes. \n\nClaude 3.7 Sonnet maintains performance parity with its predecessor in standard mode while offering an extended reasoning mode for enhanced accuracy in math, coding, and instruction-following tasks.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-3-7-sonnet)",
          "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-7-sonnet-20250219",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.7-sonnet",
        "modelVariantPermaslug": "anthropic/claude-3-7-sonnet-20250219",
        "providerName": "Google",
        "providerInfo": {
          "name": "Google",
          "displayName": "Google Vertex",
          "slug": "google-vertex",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cloud.google.com/products/sdXM79fz1FS6ekNpu37K/history",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleVertex.svg"
          }
        },
        "providerDisplayName": "Google Vertex",
        "providerModelId": "claude-3-7-sonnet@20250219",
        "providerGroup": "Google",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 64000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "stop",
          "reasoning",
          "include_reasoning",
          "tools",
          "tool_choice"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0.0048",
          "request": "0",
          "inputCacheRead": "0.0000003",
          "inputCacheWrite": "0.00000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": 500,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 1,
        "newest": 108,
        "throughputHighToLow": 148,
        "latencyLowToHigh": 250,
        "pricingLowToHigh": 269,
        "pricingHighToLow": 41
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 64000,
          "providerModelId": "claude-3-7-sonnet@20250219",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 56.755,
          "latency": 1909
        },
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 128000,
          "providerModelId": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 35.942,
          "latency": 1916
        },
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 128000,
          "providerModelId": "claude-3-7-sonnet-20250219",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 58.0175,
          "latency": 1610
        },
        {
          "name": "Google Vertex (Europe)",
          "icon": "",
          "slug": "googleVertex (europe)",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 64000,
          "providerModelId": "claude-3-7-sonnet@20250219",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 50.2565,
          "latency": 2262
        }
      ]
    },
    {
      "slug": "google/gemini-2.0-flash-001",
      "hfSlug": "",
      "updatedAt": "2025-04-23T18:40:40.360887+00:00",
      "createdAt": "2025-02-05T15:30:13.144552+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 2.0 Flash",
      "shortName": "Gemini 2.0 Flash",
      "author": "google",
      "description": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5). It introduces notable enhancements in multimodal understanding, coding capabilities, complex instruction following, and function calling. These advancements come together to deliver more seamless and robust agentic experiences.",
      "modelVersionGroupId": "e993dfbf-2cbd-4680-b866-c05bbdcc8f4d",
      "contextLength": 1048576,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-2.0-flash-001",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8b6c3ec6-e6a0-43f7-9e09-a5487a5756c9",
        "name": "Google AI Studio | google/gemini-2.0-flash-001",
        "contextLength": 1048576,
        "model": {
          "slug": "google/gemini-2.0-flash-001",
          "hfSlug": "",
          "updatedAt": "2025-04-23T18:40:40.360887+00:00",
          "createdAt": "2025-02-05T15:30:13.144552+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 2.0 Flash",
          "shortName": "Gemini 2.0 Flash",
          "author": "google",
          "description": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5). It introduces notable enhancements in multimodal understanding, coding capabilities, complex instruction following, and function calling. These advancements come together to deliver more seamless and robust agentic experiences.",
          "modelVersionGroupId": "e993dfbf-2cbd-4680-b866-c05bbdcc8f4d",
          "contextLength": 1000000,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemini-2.0-flash-001",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemini-2.0-flash-001",
        "modelVariantPermaslug": "google/gemini-2.0-flash-001",
        "providerName": "Google AI Studio",
        "providerInfo": {
          "name": "Google AI Studio",
          "displayName": "Google AI Studio",
          "slug": "google-ai-studio",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 55
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true,
              "retentionDays": 55
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google AI Studio",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleAIStudio.svg"
          }
        },
        "providerDisplayName": "Google AI Studio",
        "providerModelId": "gemini-2.0-flash-001",
        "providerGroup": "Google AI Studio",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 55
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000004",
          "image": "0.0000258",
          "request": "0",
          "inputCacheRead": "0.000000025",
          "inputCacheWrite": "0.0000001833",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 2,
        "newest": 118,
        "throughputHighToLow": 31,
        "latencyLowToHigh": 78,
        "pricingLowToHigh": 128,
        "pricingHighToLow": 190
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Google AI Studio",
          "icon": "https://openrouter.ai/images/icons/GoogleAIStudio.svg",
          "slug": "google",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemini-2.0-flash-001",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000004",
            "image": "0.0000258",
            "request": "0",
            "inputCacheRead": "0.000000025",
            "inputCacheWrite": "0.0000001833",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.4,
          "throughput": 154.0435,
          "latency": 550
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": null,
          "context": 1000000,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemini-2.0-flash-001",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0.0000387",
            "request": "0",
            "inputCacheRead": "0.0000000375",
            "inputCacheWrite": "0.0000002333",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 163.9075,
          "latency": 479
        }
      ]
    },
    {
      "slug": "google/gemini-2.5-flash-preview",
      "hfSlug": "",
      "updatedAt": "2025-04-23T18:36:05.411237+00:00",
      "createdAt": "2025-04-17T18:31:07.815979+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 2.5 Flash Preview",
      "shortName": "Gemini 2.5 Flash Preview",
      "author": "google",
      "description": "Gemini 2.5 Flash is Google's state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks. It includes built-in \"thinking\" capabilities, enabling it to provide responses with greater accuracy and nuanced context handling. \n\nNote: This model is available in two variants: thinking and non-thinking. The output pricing varies significantly depending on whether the thinking capability is active. If you select the standard variant (without the \":thinking\" suffix), the model will explicitly avoid generating thinking tokens. \n\nTo utilize the thinking capability and receive thinking tokens, you must choose the \":thinking\" variant, which will then incur the higher thinking-output pricing. \n\nAdditionally, Gemini 2.5 Flash is configurable through the \"max tokens for reasoning\" parameter, as described in the documentation (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
      "modelVersionGroupId": null,
      "contextLength": 1048576,
      "inputModalities": [
        "image",
        "text",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-2.5-flash-preview-04-17",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "38387a4b-bc0f-446c-b622-b73353eb857c",
        "name": "Google | google/gemini-2.5-flash-preview-04-17",
        "contextLength": 1048576,
        "model": {
          "slug": "google/gemini-2.5-flash-preview",
          "hfSlug": "",
          "updatedAt": "2025-04-23T18:36:05.411237+00:00",
          "createdAt": "2025-04-17T18:31:07.815979+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 2.5 Flash Preview",
          "shortName": "Gemini 2.5 Flash Preview",
          "author": "google",
          "description": "Gemini 2.5 Flash is Google's state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks. It includes built-in \"thinking\" capabilities, enabling it to provide responses with greater accuracy and nuanced context handling. \n\nNote: This model is available in two variants: thinking and non-thinking. The output pricing varies significantly depending on whether the thinking capability is active. If you select the standard variant (without the \":thinking\" suffix), the model will explicitly avoid generating thinking tokens. \n\nTo utilize the thinking capability and receive thinking tokens, you must choose the \":thinking\" variant, which will then incur the higher thinking-output pricing. \n\nAdditionally, Gemini 2.5 Flash is configurable through the \"max tokens for reasoning\" parameter, as described in the documentation (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
          "modelVersionGroupId": null,
          "contextLength": 1048576,
          "inputModalities": [
            "image",
            "text",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemini-2.5-flash-preview-04-17",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemini-2.5-flash-preview",
        "modelVariantPermaslug": "google/gemini-2.5-flash-preview-04-17",
        "providerName": "Google",
        "providerInfo": {
          "name": "Google",
          "displayName": "Vertex Non-Thinking",
          "slug": "google-vertex",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cloud.google.com/products/sdXM79fz1FS6ekNpu37K/history",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleVertex.svg"
          }
        },
        "providerDisplayName": "Vertex Non-Thinking",
        "providerModelId": "gemini-2.5-flash-preview-04-17",
        "providerGroup": "Google",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 65535,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "tools",
          "tool_choice",
          "stop",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000006",
          "image": "0.0006192",
          "request": "0",
          "inputCacheRead": "0.0000000375",
          "inputCacheWrite": "0.0000002333",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {
            "responseFormat": true,
            "structuredOutputs": true
          },
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 3,
        "newest": 41,
        "throughputHighToLow": 52,
        "latencyLowToHigh": 92,
        "pricingLowToHigh": 141,
        "pricingHighToLow": 144
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Vertex Non-Thinking",
          "icon": "",
          "slug": "vertexNonThinking",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 65535,
          "providerModelId": "gemini-2.5-flash-preview-04-17",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0.0006192",
            "request": "0",
            "inputCacheRead": "0.0000000375",
            "inputCacheWrite": "0.0000002333",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "tools",
            "tool_choice",
            "stop",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 100.181,
          "latency": 587
        },
        {
          "name": "AI Studio Non-Thinking",
          "icon": "",
          "slug": "aiStudioNonThinking",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 65535,
          "providerModelId": "gemini-2.5-flash-preview-04-17",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0.0006192",
            "request": "0",
            "inputCacheRead": "0.0000000375",
            "inputCacheWrite": "0.0000002333",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "tools",
            "tool_choice",
            "stop",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 126.0255,
          "latency": 610
        }
      ]
    },
    {
      "slug": "google/gemini-2.5-pro-preview",
      "hfSlug": "",
      "updatedAt": "2025-05-07T00:41:53.500835+00:00",
      "createdAt": "2025-05-07T00:41:53+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 2.5 Pro Preview",
      "shortName": "Gemini 2.5 Pro Preview",
      "author": "google",
      "description": "Gemini 2.5 Pro is Google’s state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs “thinking” capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
      "modelVersionGroupId": null,
      "contextLength": 1048576,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "google/gemini-2.5-pro-preview-03-25",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9d2cac4d-81d4-4e67-ac7a-6c73040655ee",
        "name": "Google | google/gemini-2.5-pro-preview-03-25",
        "contextLength": 1048576,
        "model": {
          "slug": "google/gemini-2.5-pro-preview",
          "hfSlug": "",
          "updatedAt": "2025-05-07T00:41:53.500835+00:00",
          "createdAt": "2025-05-07T00:41:53+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 2.5 Pro Preview",
          "shortName": "Gemini 2.5 Pro Preview",
          "author": "google",
          "description": "Gemini 2.5 Pro is Google’s state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs “thinking” capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
          "modelVersionGroupId": null,
          "contextLength": 1048576,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "google/gemini-2.5-pro-preview-03-25",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemini-2.5-pro-preview",
        "modelVariantPermaslug": "google/gemini-2.5-pro-preview-03-25",
        "providerName": "Google",
        "providerInfo": {
          "name": "Google",
          "displayName": "Google Vertex",
          "slug": "google-vertex",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cloud.google.com/products/sdXM79fz1FS6ekNpu37K/history",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleVertex.svg"
          }
        },
        "providerDisplayName": "Google Vertex",
        "providerModelId": "gemini-2.5-pro-preview-05-06",
        "providerGroup": "Google",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 65535,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "tools",
          "tool_choice",
          "stop",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000125",
          "completion": "0.00001",
          "image": "0.00516",
          "request": "0",
          "inputCacheRead": "0.00000031",
          "inputCacheWrite": "0.000001625",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "prompt-threshold",
            "threshold": 200000,
            "prompt": "0.0000025",
            "completions": "0.000015",
            "inputCacheRead": "0.000000625",
            "inputCacheWrite": "0.000002875"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 4,
        "newest": 2,
        "throughputHighToLow": 96,
        "latencyLowToHigh": 274,
        "pricingLowToHigh": 242,
        "pricingHighToLow": 76
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 65535,
          "providerModelId": "gemini-2.5-pro-preview-05-06",
          "pricing": {
            "prompt": "0.00000125",
            "completion": "0.00001",
            "image": "0.00516",
            "request": "0",
            "inputCacheRead": "0.00000031",
            "inputCacheWrite": "0.000001625",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "tools",
            "tool_choice",
            "stop",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1.25,
          "outputCost": 10,
          "throughput": 81.285,
          "latency": 2547.5
        },
        {
          "name": "Google AI Studio",
          "icon": "https://openrouter.ai/images/icons/GoogleAIStudio.svg",
          "slug": "google",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 65536,
          "providerModelId": "gemini-2.5-pro-preview-05-06",
          "pricing": {
            "prompt": "0.00000125",
            "completion": "0.00001",
            "image": "0.00516",
            "request": "0",
            "inputCacheRead": "0.00000031",
            "inputCacheWrite": "0.000001625",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "tools",
            "tool_choice",
            "stop",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1.25,
          "outputCost": 10,
          "throughput": 83.6465,
          "latency": 4081.5
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-chat-v3-0324",
      "hfSlug": "deepseek-ai/DeepSeek-V3-0324",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-24T13:59:15.252028+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: DeepSeek V3 0324 (free)",
      "shortName": "DeepSeek V3 0324 (free)",
      "author": "deepseek",
      "description": "DeepSeek V3, a 685B-parameter, mixture-of-experts model, is the latest iteration of the flagship chat model family from the DeepSeek team.\n\nIt succeeds the [DeepSeek V3](/deepseek/deepseek-chat-v3) model and performs really well on a variety of tasks.",
      "modelVersionGroupId": "be67b3ba-9d99-440c-ae90-6514d99b93ed",
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-chat-v3-0324",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "207226f6-161d-4196-9738-0ee4dac9a244",
        "name": "Chutes | deepseek/deepseek-chat-v3-0324:free",
        "contextLength": 163840,
        "model": {
          "slug": "deepseek/deepseek-chat-v3-0324",
          "hfSlug": "deepseek-ai/DeepSeek-V3-0324",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-24T13:59:15.252028+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: DeepSeek V3 0324",
          "shortName": "DeepSeek V3 0324",
          "author": "deepseek",
          "description": "DeepSeek V3, a 685B-parameter, mixture-of-experts model, is the latest iteration of the flagship chat model family from the DeepSeek team.\n\nIt succeeds the [DeepSeek V3](/deepseek/deepseek-chat-v3) model and performs really well on a variety of tasks.",
          "modelVersionGroupId": "be67b3ba-9d99-440c-ae90-6514d99b93ed",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-chat-v3-0324",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "deepseek/deepseek-chat-v3-0324:free",
        "modelVariantPermaslug": "deepseek/deepseek-chat-v3-0324:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
        "providerGroup": "Chutes",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 5,
        "newest": 75,
        "throughputHighToLow": 245,
        "latencyLowToHigh": 140,
        "pricingLowToHigh": 33,
        "pricingHighToLow": 148
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.3,
          "outputCost": 0.88,
          "throughput": 23.7255,
          "latency": 844
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 16000,
          "providerModelId": "deepseek/deepseek-v3-0324",
          "pricing": {
            "prompt": "0.00000033",
            "completion": "0.0000013",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.33,
          "outputCost": 1.3,
          "throughput": 21.672,
          "latency": 1172
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.00000033",
            "completion": "0.0000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.33,
          "outputCost": 1.4,
          "throughput": 17.787,
          "latency": 1094
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-v3-0324",
          "pricing": {
            "prompt": "0.00000034",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.34,
          "outputCost": 0.88,
          "throughput": 26.5515,
          "latency": 900.5
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek/deepseek-v3-0324/fp-8",
          "pricing": {
            "prompt": "0.00000045",
            "completion": "0.00000145",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.45,
          "outputCost": 1.45,
          "throughput": 11.4845,
          "latency": 1770
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 18.982,
          "latency": 920
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "parasail-deepseek-v3-0324",
          "pricing": {
            "prompt": "0.00000074",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.74,
          "outputCost": 1.5,
          "throughput": 28.772,
          "latency": 819
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 26.3375,
          "latency": 913
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/deepseek-v3-0324",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 64.2745,
          "latency": 745
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "seed"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 58.278,
          "latency": 823
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.00000125",
            "completion": "0.00000125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 1.25,
          "outputCost": 1.25,
          "throughput": 23.1435,
          "latency": 1822
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 12288,
          "providerModelId": "deepseek-ai/DeepSeek-V3",
          "pricing": {
            "prompt": "0.00000125",
            "completion": "0.00000125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.25,
          "outputCost": 1.25,
          "throughput": 24.258,
          "latency": 2662
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.0000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 4.5,
          "throughput": 165.6035,
          "latency": 2393
        },
        {
          "name": "DeepSeek",
          "icon": "https://openrouter.ai/images/icons/DeepSeek.png",
          "slug": "deepSeek",
          "quantization": "fp8",
          "context": 64000,
          "maxCompletionTokens": 8192,
          "providerModelId": "deepseek-chat",
          "pricing": {
            "prompt": "0.00000027",
            "completion": "0.0000011",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000007",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.27,
          "outputCost": 1.1,
          "throughput": 19.446,
          "latency": 4568
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-chat-v3-0324",
      "hfSlug": "deepseek-ai/DeepSeek-V3-0324",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-24T13:59:15.252028+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: DeepSeek V3 0324",
      "shortName": "DeepSeek V3 0324",
      "author": "deepseek",
      "description": "DeepSeek V3, a 685B-parameter, mixture-of-experts model, is the latest iteration of the flagship chat model family from the DeepSeek team.\n\nIt succeeds the [DeepSeek V3](/deepseek/deepseek-chat-v3) model and performs really well on a variety of tasks.",
      "modelVersionGroupId": "be67b3ba-9d99-440c-ae90-6514d99b93ed",
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-chat-v3-0324",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "820376cb-f110-4d56-ab52-5bd6ca269420",
        "name": "DeepInfra | deepseek/deepseek-chat-v3-0324",
        "contextLength": 163840,
        "model": {
          "slug": "deepseek/deepseek-chat-v3-0324",
          "hfSlug": "deepseek-ai/DeepSeek-V3-0324",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-24T13:59:15.252028+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: DeepSeek V3 0324",
          "shortName": "DeepSeek V3 0324",
          "author": "deepseek",
          "description": "DeepSeek V3, a 685B-parameter, mixture-of-experts model, is the latest iteration of the flagship chat model family from the DeepSeek team.\n\nIt succeeds the [DeepSeek V3](/deepseek/deepseek-chat-v3) model and performs really well on a variety of tasks.",
          "modelVersionGroupId": "be67b3ba-9d99-440c-ae90-6514d99b93ed",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-chat-v3-0324",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "deepseek/deepseek-chat-v3-0324",
        "modelVariantPermaslug": "deepseek/deepseek-chat-v3-0324",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000003",
          "completion": "0.00000088",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 5,
        "newest": 75,
        "throughputHighToLow": 245,
        "latencyLowToHigh": 140,
        "pricingLowToHigh": 33,
        "pricingHighToLow": 148
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.3,
          "outputCost": 0.88,
          "throughput": 23.7255,
          "latency": 844
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 16000,
          "providerModelId": "deepseek/deepseek-v3-0324",
          "pricing": {
            "prompt": "0.00000033",
            "completion": "0.0000013",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.33,
          "outputCost": 1.3,
          "throughput": 21.672,
          "latency": 1172
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.00000033",
            "completion": "0.0000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.33,
          "outputCost": 1.4,
          "throughput": 17.787,
          "latency": 1094
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-v3-0324",
          "pricing": {
            "prompt": "0.00000034",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.34,
          "outputCost": 0.88,
          "throughput": 26.5515,
          "latency": 900.5
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek/deepseek-v3-0324/fp-8",
          "pricing": {
            "prompt": "0.00000045",
            "completion": "0.00000145",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.45,
          "outputCost": 1.45,
          "throughput": 11.4845,
          "latency": 1770
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 18.982,
          "latency": 920
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "parasail-deepseek-v3-0324",
          "pricing": {
            "prompt": "0.00000074",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.74,
          "outputCost": 1.5,
          "throughput": 28.772,
          "latency": 819
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 26.3375,
          "latency": 913
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/deepseek-v3-0324",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 64.2745,
          "latency": 745
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "seed"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 58.278,
          "latency": 823
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.00000125",
            "completion": "0.00000125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 1.25,
          "outputCost": 1.25,
          "throughput": 23.1435,
          "latency": 1822
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 12288,
          "providerModelId": "deepseek-ai/DeepSeek-V3",
          "pricing": {
            "prompt": "0.00000125",
            "completion": "0.00000125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.25,
          "outputCost": 1.25,
          "throughput": 24.258,
          "latency": 2662
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "DeepSeek-V3-0324",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.0000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 4.5,
          "throughput": 165.6035,
          "latency": 2393
        },
        {
          "name": "DeepSeek",
          "icon": "https://openrouter.ai/images/icons/DeepSeek.png",
          "slug": "deepSeek",
          "quantization": "fp8",
          "context": 64000,
          "maxCompletionTokens": 8192,
          "providerModelId": "deepseek-chat",
          "pricing": {
            "prompt": "0.00000027",
            "completion": "0.0000011",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000007",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.27,
          "outputCost": 1.1,
          "throughput": 19.446,
          "latency": 4568
        }
      ]
    },
    {
      "slug": "google/gemini-2.5-pro-exp-03-25",
      "hfSlug": "",
      "updatedAt": "2025-05-12T16:02:53.80897+00:00",
      "createdAt": "2025-03-25T17:01:39.919989+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 2.5 Pro Experimental",
      "shortName": "Gemini 2.5 Pro Experimental",
      "author": "google",
      "description": "Gemini 2.5 Pro is Google’s state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs “thinking” capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
      "modelVersionGroupId": null,
      "contextLength": 1048576,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "Update: Google has severly lowered rate limits on this model. Original: Due to extremely high demand, the [Gemini 2.5 Pro Experimental](/google/gemini-2.5-pro-exp-03-25) model is now strictly limited to **1 request per minute and 1000 requests per day** (including errors). Frequent `429` errors are expected. To maintain reliable performance, please switch to the [paid Gemini 2.5 Pro endpoint](/google/gemini-2.5-pro-preview-03-25). Your credits (such as the $10 minimum purchase) can be used directly on the paid endpoint without affecting your free-tier quotas.",
      "permaslug": "google/gemini-2.5-pro-exp-03-25",
      "reasoningConfig": null,
      "features": null,
      "endpoint": {
        "id": "e5b7a905-dd02-4f6e-b61b-3aa1a1b8b9c8",
        "name": "Google AI Studio | google/gemini-2.5-pro-exp-03-25",
        "contextLength": 1048576,
        "model": {
          "slug": "google/gemini-2.5-pro-exp-03-25",
          "hfSlug": "",
          "updatedAt": "2025-05-12T16:02:53.80897+00:00",
          "createdAt": "2025-03-25T17:01:39.919989+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 2.5 Pro Experimental",
          "shortName": "Gemini 2.5 Pro Experimental",
          "author": "google",
          "description": "Gemini 2.5 Pro is Google’s state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs “thinking” capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
          "modelVersionGroupId": null,
          "contextLength": 1048576,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "Update: Google has severly lowered rate limits on this model. Original: Due to extremely high demand, the [Gemini 2.5 Pro Experimental](/google/gemini-2.5-pro-exp-03-25) model is now strictly limited to **1 request per minute and 1000 requests per day** (including errors). Frequent `429` errors are expected. To maintain reliable performance, please switch to the [paid Gemini 2.5 Pro endpoint](/google/gemini-2.5-pro-preview-03-25). Your credits (such as the $10 minimum purchase) can be used directly on the paid endpoint without affecting your free-tier quotas.",
          "permaslug": "google/gemini-2.5-pro-exp-03-25",
          "reasoningConfig": null,
          "features": null
        },
        "modelVariantSlug": "google/gemini-2.5-pro-exp-03-25",
        "modelVariantPermaslug": "google/gemini-2.5-pro-exp-03-25",
        "providerName": "Google AI Studio",
        "providerInfo": {
          "name": "Google AI Studio",
          "displayName": "Google AI Studio",
          "slug": "google-ai-studio",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 55
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true,
              "retentionDays": 55
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google AI Studio",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleAIStudio.svg"
          }
        },
        "providerDisplayName": "Google AI Studio",
        "providerModelId": "gemini-2.5-pro-exp-03-25",
        "providerGroup": "Google AI Studio",
        "quantization": null,
        "variant": "standard",
        "isFree": true,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 65536,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "tools",
          "tool_choice",
          "stop",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "training": true,
          "retainsPrompts": true,
          "retentionDays": 55
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": 1,
        "limitRpd": 2000,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 7,
        "newest": 72,
        "throughputHighToLow": 308,
        "latencyLowToHigh": 315,
        "pricingLowToHigh": 31,
        "pricingHighToLow": 279
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Google AI Studio",
          "icon": "https://openrouter.ai/images/icons/GoogleAIStudio.svg",
          "slug": "google",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 65536,
          "providerModelId": "gemini-2.5-pro-exp-03-25",
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "tools",
            "tool_choice",
            "stop",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0,
          "outputCost": 0,
          "throughput": 178.311,
          "latency": 7343
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 65535,
          "providerModelId": "gemini-2.5-pro-exp-03-25",
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "tools",
            "tool_choice",
            "stop",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0,
          "outputCost": 0,
          "throughput": 500.498,
          "latency": 15910
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.3-70b-instruct",
      "hfSlug": "meta-llama/Llama-3.3-70B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-06T17:28:57.828422+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.3 70B Instruct",
      "shortName": "Llama 3.3 70B Instruct",
      "author": "meta-llama",
      "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n\nSupported languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n\n[Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)",
      "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
      "contextLength": 131000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.3-70b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f85e853d-675d-4025-a0e1-1a0798723540",
        "name": "Kluster | meta-llama/llama-3.3-70b-instruct",
        "contextLength": 131000,
        "model": {
          "slug": "meta-llama/llama-3.3-70b-instruct",
          "hfSlug": "meta-llama/Llama-3.3-70B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-06T17:28:57.828422+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.3 70B Instruct",
          "shortName": "Llama 3.3 70B Instruct",
          "author": "meta-llama",
          "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n\nSupported languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n\n[Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)",
          "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.3-70b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.3-70b-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3.3-70b-instruct",
        "providerName": "Kluster",
        "providerInfo": {
          "name": "Kluster",
          "displayName": "kluster.ai",
          "slug": "klusterai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.kluster.ai/terms-of-use",
            "privacyPolicyUrl": "https://www.kluster.ai/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Kluster",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256"
          }
        },
        "providerDisplayName": "kluster.ai",
        "providerModelId": "klusterai/Meta-Llama-3.3-70B-Instruct-Turbo",
        "providerGroup": "Kluster",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 131000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.kluster.ai/terms-of-use",
          "privacyPolicyUrl": "https://www.kluster.ai/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000007",
          "completion": "0.00000033",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 8,
        "newest": 157,
        "throughputHighToLow": 235,
        "latencyLowToHigh": 88,
        "pricingLowToHigh": 56,
        "pricingHighToLow": 211
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 131000,
          "maxCompletionTokens": 131000,
          "providerModelId": "klusterai/Meta-Llama-3.3-70B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000033",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.07,
          "outputCost": 0.33,
          "throughput": 33.086,
          "latency": 567.5
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.08,
          "outputCost": 0.25,
          "throughput": 34.006,
          "latency": 269
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.3-70b-instruct-fp8",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.12,
          "outputCost": 0.3,
          "throughput": 60.497,
          "latency": 517
        },
        {
          "name": "Phala",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://phala.network/&size=256",
          "slug": "phala",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "phala/llama-3.3-70b-instruct",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.00000035",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.12,
          "outputCost": 0.35,
          "throughput": 29.951,
          "latency": 741
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/llama-3.3-70b-instruct",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.00000039",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.13,
          "outputCost": 0.39,
          "throughput": 76.1375,
          "latency": 798
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.13,
          "outputCost": 0.4,
          "throughput": 38.655,
          "latency": 661
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-llama-33-70b-fp8",
          "pricing": {
            "prompt": "0.00000028",
            "completion": "0.00000078",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.28,
          "outputCost": 0.78,
          "throughput": 81.65,
          "latency": 548
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": "fp8",
          "context": 24000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
          "pricing": {
            "prompt": "0.00000029",
            "completion": "0.00000225",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.29,
          "outputCost": 2.25,
          "throughput": 35.862,
          "latency": 663
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct",
          "pricing": {
            "prompt": "0.00000035",
            "completion": "0.00000035",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.35,
          "outputCost": 0.35,
          "throughput": 69.9225,
          "latency": 740.5
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 36.3885,
          "latency": 1271
        },
        {
          "name": "Atoma",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://atoma.network/&size=256",
          "slug": "atoma",
          "quantization": "fp8",
          "context": 104962,
          "maxCompletionTokens": 100000,
          "providerModelId": "Infermatic/Llama-3.3-70B-Instruct-FP8-Dynamic",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 28.22,
          "latency": 937
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "llama-3.3-70b-versatile",
          "pricing": {
            "prompt": "0.00000059",
            "completion": "0.00000079",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.59,
          "outputCost": 0.79,
          "throughput": 342.9925,
          "latency": 460
        },
        {
          "name": "Friendli",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://friendli.ai/&size=256",
          "slug": "friendli",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "meta-llama-3.3-70b-instruct",
          "pricing": {
            "prompt": "0.0000006",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.6,
          "outputCost": 0.6,
          "throughput": 95.7715,
          "latency": 819
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "llama3.3:70b",
          "pricing": {
            "prompt": "0.0000006",
            "completion": "0.00000075",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.6,
          "outputCost": 0.75,
          "throughput": 32.632,
          "latency": 2378
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 3072,
          "providerModelId": "Meta-Llama-3.3-70B-Instruct",
          "pricing": {
            "prompt": "0.0000006",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.6,
          "outputCost": 1.2,
          "throughput": 308.397,
          "latency": 2227
        },
        {
          "name": "Cerebras",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cerebras.ai/&size=256",
          "slug": "cerebras",
          "quantization": "fp16",
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "llama-3.3-70b",
          "pricing": {
            "prompt": "0.00000085",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.85,
          "outputCost": 1.2,
          "throughput": 4600,
          "latency": 272
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 2048,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000088",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.88,
          "outputCost": 0.88,
          "throughput": 95.525,
          "latency": 556
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "fp16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama-v3p3-70b-instruct",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 109.5455,
          "latency": 3204.5
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.3-70b-instruct/fp-8",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.00000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.25,
          "throughput": 13.1625,
          "latency": 1625.5
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.7-sonnet",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-24T18:35:10.00008+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.7 Sonnet (thinking)",
      "shortName": "Claude 3.7 Sonnet (thinking)",
      "author": "anthropic",
      "description": "Claude 3.7 Sonnet is an advanced large language model with improved reasoning, coding, and problem-solving capabilities. It introduces a hybrid reasoning approach, allowing users to choose between rapid responses and extended, step-by-step processing for complex tasks. The model demonstrates notable improvements in coding, particularly in front-end development and full-stack updates, and excels in agentic workflows, where it can autonomously navigate multi-step processes. \n\nClaude 3.7 Sonnet maintains performance parity with its predecessor in standard mode while offering an extended reasoning mode for enhanced accuracy in math, coding, and instruction-following tasks.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-3-7-sonnet)",
      "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-7-sonnet-20250219",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "1c9b8776-e266-4efb-b5ba-19a6753e7736",
        "name": "Google | anthropic/claude-3-7-sonnet-20250219:thinking",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.7-sonnet",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-24T18:35:10.00008+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.7 Sonnet",
          "shortName": "Claude 3.7 Sonnet",
          "author": "anthropic",
          "description": "Claude 3.7 Sonnet is an advanced large language model with improved reasoning, coding, and problem-solving capabilities. It introduces a hybrid reasoning approach, allowing users to choose between rapid responses and extended, step-by-step processing for complex tasks. The model demonstrates notable improvements in coding, particularly in front-end development and full-stack updates, and excels in agentic workflows, where it can autonomously navigate multi-step processes. \n\nClaude 3.7 Sonnet maintains performance parity with its predecessor in standard mode while offering an extended reasoning mode for enhanced accuracy in math, coding, and instruction-following tasks.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-3-7-sonnet)",
          "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-7-sonnet-20250219",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.7-sonnet:thinking",
        "modelVariantPermaslug": "anthropic/claude-3-7-sonnet-20250219:thinking",
        "providerName": "Google",
        "providerInfo": {
          "name": "Google",
          "displayName": "Google Vertex",
          "slug": "google-vertex",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cloud.google.com/products/sdXM79fz1FS6ekNpu37K/history",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleVertex.svg"
          }
        },
        "providerDisplayName": "Google Vertex",
        "providerModelId": "claude-3-7-sonnet@20250219",
        "providerGroup": "Google",
        "quantization": null,
        "variant": "thinking",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 64000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "stop",
          "reasoning",
          "include_reasoning",
          "tools",
          "tool_choice"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0.0048",
          "request": "0",
          "inputCacheRead": "0.0000003",
          "inputCacheWrite": "0.00000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": 500,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 1,
        "newest": 108,
        "throughputHighToLow": 148,
        "latencyLowToHigh": 250,
        "pricingLowToHigh": 269,
        "pricingHighToLow": 41
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 64000,
          "providerModelId": "claude-3-7-sonnet@20250219",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 56.755,
          "latency": 1909
        },
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 128000,
          "providerModelId": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 35.942,
          "latency": 1916
        },
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 128000,
          "providerModelId": "claude-3-7-sonnet-20250219",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 58.0175,
          "latency": 1610
        },
        {
          "name": "Google Vertex (Europe)",
          "icon": "",
          "slug": "googleVertex (europe)",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 64000,
          "providerModelId": "claude-3-7-sonnet@20250219",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 50.2565,
          "latency": 2262
        }
      ]
    },
    {
      "slug": "google/gemini-flash-1.5-8b",
      "hfSlug": null,
      "updatedAt": "2025-04-04T21:52:07.548792+00:00",
      "createdAt": "2024-10-03T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 1.5 Flash 8B",
      "shortName": "Gemini 1.5 Flash 8B",
      "author": "google",
      "description": "Gemini Flash 1.5 8B is optimized for speed and efficiency, offering enhanced performance in small prompt tasks like chat, transcription, and translation. With reduced latency, it is highly effective for real-time and large-scale operations. This model focuses on cost-effective solutions while maintaining high-quality results.\n\n[Click here to learn more about this model](https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/).\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).",
      "modelVersionGroupId": "3a412ab9-b077-48de-884c-90843f7abbf2",
      "contextLength": 1000000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-flash-1.5-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "6f393253-cfcc-468e-a875-f5747a647953",
        "name": "Google AI Studio | google/gemini-flash-1.5-8b",
        "contextLength": 1000000,
        "model": {
          "slug": "google/gemini-flash-1.5-8b",
          "hfSlug": null,
          "updatedAt": "2025-04-04T21:52:07.548792+00:00",
          "createdAt": "2024-10-03T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 1.5 Flash 8B",
          "shortName": "Gemini 1.5 Flash 8B",
          "author": "google",
          "description": "Gemini Flash 1.5 8B is optimized for speed and efficiency, offering enhanced performance in small prompt tasks like chat, transcription, and translation. With reduced latency, it is highly effective for real-time and large-scale operations. This model focuses on cost-effective solutions while maintaining high-quality results.\n\n[Click here to learn more about this model](https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/).\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).",
          "modelVersionGroupId": "3a412ab9-b077-48de-884c-90843f7abbf2",
          "contextLength": 1000000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemini-flash-1.5-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemini-flash-1.5-8b",
        "modelVariantPermaslug": "google/gemini-flash-1.5-8b",
        "providerName": "Google AI Studio",
        "providerInfo": {
          "name": "Google AI Studio",
          "displayName": "Google AI Studio",
          "slug": "google-ai-studio",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 55
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true,
              "retentionDays": 55
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google AI Studio",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleAIStudio.svg"
          }
        },
        "providerDisplayName": "Google AI Studio",
        "providerModelId": "gemini-1.5-flash-8b-001",
        "providerGroup": "Google AI Studio",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "tools",
          "tool_choice",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 55
        },
        "pricing": {
          "prompt": "0.0000000375",
          "completion": "0.00000015",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.00000001",
          "inputCacheWrite": "0.0000000583",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "prompt-threshold",
            "threshold": 128000,
            "prompt": "0.000000075",
            "completions": "0.0000003",
            "inputCacheRead": "0.00000001",
            "inputCacheWrite": "0.0000000583"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 10,
        "newest": 193,
        "throughputHighToLow": 13,
        "latencyLowToHigh": 9,
        "pricingLowToHigh": 94,
        "pricingHighToLow": 225
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Google AI Studio",
          "icon": "https://openrouter.ai/images/icons/GoogleAIStudio.svg",
          "slug": "google",
          "quantization": "unknown",
          "context": 1000000,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemini-1.5-flash-8b-001",
          "pricing": {
            "prompt": "0.0000000375",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000001",
            "inputCacheWrite": "0.0000000583",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "tools",
            "tool_choice",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.04,
          "outputCost": 0.15,
          "throughput": 200.668,
          "latency": 211
        }
      ]
    },
    {
      "slug": "google/gemini-2.5-flash-preview",
      "hfSlug": "",
      "updatedAt": "2025-04-23T18:36:05.411237+00:00",
      "createdAt": "2025-04-17T18:31:07.815979+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 2.5 Flash Preview (thinking)",
      "shortName": "Gemini 2.5 Flash Preview (thinking)",
      "author": "google",
      "description": "Gemini 2.5 Flash is Google's state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks. It includes built-in \"thinking\" capabilities, enabling it to provide responses with greater accuracy and nuanced context handling. \n\nNote: This model is available in two variants: thinking and non-thinking. The output pricing varies significantly depending on whether the thinking capability is active. If you select the standard variant (without the \":thinking\" suffix), the model will explicitly avoid generating thinking tokens. \n\nTo utilize the thinking capability and receive thinking tokens, you must choose the \":thinking\" variant, which will then incur the higher thinking-output pricing. \n\nAdditionally, Gemini 2.5 Flash is configurable through the \"max tokens for reasoning\" parameter, as described in the documentation (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
      "modelVersionGroupId": null,
      "contextLength": 1048576,
      "inputModalities": [
        "image",
        "text",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-2.5-flash-preview-04-17",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "a5215739-cb87-49cb-adcb-c0c61c1e653e",
        "name": "Google | google/gemini-2.5-flash-preview-04-17:thinking",
        "contextLength": 1048576,
        "model": {
          "slug": "google/gemini-2.5-flash-preview",
          "hfSlug": "",
          "updatedAt": "2025-04-23T18:36:05.411237+00:00",
          "createdAt": "2025-04-17T18:31:07.815979+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 2.5 Flash Preview",
          "shortName": "Gemini 2.5 Flash Preview",
          "author": "google",
          "description": "Gemini 2.5 Flash is Google's state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks. It includes built-in \"thinking\" capabilities, enabling it to provide responses with greater accuracy and nuanced context handling. \n\nNote: This model is available in two variants: thinking and non-thinking. The output pricing varies significantly depending on whether the thinking capability is active. If you select the standard variant (without the \":thinking\" suffix), the model will explicitly avoid generating thinking tokens. \n\nTo utilize the thinking capability and receive thinking tokens, you must choose the \":thinking\" variant, which will then incur the higher thinking-output pricing. \n\nAdditionally, Gemini 2.5 Flash is configurable through the \"max tokens for reasoning\" parameter, as described in the documentation (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
          "modelVersionGroupId": null,
          "contextLength": 1048576,
          "inputModalities": [
            "image",
            "text",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemini-2.5-flash-preview-04-17",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemini-2.5-flash-preview:thinking",
        "modelVariantPermaslug": "google/gemini-2.5-flash-preview-04-17:thinking",
        "providerName": "Google",
        "providerInfo": {
          "name": "Google",
          "displayName": "Vertex Thinking",
          "slug": "google-vertex",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cloud.google.com/products/sdXM79fz1FS6ekNpu37K/history",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleVertex.svg"
          }
        },
        "providerDisplayName": "Vertex Thinking",
        "providerModelId": "gemini-2.5-flash-preview-04-17",
        "providerGroup": "Google",
        "quantization": null,
        "variant": "thinking",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 65535,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "tools",
          "tool_choice",
          "stop",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000035",
          "image": "0.0006192",
          "request": "0",
          "inputCacheRead": "0.0000000375",
          "inputCacheWrite": "0.0000002333",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {
            "responseFormat": true,
            "structuredOutputs": true
          },
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 3,
        "newest": 41,
        "throughputHighToLow": 52,
        "latencyLowToHigh": 92,
        "pricingLowToHigh": 141,
        "pricingHighToLow": 144
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Vertex Non-Thinking",
          "icon": "",
          "slug": "vertexNonThinking",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 65535,
          "providerModelId": "gemini-2.5-flash-preview-04-17",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0.0006192",
            "request": "0",
            "inputCacheRead": "0.0000000375",
            "inputCacheWrite": "0.0000002333",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "tools",
            "tool_choice",
            "stop",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 100.181,
          "latency": 587
        },
        {
          "name": "AI Studio Non-Thinking",
          "icon": "",
          "slug": "aiStudioNonThinking",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 65535,
          "providerModelId": "gemini-2.5-flash-preview-04-17",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0.0006192",
            "request": "0",
            "inputCacheRead": "0.0000000375",
            "inputCacheWrite": "0.0000002333",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "tools",
            "tool_choice",
            "stop",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 126.0255,
          "latency": 610
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1",
      "hfSlug": "deepseek-ai/DeepSeek-R1",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-20T13:51:35.96912+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1 (free)",
      "shortName": "R1 (free)",
      "author": "deepseek",
      "description": "DeepSeek R1 is here: Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens. It's 671B parameters in size, with 37B active in an inference pass.\n\nFully open-source model & [technical report](https://api-docs.deepseek.com/news/news250120).\n\nMIT licensed: Distill & commercialize freely!",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-r1",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "bbcacac4-e58a-4c88-b54b-ffc69b5b64cc",
        "name": "Chutes | deepseek/deepseek-r1:free",
        "contextLength": 163840,
        "model": {
          "slug": "deepseek/deepseek-r1",
          "hfSlug": "deepseek-ai/DeepSeek-R1",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-20T13:51:35.96912+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1",
          "shortName": "R1",
          "author": "deepseek",
          "description": "DeepSeek R1 is here: Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens. It's 671B parameters in size, with 37B active in an inference pass.\n\nFully open-source model & [technical report](https://api-docs.deepseek.com/news/news250120).\n\nMIT licensed: Distill & commercialize freely!",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 163840,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-r1",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1:free",
        "modelVariantPermaslug": "deepseek/deepseek-r1:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "deepseek-ai/DeepSeek-R1",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "reasoning",
          "include_reasoning",
          "temperature"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 12,
        "newest": 143,
        "throughputHighToLow": 171,
        "latencyLowToHigh": 111,
        "pricingLowToHigh": 53,
        "pricingHighToLow": 124
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.00000218",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.5,
          "outputCost": 2.18,
          "throughput": 42.5465,
          "latency": 775
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek/deepseek-r1/fp-8",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.5,
          "outputCost": 3,
          "throughput": 19.959,
          "latency": 1269
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-r1-671b",
          "pricing": {
            "prompt": "0.00000054",
            "completion": "0.00000218",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.54,
          "outputCost": 2.18,
          "throughput": 37.487,
          "latency": 981
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 16000,
          "providerModelId": "deepseek/deepseek-r1-turbo",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.7,
          "outputCost": 2.5,
          "throughput": 28.936,
          "latency": 1273.5
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.8,
          "outputCost": 2.4,
          "throughput": 26.6925,
          "latency": 790
        },
        {
          "name": "DeepInfra Turbo",
          "icon": "",
          "slug": "deepInfraTurbo",
          "quantization": "fp4",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Turbo",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 1,
          "outputCost": 3,
          "throughput": 109.355,
          "latency": 524
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.00000175",
            "completion": "0.000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 1.75,
          "outputCost": 5,
          "throughput": 29.294,
          "latency": 952
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-deepseek-r1",
          "pricing": {
            "prompt": "0.00000195",
            "completion": "0.000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 1.95,
          "outputCost": 5,
          "throughput": 52.051,
          "latency": 557
        },
        {
          "name": "Nebius Fast",
          "icon": "",
          "slug": "nebiusFast",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-R1-fast",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 2,
          "outputCost": 6,
          "throughput": 53.4185,
          "latency": 815
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.00000299",
            "completion": "0.00000299",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 2.99,
          "outputCost": 2.99,
          "throughput": 60.47,
          "latency": 895
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 3,
          "outputCost": 7,
          "throughput": 49.2495,
          "latency": 1261.5
        },
        {
          "name": "Friendli",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://friendli.ai/&size=256",
          "slug": "friendli",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-r1",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 3,
          "outputCost": 7,
          "throughput": 59.7745,
          "latency": 927
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/deepseek-r1",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 3,
          "outputCost": 8,
          "throughput": 44.5635,
          "latency": 740
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "DeepSeek-R1",
          "pricing": {
            "prompt": "0.000005",
            "completion": "0.000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "stop"
          ],
          "inputCost": 5,
          "outputCost": 7,
          "throughput": 114.5795,
          "latency": 2449
        },
        {
          "name": "Minimax",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://minimaxi.com/&size=256",
          "slug": "minimax",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 64000,
          "providerModelId": "DeepSeek-R1",
          "pricing": {
            "prompt": "0.00000055",
            "completion": "0.00000219",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning"
          ],
          "inputCost": 0.55,
          "outputCost": 2.19,
          "throughput": 21.5065,
          "latency": 2109
        },
        {
          "name": "DeepSeek",
          "icon": "https://openrouter.ai/images/icons/DeepSeek.png",
          "slug": "deepSeek",
          "quantization": "fp8",
          "context": 64000,
          "maxCompletionTokens": 8000,
          "providerModelId": "deepseek-reasoner",
          "pricing": {
            "prompt": "0.00000055",
            "completion": "0.00000219",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "reasoning",
            "include_reasoning"
          ],
          "inputCost": 0.55,
          "outputCost": 2.19,
          "throughput": 21.513,
          "latency": 4052
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": null,
          "context": 163840,
          "maxCompletionTokens": 4096,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.000001485",
            "completion": "0.00000594",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning"
          ],
          "inputCost": 1.48,
          "outputCost": 5.94,
          "throughput": 78.0455,
          "latency": 1786
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 4096,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.0000065",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 6.5,
          "outputCost": 8,
          "throughput": 13.743,
          "latency": 2659
        }
      ]
    },
    {
      "slug": "openai/gpt-4.1",
      "hfSlug": "",
      "updatedAt": "2025-05-12T18:09:29.635063+00:00",
      "createdAt": "2025-04-14T17:23:05+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4.1",
      "shortName": "GPT-4.1",
      "author": "openai",
      "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
      "modelVersionGroupId": null,
      "contextLength": 1047576,
      "inputModalities": [
        "image",
        "text",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4.1-2025-04-14",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c235abe8-11cc-42d3-95ad-72f4d198287a",
        "name": "OpenAI | openai/gpt-4.1-2025-04-14",
        "contextLength": 1047576,
        "model": {
          "slug": "openai/gpt-4.1",
          "hfSlug": "",
          "updatedAt": "2025-05-12T18:09:29.635063+00:00",
          "createdAt": "2025-04-14T17:23:05+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4.1",
          "shortName": "GPT-4.1",
          "author": "openai",
          "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
          "modelVersionGroupId": null,
          "contextLength": 1047576,
          "inputModalities": [
            "image",
            "text",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4.1-2025-04-14",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4.1",
        "modelVariantPermaslug": "openai/gpt-4.1-2025-04-14",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4.1-2025-04-14",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "web_search_options",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000008",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.0000005",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.05"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.035"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.03"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 13,
        "newest": 48,
        "throughputHighToLow": 119,
        "latencyLowToHigh": 104,
        "pricingLowToHigh": 247,
        "pricingHighToLow": 67
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 1047576,
          "maxCompletionTokens": 32768,
          "providerModelId": "gpt-4.1-2025-04-14",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.0000005",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2,
          "outputCost": 8,
          "throughput": 64.5015,
          "latency": 675
        }
      ]
    },
    {
      "slug": "google/gemini-2.0-flash-exp",
      "hfSlug": "",
      "updatedAt": "2025-04-04T21:51:57.421583+00:00",
      "createdAt": "2024-12-11T17:18:43.999311+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 2.0 Flash Experimental (free)",
      "shortName": "Gemini 2.0 Flash Experimental (free)",
      "author": "google",
      "description": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5). It introduces notable enhancements in multimodal understanding, coding capabilities, complex instruction following, and function calling. These advancements come together to deliver more seamless and robust agentic experiences.",
      "modelVersionGroupId": "e993dfbf-2cbd-4680-b866-c05bbdcc8f4d",
      "contextLength": 1048576,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-2.0-flash-exp",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "65df650a-3eae-46b0-b5b0-87546ca90cc3",
        "name": "Google | google/gemini-2.0-flash-exp:free",
        "contextLength": 1048576,
        "model": {
          "slug": "google/gemini-2.0-flash-exp",
          "hfSlug": "",
          "updatedAt": "2025-04-04T21:51:57.421583+00:00",
          "createdAt": "2024-12-11T17:18:43.999311+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 2.0 Flash Experimental",
          "shortName": "Gemini 2.0 Flash Experimental",
          "author": "google",
          "description": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5). It introduces notable enhancements in multimodal understanding, coding capabilities, complex instruction following, and function calling. These advancements come together to deliver more seamless and robust agentic experiences.",
          "modelVersionGroupId": "e993dfbf-2cbd-4680-b866-c05bbdcc8f4d",
          "contextLength": 1048576,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemini-2.0-flash-exp",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemini-2.0-flash-exp:free",
        "modelVariantPermaslug": "google/gemini-2.0-flash-exp:free",
        "providerName": "Google",
        "providerInfo": {
          "name": "Google",
          "displayName": "Google Vertex",
          "slug": "google-vertex",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cloud.google.com/products/sdXM79fz1FS6ekNpu37K/history",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleVertex.svg"
          }
        },
        "providerDisplayName": "Google Vertex",
        "providerModelId": "gemini-2.0-flash-exp",
        "providerGroup": "Google",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 14,
        "newest": 156,
        "throughputHighToLow": 15,
        "latencyLowToHigh": 162,
        "pricingLowToHigh": 55,
        "pricingHighToLow": 303
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "mistralai/mistral-nemo",
      "hfSlug": "mistralai/Mistral-Nemo-Instruct-2407",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-19T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral Nemo",
      "shortName": "Mistral Nemo",
      "author": "mistralai",
      "description": "A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.\n\nThe model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.\n\nIt supports function calling and is released under the Apache 2.0 license.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-nemo",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cf12e7bb-214e-4054-967f-d55aafda8a6f",
        "name": "Kluster | mistralai/mistral-nemo",
        "contextLength": 131072,
        "model": {
          "slug": "mistralai/mistral-nemo",
          "hfSlug": "mistralai/Mistral-Nemo-Instruct-2407",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-07-19T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral Nemo",
          "shortName": "Mistral Nemo",
          "author": "mistralai",
          "description": "A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.\n\nThe model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.\n\nIt supports function calling and is released under the Apache 2.0 license.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-nemo",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-nemo",
        "modelVariantPermaslug": "mistralai/mistral-nemo",
        "providerName": "Kluster",
        "providerInfo": {
          "name": "Kluster",
          "displayName": "kluster.ai",
          "slug": "klusterai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.kluster.ai/terms-of-use",
            "privacyPolicyUrl": "https://www.kluster.ai/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Kluster",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256"
          }
        },
        "providerDisplayName": "kluster.ai",
        "providerModelId": "mistralai/Mistral-Nemo-Instruct-2407",
        "providerGroup": "Kluster",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 131072,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.kluster.ai/terms-of-use",
          "privacyPolicyUrl": "https://www.kluster.ai/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000000025",
          "completion": "0.00000007",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 15,
        "newest": 234,
        "throughputHighToLow": 57,
        "latencyLowToHigh": 61,
        "pricingLowToHigh": 68,
        "pricingHighToLow": 236
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "mistralai/Mistral-Nemo-Instruct-2407",
          "pricing": {
            "prompt": "0.000000025",
            "completion": "0.00000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.02,
          "outputCost": 0.07,
          "throughput": 120.843,
          "latency": 474
        },
        {
          "name": "Enfer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256",
          "slug": "enfer",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 65536,
          "providerModelId": "mistralai/mistral-nemo",
          "pricing": {
            "prompt": "0.00000003",
            "completion": "0.00000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logit_bias",
            "logprobs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.07,
          "throughput": 54.5395,
          "latency": 6404
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "mistral:nemo",
          "pricing": {
            "prompt": "0.000000033",
            "completion": "0.00000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.07,
          "throughput": 51.5295,
          "latency": 1619.5
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/Mistral-Nemo-Instruct-2407",
          "pricing": {
            "prompt": "0.000000035",
            "completion": "0.00000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.04,
          "outputCost": 0.08,
          "throughput": 55.309,
          "latency": 452
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/mistral-nemo-12b-instruct/fp-8",
          "pricing": {
            "prompt": "0.0000000375",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.04,
          "outputCost": 0.1,
          "throughput": 60.969,
          "latency": 1218
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/Mistral-Nemo-Instruct-2407",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.04,
          "outputCost": 0.12,
          "throughput": 34.442,
          "latency": 675
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/mistral-nemo",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000017",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.04,
          "outputCost": 0.17,
          "throughput": 36.7265,
          "latency": 1356
        },
        {
          "name": "Atoma",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://atoma.network/&size=256",
          "slug": "atoma",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 80000,
          "providerModelId": "mistralai/Mistral-Nemo-Instruct-2407",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 51.7,
          "latency": 641
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-mistral-nemo",
          "pricing": {
            "prompt": "0.00000011",
            "completion": "0.00000011",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.11,
          "outputCost": 0.11,
          "throughput": 144.2685,
          "latency": 509
        },
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "open-mistral-nemo-2407",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.15,
          "outputCost": 0.15,
          "throughput": 143.459,
          "latency": 212
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-nemo",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "response_format",
            "stop",
            "seed"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 98.2295,
          "latency": 1152
        }
      ]
    },
    {
      "slug": "openai/gpt-4.1-mini",
      "hfSlug": "",
      "updatedAt": "2025-05-12T18:45:53.698316+00:00",
      "createdAt": "2025-04-14T17:23:01+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4.1 Mini",
      "shortName": "GPT-4.1 Mini",
      "author": "openai",
      "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aider’s polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
      "modelVersionGroupId": null,
      "contextLength": 1047576,
      "inputModalities": [
        "image",
        "text",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4.1-mini-2025-04-14",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "872eccb7-9c85-45fc-974a-ff7c8e2407e6",
        "name": "OpenAI | openai/gpt-4.1-mini-2025-04-14",
        "contextLength": 1047576,
        "model": {
          "slug": "openai/gpt-4.1-mini",
          "hfSlug": "",
          "updatedAt": "2025-05-12T18:45:53.698316+00:00",
          "createdAt": "2025-04-14T17:23:01+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4.1 Mini",
          "shortName": "GPT-4.1 Mini",
          "author": "openai",
          "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aider’s polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
          "modelVersionGroupId": null,
          "contextLength": 1047576,
          "inputModalities": [
            "image",
            "text",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4.1-mini-2025-04-14",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4.1-mini",
        "modelVariantPermaslug": "openai/gpt-4.1-mini-2025-04-14",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4.1-mini-2025-04-14",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "web_search_options",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000004",
          "completion": "0.0000016",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.0000001",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.03"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.0275"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.025"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 16,
        "newest": 49,
        "throughputHighToLow": 122,
        "latencyLowToHigh": 116,
        "pricingLowToHigh": 180,
        "pricingHighToLow": 138
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 1047576,
          "maxCompletionTokens": 32768,
          "providerModelId": "gpt-4.1-mini-2025-04-14",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000016",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.0000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.4,
          "outputCost": 1.6,
          "throughput": 64.505,
          "latency": 714
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.7-sonnet",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-24T18:35:10.00008+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.7 Sonnet (self-moderated)",
      "shortName": "Claude 3.7 Sonnet (self-moderated)",
      "author": "anthropic",
      "description": "Claude 3.7 Sonnet is an advanced large language model with improved reasoning, coding, and problem-solving capabilities. It introduces a hybrid reasoning approach, allowing users to choose between rapid responses and extended, step-by-step processing for complex tasks. The model demonstrates notable improvements in coding, particularly in front-end development and full-stack updates, and excels in agentic workflows, where it can autonomously navigate multi-step processes. \n\nClaude 3.7 Sonnet maintains performance parity with its predecessor in standard mode while offering an extended reasoning mode for enhanced accuracy in math, coding, and instruction-following tasks.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-3-7-sonnet)",
      "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-7-sonnet-20250219",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9770425a-9db8-46be-87fa-d66ad537aafc",
        "name": "Anthropic | anthropic/claude-3-7-sonnet-20250219:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.7-sonnet",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-24T18:35:10.00008+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.7 Sonnet",
          "shortName": "Claude 3.7 Sonnet",
          "author": "anthropic",
          "description": "Claude 3.7 Sonnet is an advanced large language model with improved reasoning, coding, and problem-solving capabilities. It introduces a hybrid reasoning approach, allowing users to choose between rapid responses and extended, step-by-step processing for complex tasks. The model demonstrates notable improvements in coding, particularly in front-end development and full-stack updates, and excels in agentic workflows, where it can autonomously navigate multi-step processes. \n\nClaude 3.7 Sonnet maintains performance parity with its predecessor in standard mode while offering an extended reasoning mode for enhanced accuracy in math, coding, and instruction-following tasks.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-3-7-sonnet)",
          "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-7-sonnet-20250219",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.7-sonnet:beta",
        "modelVariantPermaslug": "anthropic/claude-3-7-sonnet-20250219:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-7-sonnet-20250219",
        "providerGroup": "Anthropic",
        "quantization": null,
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 128000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "stop",
          "reasoning",
          "include_reasoning",
          "tools",
          "tool_choice"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0.0048",
          "request": "0",
          "inputCacheRead": "0.0000003",
          "inputCacheWrite": "0.00000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": true,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 1,
        "newest": 108,
        "throughputHighToLow": 148,
        "latencyLowToHigh": 250,
        "pricingLowToHigh": 269,
        "pricingHighToLow": 41
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 64000,
          "providerModelId": "claude-3-7-sonnet@20250219",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 56.755,
          "latency": 1909
        },
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 128000,
          "providerModelId": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 35.942,
          "latency": 1916
        },
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 128000,
          "providerModelId": "claude-3-7-sonnet-20250219",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 58.0175,
          "latency": 1610
        },
        {
          "name": "Google Vertex (Europe)",
          "icon": "",
          "slug": "googleVertex (europe)",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 64000,
          "providerModelId": "claude-3-7-sonnet@20250219",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "stop",
            "tools",
            "tool_choice"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 50.2565,
          "latency": 2262
        }
      ]
    },
    {
      "slug": "google/gemini-2.0-flash-lite-001",
      "hfSlug": "",
      "updatedAt": "2025-04-23T18:40:44.113639+00:00",
      "createdAt": "2025-02-25T17:56:52.206054+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 2.0 Flash Lite",
      "shortName": "Gemini 2.0 Flash Lite",
      "author": "google",
      "description": "Gemini 2.0 Flash Lite offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5), all at extremely economical token prices.",
      "modelVersionGroupId": "e993dfbf-2cbd-4680-b866-c05bbdcc8f4d",
      "contextLength": 1048576,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-2.0-flash-lite-001",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cae2e26e-549c-494f-b613-99783f016f8b",
        "name": "Google AI Studio | google/gemini-2.0-flash-lite-001",
        "contextLength": 1048576,
        "model": {
          "slug": "google/gemini-2.0-flash-lite-001",
          "hfSlug": "",
          "updatedAt": "2025-04-23T18:40:44.113639+00:00",
          "createdAt": "2025-02-25T17:56:52.206054+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 2.0 Flash Lite",
          "shortName": "Gemini 2.0 Flash Lite",
          "author": "google",
          "description": "Gemini 2.0 Flash Lite offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5), all at extremely economical token prices.",
          "modelVersionGroupId": "e993dfbf-2cbd-4680-b866-c05bbdcc8f4d",
          "contextLength": 1048576,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemini-2.0-flash-lite-001",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemini-2.0-flash-lite-001",
        "modelVariantPermaslug": "google/gemini-2.0-flash-lite-001",
        "providerName": "Google AI Studio",
        "providerInfo": {
          "name": "Google AI Studio",
          "displayName": "Google AI Studio",
          "slug": "google-ai-studio",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 55
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true,
              "retentionDays": 55
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google AI Studio",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleAIStudio.svg"
          }
        },
        "providerDisplayName": "Google AI Studio",
        "providerModelId": "gemini-2.0-flash-lite-001",
        "providerGroup": "Google AI Studio",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": 1048576,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 55
        },
        "pricing": {
          "prompt": "0.000000075",
          "completion": "0.0000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 18,
        "newest": 107,
        "throughputHighToLow": 30,
        "latencyLowToHigh": 59,
        "pricingLowToHigh": 111,
        "pricingHighToLow": 207
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Google AI Studio",
          "icon": "https://openrouter.ai/images/icons/GoogleAIStudio.svg",
          "slug": "google",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemini-2.0-flash-lite-001",
          "pricing": {
            "prompt": "0.000000075",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.07,
          "outputCost": 0.3,
          "throughput": 159.2635,
          "latency": 443
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemini-2.0-flash-lite-001",
          "pricing": {
            "prompt": "0.000000075",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.07,
          "outputCost": 0.3,
          "throughput": 185.209,
          "latency": 1104.5
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.5-sonnet",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.5 Sonnet",
      "shortName": "Claude 3.5 Sonnet",
      "author": "anthropic",
      "description": "New Claude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Scores ~49% on SWE-Bench Verified, higher than the last best score, and without any fancy prompt scaffolding\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\n#multimodal",
      "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3.5-sonnet",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "07be01e7-3f6a-4b0f-854b-103b7b0a7ad5",
        "name": "Anthropic | anthropic/claude-3.5-sonnet",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.5-sonnet",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.5 Sonnet",
          "shortName": "Claude 3.5 Sonnet",
          "author": "anthropic",
          "description": "New Claude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Scores ~49% on SWE-Bench Verified, higher than the last best score, and without any fancy prompt scaffolding\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\n#multimodal",
          "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3.5-sonnet",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.5-sonnet",
        "modelVariantPermaslug": "anthropic/claude-3.5-sonnet",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-5-sonnet-20241022",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0.0048",
          "request": "0",
          "inputCacheRead": "0.0000003",
          "inputCacheWrite": "0.00000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 19,
        "newest": 183,
        "throughputHighToLow": 137,
        "latencyLowToHigh": 210,
        "pricingLowToHigh": 272,
        "pricingHighToLow": 44
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet-20241022",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 57.817,
          "latency": 1363
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet-v2@20241022",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 60.7715,
          "latency": 1380.5
        },
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 35.699,
          "latency": 1793.5
        },
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 37.745,
          "latency": 1627
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet-v2@20241022",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 60.0465,
          "latency": 1024
        }
      ]
    },
    {
      "slug": "google/gemini-flash-1.5",
      "hfSlug": null,
      "updatedAt": "2025-04-12T05:00:52.517115+00:00",
      "createdAt": "2024-05-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 1.5 Flash ",
      "shortName": "Gemini 1.5 Flash ",
      "author": "google",
      "description": "Gemini 1.5 Flash is a foundation model that performs well at a variety of multimodal tasks such as visual understanding, classification, summarization, and creating content from image, audio and video. It's adept at processing visual and text inputs such as photographs, documents, infographics, and screenshots.\n\nGemini 1.5 Flash is designed for high-volume, high-frequency tasks where cost and latency matter. On most common tasks, Flash achieves comparable quality to other Gemini Pro models at a significantly reduced cost. Flash is well-suited for applications like chat assistants and on-demand content generation where speed and scale matter.\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n#multimodal",
      "modelVersionGroupId": "86ec374b-de4b-4920-a960-94f25078e303",
      "contextLength": 1000000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "google/gemini-flash-1.5",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b2282ba2-7373-46c2-af2b-e37ceeb54687",
        "name": "Google | google/gemini-flash-1.5",
        "contextLength": 1000000,
        "model": {
          "slug": "google/gemini-flash-1.5",
          "hfSlug": null,
          "updatedAt": "2025-04-12T05:00:52.517115+00:00",
          "createdAt": "2024-05-14T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 1.5 Flash ",
          "shortName": "Gemini 1.5 Flash ",
          "author": "google",
          "description": "Gemini 1.5 Flash is a foundation model that performs well at a variety of multimodal tasks such as visual understanding, classification, summarization, and creating content from image, audio and video. It's adept at processing visual and text inputs such as photographs, documents, infographics, and screenshots.\n\nGemini 1.5 Flash is designed for high-volume, high-frequency tasks where cost and latency matter. On most common tasks, Flash achieves comparable quality to other Gemini Pro models at a significantly reduced cost. Flash is well-suited for applications like chat assistants and on-demand content generation where speed and scale matter.\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n#multimodal",
          "modelVersionGroupId": "86ec374b-de4b-4920-a960-94f25078e303",
          "contextLength": 1000000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "google/gemini-flash-1.5",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemini-flash-1.5",
        "modelVariantPermaslug": "google/gemini-flash-1.5",
        "providerName": "Google",
        "providerInfo": {
          "name": "Google",
          "displayName": "Google Vertex",
          "slug": "google-vertex",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cloud.google.com/products/sdXM79fz1FS6ekNpu37K/history",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleVertex.svg"
          }
        },
        "providerDisplayName": "Google Vertex",
        "providerModelId": "gemini-1.5-flash-002",
        "providerGroup": "Google",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "tools",
          "tool_choice",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000000075",
          "completion": "0.0000003",
          "image": "0.00004",
          "request": "0",
          "inputCacheRead": "0.00000001875",
          "inputCacheWrite": "0.0000001583",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "prompt-threshold",
            "threshold": 128000,
            "prompt": "0.00000015",
            "completions": "0.0000006",
            "inputCacheRead": "0.00000001875",
            "inputCacheWrite": "0.0000001583"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 20,
        "newest": 257,
        "throughputHighToLow": 37,
        "latencyLowToHigh": 37,
        "pricingLowToHigh": 112,
        "pricingHighToLow": 208
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 1000000,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemini-1.5-flash-002",
          "pricing": {
            "prompt": "0.000000075",
            "completion": "0.0000003",
            "image": "0.00004",
            "request": "0",
            "inputCacheRead": "0.00000001875",
            "inputCacheWrite": "0.0000001583",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "tools",
            "tool_choice",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.07,
          "outputCost": 0.3,
          "throughput": 148.555,
          "latency": 355
        },
        {
          "name": "Google AI Studio",
          "icon": "https://openrouter.ai/images/icons/GoogleAIStudio.svg",
          "slug": "google",
          "quantization": "unknown",
          "context": 1000000,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemini-1.5-flash-002",
          "pricing": {
            "prompt": "0.000000075",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000001875",
            "inputCacheWrite": "0.0000001583",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "tools",
            "tool_choice",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.07,
          "outputCost": 0.3,
          "throughput": 150.644,
          "latency": 400.5
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1-distill-llama-70b",
      "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-23T20:12:49.780212+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1 Distill Llama 70B",
      "shortName": "R1 Distill Llama 70B",
      "author": "deepseek",
      "description": "DeepSeek R1 Distill Llama 70B is a distilled large language model based on [Llama-3.3-70B-Instruct](/meta-llama/llama-3.3-70b-instruct), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). The model combines advanced distillation techniques to achieve high performance across multiple benchmarks, including:\n\n- AIME 2024 pass@1: 70.0\n- MATH-500 pass@1: 94.5\n- CodeForces Rating: 1633\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-r1-distill-llama-70b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "281e8d8c-3d82-436d-b61e-6ed75158513c",
        "name": "DeepInfra | deepseek/deepseek-r1-distill-llama-70b",
        "contextLength": 131072,
        "model": {
          "slug": "deepseek/deepseek-r1-distill-llama-70b",
          "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-23T20:12:49.780212+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1 Distill Llama 70B",
          "shortName": "R1 Distill Llama 70B",
          "author": "deepseek",
          "description": "DeepSeek R1 Distill Llama 70B is a distilled large language model based on [Llama-3.3-70B-Instruct](/meta-llama/llama-3.3-70b-instruct), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). The model combines advanced distillation techniques to achieve high performance across multiple benchmarks, including:\n\n- AIME 2024 pass@1: 70.0\n- MATH-500 pass@1: 94.5\n- CodeForces Rating: 1633\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-r1-distill-llama-70b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1-distill-llama-70b",
        "modelVariantPermaslug": "deepseek/deepseek-r1-distill-llama-70b",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000004",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 21,
        "newest": 141,
        "throughputHighToLow": 162,
        "latencyLowToHigh": 39,
        "pricingLowToHigh": 52,
        "pricingHighToLow": 191
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.4,
          "throughput": 36.4015,
          "latency": 342.5
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "deepseek/r1-distill-llama-70b/fp-8",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.4,
          "throughput": 37.936,
          "latency": 754
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "deepseek-llama3.3-70b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 67.8005,
          "latency": 446
        },
        {
          "name": "Phala",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://phala.network/&size=256",
          "slug": "phala",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "phala/deepseek-r1-70b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.7,
          "throughput": 36.602,
          "latency": 608
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000075",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.25,
          "outputCost": 0.75,
          "throughput": 59.607,
          "latency": 485
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 4096,
          "providerModelId": "DeepSeek-R1-Distill-Llama-70B",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "stop"
          ],
          "inputCost": 0.7,
          "outputCost": 1.4,
          "throughput": 232.642,
          "latency": 2059
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "deepseek-r1-distill-llama-70b",
          "pricing": {
            "prompt": "0.00000075",
            "completion": "0.00000099",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.75,
          "outputCost": 0.99,
          "throughput": 293.08,
          "latency": 880
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "deepseek/deepseek-r1-distill-llama-70b",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 71.414,
          "latency": 891
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 2,
          "outputCost": 2,
          "throughput": 101.26,
          "latency": 690.5
        },
        {
          "name": "Cerebras",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cerebras.ai/&size=256",
          "slug": "cerebras",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "deepseek-r1-distill-llama-70b",
          "pricing": {
            "prompt": "0.0000022",
            "completion": "0.0000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "structured_outputs",
            "response_format",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 2.2,
          "outputCost": 2.5,
          "throughput": 1983.8895,
          "latency": 892
        }
      ]
    },
    {
      "slug": "qwen/qwen-2.5-7b-instruct",
      "hfSlug": "Qwen/Qwen2.5-7B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen2.5 7B Instruct",
      "shortName": "Qwen2.5 7B Instruct",
      "author": "qwen",
      "description": "Qwen2.5 7B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2.5-7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7b70cad4-5c0f-4bfc-8317-17e03eb17c8b",
        "name": "NextBit | qwen/qwen-2.5-7b-instruct",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen-2.5-7b-instruct",
          "hfSlug": "Qwen/Qwen2.5-7B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-16T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen2.5 7B Instruct",
          "shortName": "Qwen2.5 7B Instruct",
          "author": "qwen",
          "description": "Qwen2.5 7B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-2.5-7b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-2.5-7b-instruct",
        "modelVariantPermaslug": "qwen/qwen-2.5-7b-instruct",
        "providerName": "NextBit",
        "providerInfo": {
          "name": "NextBit",
          "displayName": "NextBit",
          "slug": "nextbit",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.nextbit256.com/docs/terms-of-service",
            "privacyPolicyUrl": "https://www.nextbit256.com/docs/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "NextBit",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256"
          }
        },
        "providerDisplayName": "NextBit",
        "providerModelId": "qwen:2-5-7b",
        "providerGroup": "NextBit",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.nextbit256.com/docs/terms-of-service",
          "privacyPolicyUrl": "https://www.nextbit256.com/docs/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000004",
          "completion": "0.0000001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 22,
        "newest": 188,
        "throughputHighToLow": 5,
        "latencyLowToHigh": 89,
        "pricingLowToHigh": 60,
        "pricingHighToLow": 227
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "qwen:2-5-7b",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.04,
          "outputCost": 0.1,
          "throughput": 5.301,
          "latency": 1961
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "Qwen/Qwen2.5-7B-Instruct",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.05,
          "outputCost": 0.1,
          "throughput": 53.032,
          "latency": 240
        },
        {
          "name": "nCompass",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://console.ncompass.tech/&size=256",
          "slug": "nCompass",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "Qwen/Qwen2.5-7B-Instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 145.933,
          "latency": 113
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "Qwen/Qwen2.5-7B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 179.5095,
          "latency": 201
        }
      ]
    },
    {
      "slug": "meta-llama/llama-4-maverick",
      "hfSlug": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "updatedAt": "2025-04-05T19:58:55.362967+00:00",
      "createdAt": "2025-04-05T19:37:02.129674+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 4 Maverick",
      "shortName": "Llama 4 Maverick",
      "author": "meta-llama",
      "description": "Llama 4 Maverick 17B Instruct (128E) is a high-capacity multimodal language model from Meta, built on a mixture-of-experts (MoE) architecture with 128 experts and 17 billion active parameters per forward pass (400B total). It supports multilingual text and image input, and produces multilingual text and code output across 12 supported languages. Optimized for vision-language tasks, Maverick is instruction-tuned for assistant-like behavior, image reasoning, and general-purpose multimodal interaction.\n\nMaverick features early fusion for native multimodality and a 1 million token context window. It was trained on a curated mixture of public, licensed, and Meta-platform data, covering ~22 trillion tokens, with a knowledge cutoff in August 2024. Released on April 5, 2025 under the Llama 4 Community License, Maverick is suited for research and commercial applications requiring advanced multimodal understanding and high model throughput.",
      "modelVersionGroupId": null,
      "contextLength": 1048576,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-4-maverick-17b-128e-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "69a5d06e-1935-4aa5-903f-71058e64399f",
        "name": "DeepInfra | meta-llama/llama-4-maverick-17b-128e-instruct",
        "contextLength": 1048576,
        "model": {
          "slug": "meta-llama/llama-4-maverick",
          "hfSlug": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
          "updatedAt": "2025-04-05T19:58:55.362967+00:00",
          "createdAt": "2025-04-05T19:37:02.129674+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 4 Maverick",
          "shortName": "Llama 4 Maverick",
          "author": "meta-llama",
          "description": "Llama 4 Maverick 17B Instruct (128E) is a high-capacity multimodal language model from Meta, built on a mixture-of-experts (MoE) architecture with 128 experts and 17 billion active parameters per forward pass (400B total). It supports multilingual text and image input, and produces multilingual text and code output across 12 supported languages. Optimized for vision-language tasks, Maverick is instruction-tuned for assistant-like behavior, image reasoning, and general-purpose multimodal interaction.\n\nMaverick features early fusion for native multimodality and a 1 million token context window. It was trained on a curated mixture of public, licensed, and Meta-platform data, covering ~22 trillion tokens, with a knowledge cutoff in August 2024. Released on April 5, 2025 under the Llama 4 Community License, Maverick is suited for research and commercial applications requiring advanced multimodal understanding and high model throughput.",
          "modelVersionGroupId": null,
          "contextLength": 1048576,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-4-maverick-17b-128e-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-4-maverick",
        "modelVariantPermaslug": "meta-llama/llama-4-maverick-17b-128e-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": 1,
        "maxTokensPerImage": 3342,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000016",
          "completion": "0.0000006",
          "image": "0.0006684",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 23,
        "newest": 61,
        "throughputHighToLow": 84,
        "latencyLowToHigh": 60,
        "pricingLowToHigh": 26,
        "pricingHighToLow": 169
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.00000016",
            "completion": "0.0000006",
            "image": "0.0006684",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.16,
          "outputCost": 0.6,
          "throughput": 75.413,
          "latency": 419
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.00000016",
            "completion": "0.0000008",
            "image": "0.0008355",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.16,
          "outputCost": 0.8,
          "throughput": 131.248,
          "latency": 515
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "meta-llama/llama-4-maverick-17b-128e-instruct-fp8",
          "pricing": {
            "prompt": "0.00000017",
            "completion": "0.00000085",
            "image": "0.0006684",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.17,
          "outputCost": 0.85,
          "throughput": 59.586,
          "latency": 725
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "llama-4-maverick-17b-128e-instruct-fp8",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.6,
          "throughput": 150.3505,
          "latency": 686
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "parasail-llama-4-maverick-instruct-fp8",
          "pricing": {
            "prompt": "0.00000019",
            "completion": "0.00000085",
            "image": "0.00070182",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.19,
          "outputCost": 0.85,
          "throughput": 152.628,
          "latency": 502
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 80.624,
          "latency": 416
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 8192,
          "providerModelId": "meta-llama/llama-4-maverick-17b-128e-instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 265.9425,
          "latency": 479
        },
        {
          "name": "nCompass",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://console.ncompass.tech/&size=256",
          "slug": "nCompass",
          "quantization": "fp8",
          "context": 400000,
          "maxCompletionTokens": 400000,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.7,
          "throughput": 134.335,
          "latency": 444
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama4-maverick-instruct-basic",
          "pricing": {
            "prompt": "0.00000022",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.22,
          "outputCost": 0.88,
          "throughput": 85.3495,
          "latency": 626
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "seed"
          ],
          "inputCost": 0.25,
          "outputCost": 0.8,
          "throughput": 92.127,
          "latency": 682
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.00000027",
            "completion": "0.00000085",
            "image": "0.00090234",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.27,
          "outputCost": 0.85,
          "throughput": 101.7275,
          "latency": 473
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 4096,
          "providerModelId": "Llama-4-Maverick-17B-128E-Instruct",
          "pricing": {
            "prompt": "0.00000063",
            "completion": "0.0000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.63,
          "outputCost": 1.8,
          "throughput": 647.2275,
          "latency": 803
        }
      ]
    },
    {
      "slug": "qwen/qwen3-235b-a22b",
      "hfSlug": "Qwen/Qwen3-235B-A22B",
      "updatedAt": "2025-05-11T22:44:42.939095+00:00",
      "createdAt": "2025-04-28T21:29:17.25671+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 235B A22B",
      "shortName": "Qwen3 235B A22B",
      "author": "qwen",
      "description": "Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless switching between a \"thinking\" mode for complex reasoning, math, and code tasks, and a \"non-thinking\" mode for general conversational efficiency. The model demonstrates strong reasoning ability, multilingual support (100+ languages and dialects), advanced instruction-following, and agent tool-calling capabilities. It natively handles a 32K token context window and extends up to 131K tokens using YaRN-based scaling.",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-235b-a22b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "5f108245-8fec-4702-859d-56c5b54a71d7",
        "name": "DeepInfra | qwen/qwen3-235b-a22b-04-28",
        "contextLength": 40960,
        "model": {
          "slug": "qwen/qwen3-235b-a22b",
          "hfSlug": "Qwen/Qwen3-235B-A22B",
          "updatedAt": "2025-05-11T22:44:42.939095+00:00",
          "createdAt": "2025-04-28T21:29:17.25671+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 235B A22B",
          "shortName": "Qwen3 235B A22B",
          "author": "qwen",
          "description": "Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless switching between a \"thinking\" mode for complex reasoning, math, and code tasks, and a \"non-thinking\" mode for general conversational efficiency. The model demonstrates strong reasoning ability, multilingual support (100+ languages and dialects), advanced instruction-following, and agent tool-calling capabilities. It natively handles a 32K token context window and extends up to 131K tokens using YaRN-based scaling.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-235b-a22b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-235b-a22b",
        "modelVariantPermaslug": "qwen/qwen3-235b-a22b-04-28",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Qwen/Qwen3-235B-A22B",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 40960,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000014",
          "completion": "0.0000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 24,
        "newest": 30,
        "throughputHighToLow": 244,
        "latencyLowToHigh": 180,
        "pricingLowToHigh": 13,
        "pricingHighToLow": 178
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/Qwen3-235B-A22B",
          "pricing": {
            "prompt": "0.00000014",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.14,
          "outputCost": 0.6,
          "throughput": 23.0245,
          "latency": 1201
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/Qwen3-235B-A22B-FP8",
          "pricing": {
            "prompt": "0.00000014",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.14,
          "outputCost": 2,
          "throughput": 41.1275,
          "latency": 792
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "parasail-qwen3-235b-a22b",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000085",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.18,
          "outputCost": 0.85,
          "throughput": 56.146,
          "latency": 961
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-235B-A22B-fp8-tput",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 30.3685,
          "latency": 831
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-235B-A22B",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 31.8295,
          "latency": 701
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-235b-a22b-fp8",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.2,
          "outputCost": 0.8,
          "throughput": 55.649,
          "latency": 1289
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwen3-235b-a22b",
          "pricing": {
            "prompt": "0.00000022",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.22,
          "outputCost": 0.88,
          "throughput": 54.1885,
          "latency": 856
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-235B-A22B-FP8",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000109",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "seed"
          ],
          "inputCost": 0.25,
          "outputCost": 1.09,
          "throughput": 48.5485,
          "latency": 933.5
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.1-70b-instruct",
      "hfSlug": "meta-llama/Meta-Llama-3.1-70B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-23T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.1 70B Instruct",
      "shortName": "Llama 3.1 70B Instruct",
      "author": "meta-llama",
      "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 70B instruct-tuned version is optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.1-70b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "036dfa0a-ebbb-4a51-aa90-091a75c2cadb",
        "name": "DeepInfra | meta-llama/llama-3.1-70b-instruct",
        "contextLength": 131072,
        "model": {
          "slug": "meta-llama/llama-3.1-70b-instruct",
          "hfSlug": "meta-llama/Meta-Llama-3.1-70B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-07-23T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.1 70B Instruct",
          "shortName": "Llama 3.1 70B Instruct",
          "author": "meta-llama",
          "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 70B instruct-tuned version is optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.1-70b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.1-70b-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3.1-70b-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.00000028",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 25,
        "newest": 232,
        "throughputHighToLow": 219,
        "latencyLowToHigh": 27,
        "pricingLowToHigh": 120,
        "pricingHighToLow": 198
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.00000028",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.28,
          "throughput": 37.3875,
          "latency": 307
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "meta-llama/llama-3.1-70b-instruct",
          "pricing": {
            "prompt": "0.000000119",
            "completion": "0.00000039",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.12,
          "outputCost": 0.39,
          "throughput": 30.494,
          "latency": 1537
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.1-70b-instruct-fp8",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.12,
          "outputCost": 0.3,
          "throughput": 53.158,
          "latency": 530
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-70B-Instruct",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.13,
          "outputCost": 0.4,
          "throughput": 35.3215,
          "latency": 775
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.1-70b-instruct/fp-16",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.3,
          "outputCost": 0.4
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-70B-Instruct",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 113.38,
          "latency": 929.5
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000088",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.88,
          "outputCost": 0.88,
          "throughput": 95.6315,
          "latency": 608
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama-v3p1-70b-instruct",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 126.1165,
          "latency": 380
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.1-8b-instruct",
      "hfSlug": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-23T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.1 8B Instruct",
      "shortName": "Llama 3.1 8B Instruct",
      "author": "meta-llama",
      "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 8B instruct-tuned version is fast and efficient.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "803c32ed-9861-4abf-b5da-7d9c9e6dcf04",
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.1-8b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "612663e2-9ede-4c5d-b993-c55cd12e3055",
        "name": "InferenceNet | meta-llama/llama-3.1-8b-instruct",
        "contextLength": 16384,
        "model": {
          "slug": "meta-llama/llama-3.1-8b-instruct",
          "hfSlug": "meta-llama/Meta-Llama-3.1-8B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-07-23T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.1 8B Instruct",
          "shortName": "Llama 3.1 8B Instruct",
          "author": "meta-llama",
          "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 8B instruct-tuned version is fast and efficient.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": "803c32ed-9861-4abf-b5da-7d9c9e6dcf04",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.1-8b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.1-8b-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3.1-8b-instruct",
        "providerName": "InferenceNet",
        "providerInfo": {
          "name": "InferenceNet",
          "displayName": "inference.net",
          "slug": "inference-net",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://inference.net/privacy-policy",
            "termsOfServiceUrl": "https://inference.net/terms-of-service",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "InferenceNet",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "inference.net",
        "providerModelId": "meta-llama/llama-3.1-8b-instruct/fp-16",
        "providerGroup": "InferenceNet",
        "quantization": "fp16",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://inference.net/privacy-policy",
          "termsOfServiceUrl": "https://inference.net/terms-of-service",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000002",
          "completion": "0.00000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 26,
        "newest": 229,
        "throughputHighToLow": 147,
        "latencyLowToHigh": 172,
        "pricingLowToHigh": 67,
        "pricingHighToLow": 242
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.1-8b-instruct/fp-16",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.02,
          "outputCost": 0.03,
          "throughput": 51.254,
          "latency": 1216
        },
        {
          "name": "DeepInfra (Turbo)",
          "icon": "",
          "slug": "deepInfra (turbo)",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.02,
          "outputCost": 0.03,
          "throughput": 101.8025,
          "latency": 250
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 8192,
          "providerModelId": "meta-llama/llama-3.1-8b-instruct",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.02,
          "outputCost": 0.05,
          "throughput": 78.6195,
          "latency": 720
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.02,
          "outputCost": 0.06,
          "throughput": 54.2545,
          "latency": 482
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.1-8b-instruct",
          "pricing": {
            "prompt": "0.000000025",
            "completion": "0.00000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.02,
          "outputCost": 0.04,
          "throughput": 162.054,
          "latency": 599
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.00000003",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.03,
          "outputCost": 0.05,
          "throughput": 52.068,
          "latency": 335
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": "fp8",
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.1-8b-instruct-fp8",
          "pricing": {
            "prompt": "0.000000045",
            "completion": "0.000000384",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.04,
          "outputCost": 0.38,
          "throughput": 23.518,
          "latency": 784
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama-3.1-8b-instant",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.05,
          "outputCost": 0.08,
          "throughput": 1509.833,
          "latency": 1465
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "llama3.1:8b",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.06,
          "outputCost": 0.1,
          "throughput": 115.271,
          "latency": 1593
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 268.7995,
          "latency": 981
        },
        {
          "name": "Cerebras",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cerebras.ai/&size=256",
          "slug": "cerebras",
          "quantization": "fp16",
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "llama3.1-8b",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "response_format",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 3924.764,
          "latency": 187
        },
        {
          "name": "Friendli",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://friendli.ai/&size=256",
          "slug": "friendli",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 8000,
          "providerModelId": "meta-llama-3.1-8b-instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 282.548,
          "latency": 303
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.1,
          "outputCost": 0.2,
          "throughput": 878.542,
          "latency": 321.5
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 131000,
          "maxCompletionTokens": 131000,
          "providerModelId": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.18,
          "outputCost": 0.18,
          "throughput": 62.505,
          "latency": 551
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.18,
          "throughput": 252.641,
          "latency": 313
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama-v3p1-8b-instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 255.782,
          "latency": 361
        },
        {
          "name": "Avian.io",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://avian.io/&size=256",
          "slug": "avianIo",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "response_format",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2
        }
      ]
    },
    {
      "slug": "google/gemma-3-27b-it",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-12T05:12:39.645813+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 3 27B",
      "shortName": "Gemma 3 27B",
      "author": "google",
      "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google's latest open source model, successor to [Gemma 2](google/gemma-2-27b-it)",
      "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "google/gemma-3-27b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8f22002c-c045-446f-a1b9-9896133536b8",
        "name": "DeepInfra | google/gemma-3-27b-it",
        "contextLength": 131072,
        "model": {
          "slug": "google/gemma-3-27b-it",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-12T05:12:39.645813+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 3 27B",
          "shortName": "Gemma 3 27B",
          "author": "google",
          "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google's latest open source model, successor to [Gemma 2](google/gemma-2-27b-it)",
          "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "google/gemma-3-27b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-3-27b-it",
        "modelVariantPermaslug": "google/gemma-3-27b-it",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "google/gemma-3-27b-it",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000002",
          "image": "0.0000256",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 27,
        "newest": 93,
        "throughputHighToLow": 35,
        "latencyLowToHigh": 143,
        "pricingLowToHigh": 41,
        "pricingHighToLow": 199
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000002",
            "image": "0.0000256",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.2,
          "throughput": 32.3795,
          "latency": 870
        },
        {
          "name": "InoCloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inocloud.com/&size=256",
          "slug": "inoCloud",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.1,
          "outputCost": 0.2,
          "throughput": 27.2075,
          "latency": 1206
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 110000,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 47.451,
          "latency": 955
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.000000119",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.12,
          "outputCost": 0.2,
          "throughput": 31.0825,
          "latency": 2277
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 8000,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.00000035",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.35,
          "throughput": 55.241,
          "latency": 1221.5
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-gemma3-27b-it",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.25,
          "outputCost": 0.4,
          "throughput": 50.6245,
          "latency": 1201.5
        },
        {
          "name": "nCompass",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://console.ncompass.tech/&size=256",
          "slug": "nCompass",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 43.7135,
          "latency": 986
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": 8192,
          "providerModelId": "google/gemma-3-27b-instruct/bf-16",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.3,
          "outputCost": 0.4,
          "throughput": 15.433,
          "latency": 2120.5
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-chat",
      "hfSlug": "deepseek-ai/DeepSeek-V3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-26T19:28:40.559917+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: DeepSeek V3",
      "shortName": "DeepSeek V3",
      "author": "deepseek",
      "description": "DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions. Pre-trained on nearly 15 trillion tokens, the reported evaluations reveal that the model outperforms other open-source models and rivals leading closed-source models.\n\nFor model details, please visit [the DeepSeek-V3 repo](https://github.com/deepseek-ai/DeepSeek-V3) for more information, or see the [launch announcement](https://api-docs.deepseek.com/news/news1226).",
      "modelVersionGroupId": null,
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-chat-v3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "5294d55f-9012-496b-8f22-8cc919432dcd",
        "name": "DeepInfra | deepseek/deepseek-chat-v3",
        "contextLength": 163840,
        "model": {
          "slug": "deepseek/deepseek-chat",
          "hfSlug": "deepseek-ai/DeepSeek-V3",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-26T19:28:40.559917+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: DeepSeek V3",
          "shortName": "DeepSeek V3",
          "author": "deepseek",
          "description": "DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions. Pre-trained on nearly 15 trillion tokens, the reported evaluations reveal that the model outperforms other open-source models and rivals leading closed-source models.\n\nFor model details, please visit [the DeepSeek-V3 repo](https://github.com/deepseek-ai/DeepSeek-V3) for more information, or see the [launch announcement](https://api-docs.deepseek.com/news/news1226).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-chat-v3",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "deepseek/deepseek-chat",
        "modelVariantPermaslug": "deepseek/deepseek-chat-v3",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "deepseek-ai/DeepSeek-V3",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 163840,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000038",
          "completion": "0.00000089",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 28,
        "newest": 148,
        "throughputHighToLow": 126,
        "latencyLowToHigh": 119,
        "pricingLowToHigh": 54,
        "pricingHighToLow": 146
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-V3",
          "pricing": {
            "prompt": "0.00000038",
            "completion": "0.00000089",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.38,
          "outputCost": 0.89,
          "throughput": 22.937,
          "latency": 689
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 16000,
          "providerModelId": "deepseek/deepseek-v3-turbo",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000013",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.4,
          "outputCost": 1.3,
          "throughput": 26.703,
          "latency": 887
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 20.009,
          "latency": 422
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/deepseek-v3",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 50.9045,
          "latency": 1684
        }
      ]
    },
    {
      "slug": "meta-llama/llama-4-maverick",
      "hfSlug": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "updatedAt": "2025-04-05T19:58:55.362967+00:00",
      "createdAt": "2025-04-05T19:37:02.129674+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 4 Maverick (free)",
      "shortName": "Llama 4 Maverick (free)",
      "author": "meta-llama",
      "description": "Llama 4 Maverick 17B Instruct (128E) is a high-capacity multimodal language model from Meta, built on a mixture-of-experts (MoE) architecture with 128 experts and 17 billion active parameters per forward pass (400B total). It supports multilingual text and image input, and produces multilingual text and code output across 12 supported languages. Optimized for vision-language tasks, Maverick is instruction-tuned for assistant-like behavior, image reasoning, and general-purpose multimodal interaction.\n\nMaverick features early fusion for native multimodality and a 1 million token context window. It was trained on a curated mixture of public, licensed, and Meta-platform data, covering ~22 trillion tokens, with a knowledge cutoff in August 2024. Released on April 5, 2025 under the Llama 4 Community License, Maverick is suited for research and commercial applications requiring advanced multimodal understanding and high model throughput.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-4-maverick-17b-128e-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2ff5f508-d666-4051-9625-0c795e746c32",
        "name": "Chutes | meta-llama/llama-4-maverick-17b-128e-instruct:free",
        "contextLength": 128000,
        "model": {
          "slug": "meta-llama/llama-4-maverick",
          "hfSlug": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
          "updatedAt": "2025-04-05T19:58:55.362967+00:00",
          "createdAt": "2025-04-05T19:37:02.129674+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 4 Maverick",
          "shortName": "Llama 4 Maverick",
          "author": "meta-llama",
          "description": "Llama 4 Maverick 17B Instruct (128E) is a high-capacity multimodal language model from Meta, built on a mixture-of-experts (MoE) architecture with 128 experts and 17 billion active parameters per forward pass (400B total). It supports multilingual text and image input, and produces multilingual text and code output across 12 supported languages. Optimized for vision-language tasks, Maverick is instruction-tuned for assistant-like behavior, image reasoning, and general-purpose multimodal interaction.\n\nMaverick features early fusion for native multimodality and a 1 million token context window. It was trained on a curated mixture of public, licensed, and Meta-platform data, covering ~22 trillion tokens, with a knowledge cutoff in August 2024. Released on April 5, 2025 under the Llama 4 Community License, Maverick is suited for research and commercial applications requiring advanced multimodal understanding and high model throughput.",
          "modelVersionGroupId": null,
          "contextLength": 1048576,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-4-maverick-17b-128e-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-4-maverick:free",
        "modelVariantPermaslug": "meta-llama/llama-4-maverick-17b-128e-instruct:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "chutesai/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "providerGroup": "Chutes",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": 8,
        "maxTokensPerImage": 3342,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "structured_outputs",
          "response_format",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {
            "responseFormat": true,
            "structuredOutputs": true
          },
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 23,
        "newest": 61,
        "throughputHighToLow": 84,
        "latencyLowToHigh": 60,
        "pricingLowToHigh": 26,
        "pricingHighToLow": 169
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.00000016",
            "completion": "0.0000006",
            "image": "0.0006684",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.16,
          "outputCost": 0.6,
          "throughput": 75.413,
          "latency": 419
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.00000016",
            "completion": "0.0000008",
            "image": "0.0008355",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.16,
          "outputCost": 0.8,
          "throughput": 131.248,
          "latency": 515
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "meta-llama/llama-4-maverick-17b-128e-instruct-fp8",
          "pricing": {
            "prompt": "0.00000017",
            "completion": "0.00000085",
            "image": "0.0006684",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.17,
          "outputCost": 0.85,
          "throughput": 59.586,
          "latency": 725
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "llama-4-maverick-17b-128e-instruct-fp8",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.6,
          "throughput": 150.3505,
          "latency": 686
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "parasail-llama-4-maverick-instruct-fp8",
          "pricing": {
            "prompt": "0.00000019",
            "completion": "0.00000085",
            "image": "0.00070182",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.19,
          "outputCost": 0.85,
          "throughput": 152.628,
          "latency": 502
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 80.624,
          "latency": 416
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 8192,
          "providerModelId": "meta-llama/llama-4-maverick-17b-128e-instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 265.9425,
          "latency": 479
        },
        {
          "name": "nCompass",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://console.ncompass.tech/&size=256",
          "slug": "nCompass",
          "quantization": "fp8",
          "context": 400000,
          "maxCompletionTokens": 400000,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.7,
          "throughput": 134.335,
          "latency": 444
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama4-maverick-instruct-basic",
          "pricing": {
            "prompt": "0.00000022",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.22,
          "outputCost": 0.88,
          "throughput": 85.3495,
          "latency": 626
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "seed"
          ],
          "inputCost": 0.25,
          "outputCost": 0.8,
          "throughput": 92.127,
          "latency": 682
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
          "pricing": {
            "prompt": "0.00000027",
            "completion": "0.00000085",
            "image": "0.00090234",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.27,
          "outputCost": 0.85,
          "throughput": 101.7275,
          "latency": 473
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 4096,
          "providerModelId": "Llama-4-Maverick-17B-128E-Instruct",
          "pricing": {
            "prompt": "0.00000063",
            "completion": "0.0000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.63,
          "outputCost": 1.8,
          "throughput": 647.2275,
          "latency": 803
        }
      ]
    },
    {
      "slug": "x-ai/grok-3-mini-beta",
      "hfSlug": "",
      "updatedAt": "2025-04-10T00:40:58.337579+00:00",
      "createdAt": "2025-04-09T23:09:55.305821+00:00",
      "hfUpdatedAt": null,
      "name": "xAI: Grok 3 Mini Beta",
      "shortName": "Grok 3 Mini Beta",
      "author": "x-ai",
      "description": "Grok 3 Mini is a lightweight, smaller thinking model. Unlike traditional models that generate answers immediately, Grok 3 Mini thinks before responding. It’s ideal for reasoning-heavy tasks that don’t demand extensive domain knowledge, and shines in math-specific and quantitative use cases, such as solving challenging puzzles or math problems.\n\nTransparent \"thinking\" traces accessible. Defaults to low reasoning, can boost with setting `reasoning: { effort: \"high\" }`\n\nNote: That there are two xAI endpoints for this model. By default when using this model we will always route you to the base endpoint. If you want the fast endpoint you can add `provider: { sort: throughput}`, to sort by throughput instead. \n",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Grok",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "x-ai/grok-3-mini-beta",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e1b8a32c-6b6b-456b-91c9-ede164b895ad",
        "name": "xAI | x-ai/grok-3-mini-beta",
        "contextLength": 131072,
        "model": {
          "slug": "x-ai/grok-3-mini-beta",
          "hfSlug": "",
          "updatedAt": "2025-04-10T00:40:58.337579+00:00",
          "createdAt": "2025-04-09T23:09:55.305821+00:00",
          "hfUpdatedAt": null,
          "name": "xAI: Grok 3 Mini Beta",
          "shortName": "Grok 3 Mini Beta",
          "author": "x-ai",
          "description": "Grok 3 Mini is a lightweight, smaller thinking model. Unlike traditional models that generate answers immediately, Grok 3 Mini thinks before responding. It’s ideal for reasoning-heavy tasks that don’t demand extensive domain knowledge, and shines in math-specific and quantitative use cases, such as solving challenging puzzles or math problems.\n\nTransparent \"thinking\" traces accessible. Defaults to low reasoning, can boost with setting `reasoning: { effort: \"high\" }`\n\nNote: That there are two xAI endpoints for this model. By default when using this model we will always route you to the base endpoint. If you want the fast endpoint you can add `provider: { sort: throughput}`, to sort by throughput instead. \n",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Grok",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "x-ai/grok-3-mini-beta",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "x-ai/grok-3-mini-beta",
        "modelVariantPermaslug": "x-ai/grok-3-mini-beta",
        "providerName": "xAI",
        "providerInfo": {
          "name": "xAI",
          "displayName": "xAI",
          "slug": "xai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "xAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.x.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256"
          }
        },
        "providerDisplayName": "xAI",
        "providerModelId": "grok-3-mini-beta",
        "providerGroup": "xAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "seed",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000003",
          "completion": "0.0000005",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 30,
        "newest": 56,
        "throughputHighToLow": 87,
        "latencyLowToHigh": 45,
        "pricingLowToHigh": 167,
        "pricingHighToLow": 152
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://x.ai/\\u0026size=256",
      "providers": [
        {
          "name": "xAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256",
          "slug": "xAi",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "grok-3-mini-beta",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.3,
          "outputCost": 0.5,
          "throughput": 88.3815,
          "latency": 399
        },
        {
          "name": "xAI Fast",
          "icon": "",
          "slug": "xAiFast",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "grok-3-mini-fast-beta",
          "pricing": {
            "prompt": "0.0000006",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.6,
          "outputCost": 4,
          "throughput": 121.897,
          "latency": 573
        }
      ]
    },
    {
      "slug": "qwen/qwen-2.5-72b-instruct",
      "hfSlug": "Qwen/Qwen2.5-72B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-19T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen2.5 72B Instruct",
      "shortName": "Qwen2.5 72B Instruct",
      "author": "qwen",
      "description": "Qwen2.5 72B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2.5-72b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8b6b26e9-621a-4b31-b55a-c9aaa7482ede",
        "name": "DeepInfra | qwen/qwen-2.5-72b-instruct",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen-2.5-72b-instruct",
          "hfSlug": "Qwen/Qwen2.5-72B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-19T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen2.5 72B Instruct",
          "shortName": "Qwen2.5 72B Instruct",
          "author": "qwen",
          "description": "Qwen2.5 72B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-2.5-72b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-2.5-72b-instruct",
        "modelVariantPermaslug": "qwen/qwen-2.5-72b-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Qwen/Qwen2.5-72B-Instruct",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000012",
          "completion": "0.00000039",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 31,
        "newest": 204,
        "throughputHighToLow": 221,
        "latencyLowToHigh": 135,
        "pricingLowToHigh": 64,
        "pricingHighToLow": 186
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "Qwen/Qwen2.5-72B-Instruct",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.00000039",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.12,
          "outputCost": 0.39,
          "throughput": 33.5375,
          "latency": 656.5
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-72B-Instruct",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.13,
          "outputCost": 0.4,
          "throughput": 19.7725,
          "latency": 1949
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 32000,
          "maxCompletionTokens": 4096,
          "providerModelId": "qwen/qwen-2.5-72b-instruct",
          "pricing": {
            "prompt": "0.00000038",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.38,
          "outputCost": 0.4,
          "throughput": 21.3505,
          "latency": 4114.5
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-72B-Instruct",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 32.5955,
          "latency": 2151.5
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwen2p5-72b-instruct",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 70.528,
          "latency": 354
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 2048,
          "providerModelId": "Qwen/Qwen2.5-72B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.0000012",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.2,
          "outputCost": 1.2,
          "throughput": 95.3675,
          "latency": 805
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1",
      "hfSlug": "deepseek-ai/DeepSeek-R1",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-20T13:51:35.96912+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1",
      "shortName": "R1",
      "author": "deepseek",
      "description": "DeepSeek R1 is here: Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens. It's 671B parameters in size, with 37B active in an inference pass.\n\nFully open-source model & [technical report](https://api-docs.deepseek.com/news/news250120).\n\nMIT licensed: Distill & commercialize freely!",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-r1",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "cc004fe3-9ed7-4490-b69a-3b83ab1a1db6",
        "name": "DeepInfra | deepseek/deepseek-r1",
        "contextLength": 163840,
        "model": {
          "slug": "deepseek/deepseek-r1",
          "hfSlug": "deepseek-ai/DeepSeek-R1",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-20T13:51:35.96912+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1",
          "shortName": "R1",
          "author": "deepseek",
          "description": "DeepSeek R1 is here: Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens. It's 671B parameters in size, with 37B active in an inference pass.\n\nFully open-source model & [technical report](https://api-docs.deepseek.com/news/news250120).\n\nMIT licensed: Distill & commercialize freely!",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 163840,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-r1",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1",
        "modelVariantPermaslug": "deepseek/deepseek-r1",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "deepseek-ai/DeepSeek-R1",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 163840,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.00000218",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 12,
        "newest": 143,
        "throughputHighToLow": 171,
        "latencyLowToHigh": 111,
        "pricingLowToHigh": 53,
        "pricingHighToLow": 124
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.00000218",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.5,
          "outputCost": 2.18,
          "throughput": 42.5465,
          "latency": 775
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek/deepseek-r1/fp-8",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.5,
          "outputCost": 3,
          "throughput": 19.959,
          "latency": 1269
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-r1-671b",
          "pricing": {
            "prompt": "0.00000054",
            "completion": "0.00000218",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.54,
          "outputCost": 2.18,
          "throughput": 37.487,
          "latency": 981
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 16000,
          "providerModelId": "deepseek/deepseek-r1-turbo",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.7,
          "outputCost": 2.5,
          "throughput": 28.936,
          "latency": 1273.5
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.8,
          "outputCost": 2.4,
          "throughput": 26.6925,
          "latency": 790
        },
        {
          "name": "DeepInfra Turbo",
          "icon": "",
          "slug": "deepInfraTurbo",
          "quantization": "fp4",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Turbo",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 1,
          "outputCost": 3,
          "throughput": 109.355,
          "latency": 524
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.00000175",
            "completion": "0.000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 1.75,
          "outputCost": 5,
          "throughput": 29.294,
          "latency": 952
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-deepseek-r1",
          "pricing": {
            "prompt": "0.00000195",
            "completion": "0.000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 1.95,
          "outputCost": 5,
          "throughput": 52.051,
          "latency": 557
        },
        {
          "name": "Nebius Fast",
          "icon": "",
          "slug": "nebiusFast",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-R1-fast",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 2,
          "outputCost": 6,
          "throughput": 53.4185,
          "latency": 815
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.00000299",
            "completion": "0.00000299",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 2.99,
          "outputCost": 2.99,
          "throughput": 60.47,
          "latency": 895
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 3,
          "outputCost": 7,
          "throughput": 49.2495,
          "latency": 1261.5
        },
        {
          "name": "Friendli",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://friendli.ai/&size=256",
          "slug": "friendli",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-r1",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 3,
          "outputCost": 7,
          "throughput": 59.7745,
          "latency": 927
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/deepseek-r1",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 3,
          "outputCost": 8,
          "throughput": 44.5635,
          "latency": 740
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "DeepSeek-R1",
          "pricing": {
            "prompt": "0.000005",
            "completion": "0.000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "stop"
          ],
          "inputCost": 5,
          "outputCost": 7,
          "throughput": 114.5795,
          "latency": 2449
        },
        {
          "name": "Minimax",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://minimaxi.com/&size=256",
          "slug": "minimax",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 64000,
          "providerModelId": "DeepSeek-R1",
          "pricing": {
            "prompt": "0.00000055",
            "completion": "0.00000219",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning"
          ],
          "inputCost": 0.55,
          "outputCost": 2.19,
          "throughput": 21.5065,
          "latency": 2109
        },
        {
          "name": "DeepSeek",
          "icon": "https://openrouter.ai/images/icons/DeepSeek.png",
          "slug": "deepSeek",
          "quantization": "fp8",
          "context": 64000,
          "maxCompletionTokens": 8000,
          "providerModelId": "deepseek-reasoner",
          "pricing": {
            "prompt": "0.00000055",
            "completion": "0.00000219",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "reasoning",
            "include_reasoning"
          ],
          "inputCost": 0.55,
          "outputCost": 2.19,
          "throughput": 21.513,
          "latency": 4052
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": null,
          "context": 163840,
          "maxCompletionTokens": 4096,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.000001485",
            "completion": "0.00000594",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning"
          ],
          "inputCost": 1.48,
          "outputCost": 5.94,
          "throughput": 78.0455,
          "latency": 1786
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 4096,
          "providerModelId": "deepseek-ai/DeepSeek-R1",
          "pricing": {
            "prompt": "0.0000065",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 6.5,
          "outputCost": 8,
          "throughput": 13.743,
          "latency": 2659
        }
      ]
    },
    {
      "slug": "openai/o4-mini",
      "hfSlug": "",
      "updatedAt": "2025-04-17T14:00:40.898359+00:00",
      "createdAt": "2025-04-16T16:29:02.980764+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o4 Mini",
      "shortName": "o4 Mini",
      "author": "openai",
      "description": "OpenAI o4-mini is a compact reasoning model in the o-series, optimized for fast, cost-efficient performance while retaining strong multimodal and agentic capabilities. It supports tool use and demonstrates competitive reasoning and coding performance across benchmarks like AIME (99.5% with Python) and SWE-bench, outperforming its predecessor o3-mini and even approaching o3 in some domains.\n\nDespite its smaller size, o4-mini exhibits high accuracy in STEM tasks, visual problem solving (e.g., MathVista, MMMU), and code editing. It is especially well-suited for high-throughput scenarios where latency or cost is critical. Thanks to its efficient architecture and refined reinforcement learning training, o4-mini can chain tools, generate structured outputs, and solve multi-step tasks with minimal delay—often in under a minute.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "image",
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "openai/o4-mini-2025-04-16",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "bd121898-b27c-4e2c-bc92-278627465a54",
        "name": "OpenAI | openai/o4-mini-2025-04-16",
        "contextLength": 200000,
        "model": {
          "slug": "openai/o4-mini",
          "hfSlug": "",
          "updatedAt": "2025-04-17T14:00:40.898359+00:00",
          "createdAt": "2025-04-16T16:29:02.980764+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o4 Mini",
          "shortName": "o4 Mini",
          "author": "openai",
          "description": "OpenAI o4-mini is a compact reasoning model in the o-series, optimized for fast, cost-efficient performance while retaining strong multimodal and agentic capabilities. It supports tool use and demonstrates competitive reasoning and coding performance across benchmarks like AIME (99.5% with Python) and SWE-bench, outperforming its predecessor o3-mini and even approaching o3 in some domains.\n\nDespite its smaller size, o4-mini exhibits high accuracy in STEM tasks, visual problem solving (e.g., MathVista, MMMU), and code editing. It is especially well-suited for high-throughput scenarios where latency or cost is critical. Thanks to its efficient architecture and refined reinforcement learning training, o4-mini can chain tools, generate structured outputs, and solve multi-step tasks with minimal delay—often in under a minute.",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "image",
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "openai/o4-mini-2025-04-16",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o4-mini",
        "modelVariantPermaslug": "openai/o4-mini-2025-04-16",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o4-mini-2025-04-16",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 100000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "seed",
          "max_tokens",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000011",
          "completion": "0.0000044",
          "image": "0.0008415",
          "request": "0",
          "inputCacheRead": "0.000000275",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {
            "responseFormat": true,
            "structuredOutputs": true
          },
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 33,
        "newest": 45,
        "throughputHighToLow": 83,
        "latencyLowToHigh": 299,
        "pricingLowToHigh": 230,
        "pricingHighToLow": 85
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 100000,
          "providerModelId": "o4-mini-2025-04-16",
          "pricing": {
            "prompt": "0.0000011",
            "completion": "0.0000044",
            "image": "0.0008415",
            "request": "0",
            "inputCacheRead": "0.000000275",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "seed",
            "max_tokens",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1.1,
          "outputCost": 4.4,
          "throughput": 93.615,
          "latency": 4538.5
        }
      ]
    },
    {
      "slug": "microsoft/wizardlm-2-8x22b",
      "hfSlug": "microsoft/WizardLM-2-8x22B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "WizardLM-2 8x22B",
      "shortName": "WizardLM-2 8x22B",
      "author": "microsoft",
      "description": "WizardLM-2 8x22B is Microsoft AI's most advanced Wizard model. It demonstrates highly competitive performance compared to leading proprietary models, and it consistently outperforms all existing state-of-the-art opensource models.\n\nIt is an instruct finetune of [Mixtral 8x22B](/models/mistralai/mixtral-8x22b).\n\nTo read more about the model release, [click here](https://wizardlm.github.io/WizardLM2/).\n\n#moe",
      "modelVersionGroupId": null,
      "contextLength": 65536,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "vicuna",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/wizardlm-2-8x22b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "03ac4ad1-a230-4ce7-821c-e797305733df",
        "name": "DeepInfra | microsoft/wizardlm-2-8x22b",
        "contextLength": 65536,
        "model": {
          "slug": "microsoft/wizardlm-2-8x22b",
          "hfSlug": "microsoft/WizardLM-2-8x22B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-04-16T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "WizardLM-2 8x22B",
          "shortName": "WizardLM-2 8x22B",
          "author": "microsoft",
          "description": "WizardLM-2 8x22B is Microsoft AI's most advanced Wizard model. It demonstrates highly competitive performance compared to leading proprietary models, and it consistently outperforms all existing state-of-the-art opensource models.\n\nIt is an instruct finetune of [Mixtral 8x22B](/models/mistralai/mixtral-8x22b).\n\nTo read more about the model release, [click here](https://wizardlm.github.io/WizardLM2/).\n\n#moe",
          "modelVersionGroupId": null,
          "contextLength": 65536,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "vicuna",
          "defaultSystem": null,
          "defaultStops": [
            "USER:",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/wizardlm-2-8x22b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "microsoft/wizardlm-2-8x22b",
        "modelVariantPermaslug": "microsoft/wizardlm-2-8x22b",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "microsoft/WizardLM-2-8x22B",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000005",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 34,
        "newest": 269,
        "throughputHighToLow": 238,
        "latencyLowToHigh": 139,
        "pricingLowToHigh": 178,
        "pricingHighToLow": 139
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 65536,
          "maxCompletionTokens": 16384,
          "providerModelId": "microsoft/WizardLM-2-8x22B",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.5,
          "outputCost": 0.5,
          "throughput": 34.059,
          "latency": 807
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 65536,
          "maxCompletionTokens": 65536,
          "providerModelId": "parasail-wizardlm-2-8x22b",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.5,
          "outputCost": 0.6,
          "throughput": 47.0425,
          "latency": 579
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 65535,
          "maxCompletionTokens": null,
          "providerModelId": "microsoft/wizardlm-2-8x22b",
          "pricing": {
            "prompt": "0.00000062",
            "completion": "0.00000062",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.62,
          "outputCost": 0.62,
          "throughput": 33.8045,
          "latency": 967
        }
      ]
    },
    {
      "slug": "openai/gpt-4o",
      "hfSlug": null,
      "updatedAt": "2025-04-23T22:07:26.226912+00:00",
      "createdAt": "2024-05-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4o",
      "shortName": "GPT-4o",
      "author": "openai",
      "description": "GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n#multimodal",
      "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4o",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "452a72a0-2c24-4e31-98cb-d6cc1084fb99",
        "name": "OpenAI | openai/gpt-4o",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4o",
          "hfSlug": null,
          "updatedAt": "2025-04-23T22:07:26.226912+00:00",
          "createdAt": "2024-05-13T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4o",
          "shortName": "GPT-4o",
          "author": "openai",
          "description": "GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n#multimodal",
          "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4o",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4o",
        "modelVariantPermaslug": "openai/gpt-4o",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4o",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "web_search_options",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000025",
          "completion": "0.00001",
          "image": "0.003613",
          "request": "0",
          "inputCacheRead": "0.00000125",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.05"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.035"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.03"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 35,
        "newest": 258,
        "throughputHighToLow": 43,
        "latencyLowToHigh": 110,
        "pricingLowToHigh": 265,
        "pricingHighToLow": 24
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0.003613",
            "request": "0",
            "inputCacheRead": "0.00000125",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 49.275,
          "latency": 674
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0.003613",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 111.027,
          "latency": 2187
        }
      ]
    },
    {
      "slug": "openai/gpt-4.1-nano",
      "hfSlug": "",
      "updatedAt": "2025-05-12T18:45:58.542641+00:00",
      "createdAt": "2025-04-14T17:22:49+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4.1 Nano",
      "shortName": "GPT-4.1 Nano",
      "author": "openai",
      "description": "For tasks that demand low latency, GPT‑4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding – even higher than GPT‑4o mini. It’s ideal for tasks like classification or autocompletion.",
      "modelVersionGroupId": null,
      "contextLength": 1047576,
      "inputModalities": [
        "image",
        "text",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4.1-nano-2025-04-14",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9251cee5-5503-4be9-9439-7ae21ff062a3",
        "name": "OpenAI | openai/gpt-4.1-nano-2025-04-14",
        "contextLength": 1047576,
        "model": {
          "slug": "openai/gpt-4.1-nano",
          "hfSlug": "",
          "updatedAt": "2025-05-12T18:45:58.542641+00:00",
          "createdAt": "2025-04-14T17:22:49+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4.1 Nano",
          "shortName": "GPT-4.1 Nano",
          "author": "openai",
          "description": "For tasks that demand low latency, GPT‑4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding – even higher than GPT‑4o mini. It’s ideal for tasks like classification or autocompletion.",
          "modelVersionGroupId": null,
          "contextLength": 1047576,
          "inputModalities": [
            "image",
            "text",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4.1-nano-2025-04-14",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4.1-nano",
        "modelVariantPermaslug": "openai/gpt-4.1-nano-2025-04-14",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4.1-nano-2025-04-14",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000004",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.000000025",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 36,
        "newest": 50,
        "throughputHighToLow": 41,
        "latencyLowToHigh": 44,
        "pricingLowToHigh": 127,
        "pricingHighToLow": 189
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 1047576,
          "maxCompletionTokens": 32768,
          "providerModelId": "gpt-4.1-nano-2025-04-14",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.000000025",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.4,
          "throughput": 166.4455,
          "latency": 407
        }
      ]
    },
    {
      "slug": "mistralai/mistral-small-24b-instruct-2501",
      "hfSlug": "mistralai/Mistral-Small-24B-Instruct-2501",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-01-30T16:43:29.33592+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral Small 3",
      "shortName": "Mistral Small 3",
      "author": "mistralai",
      "description": "Mistral Small 3 is a 24B-parameter language model optimized for low-latency performance across common AI tasks. Released under the Apache 2.0 license, it features both pre-trained and instruction-tuned versions designed for efficient local deployment.\n\nThe model achieves 81% accuracy on the MMLU benchmark and performs competitively with larger models like Llama 3.3 70B and Qwen 32B, while operating at three times the speed on equivalent hardware. [Read the blog post about the model here.](https://mistral.ai/news/mistral-small-3/)",
      "modelVersionGroupId": null,
      "contextLength": 28000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-small-24b-instruct-2501",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c059bd0b-f91e-4878-9ad6-4ccf65443b63",
        "name": "Enfer | mistralai/mistral-small-24b-instruct-2501",
        "contextLength": 28000,
        "model": {
          "slug": "mistralai/mistral-small-24b-instruct-2501",
          "hfSlug": "mistralai/Mistral-Small-24B-Instruct-2501",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-01-30T16:43:29.33592+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral Small 3",
          "shortName": "Mistral Small 3",
          "author": "mistralai",
          "description": "Mistral Small 3 is a 24B-parameter language model optimized for low-latency performance across common AI tasks. Released under the Apache 2.0 license, it features both pre-trained and instruction-tuned versions designed for efficient local deployment.\n\nThe model achieves 81% accuracy on the MMLU benchmark and performs competitively with larger models like Llama 3.3 70B and Qwen 32B, while operating at three times the speed on equivalent hardware. [Read the blog post about the model here.](https://mistral.ai/news/mistral-small-3/)",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-small-24b-instruct-2501",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-small-24b-instruct-2501",
        "modelVariantPermaslug": "mistralai/mistral-small-24b-instruct-2501",
        "providerName": "Enfer",
        "providerInfo": {
          "name": "Enfer",
          "displayName": "Enfer",
          "slug": "enfer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://enfer.ai/privacy-policy",
            "privacyPolicyUrl": "https://enfer.ai/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Enfer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256"
          }
        },
        "providerDisplayName": "Enfer",
        "providerModelId": "mistralai/mistral-small-24b-instruct-2501",
        "providerGroup": "Enfer",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 14000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "logit_bias",
          "logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://enfer.ai/privacy-policy",
          "privacyPolicyUrl": "https://enfer.ai/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000006",
          "completion": "0.00000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 37,
        "newest": 131,
        "throughputHighToLow": 79,
        "latencyLowToHigh": 272,
        "pricingLowToHigh": 49,
        "pricingHighToLow": 216
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Enfer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256",
          "slug": "enfer",
          "quantization": null,
          "context": 28000,
          "maxCompletionTokens": 14000,
          "providerModelId": "mistralai/mistral-small-24b-instruct-2501",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logit_bias",
            "logprobs"
          ],
          "inputCost": 0.06,
          "outputCost": 0.12,
          "throughput": 29.9345,
          "latency": 6892
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral:small3",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000013",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.07,
          "outputCost": 0.13,
          "throughput": 38.234,
          "latency": 1662.5
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/Mistral-Small-24B-Instruct-2501",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.07,
          "outputCost": 0.14,
          "throughput": 77.2675,
          "latency": 510
        },
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-small-2501",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 145.0315,
          "latency": 259
        },
        {
          "name": "Ubicloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.ubicloud.com/&size=256",
          "slug": "ubicloud",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "mistral-small-3",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "min_p",
            "seed",
            "response_format",
            "top_k"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 32.4045,
          "latency": 747
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "mistralai/Mistral-Small-24B-Instruct-2501",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 80.305,
          "latency": 654.5
        }
      ]
    },
    {
      "slug": "openai/gpt-4o-2024-11-20",
      "hfSlug": "",
      "updatedAt": "2025-04-23T22:07:38.265826+00:00",
      "createdAt": "2024-11-20T18:33:14.771895+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4o (2024-11-20)",
      "shortName": "GPT-4o (2024-11-20)",
      "author": "openai",
      "description": "The 2024-11-20 version of GPT-4o offers a leveled-up creative writing ability with more natural, engaging, and tailored writing to improve relevance & readability. It’s also better at working with uploaded files, providing deeper insights & more thorough responses.\n\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.",
      "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4o-2024-11-20",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3e86b7c5-bffe-4b60-a3dd-b36451978775",
        "name": "OpenAI | openai/gpt-4o-2024-11-20",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4o-2024-11-20",
          "hfSlug": "",
          "updatedAt": "2025-04-23T22:07:38.265826+00:00",
          "createdAt": "2024-11-20T18:33:14.771895+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4o (2024-11-20)",
          "shortName": "GPT-4o (2024-11-20)",
          "author": "openai",
          "description": "The 2024-11-20 version of GPT-4o offers a leveled-up creative writing ability with more natural, engaging, and tailored writing to improve relevance & readability. It’s also better at working with uploaded files, providing deeper insights & more thorough responses.\n\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.",
          "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4o-2024-11-20",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4o-2024-11-20",
        "modelVariantPermaslug": "openai/gpt-4o-2024-11-20",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4o-2024-11-20",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "web_search_options",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000025",
          "completion": "0.00001",
          "image": "0.003613",
          "request": "0",
          "inputCacheRead": "0.00000125",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.05"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.035"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.03"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 38,
        "newest": 166,
        "throughputHighToLow": 169,
        "latencyLowToHigh": 90,
        "pricingLowToHigh": 260,
        "pricingHighToLow": 54
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o-2024-11-20",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0.003613",
            "request": "0",
            "inputCacheRead": "0.00000125",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 53.115,
          "latency": 605
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.2-1b-instruct",
      "hfSlug": "meta-llama/Llama-3.2-1B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.2 1B Instruct",
      "shortName": "Llama 3.2 1B Instruct",
      "author": "meta-llama",
      "description": "Llama 3.2 1B is a 1-billion-parameter language model focused on efficiently performing natural language tasks, such as summarization, dialogue, and multilingual text analysis. Its smaller size allows it to operate efficiently in low-resource environments while maintaining strong task performance.\n\nSupporting eight core languages and fine-tunable for more, Llama 1.3B is ideal for businesses or developers seeking lightweight yet powerful AI solutions that can operate in diverse multilingual settings without the high computational demand of larger models.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.2-1b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "02c4e6a2-dd12-4efc-81ec-12c8bb5c035e",
        "name": "Nebius | meta-llama/llama-3.2-1b-instruct",
        "contextLength": 131072,
        "model": {
          "slug": "meta-llama/llama-3.2-1b-instruct",
          "hfSlug": "meta-llama/Llama-3.2-1B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.2 1B Instruct",
          "shortName": "Llama 3.2 1B Instruct",
          "author": "meta-llama",
          "description": "Llama 3.2 1B is a 1-billion-parameter language model focused on efficiently performing natural language tasks, such as summarization, dialogue, and multilingual text analysis. Its smaller size allows it to operate efficiently in low-resource environments while maintaining strong task performance.\n\nSupporting eight core languages and fine-tunable for more, Llama 1.3B is ideal for businesses or developers seeking lightweight yet powerful AI solutions that can operate in diverse multilingual settings without the high computational demand of larger models.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.2-1b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.2-1b-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3.2-1b-instruct",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "meta-llama/Llama-3.2-1B-Instruct",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000000005",
          "completion": "0.00000001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 39,
        "newest": 199,
        "throughputHighToLow": 4,
        "latencyLowToHigh": 91,
        "pricingLowToHigh": 62,
        "pricingHighToLow": 247
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.2-1B-Instruct",
          "pricing": {
            "prompt": "0.000000005",
            "completion": "0.00000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.01,
          "outputCost": 0.01,
          "throughput": 31.5455,
          "latency": 583
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.2-1B-Instruct",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.01,
          "outputCost": 0.01,
          "throughput": 144.546,
          "latency": 649
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.2-1b-instruct/fp-16",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.01,
          "outputCost": 0.01,
          "throughput": 143.192,
          "latency": 1023
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": "unknown",
          "context": 60000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.2-1b-instruct",
          "pricing": {
            "prompt": "0.000000027",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.03,
          "outputCost": 0.2,
          "throughput": 277.904,
          "latency": 789
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "Meta-Llama-3.2-1B-Instruct",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.04,
          "outputCost": 0.08,
          "throughput": 4054.054,
          "latency": 827
        }
      ]
    },
    {
      "slug": "nousresearch/hermes-3-llama-3.1-70b",
      "hfSlug": "NousResearch/Hermes-3-Llama-3.1-70B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-18T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 3 70B Instruct",
      "shortName": "Hermes 3 70B Instruct",
      "author": "nousresearch",
      "description": "Hermes 3 is a generalist language model with many improvements over [Hermes 2](/models/nousresearch/nous-hermes-2-mistral-7b-dpo), including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nHermes 3 70B is a competitive, if not superior finetune of the [Llama-3.1 70B foundation model](/models/meta-llama/llama-3.1-70b-instruct), focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\nThe Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/hermes-3-llama-3.1-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "0ad886d0-f895-4fd0-857c-b242deeb3516",
        "name": "Lambda | nousresearch/hermes-3-llama-3.1-70b",
        "contextLength": 131072,
        "model": {
          "slug": "nousresearch/hermes-3-llama-3.1-70b",
          "hfSlug": "NousResearch/Hermes-3-Llama-3.1-70B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-18T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Nous: Hermes 3 70B Instruct",
          "shortName": "Hermes 3 70B Instruct",
          "author": "nousresearch",
          "description": "Hermes 3 is a generalist language model with many improvements over [Hermes 2](/models/nousresearch/nous-hermes-2-mistral-7b-dpo), including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nHermes 3 70B is a competitive, if not superior finetune of the [Llama-3.1 70B foundation model](/models/meta-llama/llama-3.1-70b-instruct), focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\nThe Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nousresearch/hermes-3-llama-3.1-70b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nousresearch/hermes-3-llama-3.1-70b",
        "modelVariantPermaslug": "nousresearch/hermes-3-llama-3.1-70b",
        "providerName": "Lambda",
        "providerInfo": {
          "name": "Lambda",
          "displayName": "Lambda",
          "slug": "lambda",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
            "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Lambda",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256"
          }
        },
        "providerDisplayName": "Lambda",
        "providerModelId": "hermes3-70b",
        "providerGroup": "Lambda",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 131072,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
          "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000012",
          "completion": "0.0000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 40,
        "newest": 218,
        "throughputHighToLow": 173,
        "latencyLowToHigh": 76,
        "pricingLowToHigh": 131,
        "pricingHighToLow": 188
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": [
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "hermes3-70b",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.12,
          "outputCost": 0.3,
          "throughput": 52.3125,
          "latency": 1491
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 12288,
          "maxCompletionTokens": null,
          "providerModelId": "NousResearch/Hermes-3-Llama-3.1-70B",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 34.512,
          "latency": 861.5
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-chat",
      "hfSlug": "deepseek-ai/DeepSeek-V3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-26T19:28:40.559917+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: DeepSeek V3 (free)",
      "shortName": "DeepSeek V3 (free)",
      "author": "deepseek",
      "description": "DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions. Pre-trained on nearly 15 trillion tokens, the reported evaluations reveal that the model outperforms other open-source models and rivals leading closed-source models.\n\nFor model details, please visit [the DeepSeek-V3 repo](https://github.com/deepseek-ai/DeepSeek-V3) for more information, or see the [launch announcement](https://api-docs.deepseek.com/news/news1226).",
      "modelVersionGroupId": null,
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-chat-v3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cac452eb-4e38-4952-ad98-f59f68204bda",
        "name": "Chutes | deepseek/deepseek-chat-v3:free",
        "contextLength": 163840,
        "model": {
          "slug": "deepseek/deepseek-chat",
          "hfSlug": "deepseek-ai/DeepSeek-V3",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-26T19:28:40.559917+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: DeepSeek V3",
          "shortName": "DeepSeek V3",
          "author": "deepseek",
          "description": "DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions. Pre-trained on nearly 15 trillion tokens, the reported evaluations reveal that the model outperforms other open-source models and rivals leading closed-source models.\n\nFor model details, please visit [the DeepSeek-V3 repo](https://github.com/deepseek-ai/DeepSeek-V3) for more information, or see the [launch announcement](https://api-docs.deepseek.com/news/news1226).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-chat-v3",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "deepseek/deepseek-chat:free",
        "modelVariantPermaslug": "deepseek/deepseek-chat-v3:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "deepseek-ai/DeepSeek-V3",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 28,
        "newest": 148,
        "throughputHighToLow": 126,
        "latencyLowToHigh": 119,
        "pricingLowToHigh": 54,
        "pricingHighToLow": 146
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": 163840,
          "providerModelId": "deepseek-ai/DeepSeek-V3",
          "pricing": {
            "prompt": "0.00000038",
            "completion": "0.00000089",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.38,
          "outputCost": 0.89,
          "throughput": 22.937,
          "latency": 689
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 16000,
          "providerModelId": "deepseek/deepseek-v3-turbo",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000013",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.4,
          "outputCost": 1.3,
          "throughput": 26.703,
          "latency": 887
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-V3",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 20.009,
          "latency": 422
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/deepseek-v3",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 50.9045,
          "latency": 1684
        }
      ]
    },
    {
      "slug": "meta-llama/llama-4-scout",
      "hfSlug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "updatedAt": "2025-04-05T19:34:05.019062+00:00",
      "createdAt": "2025-04-05T19:31:59.735804+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 4 Scout",
      "shortName": "Llama 4 Scout",
      "author": "meta-llama",
      "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
      "modelVersionGroupId": null,
      "contextLength": 1048576,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cf59e549-6141-4393-b073-3cf13b31c187",
        "name": "Lambda | meta-llama/llama-4-scout-17b-16e-instruct",
        "contextLength": 1048576,
        "model": {
          "slug": "meta-llama/llama-4-scout",
          "hfSlug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "updatedAt": "2025-04-05T19:34:05.019062+00:00",
          "createdAt": "2025-04-05T19:31:59.735804+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 4 Scout",
          "shortName": "Llama 4 Scout",
          "author": "meta-llama",
          "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
          "modelVersionGroupId": null,
          "contextLength": 10000000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-4-scout",
        "modelVariantPermaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "providerName": "Lambda",
        "providerInfo": {
          "name": "Lambda",
          "displayName": "Lambda",
          "slug": "lambda",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
            "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Lambda",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256"
          }
        },
        "providerDisplayName": "Lambda",
        "providerModelId": "llama-4-scout-17b-16e-instruct",
        "providerGroup": "Lambda",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 1048576,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
          "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000008",
          "completion": "0.0000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 42,
        "newest": 63,
        "throughputHighToLow": 76,
        "latencyLowToHigh": 43,
        "pricingLowToHigh": 27,
        "pricingHighToLow": 201
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "llama-4-scout-17b-16e-instruct",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.08,
          "outputCost": 0.3,
          "throughput": 99.2805,
          "latency": 816
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 327680,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.0000003",
            "image": "0.0003342",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.08,
          "outputCost": 0.3,
          "throughput": 45.32,
          "latency": 845
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000045",
            "image": "0.0005013",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.08,
          "outputCost": 0.45,
          "throughput": 59.9425,
          "latency": 585
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 158000,
          "maxCompletionTokens": 158000,
          "providerModelId": "parasail-llama-4-scout-instruct",
          "pricing": {
            "prompt": "0.00000009",
            "completion": "0.00000048",
            "image": "0.00046788",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.09,
          "outputCost": 0.48,
          "throughput": 96.079,
          "latency": 618.5
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "bf16",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 81.2295,
          "latency": 403
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "meta-llama/llama-4-scout-17b-16e-instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000005",
            "image": "0.0003342",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.1,
          "outputCost": 0.5,
          "throughput": 33.2045,
          "latency": 1303
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 8192,
          "providerModelId": "meta-llama/llama-4-scout-17b-16e-instruct",
          "pricing": {
            "prompt": "0.00000011",
            "completion": "0.00000034",
            "image": "0.00036762",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.11,
          "outputCost": 0.34,
          "throughput": 707.1805,
          "latency": 603
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama4-scout-instruct-basic",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 97.3415,
          "latency": 650
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "bf16",
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "seed"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 100.231,
          "latency": 921
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000059",
            "image": "0.00090234",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.59,
          "throughput": 98.2635,
          "latency": 529
        },
        {
          "name": "Cerebras",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cerebras.ai/&size=256",
          "slug": "cerebras",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "llama-4-scout-17b-16e-instruct",
          "pricing": {
            "prompt": "0.00000065",
            "completion": "0.00000085",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.65,
          "outputCost": 0.85,
          "throughput": 6936.2505,
          "latency": 323
        }
      ]
    },
    {
      "slug": "qwen/qwen3-32b",
      "hfSlug": "Qwen/Qwen3-32B",
      "updatedAt": "2025-05-11T22:45:44.273213+00:00",
      "createdAt": "2025-04-28T21:32:25.189881+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 32B",
      "shortName": "Qwen3 32B",
      "author": "qwen",
      "description": "Qwen3-32B is a dense 32.8B parameter causal language model from the Qwen3 series, optimized for both complex reasoning and efficient dialogue. It supports seamless switching between a \"thinking\" mode for tasks like math, coding, and logical inference, and a \"non-thinking\" mode for faster, general-purpose conversation. The model demonstrates strong performance in instruction-following, agent tool use, creative writing, and multilingual tasks across 100+ languages and dialects. It natively handles 32K token contexts and can extend to 131K tokens using YaRN-based scaling. ",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-32b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "6b8c829d-3094-45e7-8139-0a67e09060c3",
        "name": "DeepInfra | qwen/qwen3-32b-04-28",
        "contextLength": 40960,
        "model": {
          "slug": "qwen/qwen3-32b",
          "hfSlug": "Qwen/Qwen3-32B",
          "updatedAt": "2025-05-11T22:45:44.273213+00:00",
          "createdAt": "2025-04-28T21:32:25.189881+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 32B",
          "shortName": "Qwen3 32B",
          "author": "qwen",
          "description": "Qwen3-32B is a dense 32.8B parameter causal language model from the Qwen3 series, optimized for both complex reasoning and efficient dialogue. It supports seamless switching between a \"thinking\" mode for tasks like math, coding, and logical inference, and a \"non-thinking\" mode for faster, general-purpose conversation. The model demonstrates strong performance in instruction-following, agent tool use, creative writing, and multilingual tasks across 100+ languages and dialects. It natively handles 32K token contexts and can extend to 131K tokens using YaRN-based scaling. ",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-32b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-32b",
        "modelVariantPermaslug": "qwen/qwen3-32b-04-28",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Qwen/Qwen3-32B",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 43,
        "newest": 28,
        "throughputHighToLow": 133,
        "latencyLowToHigh": 142,
        "pricingLowToHigh": 12,
        "pricingHighToLow": 194
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-32B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 45.37,
          "latency": 873
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-32B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 31.8995,
          "latency": 801
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-32b-fp8",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.00000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.1,
          "outputCost": 0.45,
          "throughput": 30.4325,
          "latency": 975
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "parasail-qwen3-32b",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.1,
          "outputCost": 0.5,
          "throughput": 49.746,
          "latency": 813
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-32B-FP8",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "seed"
          ],
          "inputCost": 0.3,
          "outputCost": 0.6,
          "throughput": 57.57,
          "latency": 734.5
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": 4096,
          "providerModelId": "Qwen3-32B",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "stop"
          ],
          "inputCost": 0.4,
          "outputCost": 0.8,
          "throughput": 320.3015,
          "latency": 1143
        }
      ]
    },
    {
      "slug": "x-ai/grok-3-beta",
      "hfSlug": "",
      "updatedAt": "2025-04-18T22:22:00.948066+00:00",
      "createdAt": "2025-04-09T23:07:48.450334+00:00",
      "hfUpdatedAt": null,
      "name": "xAI: Grok 3 Beta",
      "shortName": "Grok 3 Beta",
      "author": "x-ai",
      "description": "Grok 3 is the latest model from xAI. It's their flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.\n\nExcels in structured tasks and benchmarks like GPQA, LCB, and MMLU-Pro where it outperforms Grok 3 Mini even on high thinking. \n\nNote: That there are two xAI endpoints for this model. By default when using this model we will always route you to the base endpoint. If you want the fast endpoint you can add `provider: { sort: throughput}`, to sort by throughput instead. \n",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Grok",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "x-ai/grok-3-beta",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ac4e073c-740f-4e9f-9e38-bde83e4ab515",
        "name": "xAI | x-ai/grok-3-beta",
        "contextLength": 131072,
        "model": {
          "slug": "x-ai/grok-3-beta",
          "hfSlug": "",
          "updatedAt": "2025-04-18T22:22:00.948066+00:00",
          "createdAt": "2025-04-09T23:07:48.450334+00:00",
          "hfUpdatedAt": null,
          "name": "xAI: Grok 3 Beta",
          "shortName": "Grok 3 Beta",
          "author": "x-ai",
          "description": "Grok 3 is the latest model from xAI. It's their flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.\n\nExcels in structured tasks and benchmarks like GPQA, LCB, and MMLU-Pro where it outperforms Grok 3 Mini even on high thinking. \n\nNote: That there are two xAI endpoints for this model. By default when using this model we will always route you to the base endpoint. If you want the fast endpoint you can add `provider: { sort: throughput}`, to sort by throughput instead. \n",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Grok",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "x-ai/grok-3-beta",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "x-ai/grok-3-beta",
        "modelVariantPermaslug": "x-ai/grok-3-beta",
        "providerName": "xAI",
        "providerInfo": {
          "name": "xAI",
          "displayName": "xAI",
          "slug": "xai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "xAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.x.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256"
          }
        },
        "providerDisplayName": "xAI",
        "providerModelId": "grok-3-beta",
        "providerGroup": "xAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 44,
        "newest": 57,
        "throughputHighToLow": 217,
        "latencyLowToHigh": 151,
        "pricingLowToHigh": 267,
        "pricingHighToLow": 39
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://x.ai/\\u0026size=256",
      "providers": [
        {
          "name": "xAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256",
          "slug": "xAi",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "grok-3-beta",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 39.8155,
          "latency": 864
        },
        {
          "name": "xAI Fast",
          "icon": "",
          "slug": "xAiFast",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "grok-3-fast-beta",
          "pricing": {
            "prompt": "0.000005",
            "completion": "0.000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 5,
          "outputCost": 25,
          "throughput": 49.571,
          "latency": 882.5
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.2-3b-instruct",
      "hfSlug": "meta-llama/Llama-3.2-3B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.2 3B Instruct",
      "shortName": "Llama 3.2 3B Instruct",
      "author": "meta-llama",
      "description": "Llama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with the latest transformer architecture, it supports eight languages, including English, Spanish, and Hindi, and is adaptable for additional languages.\n\nTrained on 9 trillion tokens, the Llama 3.2 3B model excels in instruction-following, complex reasoning, and tool use. Its balanced performance makes it ideal for applications needing accuracy and efficiency in text generation across multilingual settings.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.2-3b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e462c1ad-93b6-4047-b27d-239e3ba51989",
        "name": "DeepInfra | meta-llama/llama-3.2-3b-instruct",
        "contextLength": 131072,
        "model": {
          "slug": "meta-llama/llama-3.2-3b-instruct",
          "hfSlug": "meta-llama/Llama-3.2-3B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.2 3B Instruct",
          "shortName": "Llama 3.2 3B Instruct",
          "author": "meta-llama",
          "description": "Llama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with the latest transformer architecture, it supports eight languages, including English, Spanish, and Hindi, and is adaptable for additional languages.\n\nTrained on 9 trillion tokens, the Llama 3.2 3B model excels in instruction-following, complex reasoning, and tool use. Its balanced performance makes it ideal for applications needing accuracy and efficiency in text generation across multilingual settings.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.2-3b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.2-3b-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3.2-3b-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "meta-llama/Llama-3.2-3B-Instruct",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000001",
          "completion": "0.00000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 45,
        "newest": 197,
        "throughputHighToLow": 1,
        "latencyLowToHigh": 11,
        "pricingLowToHigh": 61,
        "pricingHighToLow": 245
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.2-3B-Instruct",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.01,
          "outputCost": 0.02,
          "throughput": 112.3055,
          "latency": 225
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.2-3B-Instruct",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.01,
          "outputCost": 0.02,
          "throughput": 111.182,
          "latency": 245
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.2-3b-instruct",
          "pricing": {
            "prompt": "0.000000015",
            "completion": "0.000000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.01,
          "outputCost": 0.02,
          "throughput": 305.3715,
          "latency": 693
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.2-3b-instruct/fp-16",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.02,
          "outputCost": 0.02,
          "throughput": 85.271,
          "latency": 930
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/llama-3.2-3b-instruct",
          "pricing": {
            "prompt": "0.00000003",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.03,
          "outputCost": 0.05,
          "throughput": 108.7615,
          "latency": 559
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.2-3b-instruct",
          "pricing": {
            "prompt": "0.000000051",
            "completion": "0.00000034",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.05,
          "outputCost": 0.34,
          "throughput": 157.798,
          "latency": 575
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.06,
          "outputCost": 0.06,
          "throughput": 163.087,
          "latency": 569.5
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "Meta-Llama-3.2-3B-Instruct",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000016",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.08,
          "outputCost": 0.16,
          "throughput": 3051.282,
          "latency": 653.5
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.2-3B-Instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 113.793,
          "latency": 1108
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.5-sonnet",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.5 Sonnet (self-moderated)",
      "shortName": "Claude 3.5 Sonnet (self-moderated)",
      "author": "anthropic",
      "description": "New Claude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Scores ~49% on SWE-Bench Verified, higher than the last best score, and without any fancy prompt scaffolding\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\n#multimodal",
      "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3.5-sonnet",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "07be01e7-3f6a-4b0f-854b-103b7b0a7ad5",
        "name": "Anthropic | anthropic/claude-3.5-sonnet:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.5-sonnet",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.5 Sonnet",
          "shortName": "Claude 3.5 Sonnet",
          "author": "anthropic",
          "description": "New Claude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Scores ~49% on SWE-Bench Verified, higher than the last best score, and without any fancy prompt scaffolding\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\n#multimodal",
          "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3.5-sonnet",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.5-sonnet:beta",
        "modelVariantPermaslug": "anthropic/claude-3.5-sonnet:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-5-sonnet-20241022",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0.0048",
          "request": "0",
          "inputCacheRead": "0.0000003",
          "inputCacheWrite": "0.00000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 19,
        "newest": 183,
        "throughputHighToLow": 137,
        "latencyLowToHigh": 210,
        "pricingLowToHigh": 272,
        "pricingHighToLow": 44
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet-20241022",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 57.817,
          "latency": 1363
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet-v2@20241022",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 60.7715,
          "latency": 1380.5
        },
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 35.699,
          "latency": 1793.5
        },
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 37.745,
          "latency": 1627
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet-v2@20241022",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 60.0465,
          "latency": 1024
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.5-haiku",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-04T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.5 Haiku",
      "shortName": "Claude 3.5 Haiku",
      "author": "anthropic",
      "description": "Claude 3.5 Haiku features offers enhanced capabilities in speed, coding accuracy, and tool use. Engineered to excel in real-time applications, it delivers quick response times that are essential for dynamic tasks such as chat interactions and immediate coding suggestions.\n\nThis makes it highly suitable for environments that demand both speed and precision, such as software development, customer service bots, and data management systems.\n\nThis model is currently pointing to [Claude 3.5 Haiku (2024-10-22)](/anthropic/claude-3-5-haiku-20241022).",
      "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-5-haiku",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ced809d4-9715-4634-8b4d-ea0e09d6bb85",
        "name": "Anthropic | anthropic/claude-3-5-haiku",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.5-haiku",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-04T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.5 Haiku",
          "shortName": "Claude 3.5 Haiku",
          "author": "anthropic",
          "description": "Claude 3.5 Haiku features offers enhanced capabilities in speed, coding accuracy, and tool use. Engineered to excel in real-time applications, it delivers quick response times that are essential for dynamic tasks such as chat interactions and immediate coding suggestions.\n\nThis makes it highly suitable for environments that demand both speed and precision, such as software development, customer service bots, and data management systems.\n\nThis model is currently pointing to [Claude 3.5 Haiku (2024-10-22)](/anthropic/claude-3-5-haiku-20241022).",
          "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-5-haiku",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.5-haiku",
        "modelVariantPermaslug": "anthropic/claude-3-5-haiku",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-5-haiku-20241022",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.000004",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.00000008",
          "inputCacheWrite": "0.000001",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 47,
        "newest": 177,
        "throughputHighToLow": 153,
        "latencyLowToHigh": 187,
        "pricingLowToHigh": 219,
        "pricingHighToLow": 93
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-haiku-20241022",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 56.889,
          "latency": 1182
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-haiku@20241022",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 59.854,
          "latency": 2483
        },
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 53.981,
          "latency": 1478
        },
        {
          "name": "Amazon Bedrock (US-WEST)",
          "icon": "",
          "slug": "amazonBedrock (usWest)",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 55.934,
          "latency": 1301.5
        }
      ]
    },
    {
      "slug": "openai/o4-mini-high",
      "hfSlug": "",
      "updatedAt": "2025-04-23T18:37:59.660815+00:00",
      "createdAt": "2025-04-16T17:23:32.042157+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o4 Mini High",
      "shortName": "o4 Mini High",
      "author": "openai",
      "description": "OpenAI o4-mini-high is the same model as [o4-mini](/openai/o4-mini) with reasoning_effort set to high. \n\nOpenAI o4-mini is a compact reasoning model in the o-series, optimized for fast, cost-efficient performance while retaining strong multimodal and agentic capabilities. It supports tool use and demonstrates competitive reasoning and coding performance across benchmarks like AIME (99.5% with Python) and SWE-bench, outperforming its predecessor o3-mini and even approaching o3 in some domains.\n\nDespite its smaller size, o4-mini exhibits high accuracy in STEM tasks, visual problem solving (e.g., MathVista, MMMU), and code editing. It is especially well-suited for high-throughput scenarios where latency or cost is critical. Thanks to its efficient architecture and refined reinforcement learning training, o4-mini can chain tools, generate structured outputs, and solve multi-step tasks with minimal delay—often in under a minute.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "image",
        "text",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "openai/o4-mini-high-2025-04-16",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "60020533-2fb2-4aa1-9454-181029fd52de",
        "name": "OpenAI | openai/o4-mini-high-2025-04-16",
        "contextLength": 200000,
        "model": {
          "slug": "openai/o4-mini-high",
          "hfSlug": "",
          "updatedAt": "2025-04-23T18:37:59.660815+00:00",
          "createdAt": "2025-04-16T17:23:32.042157+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o4 Mini High",
          "shortName": "o4 Mini High",
          "author": "openai",
          "description": "OpenAI o4-mini-high is the same model as [o4-mini](/openai/o4-mini) with reasoning_effort set to high. \n\nOpenAI o4-mini is a compact reasoning model in the o-series, optimized for fast, cost-efficient performance while retaining strong multimodal and agentic capabilities. It supports tool use and demonstrates competitive reasoning and coding performance across benchmarks like AIME (99.5% with Python) and SWE-bench, outperforming its predecessor o3-mini and even approaching o3 in some domains.\n\nDespite its smaller size, o4-mini exhibits high accuracy in STEM tasks, visual problem solving (e.g., MathVista, MMMU), and code editing. It is especially well-suited for high-throughput scenarios where latency or cost is critical. Thanks to its efficient architecture and refined reinforcement learning training, o4-mini can chain tools, generate structured outputs, and solve multi-step tasks with minimal delay—often in under a minute.",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "image",
            "text",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "openai/o4-mini-high-2025-04-16",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o4-mini-high",
        "modelVariantPermaslug": "openai/o4-mini-high-2025-04-16",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o4-mini-2025-04-16",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 100000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "seed",
          "max_tokens",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000011",
          "completion": "0.0000044",
          "image": "0.0008415",
          "request": "0",
          "inputCacheRead": "0.000000275",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {
            "responseFormat": true,
            "structuredOutputs": true
          },
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 48,
        "newest": 43,
        "throughputHighToLow": 91,
        "latencyLowToHigh": 295,
        "pricingLowToHigh": 229,
        "pricingHighToLow": 84
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 100000,
          "providerModelId": "o4-mini-2025-04-16",
          "pricing": {
            "prompt": "0.0000011",
            "completion": "0.0000044",
            "image": "0.0008415",
            "request": "0",
            "inputCacheRead": "0.000000275",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "seed",
            "max_tokens",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1.1,
          "outputCost": 4.4,
          "throughput": 88.2975,
          "latency": 4952
        }
      ]
    },
    {
      "slug": "gryphe/mythomax-l2-13b",
      "hfSlug": "Gryphe/MythoMax-L2-13b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "MythoMax 13B",
      "shortName": "MythoMax 13B",
      "author": "gryphe",
      "description": "One of the highest performing and most popular fine-tunes of Llama 2 13B, with rich descriptions and roleplay. #merge",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "gryphe/mythomax-l2-13b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ffd94635-42cb-47e4-988a-b905c2e7fa57",
        "name": "DeepInfra | gryphe/mythomax-l2-13b",
        "contextLength": 4096,
        "model": {
          "slug": "gryphe/mythomax-l2-13b",
          "hfSlug": "Gryphe/MythoMax-L2-13b",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-07-02T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "MythoMax 13B",
          "shortName": "MythoMax 13B",
          "author": "gryphe",
          "description": "One of the highest performing and most popular fine-tunes of Llama 2 13B, with rich descriptions and roleplay. #merge",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "alpaca",
          "defaultSystem": null,
          "defaultStops": [
            "###",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "gryphe/mythomax-l2-13b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "gryphe/mythomax-l2-13b",
        "modelVariantPermaslug": "gryphe/mythomax-l2-13b",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Gryphe/MythoMax-L2-13b",
        "providerGroup": "DeepInfra",
        "quantization": "fp16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000000065",
          "completion": "0.000000065",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 49,
        "newest": 313,
        "throughputHighToLow": 283,
        "latencyLowToHigh": 58,
        "pricingLowToHigh": 101,
        "pricingHighToLow": 217
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp16",
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "Gryphe/MythoMax-L2-13b",
          "pricing": {
            "prompt": "0.000000065",
            "completion": "0.000000065",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.07,
          "outputCost": 0.07,
          "throughput": 18.008,
          "latency": 475
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 4096,
          "maxCompletionTokens": null,
          "providerModelId": "gryphe/mythomax-l2-13b",
          "pricing": {
            "prompt": "0.00000009",
            "completion": "0.00000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.09,
          "outputCost": 0.09,
          "throughput": 81.8995,
          "latency": 1070
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp16",
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "parasail-mythomax-13b",
          "pricing": {
            "prompt": "0.00000011",
            "completion": "0.00000011",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.11,
          "outputCost": 0.11,
          "throughput": 47.6385,
          "latency": 544
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "int4",
          "context": 4096,
          "maxCompletionTokens": null,
          "providerModelId": "Gryphe/MythoMax-L2-13b-Lite",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.4,
          "throughput": 111.351,
          "latency": 526
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 4096,
          "maxCompletionTokens": null,
          "providerModelId": "Gryphe/MythoMax-L2-13b",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 135.135,
          "latency": 419
        },
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 1024,
          "providerModelId": "mythomax",
          "pricing": {
            "prompt": "0.0000005625",
            "completion": "0.00000084375",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.56,
          "outputCost": 0.84,
          "throughput": 42.1135,
          "latency": 934.5
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 1024,
          "providerModelId": "mythomax",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 1,
          "outputCost": 1.5,
          "throughput": 43.637,
          "latency": 794
        }
      ]
    },
    {
      "slug": "microsoft/mai-ds-r1",
      "hfSlug": "microsoft/MAI-DS-R1",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-04-21T00:08:20.257185+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: MAI DS R1 (free)",
      "shortName": "MAI DS R1 (free)",
      "author": "microsoft",
      "description": "MAI-DS-R1 is a post-trained variant of DeepSeek-R1 developed by the Microsoft AI team to improve the model’s responsiveness on previously blocked topics while enhancing its safety profile. Built on top of DeepSeek-R1’s reasoning foundation, it integrates 110k examples from the Tulu-3 SFT dataset and 350k internally curated multilingual safety-alignment samples. The model retains strong reasoning, coding, and problem-solving capabilities, while unblocking a wide range of prompts previously restricted in R1.\n\nMAI-DS-R1 demonstrates improved performance on harm mitigation benchmarks and maintains competitive results across general reasoning tasks. It surpasses R1-1776 in satisfaction metrics for blocked queries and reduces leakage in harmful content categories. The model is based on a transformer MoE architecture and is suitable for general-purpose use cases, excluding high-stakes domains such as legal, medical, or autonomous systems.",
      "modelVersionGroupId": null,
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/mai-ds-r1",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "0cab7863-8f43-47de-9cc6-c3bbf3354c9a",
        "name": "Chutes | microsoft/mai-ds-r1:free",
        "contextLength": 163840,
        "model": {
          "slug": "microsoft/mai-ds-r1",
          "hfSlug": "microsoft/MAI-DS-R1",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-04-21T00:08:20.257185+00:00",
          "hfUpdatedAt": null,
          "name": "Microsoft: MAI DS R1",
          "shortName": "MAI DS R1",
          "author": "microsoft",
          "description": "MAI-DS-R1 is a post-trained variant of DeepSeek-R1 developed by the Microsoft AI team to improve the model’s responsiveness on previously blocked topics while enhancing its safety profile. Built on top of DeepSeek-R1’s reasoning foundation, it integrates 110k examples from the Tulu-3 SFT dataset and 350k internally curated multilingual safety-alignment samples. The model retains strong reasoning, coding, and problem-solving capabilities, while unblocking a wide range of prompts previously restricted in R1.\n\nMAI-DS-R1 demonstrates improved performance on harm mitigation benchmarks and maintains competitive results across general reasoning tasks. It surpasses R1-1776 in satisfaction metrics for blocked queries and reduces leakage in harmful content categories. The model is based on a transformer MoE architecture and is suitable for general-purpose use cases, excluding high-stakes domains such as legal, medical, or autonomous systems.",
          "modelVersionGroupId": null,
          "contextLength": 163840,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/mai-ds-r1",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "microsoft/mai-ds-r1:free",
        "modelVariantPermaslug": "microsoft/mai-ds-r1:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "microsoft/MAI-DS-R1-FP8",
        "providerGroup": "Chutes",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 50,
        "newest": 36,
        "throughputHighToLow": 196,
        "latencyLowToHigh": 223,
        "pricingLowToHigh": 17,
        "pricingHighToLow": 265
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": []
    },
    {
      "slug": "nousresearch/hermes-3-llama-3.1-405b",
      "hfSlug": "NousResearch/Hermes-3-Llama-3.1-405B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 3 405B Instruct",
      "shortName": "Hermes 3 405B Instruct",
      "author": "nousresearch",
      "description": "Hermes 3 is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nHermes 3 405B is a frontier-level, full-parameter finetune of the Llama-3.1 405B foundation model, focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\nThe Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.\n\nHermes 3 is competitive, if not superior, to Llama-3.1 Instruct models at general capabilities, with varying strengths and weaknesses attributable between the two.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/hermes-3-llama-3.1-405b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b0373fc3-d0ac-4873-9253-25cdda872398",
        "name": "Lambda | nousresearch/hermes-3-llama-3.1-405b",
        "contextLength": 131072,
        "model": {
          "slug": "nousresearch/hermes-3-llama-3.1-405b",
          "hfSlug": "NousResearch/Hermes-3-Llama-3.1-405B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-16T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Nous: Hermes 3 405B Instruct",
          "shortName": "Hermes 3 405B Instruct",
          "author": "nousresearch",
          "description": "Hermes 3 is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nHermes 3 405B is a frontier-level, full-parameter finetune of the Llama-3.1 405B foundation model, focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\nThe Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.\n\nHermes 3 is competitive, if not superior, to Llama-3.1 Instruct models at general capabilities, with varying strengths and weaknesses attributable between the two.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nousresearch/hermes-3-llama-3.1-405b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nousresearch/hermes-3-llama-3.1-405b",
        "modelVariantPermaslug": "nousresearch/hermes-3-llama-3.1-405b",
        "providerName": "Lambda",
        "providerInfo": {
          "name": "Lambda",
          "displayName": "Lambda",
          "slug": "lambda",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
            "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Lambda",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256"
          }
        },
        "providerDisplayName": "Lambda",
        "providerModelId": "hermes3-405b",
        "providerGroup": "Lambda",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 131072,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
          "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 51,
        "newest": 219,
        "throughputHighToLow": 239,
        "latencyLowToHigh": 163,
        "pricingLowToHigh": 200,
        "pricingHighToLow": 116
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": [
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "hermes3-405b",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 32.6665,
          "latency": 1416
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "NousResearch/Hermes-3-Llama-3.1-405B",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 11.81,
          "latency": 1269.5
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "NousResearch/Hermes-3-Llama-405B",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 1,
          "outputCost": 3,
          "throughput": 32.11,
          "latency": 680
        }
      ]
    },
    {
      "slug": "qwen/qwen3-235b-a22b",
      "hfSlug": "Qwen/Qwen3-235B-A22B",
      "updatedAt": "2025-05-11T22:44:42.939095+00:00",
      "createdAt": "2025-04-28T21:29:17.25671+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 235B A22B (free)",
      "shortName": "Qwen3 235B A22B (free)",
      "author": "qwen",
      "description": "Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless switching between a \"thinking\" mode for complex reasoning, math, and code tasks, and a \"non-thinking\" mode for general conversational efficiency. The model demonstrates strong reasoning ability, multilingual support (100+ languages and dialects), advanced instruction-following, and agent tool-calling capabilities. It natively handles a 32K token context window and extends up to 131K tokens using YaRN-based scaling.",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-235b-a22b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "07a9c185-53ed-4806-9623-520d0a4e57f3",
        "name": "Chutes | qwen/qwen3-235b-a22b-04-28:free",
        "contextLength": 40960,
        "model": {
          "slug": "qwen/qwen3-235b-a22b",
          "hfSlug": "Qwen/Qwen3-235B-A22B",
          "updatedAt": "2025-05-11T22:44:42.939095+00:00",
          "createdAt": "2025-04-28T21:29:17.25671+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 235B A22B",
          "shortName": "Qwen3 235B A22B",
          "author": "qwen",
          "description": "Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless switching between a \"thinking\" mode for complex reasoning, math, and code tasks, and a \"non-thinking\" mode for general conversational efficiency. The model demonstrates strong reasoning ability, multilingual support (100+ languages and dialects), advanced instruction-following, and agent tool-calling capabilities. It natively handles a 32K token context window and extends up to 131K tokens using YaRN-based scaling.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-235b-a22b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-235b-a22b:free",
        "modelVariantPermaslug": "qwen/qwen3-235b-a22b-04-28:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/Qwen3-235B-A22B",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 24,
        "newest": 30,
        "throughputHighToLow": 244,
        "latencyLowToHigh": 180,
        "pricingLowToHigh": 13,
        "pricingHighToLow": 178
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/Qwen3-235B-A22B",
          "pricing": {
            "prompt": "0.00000014",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.14,
          "outputCost": 0.6,
          "throughput": 23.0245,
          "latency": 1201
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/Qwen3-235B-A22B-FP8",
          "pricing": {
            "prompt": "0.00000014",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.14,
          "outputCost": 2,
          "throughput": 41.1275,
          "latency": 792
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "parasail-qwen3-235b-a22b",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000085",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.18,
          "outputCost": 0.85,
          "throughput": 56.146,
          "latency": 961
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-235B-A22B-fp8-tput",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 30.3685,
          "latency": 831
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-235B-A22B",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 31.8295,
          "latency": 701
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-235b-a22b-fp8",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.2,
          "outputCost": 0.8,
          "throughput": 55.649,
          "latency": 1289
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwen3-235b-a22b",
          "pricing": {
            "prompt": "0.00000022",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.22,
          "outputCost": 0.88,
          "throughput": 54.1885,
          "latency": 856
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-235B-A22B-FP8",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000109",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "seed"
          ],
          "inputCost": 0.25,
          "outputCost": 1.09,
          "throughput": 48.5485,
          "latency": 933.5
        }
      ]
    },
    {
      "slug": "tngtech/deepseek-r1t-chimera",
      "hfSlug": "tngtech/DeepSeek-R1T-Chimera",
      "updatedAt": "2025-05-13T18:40:57.812622+00:00",
      "createdAt": "2025-04-27T13:34:35.172638+00:00",
      "hfUpdatedAt": null,
      "name": "TNG: DeepSeek R1T Chimera (free)",
      "shortName": "DeepSeek R1T Chimera (free)",
      "author": "tngtech",
      "description": "DeepSeek-R1T-Chimera is created by merging DeepSeek-R1 and DeepSeek-V3 (0324), combining the reasoning capabilities of R1 with the token efficiency improvements of V3. It is based on a DeepSeek-MoE Transformer architecture and is optimized for general text generation tasks.\n\nThe model merges pretrained weights from both source models to balance performance across reasoning, efficiency, and instruction-following tasks. It is released under the MIT license and intended for research and commercial use.",
      "modelVersionGroupId": null,
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "tngtech/deepseek-r1t-chimera",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "817eb65c-3217-4a55-9d95-834243ed3e3b",
        "name": "Chutes | tngtech/deepseek-r1t-chimera:free",
        "contextLength": 163840,
        "model": {
          "slug": "tngtech/deepseek-r1t-chimera",
          "hfSlug": "tngtech/DeepSeek-R1T-Chimera",
          "updatedAt": "2025-05-13T18:40:57.812622+00:00",
          "createdAt": "2025-04-27T13:34:35.172638+00:00",
          "hfUpdatedAt": null,
          "name": "TNG: DeepSeek R1T Chimera",
          "shortName": "DeepSeek R1T Chimera",
          "author": "tngtech",
          "description": "DeepSeek-R1T-Chimera is created by merging DeepSeek-R1 and DeepSeek-V3 (0324), combining the reasoning capabilities of R1 with the token efficiency improvements of V3. It is based on a DeepSeek-MoE Transformer architecture and is optimized for general text generation tasks.\n\nThe model merges pretrained weights from both source models to balance performance across reasoning, efficiency, and instruction-following tasks. It is released under the MIT license and intended for research and commercial use.",
          "modelVersionGroupId": null,
          "contextLength": 163840,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "tngtech/deepseek-r1t-chimera",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "tngtech/deepseek-r1t-chimera:free",
        "modelVariantPermaslug": "tngtech/deepseek-r1t-chimera:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "tngtech/DeepSeek-R1T-Chimera",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 53,
        "newest": 32,
        "throughputHighToLow": 233,
        "latencyLowToHigh": 263,
        "pricingLowToHigh": 14,
        "pricingHighToLow": 262
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "qwen/qwen-turbo",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-01T11:56:14.820636+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen-Turbo",
      "shortName": "Qwen-Turbo",
      "author": "qwen",
      "description": "Qwen-Turbo, based on Qwen2.5, is a 1M context model that provides fast speed and low cost, suitable for simple tasks.",
      "modelVersionGroupId": null,
      "contextLength": 1000000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-turbo-2024-11-01",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "5a7f2177-7886-4059-a0c5-a43af75e1302",
        "name": "Alibaba | qwen/qwen-turbo-2024-11-01",
        "contextLength": 1000000,
        "model": {
          "slug": "qwen/qwen-turbo",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-01T11:56:14.820636+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen-Turbo",
          "shortName": "Qwen-Turbo",
          "author": "qwen",
          "description": "Qwen-Turbo, based on Qwen2.5, is a 1M context model that provides fast speed and low cost, suitable for simple tasks.",
          "modelVersionGroupId": null,
          "contextLength": 1000000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-turbo-2024-11-01",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-turbo",
        "modelVariantPermaslug": "qwen/qwen-turbo-2024-11-01",
        "providerName": "Alibaba",
        "providerInfo": {
          "name": "Alibaba",
          "displayName": "Alibaba",
          "slug": "alibaba",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
            "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "CN",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Alibaba",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256"
          }
        },
        "providerDisplayName": "Alibaba",
        "providerModelId": "qwen-turbo",
        "providerGroup": "Alibaba",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "seed",
          "response_format",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
          "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000005",
          "completion": "0.0000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 54,
        "newest": 124,
        "throughputHighToLow": 73,
        "latencyLowToHigh": 102,
        "pricingLowToHigh": 100,
        "pricingHighToLow": 218
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Alibaba",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256",
          "slug": "alibaba",
          "quantization": null,
          "context": 1000000,
          "maxCompletionTokens": 8192,
          "providerModelId": "qwen-turbo",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "seed",
            "response_format",
            "presence_penalty"
          ],
          "inputCost": 0.05,
          "outputCost": 0.2,
          "throughput": 104.3675,
          "latency": 676
        }
      ]
    },
    {
      "slug": "openai/gpt-4o-mini-2024-07-18",
      "hfSlug": null,
      "updatedAt": "2025-04-23T22:07:14.802248+00:00",
      "createdAt": "2024-07-18T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4o-mini (2024-07-18)",
      "shortName": "GPT-4o-mini (2024-07-18)",
      "author": "openai",
      "description": "GPT-4o mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting both text and image inputs with text outputs.\n\nAs their most advanced small model, it is many multiples more affordable than other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo). It maintains SOTA intelligence, while being significantly more cost-effective.\n\nGPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on chat preferences [common leaderboards](https://arena.lmsys.org/).\n\nCheck out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) to learn more.\n\n#multimodal",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4o-mini-2024-07-18",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ebcc1f0a-6621-4cdc-a93f-88a6e2cc2e15",
        "name": "OpenAI | openai/gpt-4o-mini-2024-07-18",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4o-mini-2024-07-18",
          "hfSlug": null,
          "updatedAt": "2025-04-23T22:07:14.802248+00:00",
          "createdAt": "2024-07-18T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4o-mini (2024-07-18)",
          "shortName": "GPT-4o-mini (2024-07-18)",
          "author": "openai",
          "description": "GPT-4o mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting both text and image inputs with text outputs.\n\nAs their most advanced small model, it is many multiples more affordable than other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo). It maintains SOTA intelligence, while being significantly more cost-effective.\n\nGPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on chat preferences [common leaderboards](https://arena.lmsys.org/).\n\nCheck out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) to learn more.\n\n#multimodal",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4o-mini-2024-07-18",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4o-mini-2024-07-18",
        "modelVariantPermaslug": "openai/gpt-4o-mini-2024-07-18",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4o-mini-2024-07-18",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "web_search_options",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000006",
          "image": "0.007225",
          "request": "0",
          "inputCacheRead": "0.000000075",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.03"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.0275"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.025"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 55,
        "newest": 237,
        "throughputHighToLow": 120,
        "latencyLowToHigh": 53,
        "pricingLowToHigh": 144,
        "pricingHighToLow": 177
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o-mini-2024-07-18",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0.007225",
            "request": "0",
            "inputCacheRead": "0.000000075",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 64.1985,
          "latency": 427
        }
      ]
    },
    {
      "slug": "cohere/command-r-08-2024",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-30T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Cohere: Command R (08-2024)",
      "shortName": "Command R (08-2024)",
      "author": "cohere",
      "description": "command-r-08-2024 is an update of the [Command R](/models/cohere/command-r) with improved performance for multilingual retrieval-augmented generation (RAG) and tool use. More broadly, it is better at math, code and reasoning and is competitive with the previous version of the larger Command R+ model.\n\nRead the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Cohere",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cohere/command-r-08-2024",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3d8c4986-1fc9-4ce1-b07d-d379bb75eb36",
        "name": "Cohere | cohere/command-r-08-2024",
        "contextLength": 128000,
        "model": {
          "slug": "cohere/command-r-08-2024",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-30T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Cohere: Command R (08-2024)",
          "shortName": "Command R (08-2024)",
          "author": "cohere",
          "description": "command-r-08-2024 is an update of the [Command R](/models/cohere/command-r) with improved performance for multilingual retrieval-augmented generation (RAG) and tool use. More broadly, it is better at math, code and reasoning and is competitive with the previous version of the larger Command R+ model.\n\nRead the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Cohere",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cohere/command-r-08-2024",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cohere/command-r-08-2024",
        "modelVariantPermaslug": "cohere/command-r-08-2024",
        "providerName": "Cohere",
        "providerInfo": {
          "name": "Cohere",
          "displayName": "Cohere",
          "slug": "cohere",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://cohere.com/privacy",
            "termsOfServiceUrl": "https://cohere.com/terms-of-use",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cohere",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cohere.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Cohere.png"
          }
        },
        "providerDisplayName": "Cohere",
        "providerModelId": "command-r-08-2024",
        "providerGroup": "Cohere",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://cohere.com/privacy",
          "termsOfServiceUrl": "https://cohere.com/terms-of-use",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 56,
        "newest": 213,
        "throughputHighToLow": 127,
        "latencyLowToHigh": 38,
        "pricingLowToHigh": 142,
        "pricingHighToLow": 175
      },
      "authorIcon": "https://openrouter.ai/images/icons/Cohere.png",
      "providers": [
        {
          "name": "Cohere",
          "icon": "https://openrouter.ai/images/icons/Cohere.png",
          "slug": "cohere",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4000,
          "providerModelId": "command-r-08-2024",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 61.65,
          "latency": 359
        }
      ]
    },
    {
      "slug": "google/gemini-pro-1.5",
      "hfSlug": null,
      "updatedAt": "2025-04-12T05:01:34.756668+00:00",
      "createdAt": "2024-04-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 1.5 Pro",
      "shortName": "Gemini 1.5 Pro",
      "author": "google",
      "description": "Google's latest multimodal model, supports image and video[0] in text or chat prompts.\n\nOptimized for language tasks including:\n\n- Code generation\n- Text generation\n- Text editing\n- Problem solving\n- Recommendations\n- Information extraction\n- Data extraction or generation\n- AI agents\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n* [0]: Video input is not available through OpenRouter at this time.",
      "modelVersionGroupId": null,
      "contextLength": 2000000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "google/gemini-pro-1.5",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "089465ba-a451-4730-a9dd-6a2ff05281f7",
        "name": "Google | google/gemini-pro-1.5",
        "contextLength": 2000000,
        "model": {
          "slug": "google/gemini-pro-1.5",
          "hfSlug": null,
          "updatedAt": "2025-04-12T05:01:34.756668+00:00",
          "createdAt": "2024-04-09T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemini 1.5 Pro",
          "shortName": "Gemini 1.5 Pro",
          "author": "google",
          "description": "Google's latest multimodal model, supports image and video[0] in text or chat prompts.\n\nOptimized for language tasks including:\n\n- Code generation\n- Text generation\n- Text editing\n- Problem solving\n- Recommendations\n- Information extraction\n- Data extraction or generation\n- AI agents\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n* [0]: Video input is not available through OpenRouter at this time.",
          "modelVersionGroupId": null,
          "contextLength": 2000000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "google/gemini-pro-1.5",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemini-pro-1.5",
        "modelVariantPermaslug": "google/gemini-pro-1.5",
        "providerName": "Google",
        "providerInfo": {
          "name": "Google",
          "displayName": "Google Vertex",
          "slug": "google-vertex",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cloud.google.com/products/sdXM79fz1FS6ekNpu37K/history",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleVertex.svg"
          }
        },
        "providerDisplayName": "Google Vertex",
        "providerModelId": "gemini-1.5-pro-002",
        "providerGroup": "Google",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "tools",
          "tool_choice",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "dataPolicyUrl": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000125",
          "completion": "0.000005",
          "image": "0.0006575",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "prompt-threshold",
            "threshold": 128000,
            "prompt": "0.0000025",
            "completions": "0.00001"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 57,
        "newest": 270,
        "throughputHighToLow": 123,
        "latencyLowToHigh": 160,
        "pricingLowToHigh": 237,
        "pricingHighToLow": 81
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 2000000,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemini-1.5-pro-002",
          "pricing": {
            "prompt": "0.00000125",
            "completion": "0.000005",
            "image": "0.0006575",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "tools",
            "tool_choice",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1.25,
          "outputCost": 5,
          "throughput": 65.8475,
          "latency": 957
        },
        {
          "name": "Google AI Studio",
          "icon": "https://openrouter.ai/images/icons/GoogleAIStudio.svg",
          "slug": "google",
          "quantization": "unknown",
          "context": 2000000,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemini-1.5-pro-002",
          "pricing": {
            "prompt": "0.00000125",
            "completion": "0.000005",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.000000625",
            "inputCacheWrite": "0.000002875",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "tools",
            "tool_choice",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1.25,
          "outputCost": 5,
          "throughput": 61.818,
          "latency": 836
        }
      ]
    },
    {
      "slug": "mistralai/mistral-tiny",
      "hfSlug": null,
      "updatedAt": "2025-03-31T15:57:54.980898+00:00",
      "createdAt": "2024-01-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral Tiny",
      "shortName": "Mistral Tiny",
      "author": "mistralai",
      "description": "Note: This model is being deprecated. Recommended replacement is the newer [Ministral 8B](/mistral/ministral-8b)\n\nThis model is currently powered by Mistral-7B-v0.2, and incorporates a \"better\" fine-tuning than [Mistral 7B](/models/mistralai/mistral-7b-instruct-v0.1), inspired by community work. It's best used for large batch processing tasks where cost is a significant factor but reasoning capabilities are not crucial.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "This model is deprecated and slated for retirement. Please see [Ministral 8B](/mistral/ministral-8b) for the Mistral suggested upgrade.",
      "permaslug": "mistralai/mistral-tiny",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f543d3e4-4a9b-43f3-9988-c19abd5246c0",
        "name": "Mistral | mistralai/mistral-tiny",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mistral-tiny",
          "hfSlug": null,
          "updatedAt": "2025-03-31T15:57:54.980898+00:00",
          "createdAt": "2024-01-10T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral Tiny",
          "shortName": "Mistral Tiny",
          "author": "mistralai",
          "description": "Note: This model is being deprecated. Recommended replacement is the newer [Ministral 8B](/mistral/ministral-8b)\n\nThis model is currently powered by Mistral-7B-v0.2, and incorporates a \"better\" fine-tuning than [Mistral 7B](/models/mistralai/mistral-7b-instruct-v0.1), inspired by community work. It's best used for large batch processing tasks where cost is a significant factor but reasoning capabilities are not crucial.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "This model is deprecated and slated for retirement. Please see [Ministral 8B](/mistral/ministral-8b) for the Mistral suggested upgrade.",
          "permaslug": "mistralai/mistral-tiny",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-tiny",
        "modelVariantPermaslug": "mistralai/mistral-tiny",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "open-mistral-7b",
        "providerGroup": "Mistral",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000025",
          "completion": "0.00000025",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 58,
        "newest": 290,
        "throughputHighToLow": 46,
        "latencyLowToHigh": 25,
        "pricingLowToHigh": 161,
        "pricingHighToLow": 158
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "open-mistral-7b",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.25,
          "outputCost": 0.25,
          "throughput": 136.6325,
          "latency": 287
        }
      ]
    },
    {
      "slug": "mistralai/mixtral-8x7b-instruct",
      "hfSlug": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mixtral 8x7B Instruct",
      "shortName": "Mixtral 8x7B Instruct",
      "author": "mistralai",
      "description": "Mixtral 8x7B Instruct is a pretrained generative Sparse Mixture of Experts, by Mistral AI, for chat and instruction use. Incorporates 8 experts (feed-forward networks) for a total of 47 billion parameters.\n\nInstruct model fine-tuned by Mistral. #moe",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mixtral-8x7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e63622d5-3cc6-48aa-bc27-eba8c3c17c46",
        "name": "Nebius | mistralai/mixtral-8x7b-instruct",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mixtral-8x7b-instruct",
          "hfSlug": "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-12-10T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mixtral 8x7B Instruct",
          "shortName": "Mixtral 8x7B Instruct",
          "author": "mistralai",
          "description": "Mixtral 8x7B Instruct is a pretrained generative Sparse Mixture of Experts, by Mistral AI, for chat and instruction use. Incorporates 8 experts (feed-forward networks) for a total of 47 billion parameters.\n\nInstruct model fine-tuned by Mistral. #moe",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mixtral-8x7b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mixtral-8x7b-instruct",
        "modelVariantPermaslug": "mistralai/mixtral-8x7b-instruct",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000008",
          "completion": "0.00000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 59,
        "newest": 292,
        "throughputHighToLow": 72,
        "latencyLowToHigh": 12,
        "pricingLowToHigh": 109,
        "pricingHighToLow": 210
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.08,
          "outputCost": 0.24,
          "throughput": 110.3335,
          "latency": 242
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "pricing": {
            "prompt": "0.00000024",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.24,
          "outputCost": 0.24,
          "throughput": 109.567,
          "latency": 514
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "pricing": {
            "prompt": "0.0000006",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.6,
          "outputCost": 0.6,
          "throughput": 62.8335,
          "latency": 491
        }
      ]
    },
    {
      "slug": "google/gemma-3-4b-it",
      "hfSlug": "google/gemma-3-4b-it",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-13T22:38:30.653142+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 3 4B",
      "shortName": "Gemma 3 4B",
      "author": "google",
      "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling.",
      "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemma-3-4b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "d3de3bd4-81bc-48fb-924f-2a87b2a36e75",
        "name": "DeepInfra | google/gemma-3-4b-it",
        "contextLength": 131072,
        "model": {
          "slug": "google/gemma-3-4b-it",
          "hfSlug": "google/gemma-3-4b-it",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-13T22:38:30.653142+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 3 4B",
          "shortName": "Gemma 3 4B",
          "author": "google",
          "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling.",
          "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemma-3-4b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-3-4b-it",
        "modelVariantPermaslug": "google/gemma-3-4b-it",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "google/gemma-3-4b-it",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000002",
          "completion": "0.00000004",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 60,
        "newest": 83,
        "throughputHighToLow": 70,
        "latencyLowToHigh": 26,
        "pricingLowToHigh": 38,
        "pricingHighToLow": 241
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-3-4b-it",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.02,
          "outputCost": 0.04,
          "throughput": 80.749,
          "latency": 300
        }
      ]
    },
    {
      "slug": "liquid/lfm-7b",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-01-25T12:08:03.736586+00:00",
      "hfUpdatedAt": null,
      "name": "Liquid: LFM 7B",
      "shortName": "LFM 7B",
      "author": "liquid",
      "description": "LFM-7B, a new best-in-class language model. LFM-7B is designed for exceptional chat capabilities, including languages like Arabic and Japanese. Powered by the Liquid Foundation Model (LFM) architecture, it exhibits unique features like low memory footprint and fast inference speed. \n\nLFM-7B is the world’s best-in-class multilingual language model in English, Arabic, and Japanese.\n\nSee the [launch announcement](https://www.liquid.ai/lfm-7b) for benchmarks and more info.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "liquid/lfm-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "25b2cca5-53f6-40e7-b47b-191ec968b7c2",
        "name": "Liquid | liquid/lfm-7b",
        "contextLength": 32768,
        "model": {
          "slug": "liquid/lfm-7b",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-01-25T12:08:03.736586+00:00",
          "hfUpdatedAt": null,
          "name": "Liquid: LFM 7B",
          "shortName": "LFM 7B",
          "author": "liquid",
          "description": "LFM-7B, a new best-in-class language model. LFM-7B is designed for exceptional chat capabilities, including languages like Arabic and Japanese. Powered by the Liquid Foundation Model (LFM) architecture, it exhibits unique features like low memory footprint and fast inference speed. \n\nLFM-7B is the world’s best-in-class multilingual language model in English, Arabic, and Japanese.\n\nSee the [launch announcement](https://www.liquid.ai/lfm-7b) for benchmarks and more info.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "liquid/lfm-7b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "liquid/lfm-7b",
        "modelVariantPermaslug": "liquid/lfm-7b",
        "providerName": "Liquid",
        "providerInfo": {
          "name": "Liquid",
          "displayName": "Liquid",
          "slug": "liquid",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.liquid.ai/terms-conditions",
            "privacyPolicyUrl": "https://www.liquid.ai/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Liquid",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.liquid.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Liquid",
        "providerModelId": "lfm-7b",
        "providerGroup": "Liquid",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.liquid.ai/terms-conditions",
          "privacyPolicyUrl": "https://www.liquid.ai/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000001",
          "completion": "0.00000001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 61,
        "newest": 139,
        "throughputHighToLow": 140,
        "latencyLowToHigh": 131,
        "pricingLowToHigh": 72,
        "pricingHighToLow": 246
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://www.liquid.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Liquid",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.liquid.ai/&size=256",
          "slug": "liquid",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "lfm-7b",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.01,
          "outputCost": 0.01,
          "throughput": 56.1095,
          "latency": 716
        }
      ]
    },
    {
      "slug": "anthropic/claude-3-haiku",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3 Haiku",
      "shortName": "Claude 3 Haiku",
      "author": "anthropic",
      "description": "Claude 3 Haiku is Anthropic's fastest and most compact model for\nnear-instant responsiveness. Quick and accurate targeted performance.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-haiku)\n\n#multimodal",
      "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-haiku",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8661a1db-b0cf-4eb2-ba04-c2a79f698682",
        "name": "Anthropic | anthropic/claude-3-haiku",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3-haiku",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-13T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3 Haiku",
          "shortName": "Claude 3 Haiku",
          "author": "anthropic",
          "description": "Claude 3 Haiku is Anthropic's fastest and most compact model for\nnear-instant responsiveness. Quick and accurate targeted performance.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-haiku)\n\n#multimodal",
          "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-haiku",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3-haiku",
        "modelVariantPermaslug": "anthropic/claude-3-haiku",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-haiku-20240307",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000025",
          "completion": "0.00000125",
          "image": "0.0004",
          "request": "0",
          "inputCacheRead": "0.00000003",
          "inputCacheWrite": "0.0000003",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 62,
        "newest": 277,
        "throughputHighToLow": 28,
        "latencyLowToHigh": 133,
        "pricingLowToHigh": 168,
        "pricingHighToLow": 149
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-haiku-20240307",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000125",
            "image": "0.0004",
            "request": "0",
            "inputCacheRead": "0.00000003",
            "inputCacheWrite": "0.0000003",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.25,
          "outputCost": 1.25,
          "throughput": 152.6455,
          "latency": 813
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-haiku@20240307",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000125",
            "image": "0.0004",
            "request": "0",
            "inputCacheRead": "0.00000003",
            "inputCacheWrite": "0.0000003",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.25,
          "outputCost": 1.25,
          "throughput": 152.907,
          "latency": 1524
        }
      ]
    },
    {
      "slug": "thedrummer/unslopnemo-12b",
      "hfSlug": "TheDrummer/UnslopNemo-12B-v4.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-08T22:04:08.359811+00:00",
      "hfUpdatedAt": null,
      "name": "Unslopnemo 12B",
      "shortName": "Unslopnemo 12B",
      "author": "thedrummer",
      "description": "UnslopNemo v4.1 is the latest addition from the creator of Rocinante, designed for adventure writing and role-play scenarios.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thedrummer/unslopnemo-12b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "a980db59-4eb5-4f8e-8ea3-80c32151e4a8",
        "name": "Enfer | thedrummer/unslopnemo-12b",
        "contextLength": 32000,
        "model": {
          "slug": "thedrummer/unslopnemo-12b",
          "hfSlug": "TheDrummer/UnslopNemo-12B-v4.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-08T22:04:08.359811+00:00",
          "hfUpdatedAt": null,
          "name": "Unslopnemo 12B",
          "shortName": "Unslopnemo 12B",
          "author": "thedrummer",
          "description": "UnslopNemo v4.1 is the latest addition from the creator of Rocinante, designed for adventure writing and role-play scenarios.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thedrummer/unslopnemo-12b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "thedrummer/unslopnemo-12b",
        "modelVariantPermaslug": "thedrummer/unslopnemo-12b",
        "providerName": "Enfer",
        "providerInfo": {
          "name": "Enfer",
          "displayName": "Enfer",
          "slug": "enfer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://enfer.ai/privacy-policy",
            "privacyPolicyUrl": "https://enfer.ai/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Enfer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256"
          }
        },
        "providerDisplayName": "Enfer",
        "providerModelId": "thedrummer/unslopnemo-12b-v4-1",
        "providerGroup": "Enfer",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "logit_bias",
          "logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://enfer.ai/privacy-policy",
          "privacyPolicyUrl": "https://enfer.ai/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000045",
          "completion": "0.00000045",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 63,
        "newest": 176,
        "throughputHighToLow": 113,
        "latencyLowToHigh": 297,
        "pricingLowToHigh": 173,
        "pricingHighToLow": 145
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Enfer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256",
          "slug": "enfer",
          "quantization": "fp8",
          "context": 32000,
          "maxCompletionTokens": 16000,
          "providerModelId": "thedrummer/unslopnemo-12b-v4-1",
          "pricing": {
            "prompt": "0.00000045",
            "completion": "0.00000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logit_bias",
            "logprobs"
          ],
          "inputCost": 0.45,
          "outputCost": 0.45,
          "throughput": 66.3085,
          "latency": 5461
        },
        {
          "name": "Infermatic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256",
          "slug": "infermatic",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "TheDrummer-UnslopNemo-12B-v4.1",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.5,
          "outputCost": 0.5,
          "throughput": 95.4735,
          "latency": 527
        }
      ]
    },
    {
      "slug": "mistralai/mistral-small-3.1-24b-instruct",
      "hfSlug": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-17T19:15:37.00423+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral Small 3.1 24B",
      "shortName": "Mistral Small 3.1 24B",
      "author": "mistralai",
      "description": "Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501), featuring 24 billion parameters with advanced multimodal capabilities. It provides state-of-the-art performance in text-based reasoning and vision tasks, including image analysis, programming, mathematical reasoning, and multilingual support across dozens of languages. Equipped with an extensive 128k token context window and optimized for efficient local inference, it supports use cases such as conversational agents, function calling, long-document comprehension, and privacy-sensitive deployments.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b4449f43-003d-40ba-949d-5888358e25ef",
        "name": "Nebius | mistralai/mistral-small-3.1-24b-instruct-2503",
        "contextLength": 131072,
        "model": {
          "slug": "mistralai/mistral-small-3.1-24b-instruct",
          "hfSlug": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-17T19:15:37.00423+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral Small 3.1 24B",
          "shortName": "Mistral Small 3.1 24B",
          "author": "mistralai",
          "description": "Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501), featuring 24 billion parameters with advanced multimodal capabilities. It provides state-of-the-art performance in text-based reasoning and vision tasks, including image analysis, programming, mathematical reasoning, and multilingual support across dozens of languages. Equipped with an extensive 128k token context window and optimized for efficient local inference, it supports use cases such as conversational agents, function calling, long-document comprehension, and privacy-sensitive deployments.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-small-3.1-24b-instruct",
        "modelVariantPermaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000005",
          "completion": "0.00000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 64,
        "newest": 79,
        "throughputHighToLow": 104,
        "latencyLowToHigh": 33,
        "pricingLowToHigh": 35,
        "pricingHighToLow": 219
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.05,
          "outputCost": 0.15,
          "throughput": 56.904,
          "latency": 426
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": 128000,
          "providerModelId": "parasail-mistral-small-31-24b-instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0.000926",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 67.411,
          "latency": 1392
        },
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-small-2503",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0.0009264",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 140.296,
          "latency": 219
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/mistralai/mistral-small-3.1-24b-instruct",
          "pricing": {
            "prompt": "0.00000035",
            "completion": "0.00000056",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.35,
          "outputCost": 0.56,
          "throughput": 43.312,
          "latency": 376
        }
      ]
    },
    {
      "slug": "qwen/qwq-32b",
      "hfSlug": "Qwen/QwQ-32B",
      "updatedAt": "2025-05-02T17:24:23.70143+00:00",
      "createdAt": "2025-03-05T21:06:54.875499+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: QwQ 32B",
      "shortName": "QwQ 32B",
      "author": "qwen",
      "description": "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "qwq",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwq-32b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "eec50e37-c73c-426c-ad65-f1b7d85debcb",
        "name": "DeepInfra | qwen/qwq-32b",
        "contextLength": 131072,
        "model": {
          "slug": "qwen/qwq-32b",
          "hfSlug": "Qwen/QwQ-32B",
          "updatedAt": "2025-05-02T17:24:23.70143+00:00",
          "createdAt": "2025-03-05T21:06:54.875499+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: QwQ 32B",
          "shortName": "QwQ 32B",
          "author": "qwen",
          "description": "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "qwq",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwq-32b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwq-32b",
        "modelVariantPermaslug": "qwen/qwq-32b",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Qwen/QwQ-32B",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 65,
        "newest": 102,
        "throughputHighToLow": 51,
        "latencyLowToHigh": 83,
        "pricingLowToHigh": 43,
        "pricingHighToLow": 183
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.15,
          "outputCost": 0.2,
          "throughput": 39.222,
          "latency": 358
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.00000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.45,
          "throughput": 32.054,
          "latency": 407
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 16000,
          "providerModelId": "qwen/qwq-32b",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.18,
          "outputCost": 0.2,
          "throughput": 33.979,
          "latency": 715
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "qwen/qwq-32b/fp-8",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "qwen-qwq-32b",
          "pricing": {
            "prompt": "0.00000029",
            "completion": "0.00000039",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.29,
          "outputCost": 0.39,
          "throughput": 564.2155,
          "latency": 692
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 33.561,
          "latency": 1027
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "QwQ-32B",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "stop"
          ],
          "inputCost": 0.5,
          "outputCost": 1,
          "throughput": 262.86,
          "latency": 680
        },
        {
          "name": "Nebius AI Studio (Fast)",
          "icon": "",
          "slug": "nebiusAiStudio (fast)",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B-fast",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 75.183,
          "latency": 285
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "fp16",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.00000065",
            "completion": "0.00000065",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.65,
          "outputCost": 0.65,
          "throughput": 58.471,
          "latency": 606
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwq-32b",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 132.269,
          "latency": 700
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.0000012",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.2,
          "outputCost": 1.2,
          "throughput": 88.4365,
          "latency": 965.5
        }
      ]
    },
    {
      "slug": "mistralai/mistral-medium-3",
      "hfSlug": "",
      "updatedAt": "2025-05-07T14:30:43.39556+00:00",
      "createdAt": "2025-05-07T14:15:41.980763+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral Medium 3",
      "shortName": "Mistral Medium 3",
      "author": "mistralai",
      "description": "Mistral Medium 3 is a high-performance enterprise-grade language model designed to deliver frontier-level capabilities at significantly reduced operational cost. It balances state-of-the-art reasoning and multimodal performance with 8× lower cost compared to traditional large models, making it suitable for scalable deployments across professional and industrial use cases.\n\nThe model excels in domains such as coding, STEM reasoning, and enterprise adaptation. It supports hybrid, on-prem, and in-VPC deployments and is optimized for integration into custom workflows. Mistral Medium 3 offers competitive accuracy relative to larger models like Claude Sonnet 3.5/3.7, Llama 4 Maverick, and Command R+, while maintaining broad compatibility across cloud environments.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-medium-3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9d5ba5bf-8465-46df-9185-1330820338f5",
        "name": "Mistral | mistralai/mistral-medium-3",
        "contextLength": 131072,
        "model": {
          "slug": "mistralai/mistral-medium-3",
          "hfSlug": "",
          "updatedAt": "2025-05-07T14:30:43.39556+00:00",
          "createdAt": "2025-05-07T14:15:41.980763+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral Medium 3",
          "shortName": "Mistral Medium 3",
          "author": "mistralai",
          "description": "Mistral Medium 3 is a high-performance enterprise-grade language model designed to deliver frontier-level capabilities at significantly reduced operational cost. It balances state-of-the-art reasoning and multimodal performance with 8× lower cost compared to traditional large models, making it suitable for scalable deployments across professional and industrial use cases.\n\nThe model excels in domains such as coding, STEM reasoning, and enterprise adaptation. It supports hybrid, on-prem, and in-VPC deployments and is optimized for integration into custom workflows. Mistral Medium 3 offers competitive accuracy relative to larger models like Claude Sonnet 3.5/3.7, Llama 4 Maverick, and Command R+, while maintaining broad compatibility across cloud environments.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-medium-3",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-medium-3",
        "modelVariantPermaslug": "mistralai/mistral-medium-3",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "mistral-medium-2505",
        "providerGroup": "Mistral",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000004",
          "completion": "0.000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 66,
        "newest": 1,
        "throughputHighToLow": 136,
        "latencyLowToHigh": 85,
        "pricingLowToHigh": 185,
        "pricingHighToLow": 133
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-medium-2505",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.4,
          "outputCost": 2,
          "throughput": 45.087,
          "latency": 475
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.5-haiku-20241022",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-04T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.5 Haiku (2024-10-22) (self-moderated)",
      "shortName": "Claude 3.5 Haiku (2024-10-22) (self-moderated)",
      "author": "anthropic",
      "description": "Claude 3.5 Haiku features enhancements across all skill sets including coding, tool use, and reasoning. As the fastest model in the Anthropic lineup, it offers rapid response times suitable for applications that require high interactivity and low latency, such as user-facing chatbots and on-the-fly code completions. It also excels in specialized tasks like data extraction and real-time content moderation, making it a versatile tool for a broad range of industries.\n\nIt does not support image inputs.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/3-5-models-and-computer-use)",
      "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-5-haiku-20241022",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "81dc58ef-b297-4540-ae41-b232d2bf5c3b",
        "name": "Anthropic | anthropic/claude-3-5-haiku-20241022:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.5-haiku-20241022",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-04T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.5 Haiku (2024-10-22)",
          "shortName": "Claude 3.5 Haiku (2024-10-22)",
          "author": "anthropic",
          "description": "Claude 3.5 Haiku features enhancements across all skill sets including coding, tool use, and reasoning. As the fastest model in the Anthropic lineup, it offers rapid response times suitable for applications that require high interactivity and low latency, such as user-facing chatbots and on-the-fly code completions. It also excels in specialized tasks like data extraction and real-time content moderation, making it a versatile tool for a broad range of industries.\n\nIt does not support image inputs.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/3-5-models-and-computer-use)",
          "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-5-haiku-20241022",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.5-haiku-20241022:beta",
        "modelVariantPermaslug": "anthropic/claude-3-5-haiku-20241022:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-5-haiku-20241022",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.000004",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.00000008",
          "inputCacheWrite": "0.000001",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 67,
        "newest": 179,
        "throughputHighToLow": 163,
        "latencyLowToHigh": 221,
        "pricingLowToHigh": 221,
        "pricingHighToLow": 95
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-haiku-20241022",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 52.0085,
          "latency": 1523
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-haiku@20241022",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 69.857,
          "latency": 2450
        }
      ]
    },
    {
      "slug": "openai/o3-mini",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-01-31T19:28:41.132151+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o3 Mini",
      "shortName": "o3 Mini",
      "author": "openai",
      "description": "OpenAI o3-mini is a cost-efficient language model optimized for STEM reasoning tasks, particularly excelling in science, mathematics, and coding.\n\nThis model supports the `reasoning_effort` parameter, which can be set to \"high\", \"medium\", or \"low\" to control the thinking time of the model. The default is \"medium\". OpenRouter also offers the model slug `openai/o3-mini-high` to default the parameter to \"high\".\n\nThe model features three adjustable reasoning effort levels and supports key developer capabilities including function calling, structured outputs, and streaming, though it does not include vision processing capabilities.\n\nThe model demonstrates significant improvements over its predecessor, with expert testers preferring its responses 56% of the time and noting a 39% reduction in major errors on complex questions. With medium reasoning effort settings, o3-mini matches the performance of the larger o1 model on challenging reasoning evaluations like AIME and GPQA, while maintaining lower latency and cost.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "openai/o3-mini-2025-01-31",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e93c942e-7f8f-410d-8478-21ec37bc6b0d",
        "name": "OpenAI | openai/o3-mini-2025-01-31",
        "contextLength": 200000,
        "model": {
          "slug": "openai/o3-mini",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-01-31T19:28:41.132151+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o3 Mini",
          "shortName": "o3 Mini",
          "author": "openai",
          "description": "OpenAI o3-mini is a cost-efficient language model optimized for STEM reasoning tasks, particularly excelling in science, mathematics, and coding.\n\nThis model supports the `reasoning_effort` parameter, which can be set to \"high\", \"medium\", or \"low\" to control the thinking time of the model. The default is \"medium\". OpenRouter also offers the model slug `openai/o3-mini-high` to default the parameter to \"high\".\n\nThe model features three adjustable reasoning effort levels and supports key developer capabilities including function calling, structured outputs, and streaming, though it does not include vision processing capabilities.\n\nThe model demonstrates significant improvements over its predecessor, with expert testers preferring its responses 56% of the time and noting a 39% reduction in major errors on complex questions. With medium reasoning effort settings, o3-mini matches the performance of the larger o1 model on challenging reasoning evaluations like AIME and GPQA, while maintaining lower latency and cost.",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "openai/o3-mini-2025-01-31",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o3-mini",
        "modelVariantPermaslug": "openai/o3-mini-2025-01-31",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o3-mini-2025-01-31",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 100000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "seed",
          "max_tokens",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000011",
          "completion": "0.0000044",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.00000055",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 68,
        "newest": 129,
        "throughputHighToLow": 313,
        "latencyLowToHigh": 301,
        "pricingLowToHigh": 232,
        "pricingHighToLow": 87
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 100000,
          "providerModelId": "o3-mini-2025-01-31",
          "pricing": {
            "prompt": "0.0000011",
            "completion": "0.0000044",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000055",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "seed",
            "max_tokens",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1.1,
          "outputCost": 4.4,
          "throughput": 93.161,
          "latency": 5786.5
        }
      ]
    },
    {
      "slug": "google/gemma-3-27b-it",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-12T05:12:39.645813+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 3 27B (free)",
      "shortName": "Gemma 3 27B (free)",
      "author": "google",
      "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google's latest open source model, successor to [Gemma 2](google/gemma-2-27b-it)",
      "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
      "contextLength": 96000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "google/gemma-3-27b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8755645c-af2e-4ce9-b521-2625e4d40500",
        "name": "Chutes | google/gemma-3-27b-it:free",
        "contextLength": 96000,
        "model": {
          "slug": "google/gemma-3-27b-it",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-12T05:12:39.645813+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 3 27B",
          "shortName": "Gemma 3 27B",
          "author": "google",
          "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google's latest open source model, successor to [Gemma 2](google/gemma-2-27b-it)",
          "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "google/gemma-3-27b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-3-27b-it:free",
        "modelVariantPermaslug": "google/gemma-3-27b-it:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "unsloth/gemma-3-27b-it",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 27,
        "newest": 93,
        "throughputHighToLow": 35,
        "latencyLowToHigh": 143,
        "pricingLowToHigh": 41,
        "pricingHighToLow": 199
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000002",
            "image": "0.0000256",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.2,
          "throughput": 32.3795,
          "latency": 870
        },
        {
          "name": "InoCloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inocloud.com/&size=256",
          "slug": "inoCloud",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.1,
          "outputCost": 0.2,
          "throughput": 27.2075,
          "latency": 1206
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 110000,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 47.451,
          "latency": 955
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.000000119",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.12,
          "outputCost": 0.2,
          "throughput": 31.0825,
          "latency": 2277
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 8000,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.00000035",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.35,
          "throughput": 55.241,
          "latency": 1221.5
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-gemma3-27b-it",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.25,
          "outputCost": 0.4,
          "throughput": 50.6245,
          "latency": 1201.5
        },
        {
          "name": "nCompass",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://console.ncompass.tech/&size=256",
          "slug": "nCompass",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "google/gemma-3-27b-it",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 43.7135,
          "latency": 986
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": 8192,
          "providerModelId": "google/gemma-3-27b-instruct/bf-16",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.3,
          "outputCost": 0.4,
          "throughput": 15.433,
          "latency": 2120.5
        }
      ]
    },
    {
      "slug": "nousresearch/hermes-2-pro-llama-3-8b",
      "hfSlug": "NousResearch/Hermes-2-Pro-Llama-3-8B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-27T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "NousResearch: Hermes 2 Pro - Llama-3 8B",
      "shortName": "Hermes 2 Pro - Llama-3 8B",
      "author": "nousresearch",
      "description": "Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/hermes-2-pro-llama-3-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "289a8cae-38f7-40d1-9f16-285f9868698c",
        "name": "Lambda | nousresearch/hermes-2-pro-llama-3-8b",
        "contextLength": 131072,
        "model": {
          "slug": "nousresearch/hermes-2-pro-llama-3-8b",
          "hfSlug": "NousResearch/Hermes-2-Pro-Llama-3-8B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-27T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "NousResearch: Hermes 2 Pro - Llama-3 8B",
          "shortName": "Hermes 2 Pro - Llama-3 8B",
          "author": "nousresearch",
          "description": "Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house.",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nousresearch/hermes-2-pro-llama-3-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nousresearch/hermes-2-pro-llama-3-8b",
        "modelVariantPermaslug": "nousresearch/hermes-2-pro-llama-3-8b",
        "providerName": "Lambda",
        "providerInfo": {
          "name": "Lambda",
          "displayName": "Lambda",
          "slug": "lambda",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
            "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Lambda",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256"
          }
        },
        "providerDisplayName": "Lambda",
        "providerModelId": "hermes3-8b",
        "providerGroup": "Lambda",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 131072,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
          "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000000025",
          "completion": "0.00000004",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 70,
        "newest": 251,
        "throughputHighToLow": 33,
        "latencyLowToHigh": 28,
        "pricingLowToHigh": 81,
        "pricingHighToLow": 237
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": [
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "hermes3-8b",
          "pricing": {
            "prompt": "0.000000025",
            "completion": "0.00000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.02,
          "outputCost": 0.04,
          "throughput": 153.653,
          "latency": 311
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "nousresearch/hermes-2-pro-llama-3-8b",
          "pricing": {
            "prompt": "0.00000014",
            "completion": "0.00000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.14,
          "outputCost": 0.14,
          "throughput": 132.7985,
          "latency": 683
        }
      ]
    },
    {
      "slug": "qwen/qwen2.5-vl-72b-instruct",
      "hfSlug": "Qwen/Qwen2.5-VL-72B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-01T11:45:11.997326+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen2.5 VL 72B Instruct",
      "shortName": "Qwen2.5 VL 72B Instruct",
      "author": "qwen",
      "description": "Qwen2.5-VL is proficient in recognizing common objects such as flowers, birds, fish, and insects. It is also highly capable of analyzing texts, charts, icons, graphics, and layouts within images.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen2.5-vl-72b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2fff2f07-5438-4dcd-854c-6a8ca11fd420",
        "name": "Nebius | qwen/qwen2.5-vl-72b-instruct",
        "contextLength": 32000,
        "model": {
          "slug": "qwen/qwen2.5-vl-72b-instruct",
          "hfSlug": "Qwen/Qwen2.5-VL-72B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-01T11:45:11.997326+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen2.5 VL 72B Instruct",
          "shortName": "Qwen2.5 VL 72B Instruct",
          "author": "qwen",
          "description": "Qwen2.5-VL is proficient in recognizing common objects such as flowers, birds, fish, and insects. It is also highly capable of analyzing texts, charts, icons, graphics, and layouts within images.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen2.5-vl-72b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen2.5-vl-72b-instruct",
        "modelVariantPermaslug": "qwen/qwen2.5-vl-72b-instruct",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "Qwen/Qwen2.5-VL-72B-Instruct",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000025",
          "completion": "0.00000075",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 71,
        "newest": 125,
        "throughputHighToLow": 249,
        "latencyLowToHigh": 257,
        "pricingLowToHigh": 48,
        "pricingHighToLow": 154
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-VL-72B-Instruct",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000075",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.25,
          "outputCost": 0.75,
          "throughput": 12.992,
          "latency": 2030
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": 128000,
          "providerModelId": "parasail-qwen25-vl-72b-instruct",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.7,
          "outputCost": 0.7,
          "throughput": 33.27,
          "latency": 1933.5
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 96000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen2.5-vl-72b-instruct",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 17.5275,
          "latency": 4803
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-VL-72B-Instruct",
          "pricing": {
            "prompt": "0.00000195",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.95,
          "outputCost": 8,
          "throughput": 31.412,
          "latency": 1338.5
        }
      ]
    },
    {
      "slug": "amazon/nova-lite-v1",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-05T22:22:43.403315+00:00",
      "hfUpdatedAt": null,
      "name": "Amazon: Nova Lite 1.0",
      "shortName": "Nova Lite 1.0",
      "author": "amazon",
      "description": "Amazon Nova Lite 1.0 is a very low-cost multimodal model from Amazon that focused on fast processing of image, video, and text inputs to generate text output. Amazon Nova Lite can handle real-time customer interactions, document analysis, and visual question-answering tasks with high accuracy.\n\nWith an input context of 300K tokens, it can analyze multiple images or up to 30 minutes of video in a single input.",
      "modelVersionGroupId": null,
      "contextLength": 300000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Nova",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "amazon/nova-lite-v1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "72eda073-d180-4482-8e4f-81051cb66f7e",
        "name": "Amazon Bedrock | amazon/nova-lite-v1",
        "contextLength": 300000,
        "model": {
          "slug": "amazon/nova-lite-v1",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-05T22:22:43.403315+00:00",
          "hfUpdatedAt": null,
          "name": "Amazon: Nova Lite 1.0",
          "shortName": "Nova Lite 1.0",
          "author": "amazon",
          "description": "Amazon Nova Lite 1.0 is a very low-cost multimodal model from Amazon that focused on fast processing of image, video, and text inputs to generate text output. Amazon Nova Lite can handle real-time customer interactions, document analysis, and visual question-answering tasks with high accuracy.\n\nWith an input context of 300K tokens, it can analyze multiple images or up to 30 minutes of video in a single input.",
          "modelVersionGroupId": null,
          "contextLength": 300000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Nova",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "amazon/nova-lite-v1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "amazon/nova-lite-v1",
        "modelVariantPermaslug": "amazon/nova-lite-v1",
        "providerName": "Amazon Bedrock",
        "providerInfo": {
          "name": "Amazon Bedrock",
          "displayName": "Amazon Bedrock",
          "slug": "amazon-bedrock",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://aws.amazon.com/service-terms/",
            "privacyPolicyUrl": "https://aws.amazon.com/privacy",
            "dataPolicyUrl": "https://docs.aws.amazon.com/bedrock/latest/userguide/data-protection.html",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": true,
          "group": "Amazon Bedrock",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Bedrock.svg"
          }
        },
        "providerDisplayName": "Amazon Bedrock",
        "providerModelId": "us.amazon.nova-lite-v1:0",
        "providerGroup": "Amazon Bedrock",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 5120,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://aws.amazon.com/service-terms/",
          "privacyPolicyUrl": "https://aws.amazon.com/privacy",
          "dataPolicyUrl": "https://docs.aws.amazon.com/bedrock/latest/userguide/data-protection.html",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000006",
          "completion": "0.00000024",
          "image": "0.00009",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 72,
        "newest": 159,
        "throughputHighToLow": 17,
        "latencyLowToHigh": 49,
        "pricingLowToHigh": 105,
        "pricingHighToLow": 214
      },
      "authorIcon": "https://openrouter.ai/images/icons/Bedrock.svg",
      "providers": [
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": null,
          "context": 300000,
          "maxCompletionTokens": 5120,
          "providerModelId": "us.amazon.nova-lite-v1:0",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000024",
            "image": "0.00009",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.06,
          "outputCost": 0.24,
          "throughput": 182.142,
          "latency": 415
        }
      ]
    },
    {
      "slug": "amazon/nova-pro-v1",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-05T22:05:03.587216+00:00",
      "hfUpdatedAt": null,
      "name": "Amazon: Nova Pro 1.0",
      "shortName": "Nova Pro 1.0",
      "author": "amazon",
      "description": "Amazon Nova Pro 1.0 is a capable multimodal model from Amazon focused on providing a combination of accuracy, speed, and cost for a wide range of tasks. As of December 2024, it achieves state-of-the-art performance on key benchmarks including visual question answering (TextVQA) and video understanding (VATEX).\n\nAmazon Nova Pro demonstrates strong capabilities in processing both visual and textual information and at analyzing financial documents.\n\n**NOTE**: Video input is not supported at this time.",
      "modelVersionGroupId": null,
      "contextLength": 300000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Nova",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "amazon/nova-pro-v1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "959381a4-8054-450f-9daf-5fcab64ba9aa",
        "name": "Amazon Bedrock | amazon/nova-pro-v1",
        "contextLength": 300000,
        "model": {
          "slug": "amazon/nova-pro-v1",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-05T22:05:03.587216+00:00",
          "hfUpdatedAt": null,
          "name": "Amazon: Nova Pro 1.0",
          "shortName": "Nova Pro 1.0",
          "author": "amazon",
          "description": "Amazon Nova Pro 1.0 is a capable multimodal model from Amazon focused on providing a combination of accuracy, speed, and cost for a wide range of tasks. As of December 2024, it achieves state-of-the-art performance on key benchmarks including visual question answering (TextVQA) and video understanding (VATEX).\n\nAmazon Nova Pro demonstrates strong capabilities in processing both visual and textual information and at analyzing financial documents.\n\n**NOTE**: Video input is not supported at this time.",
          "modelVersionGroupId": null,
          "contextLength": 300000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Nova",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "amazon/nova-pro-v1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "amazon/nova-pro-v1",
        "modelVariantPermaslug": "amazon/nova-pro-v1",
        "providerName": "Amazon Bedrock",
        "providerInfo": {
          "name": "Amazon Bedrock",
          "displayName": "Amazon Bedrock",
          "slug": "amazon-bedrock",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://aws.amazon.com/service-terms/",
            "privacyPolicyUrl": "https://aws.amazon.com/privacy",
            "dataPolicyUrl": "https://docs.aws.amazon.com/bedrock/latest/userguide/data-protection.html",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": true,
          "group": "Amazon Bedrock",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Bedrock.svg"
          }
        },
        "providerDisplayName": "Amazon Bedrock",
        "providerModelId": "us.amazon.nova-pro-v1:0",
        "providerGroup": "Amazon Bedrock",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 5120,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://aws.amazon.com/service-terms/",
          "privacyPolicyUrl": "https://aws.amazon.com/privacy",
          "dataPolicyUrl": "https://docs.aws.amazon.com/bedrock/latest/userguide/data-protection.html",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000032",
          "image": "0.0012",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 73,
        "newest": 161,
        "throughputHighToLow": 47,
        "latencyLowToHigh": 101,
        "pricingLowToHigh": 218,
        "pricingHighToLow": 101
      },
      "authorIcon": "https://openrouter.ai/images/icons/Bedrock.svg",
      "providers": [
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": null,
          "context": 300000,
          "maxCompletionTokens": 5120,
          "providerModelId": "us.amazon.nova-pro-v1:0",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000032",
            "image": "0.0012",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 3.2,
          "throughput": 125.912,
          "latency": 668
        }
      ]
    },
    {
      "slug": "meta-llama/llama-4-scout",
      "hfSlug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "updatedAt": "2025-04-05T19:34:05.019062+00:00",
      "createdAt": "2025-04-05T19:31:59.735804+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 4 Scout (free)",
      "shortName": "Llama 4 Scout (free)",
      "author": "meta-llama",
      "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
      "modelVersionGroupId": null,
      "contextLength": 512000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f0b6a83b-9818-4f8c-9941-20b3ead09379",
        "name": "Chutes | meta-llama/llama-4-scout-17b-16e-instruct:free",
        "contextLength": 512000,
        "model": {
          "slug": "meta-llama/llama-4-scout",
          "hfSlug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "updatedAt": "2025-04-05T19:34:05.019062+00:00",
          "createdAt": "2025-04-05T19:31:59.735804+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 4 Scout",
          "shortName": "Llama 4 Scout",
          "author": "meta-llama",
          "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
          "modelVersionGroupId": null,
          "contextLength": 10000000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-4-scout:free",
        "modelVariantPermaslug": "meta-llama/llama-4-scout-17b-16e-instruct:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "chutesai/Llama-4-Scout-17B-16E-Instruct",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": 8,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "structured_outputs",
          "response_format",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {
            "responseFormat": true,
            "structuredOutputs": true
          },
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 42,
        "newest": 63,
        "throughputHighToLow": 76,
        "latencyLowToHigh": 43,
        "pricingLowToHigh": 27,
        "pricingHighToLow": 201
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "llama-4-scout-17b-16e-instruct",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.08,
          "outputCost": 0.3,
          "throughput": 99.2805,
          "latency": 816
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 327680,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.0000003",
            "image": "0.0003342",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.08,
          "outputCost": 0.3,
          "throughput": 45.32,
          "latency": 845
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000045",
            "image": "0.0005013",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.08,
          "outputCost": 0.45,
          "throughput": 59.9425,
          "latency": 585
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 158000,
          "maxCompletionTokens": 158000,
          "providerModelId": "parasail-llama-4-scout-instruct",
          "pricing": {
            "prompt": "0.00000009",
            "completion": "0.00000048",
            "image": "0.00046788",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.09,
          "outputCost": 0.48,
          "throughput": 96.079,
          "latency": 618.5
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "bf16",
          "context": 1048576,
          "maxCompletionTokens": 1048576,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 81.2295,
          "latency": 403
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "meta-llama/llama-4-scout-17b-16e-instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000005",
            "image": "0.0003342",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.1,
          "outputCost": 0.5,
          "throughput": 33.2045,
          "latency": 1303
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 8192,
          "providerModelId": "meta-llama/llama-4-scout-17b-16e-instruct",
          "pricing": {
            "prompt": "0.00000011",
            "completion": "0.00000034",
            "image": "0.00036762",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.11,
          "outputCost": 0.34,
          "throughput": 707.1805,
          "latency": 603
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama4-scout-instruct-basic",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 97.3415,
          "latency": 650
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "bf16",
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "seed"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 100.231,
          "latency": 921
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000059",
            "image": "0.00090234",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.59,
          "throughput": 98.2635,
          "latency": 529
        },
        {
          "name": "Cerebras",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cerebras.ai/&size=256",
          "slug": "cerebras",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "llama-4-scout-17b-16e-instruct",
          "pricing": {
            "prompt": "0.00000065",
            "completion": "0.00000085",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.65,
          "outputCost": 0.85,
          "throughput": 6936.2505,
          "latency": 323
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-prover-v2",
      "hfSlug": "deepseek-ai/DeepSeek-Prover-V2-671B",
      "updatedAt": "2025-04-30T13:01:50.865169+00:00",
      "createdAt": "2025-04-30T11:38:14.302503+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: DeepSeek Prover V2 (free)",
      "shortName": "DeepSeek Prover V2 (free)",
      "author": "deepseek",
      "description": "DeepSeek Prover V2 is a 671B parameter model, speculated to be geared towards logic and mathematics. Likely an upgrade from [DeepSeek-Prover-V1.5](https://huggingface.co/deepseek-ai/DeepSeek-Prover-V1.5-RL) Not much is known about the model yet, as DeepSeek released it on Hugging Face without an announcement or description.",
      "modelVersionGroupId": null,
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-prover-v2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "447b28a4-052e-445b-af74-72cd033bff4a",
        "name": "Chutes | deepseek/deepseek-prover-v2:free",
        "contextLength": 163840,
        "model": {
          "slug": "deepseek/deepseek-prover-v2",
          "hfSlug": "deepseek-ai/DeepSeek-Prover-V2-671B",
          "updatedAt": "2025-04-30T13:01:50.865169+00:00",
          "createdAt": "2025-04-30T11:38:14.302503+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: DeepSeek Prover V2",
          "shortName": "DeepSeek Prover V2",
          "author": "deepseek",
          "description": "DeepSeek Prover V2 is a 671B parameter model, speculated to be geared towards logic and mathematics. Likely an upgrade from [DeepSeek-Prover-V1.5](https://huggingface.co/deepseek-ai/DeepSeek-Prover-V1.5-RL) Not much is known about the model yet, as DeepSeek released it on Hugging Face without an announcement or description.",
          "modelVersionGroupId": null,
          "contextLength": 163840,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-prover-v2",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "deepseek/deepseek-prover-v2:free",
        "modelVariantPermaslug": "deepseek/deepseek-prover-v2:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "deepseek-ai/DeepSeek-Prover-V2-671B",
        "providerGroup": "Chutes",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 75,
        "newest": 19,
        "throughputHighToLow": 110,
        "latencyLowToHigh": 197,
        "pricingLowToHigh": 8,
        "pricingHighToLow": 123
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-Prover-V2-671B",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.00000218",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "seed"
          ],
          "inputCost": 0.5,
          "outputCost": 2.18,
          "throughput": 61.552,
          "latency": 1233.5
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-Prover-V2-671B",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.00000218",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.7,
          "outputCost": 2.18,
          "throughput": 52.661,
          "latency": 1227
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 160000,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek/deepseek-prover-v2-671b",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.7,
          "outputCost": 2.5,
          "throughput": 24.305,
          "latency": 1334
        }
      ]
    },
    {
      "slug": "mistralai/mistral-nemo",
      "hfSlug": "mistralai/Mistral-Nemo-Instruct-2407",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-19T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral Nemo (free)",
      "shortName": "Mistral Nemo (free)",
      "author": "mistralai",
      "description": "A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.\n\nThe model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.\n\nIt supports function calling and is released under the Apache 2.0 license.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-nemo",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "d35a6a62-895e-4130-8ab6-3a7dcca5edeb",
        "name": "Chutes | mistralai/mistral-nemo:free",
        "contextLength": 128000,
        "model": {
          "slug": "mistralai/mistral-nemo",
          "hfSlug": "mistralai/Mistral-Nemo-Instruct-2407",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-07-19T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral Nemo",
          "shortName": "Mistral Nemo",
          "author": "mistralai",
          "description": "A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.\n\nThe model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.\n\nIt supports function calling and is released under the Apache 2.0 license.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-nemo",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-nemo:free",
        "modelVariantPermaslug": "mistralai/mistral-nemo:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "unsloth/Mistral-Nemo-Instruct-2407",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 128000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 15,
        "newest": 234,
        "throughputHighToLow": 57,
        "latencyLowToHigh": 61,
        "pricingLowToHigh": 68,
        "pricingHighToLow": 236
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "mistralai/Mistral-Nemo-Instruct-2407",
          "pricing": {
            "prompt": "0.000000025",
            "completion": "0.00000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.02,
          "outputCost": 0.07,
          "throughput": 120.843,
          "latency": 474
        },
        {
          "name": "Enfer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256",
          "slug": "enfer",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 65536,
          "providerModelId": "mistralai/mistral-nemo",
          "pricing": {
            "prompt": "0.00000003",
            "completion": "0.00000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logit_bias",
            "logprobs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.07,
          "throughput": 54.5395,
          "latency": 6404
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "mistral:nemo",
          "pricing": {
            "prompt": "0.000000033",
            "completion": "0.00000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.07,
          "throughput": 51.5295,
          "latency": 1619.5
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/Mistral-Nemo-Instruct-2407",
          "pricing": {
            "prompt": "0.000000035",
            "completion": "0.00000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.04,
          "outputCost": 0.08,
          "throughput": 55.309,
          "latency": 452
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/mistral-nemo-12b-instruct/fp-8",
          "pricing": {
            "prompt": "0.0000000375",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.04,
          "outputCost": 0.1,
          "throughput": 60.969,
          "latency": 1218
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/Mistral-Nemo-Instruct-2407",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.04,
          "outputCost": 0.12,
          "throughput": 34.442,
          "latency": 675
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/mistral-nemo",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000017",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.04,
          "outputCost": 0.17,
          "throughput": 36.7265,
          "latency": 1356
        },
        {
          "name": "Atoma",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://atoma.network/&size=256",
          "slug": "atoma",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 80000,
          "providerModelId": "mistralai/Mistral-Nemo-Instruct-2407",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 51.7,
          "latency": 641
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-mistral-nemo",
          "pricing": {
            "prompt": "0.00000011",
            "completion": "0.00000011",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.11,
          "outputCost": 0.11,
          "throughput": 144.2685,
          "latency": 509
        },
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "open-mistral-nemo-2407",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.15,
          "outputCost": 0.15,
          "throughput": 143.459,
          "latency": 212
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-nemo",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "response_format",
            "stop",
            "seed"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 98.2295,
          "latency": 1152
        }
      ]
    },
    {
      "slug": "google/gemma-3-12b-it",
      "hfSlug": "google/gemma-3-12b-it",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-13T21:50:25.140801+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 3 12B (free)",
      "shortName": "Gemma 3 12B (free)",
      "author": "google",
      "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 12B is the second largest in the family of Gemma 3 models after [Gemma 3 27B](google/gemma-3-27b-it)",
      "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemma-3-12b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "acf1bb7e-9623-4634-aaae-aefa5bcdc591",
        "name": "Chutes | google/gemma-3-12b-it:free",
        "contextLength": 131072,
        "model": {
          "slug": "google/gemma-3-12b-it",
          "hfSlug": "google/gemma-3-12b-it",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-13T21:50:25.140801+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 3 12B",
          "shortName": "Gemma 3 12B",
          "author": "google",
          "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 12B is the second largest in the family of Gemma 3 models after [Gemma 3 27B](google/gemma-3-27b-it)",
          "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemma-3-12b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-3-12b-it:free",
        "modelVariantPermaslug": "google/gemma-3-12b-it:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "unsloth/gemma-3-12b-it",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 77,
        "newest": 87,
        "throughputHighToLow": 170,
        "latencyLowToHigh": 196,
        "pricingLowToHigh": 39,
        "pricingHighToLow": 220
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-3-12b-it",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.05,
          "outputCost": 0.1,
          "throughput": 23.7935,
          "latency": 1191
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 80000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/google/gemma-3-12b-it",
          "pricing": {
            "prompt": "0.00000035",
            "completion": "0.00000056",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.35,
          "outputCost": 0.56,
          "throughput": 68.19,
          "latency": 593
        }
      ]
    },
    {
      "slug": "openai/chatgpt-4o-latest",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: ChatGPT-4o",
      "shortName": "ChatGPT-4o",
      "author": "openai",
      "description": "OpenAI ChatGPT 4o is continually updated by OpenAI to point to the current version of GPT-4o used by ChatGPT. It therefore differs slightly from the API version of [GPT-4o](/models/openai/gpt-4o) in that it has additional RLHF. It is intended for research and evaluation.\n\nOpenAI notes that this model is not suited for production use-cases as it may be removed or redirected to another model in the future.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/chatgpt-4o-latest",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "aff4b825-af10-4633-9ab2-9ac68c547988",
        "name": "OpenAI | openai/chatgpt-4o-latest",
        "contextLength": 128000,
        "model": {
          "slug": "openai/chatgpt-4o-latest",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-14T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: ChatGPT-4o",
          "shortName": "ChatGPT-4o",
          "author": "openai",
          "description": "OpenAI ChatGPT 4o is continually updated by OpenAI to point to the current version of GPT-4o used by ChatGPT. It therefore differs slightly from the API version of [GPT-4o](/models/openai/gpt-4o) in that it has additional RLHF. It is intended for research and evaluation.\n\nOpenAI notes that this model is not suited for production use-cases as it may be removed or redirected to another model in the future.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/chatgpt-4o-latest",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/chatgpt-4o-latest",
        "modelVariantPermaslug": "openai/chatgpt-4o-latest",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "chatgpt-4o-latest",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000005",
          "completion": "0.000015",
          "image": "0.007225",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 78,
        "newest": 220,
        "throughputHighToLow": 69,
        "latencyLowToHigh": 79,
        "pricingLowToHigh": 292,
        "pricingHighToLow": 28
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "chatgpt-4o-latest",
          "pricing": {
            "prompt": "0.000005",
            "completion": "0.000015",
            "image": "0.007225",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 5,
          "outputCost": 15,
          "throughput": 93.961,
          "latency": 496
        }
      ]
    },
    {
      "slug": "sao10k/l3.1-euryale-70b",
      "hfSlug": "Sao10K/L3.1-70B-Euryale-v2.2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Sao10K: Llama 3.1 Euryale 70B v2.2",
      "shortName": "Llama 3.1 Euryale 70B v2.2",
      "author": "sao10k",
      "description": "Euryale L3.1 70B v2.2 is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k). It is the successor of [Euryale L3 70B v2.1](/models/sao10k/l3-euryale-70b).",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "sao10k/l3.1-euryale-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7ab4ba43-98eb-4842-9046-f7f1822ab3a2",
        "name": "DeepInfra | sao10k/l3.1-euryale-70b",
        "contextLength": 131072,
        "model": {
          "slug": "sao10k/l3.1-euryale-70b",
          "hfSlug": "Sao10K/L3.1-70B-Euryale-v2.2",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Sao10K: Llama 3.1 Euryale 70B v2.2",
          "shortName": "Llama 3.1 Euryale 70B v2.2",
          "author": "sao10k",
          "description": "Euryale L3.1 70B v2.2 is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k). It is the successor of [Euryale L3 70B v2.1](/models/sao10k/l3-euryale-70b).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "sao10k/l3.1-euryale-70b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "sao10k/l3.1-euryale-70b",
        "modelVariantPermaslug": "sao10k/l3.1-euryale-70b",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Sao10K/L3.1-70B-Euryale-v2.2",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000007",
          "completion": "0.0000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 79,
        "newest": 216,
        "throughputHighToLow": 216,
        "latencyLowToHigh": 40,
        "pricingLowToHigh": 197,
        "pricingHighToLow": 122
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "Sao10K/L3.1-70B-Euryale-v2.2",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.7,
          "outputCost": 0.8,
          "throughput": 38.391,
          "latency": 468
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "sao10k/l31-70b-euryale-v2.2",
          "pricing": {
            "prompt": "0.00000148",
            "completion": "0.00000148",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 1.48,
          "outputCost": 1.48,
          "throughput": 34.1995,
          "latency": 1466.5
        },
        {
          "name": "Infermatic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256",
          "slug": "infermatic",
          "quantization": "fp8",
          "context": 16000,
          "maxCompletionTokens": null,
          "providerModelId": "L3.1-70B-Euryale-v2.2-FP8-Dynamic",
          "pricing": {
            "prompt": "0.0000015",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 1.5,
          "outputCost": 1.5,
          "throughput": 21.66,
          "latency": 1633.5
        }
      ]
    },
    {
      "slug": "neversleep/llama-3-lumimaid-8b",
      "hfSlug": "NeverSleep/Llama-3-Lumimaid-8B-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-04T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "NeverSleep: Llama 3 Lumimaid 8B (extended)",
      "shortName": "Llama 3 Lumimaid 8B (extended)",
      "author": "neversleep",
      "description": "The NeverSleep team is back, with a Llama 3 8B finetune trained on their curated roleplay data. Striking a balance between eRP and RP, Lumimaid was designed to be serious, yet uncensored when necessary.\n\nTo enhance it's overall intelligence and chat capability, roughly 40% of the training data was not roleplay. This provides a breadth of knowledge to access, while still keeping roleplay as the primary strength.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 24576,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "neversleep/llama-3-lumimaid-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2a3f32a8-a4f2-45b7-820d-ac1b4fb6dfa5",
        "name": "Mancer | neversleep/llama-3-lumimaid-8b:extended",
        "contextLength": 24576,
        "model": {
          "slug": "neversleep/llama-3-lumimaid-8b",
          "hfSlug": "NeverSleep/Llama-3-Lumimaid-8B-v0.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-04T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "NeverSleep: Llama 3 Lumimaid 8B",
          "shortName": "Llama 3 Lumimaid 8B",
          "author": "neversleep",
          "description": "The NeverSleep team is back, with a Llama 3 8B finetune trained on their curated roleplay data. Striking a balance between eRP and RP, Lumimaid was designed to be serious, yet uncensored when necessary.\n\nTo enhance it's overall intelligence and chat capability, roughly 40% of the training data was not roleplay. This provides a breadth of knowledge to access, while still keeping roleplay as the primary strength.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 24576,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "neversleep/llama-3-lumimaid-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "neversleep/llama-3-lumimaid-8b:extended",
        "modelVariantPermaslug": "neversleep/llama-3-lumimaid-8b:extended",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "lumi-8b",
        "providerGroup": "Mancer",
        "quantization": "unknown",
        "variant": "extended",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000009375",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 80,
        "newest": 263,
        "throughputHighToLow": 144,
        "latencyLowToHigh": 95,
        "pricingLowToHigh": 152,
        "pricingHighToLow": 166
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "unknown",
          "context": 24576,
          "maxCompletionTokens": 2048,
          "providerModelId": "lumi-8b",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000009375",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.15,
          "outputCost": 0.94,
          "throughput": 57.9765,
          "latency": 641
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "unknown",
          "context": 24576,
          "maxCompletionTokens": 2048,
          "providerModelId": "lumi-8b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.00000125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.2,
          "outputCost": 1.25,
          "throughput": 60.202,
          "latency": 435
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 8192,
          "maxCompletionTokens": 4096,
          "providerModelId": "NeverSleep/Llama-3-Lumimaid-8B-v0.1",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 25.6735,
          "latency": 1299.5
        }
      ]
    },
    {
      "slug": "cohere/command-r7b-12-2024",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-14T06:35:52.905418+00:00",
      "hfUpdatedAt": null,
      "name": "Cohere: Command R7B (12-2024)",
      "shortName": "Command R7B (12-2024)",
      "author": "cohere",
      "description": "Command R7B (12-2024) is a small, fast update of the Command R+ model, delivered in December 2024. It excels at RAG, tool use, agents, and similar tasks requiring complex reasoning and multiple steps.\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Cohere",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cohere/command-r7b-12-2024",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "d4a57205-8124-413a-ab4e-5ae94eb7aa9d",
        "name": "Cohere | cohere/command-r7b-12-2024",
        "contextLength": 128000,
        "model": {
          "slug": "cohere/command-r7b-12-2024",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-14T06:35:52.905418+00:00",
          "hfUpdatedAt": null,
          "name": "Cohere: Command R7B (12-2024)",
          "shortName": "Command R7B (12-2024)",
          "author": "cohere",
          "description": "Command R7B (12-2024) is a small, fast update of the Command R+ model, delivered in December 2024. It excels at RAG, tool use, agents, and similar tasks requiring complex reasoning and multiple steps.\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Cohere",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cohere/command-r7b-12-2024",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cohere/command-r7b-12-2024",
        "modelVariantPermaslug": "cohere/command-r7b-12-2024",
        "providerName": "Cohere",
        "providerInfo": {
          "name": "Cohere",
          "displayName": "Cohere",
          "slug": "cohere",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://cohere.com/privacy",
            "termsOfServiceUrl": "https://cohere.com/terms-of-use",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cohere",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cohere.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Cohere.png"
          }
        },
        "providerDisplayName": "Cohere",
        "providerModelId": "command-r7b-12-2024",
        "providerGroup": "Cohere",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://cohere.com/privacy",
          "termsOfServiceUrl": "https://cohere.com/terms-of-use",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000000375",
          "completion": "0.00000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 81,
        "newest": 155,
        "throughputHighToLow": 19,
        "latencyLowToHigh": 5,
        "pricingLowToHigh": 93,
        "pricingHighToLow": 224
      },
      "authorIcon": "https://openrouter.ai/images/icons/Cohere.png",
      "providers": [
        {
          "name": "Cohere",
          "icon": "https://openrouter.ai/images/icons/Cohere.png",
          "slug": "cohere",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 4000,
          "providerModelId": "command-r7b-12-2024",
          "pricing": {
            "prompt": "0.0000000375",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.04,
          "outputCost": 0.15,
          "throughput": 179.89,
          "latency": 166
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3-8b-instruct",
      "hfSlug": "meta-llama/Meta-Llama-3-8B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-18T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3 8B Instruct",
      "shortName": "Llama 3 8B Instruct",
      "author": "meta-llama",
      "description": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 8B instruct-tuned version was optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "803c32ed-9861-4abf-b5da-7d9c9e6dcf04",
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3-8b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c6e34375-c207-4d60-9a43-38b2b730815a",
        "name": "DeepInfra | meta-llama/llama-3-8b-instruct",
        "contextLength": 8192,
        "model": {
          "slug": "meta-llama/llama-3-8b-instruct",
          "hfSlug": "meta-llama/Meta-Llama-3-8B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-04-18T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3 8B Instruct",
          "shortName": "Llama 3 8B Instruct",
          "author": "meta-llama",
          "description": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 8B instruct-tuned version was optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": "803c32ed-9861-4abf-b5da-7d9c9e6dcf04",
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3-8b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3-8b-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3-8b-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "meta-llama/Meta-Llama-3-8B-Instruct",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000003",
          "completion": "0.00000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 82,
        "newest": 266,
        "throughputHighToLow": 56,
        "latencyLowToHigh": 47,
        "pricingLowToHigh": 85,
        "pricingHighToLow": 233
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 8192,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Meta-Llama-3-8B-Instruct",
          "pricing": {
            "prompt": "0.00000003",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 118.38,
          "latency": 414
        },
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "unknown",
          "context": 16384,
          "maxCompletionTokens": 2048,
          "providerModelId": "llama3-8b",
          "pricing": {
            "prompt": "0.0000000375",
            "completion": "0.0000001875",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.04,
          "outputCost": 0.19,
          "throughput": 62.8175,
          "latency": 489
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "meta-llama/llama-3-8b-instruct",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.04,
          "outputCost": 0.04,
          "throughput": 62.302,
          "latency": 854
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "llama3-8b-8192",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.05,
          "outputCost": 0.08,
          "throughput": 3250,
          "latency": 448
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "unknown",
          "context": 16384,
          "maxCompletionTokens": 2048,
          "providerModelId": "llama3-8b",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.05,
          "outputCost": 0.25,
          "throughput": 59.745,
          "latency": 482.5
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "int4",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3-8B-Instruct-Lite",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 207.317,
          "latency": 362
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 7968,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3-8b-instruct",
          "pricing": {
            "prompt": "0.00000028",
            "completion": "0.00000083",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.28,
          "outputCost": 0.83,
          "throughput": 15.6185,
          "latency": 833
        }
      ]
    },
    {
      "slug": "minimax/minimax-01",
      "hfSlug": "MiniMaxAI/MiniMax-Text-01",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-01-15T04:31:02.677929+00:00",
      "hfUpdatedAt": null,
      "name": "MiniMax: MiniMax-01",
      "shortName": "MiniMax-01",
      "author": "minimax",
      "description": "MiniMax-01 is a combines MiniMax-Text-01 for text generation and MiniMax-VL-01 for image understanding. It has 456 billion parameters, with 45.9 billion parameters activated per inference, and can handle a context of up to 4 million tokens.\n\nThe text model adopts a hybrid architecture that combines Lightning Attention, Softmax Attention, and Mixture-of-Experts (MoE). The image model adopts the “ViT-MLP-LLM” framework and is trained on top of the text model.\n\nTo read more about the release, see: https://www.minimaxi.com/en/news/minimax-01-series-2",
      "modelVersionGroupId": null,
      "contextLength": 1000192,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "minimax/minimax-01",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "352546d2-3758-4aa1-9e98-e1a83748aa4e",
        "name": "Minimax | minimax/minimax-01",
        "contextLength": 1000192,
        "model": {
          "slug": "minimax/minimax-01",
          "hfSlug": "MiniMaxAI/MiniMax-Text-01",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-01-15T04:31:02.677929+00:00",
          "hfUpdatedAt": null,
          "name": "MiniMax: MiniMax-01",
          "shortName": "MiniMax-01",
          "author": "minimax",
          "description": "MiniMax-01 is a combines MiniMax-Text-01 for text generation and MiniMax-VL-01 for image understanding. It has 456 billion parameters, with 45.9 billion parameters activated per inference, and can handle a context of up to 4 million tokens.\n\nThe text model adopts a hybrid architecture that combines Lightning Attention, Softmax Attention, and Mixture-of-Experts (MoE). The image model adopts the “ViT-MLP-LLM” framework and is trained on top of the text model.\n\nTo read more about the release, see: https://www.minimaxi.com/en/news/minimax-01-series-2",
          "modelVersionGroupId": null,
          "contextLength": 1000000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "minimax/minimax-01",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "minimax/minimax-01",
        "modelVariantPermaslug": "minimax/minimax-01",
        "providerName": "Minimax",
        "providerInfo": {
          "name": "Minimax",
          "displayName": "Minimax",
          "slug": "minimax",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://www.minimax.io/platform/protocol/privacy-policy",
            "termsOfServiceUrl": "https://www.minimax.io/platform/protocol/terms-of-service",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "CN",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Minimax",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://minimaxi.com/&size=256"
          }
        },
        "providerDisplayName": "Minimax",
        "providerModelId": "MiniMax-Text-01",
        "providerGroup": "Minimax",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 1000192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://www.minimax.io/platform/protocol/privacy-policy",
          "termsOfServiceUrl": "https://www.minimax.io/platform/protocol/terms-of-service",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000002",
          "completion": "0.0000011",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 83,
        "newest": 145,
        "throughputHighToLow": 254,
        "latencyLowToHigh": 217,
        "pricingLowToHigh": 163,
        "pricingHighToLow": 155
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://minimaxi.com/\\u0026size=256",
      "providers": [
        {
          "name": "Minimax",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://minimaxi.com/&size=256",
          "slug": "minimax",
          "quantization": null,
          "context": 1000192,
          "maxCompletionTokens": 1000192,
          "providerModelId": "MiniMax-Text-01",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000011",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p"
          ],
          "inputCost": 0.2,
          "outputCost": 1.1,
          "throughput": 26.798,
          "latency": 1498
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.5-haiku-20241022",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-04T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.5 Haiku (2024-10-22)",
      "shortName": "Claude 3.5 Haiku (2024-10-22)",
      "author": "anthropic",
      "description": "Claude 3.5 Haiku features enhancements across all skill sets including coding, tool use, and reasoning. As the fastest model in the Anthropic lineup, it offers rapid response times suitable for applications that require high interactivity and low latency, such as user-facing chatbots and on-the-fly code completions. It also excels in specialized tasks like data extraction and real-time content moderation, making it a versatile tool for a broad range of industries.\n\nIt does not support image inputs.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/3-5-models-and-computer-use)",
      "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-5-haiku-20241022",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "81dc58ef-b297-4540-ae41-b232d2bf5c3b",
        "name": "Anthropic | anthropic/claude-3-5-haiku-20241022",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.5-haiku-20241022",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-04T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.5 Haiku (2024-10-22)",
          "shortName": "Claude 3.5 Haiku (2024-10-22)",
          "author": "anthropic",
          "description": "Claude 3.5 Haiku features enhancements across all skill sets including coding, tool use, and reasoning. As the fastest model in the Anthropic lineup, it offers rapid response times suitable for applications that require high interactivity and low latency, such as user-facing chatbots and on-the-fly code completions. It also excels in specialized tasks like data extraction and real-time content moderation, making it a versatile tool for a broad range of industries.\n\nIt does not support image inputs.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/3-5-models-and-computer-use)",
          "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-5-haiku-20241022",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.5-haiku-20241022",
        "modelVariantPermaslug": "anthropic/claude-3-5-haiku-20241022",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-5-haiku-20241022",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.000004",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.00000008",
          "inputCacheWrite": "0.000001",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 67,
        "newest": 179,
        "throughputHighToLow": 163,
        "latencyLowToHigh": 221,
        "pricingLowToHigh": 221,
        "pricingHighToLow": 95
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-haiku-20241022",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 52.0085,
          "latency": 1523
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-haiku@20241022",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 69.857,
          "latency": 2450
        }
      ]
    },
    {
      "slug": "liquid/lfm-3b",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-01-25T12:01:41.234073+00:00",
      "hfUpdatedAt": null,
      "name": "Liquid: LFM 3B",
      "shortName": "LFM 3B",
      "author": "liquid",
      "description": "Liquid's LFM 3B delivers incredible performance for its size. It positions itself as first place among 3B parameter transformers, hybrids, and RNN models It is also on par with Phi-3.5-mini on multiple benchmarks, while being 18.4% smaller.\n\nLFM-3B is the ideal choice for mobile and other edge text-based applications.\n\nSee the [launch announcement](https://www.liquid.ai/liquid-foundation-models) for benchmarks and more info.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "liquid/lfm-3b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "d781db49-6ca7-4406-a08e-887fed07665b",
        "name": "Liquid | liquid/lfm-3b",
        "contextLength": 32768,
        "model": {
          "slug": "liquid/lfm-3b",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-01-25T12:01:41.234073+00:00",
          "hfUpdatedAt": null,
          "name": "Liquid: LFM 3B",
          "shortName": "LFM 3B",
          "author": "liquid",
          "description": "Liquid's LFM 3B delivers incredible performance for its size. It positions itself as first place among 3B parameter transformers, hybrids, and RNN models It is also on par with Phi-3.5-mini on multiple benchmarks, while being 18.4% smaller.\n\nLFM-3B is the ideal choice for mobile and other edge text-based applications.\n\nSee the [launch announcement](https://www.liquid.ai/liquid-foundation-models) for benchmarks and more info.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "liquid/lfm-3b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "liquid/lfm-3b",
        "modelVariantPermaslug": "liquid/lfm-3b",
        "providerName": "Liquid",
        "providerInfo": {
          "name": "Liquid",
          "displayName": "Liquid",
          "slug": "liquid",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.liquid.ai/terms-conditions",
            "privacyPolicyUrl": "https://www.liquid.ai/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Liquid",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.liquid.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Liquid",
        "providerModelId": "lfm-3b",
        "providerGroup": "Liquid",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.liquid.ai/terms-conditions",
          "privacyPolicyUrl": "https://www.liquid.ai/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000002",
          "completion": "0.00000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 85,
        "newest": 140,
        "throughputHighToLow": 258,
        "latencyLowToHigh": 137,
        "pricingLowToHigh": 75,
        "pricingHighToLow": 243
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://www.liquid.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Liquid",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.liquid.ai/&size=256",
          "slug": "liquid",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "lfm-3b",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.02,
          "outputCost": 0.02,
          "throughput": 23.198,
          "latency": 863
        }
      ]
    },
    {
      "slug": "qwen/qwen-2.5-coder-32b-instruct",
      "hfSlug": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-11T23:40:00.276653+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen2.5 Coder 32B Instruct",
      "shortName": "Qwen2.5 Coder 32B Instruct",
      "author": "qwen",
      "description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:\n\n- Significantly improvements in **code generation**, **code reasoning** and **code fixing**. \n- A more comprehensive foundation for real-world applications such as **Code Agents**. Not only enhancing coding capabilities but also maintaining its strengths in mathematics and general competencies.\n\nTo read more about its evaluation results, check out [Qwen 2.5 Coder's blog](https://qwenlm.github.io/blog/qwen2.5-coder-family/).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2.5-coder-32b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "48e34779-1643-4717-8c51-9a9e02f4b993",
        "name": "DeepInfra | qwen/qwen-2.5-coder-32b-instruct",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen-2.5-coder-32b-instruct",
          "hfSlug": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-11T23:40:00.276653+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen2.5 Coder 32B Instruct",
          "shortName": "Qwen2.5 Coder 32B Instruct",
          "author": "qwen",
          "description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:\n\n- Significantly improvements in **code generation**, **code reasoning** and **code fixing**. \n- A more comprehensive foundation for real-world applications such as **Code Agents**. Not only enhancing coding capabilities but also maintaining its strengths in mathematics and general competencies.\n\nTo read more about its evaluation results, check out [Qwen 2.5 Coder's blog](https://qwenlm.github.io/blog/qwen2.5-coder-family/).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-2.5-coder-32b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-2.5-coder-32b-instruct",
        "modelVariantPermaslug": "qwen/qwen-2.5-coder-32b-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000006",
          "completion": "0.00000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 86,
        "newest": 172,
        "throughputHighToLow": 159,
        "latencyLowToHigh": 66,
        "pricingLowToHigh": 59,
        "pricingHighToLow": 215
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.06,
          "outputCost": 0.15,
          "throughput": 53.256,
          "latency": 392
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.06,
          "outputCost": 0.18,
          "throughput": 52.042,
          "latency": 467
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "qwen25-coder-32b-instruct",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000016",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.07,
          "outputCost": 0.16,
          "throughput": 44.4645,
          "latency": 517
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 8192,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 53.4815,
          "latency": 1119
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-qwen-coder32b-longcontext-128",
          "pricing": {
            "prompt": "0.00000035",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.35,
          "outputCost": 0.5,
          "throughput": 56.927,
          "latency": 562.5
        },
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "qwen2.5-coder-32b",
          "pricing": {
            "prompt": "0.000000375",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.38,
          "outputCost": 1.5,
          "throughput": 31.565,
          "latency": 807
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "qwen2.5-coder-32b",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.5,
          "outputCost": 2,
          "throughput": 31.802,
          "latency": 1431
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/qwen/qwen2.5-coder-32b-instruct",
          "pricing": {
            "prompt": "0.00000066",
            "completion": "0.000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.66,
          "outputCost": 1,
          "throughput": 34.9445,
          "latency": 1051
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 2048,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 91.863,
          "latency": 803
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.0000026",
            "completion": "0.0000034",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 2.6,
          "outputCost": 3.4
        }
      ]
    },
    {
      "slug": "thedrummer/rocinante-12b",
      "hfSlug": "TheDrummer/Rocinante-12B-v1.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-30T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Rocinante 12B",
      "shortName": "Rocinante 12B",
      "author": "thedrummer",
      "description": "Rocinante 12B is designed for engaging storytelling and rich prose.\n\nEarly testers have reported:\n- Expanded vocabulary with unique and expressive word choices\n- Enhanced creativity for vivid narratives\n- Adventure-filled and captivating stories",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thedrummer/rocinante-12b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "caf29916-6adb-45f8-b895-dd863415d3ed",
        "name": "Infermatic | thedrummer/rocinante-12b",
        "contextLength": 32768,
        "model": {
          "slug": "thedrummer/rocinante-12b",
          "hfSlug": "TheDrummer/Rocinante-12B-v1.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-30T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Rocinante 12B",
          "shortName": "Rocinante 12B",
          "author": "thedrummer",
          "description": "Rocinante 12B is designed for engaging storytelling and rich prose.\n\nEarly testers have reported:\n- Expanded vocabulary with unique and expressive word choices\n- Enhanced creativity for vivid narratives\n- Adventure-filled and captivating stories",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thedrummer/rocinante-12b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "thedrummer/rocinante-12b",
        "modelVariantPermaslug": "thedrummer/rocinante-12b",
        "providerName": "Infermatic",
        "providerInfo": {
          "name": "Infermatic",
          "displayName": "Infermatic",
          "slug": "infermatic",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://infermatic.ai/privacy-policy/",
            "termsOfServiceUrl": "https://infermatic.ai/terms-and-conditions/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Infermatic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256"
          }
        },
        "providerDisplayName": "Infermatic",
        "providerModelId": "TheDrummer-Rocinante-12B-v1.1",
        "providerGroup": "Infermatic",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://infermatic.ai/privacy-policy/",
          "termsOfServiceUrl": "https://infermatic.ai/terms-and-conditions/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000025",
          "completion": "0.0000005",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 87,
        "newest": 194,
        "throughputHighToLow": 103,
        "latencyLowToHigh": 42,
        "pricingLowToHigh": 162,
        "pricingHighToLow": 156
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Infermatic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256",
          "slug": "infermatic",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "TheDrummer-Rocinante-12B-v1.1",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.25,
          "outputCost": 0.5,
          "throughput": 76.25,
          "latency": 384
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "TheDrummer/Rocinante-12B-v1.1",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 18.1835,
          "latency": 1293
        }
      ]
    },
    {
      "slug": "google/gemma-3-12b-it",
      "hfSlug": "google/gemma-3-12b-it",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-13T21:50:25.140801+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 3 12B",
      "shortName": "Gemma 3 12B",
      "author": "google",
      "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 12B is the second largest in the family of Gemma 3 models after [Gemma 3 27B](google/gemma-3-27b-it)",
      "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemma-3-12b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "eb06dc92-5a16-47ec-a776-6ef956457c47",
        "name": "DeepInfra | google/gemma-3-12b-it",
        "contextLength": 131072,
        "model": {
          "slug": "google/gemma-3-12b-it",
          "hfSlug": "google/gemma-3-12b-it",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-13T21:50:25.140801+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 3 12B",
          "shortName": "Gemma 3 12B",
          "author": "google",
          "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 12B is the second largest in the family of Gemma 3 models after [Gemma 3 27B](google/gemma-3-27b-it)",
          "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemma-3-12b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-3-12b-it",
        "modelVariantPermaslug": "google/gemma-3-12b-it",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "google/gemma-3-12b-it",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000005",
          "completion": "0.0000001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 77,
        "newest": 87,
        "throughputHighToLow": 170,
        "latencyLowToHigh": 196,
        "pricingLowToHigh": 39,
        "pricingHighToLow": 220
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-3-12b-it",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.05,
          "outputCost": 0.1,
          "throughput": 23.7935,
          "latency": 1191
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 80000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/google/gemma-3-12b-it",
          "pricing": {
            "prompt": "0.00000035",
            "completion": "0.00000056",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.35,
          "outputCost": 0.56,
          "throughput": 68.19,
          "latency": 593
        }
      ]
    },
    {
      "slug": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "hfSlug": "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1",
      "updatedAt": "2025-04-08T16:16:48.985354+00:00",
      "createdAt": "2025-04-08T12:24:19.697786+00:00",
      "hfUpdatedAt": null,
      "name": "NVIDIA: Llama 3.1 Nemotron Ultra 253B v1 (free)",
      "shortName": "Llama 3.1 Nemotron Ultra 253B v1 (free)",
      "author": "nvidia",
      "description": "Llama-3.1-Nemotron-Ultra-253B-v1 is a large language model (LLM) optimized for advanced reasoning, human-interactive chat, retrieval-augmented generation (RAG), and tool-calling tasks. Derived from Meta’s Llama-3.1-405B-Instruct, it has been significantly customized using Neural Architecture Search (NAS), resulting in enhanced efficiency, reduced memory usage, and improved inference latency. The model supports a context length of up to 128K tokens and can operate efficiently on an 8x NVIDIA H100 node.\n\nNote: you must include `detailed thinking on` in the system prompt to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations) for more.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2ce4225f-d3bf-47ed-9d92-d6a5c37c1725",
        "name": "Chutes | nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
        "contextLength": 131072,
        "model": {
          "slug": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
          "hfSlug": "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1",
          "updatedAt": "2025-04-08T16:16:48.985354+00:00",
          "createdAt": "2025-04-08T12:24:19.697786+00:00",
          "hfUpdatedAt": null,
          "name": "NVIDIA: Llama 3.1 Nemotron Ultra 253B v1",
          "shortName": "Llama 3.1 Nemotron Ultra 253B v1",
          "author": "nvidia",
          "description": "Llama-3.1-Nemotron-Ultra-253B-v1 is a large language model (LLM) optimized for advanced reasoning, human-interactive chat, retrieval-augmented generation (RAG), and tool-calling tasks. Derived from Meta’s Llama-3.1-405B-Instruct, it has been significantly customized using Neural Architecture Search (NAS), resulting in enhanced efficiency, reduced memory usage, and improved inference latency. The model supports a context length of up to 128K tokens and can operate efficiently on an 8x NVIDIA H100 node.\n\nNote: you must include `detailed thinking on` in the system prompt to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations) for more.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
        "modelVariantPermaslug": "nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 89,
        "newest": 60,
        "throughputHighToLow": 230,
        "latencyLowToHigh": 238,
        "pricingLowToHigh": 25,
        "pricingHighToLow": 273
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nvidia.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "meta-llama/llama-3.1-405b-instruct",
      "hfSlug": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-23T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.1 405B Instruct",
      "shortName": "Llama 3.1 405B Instruct",
      "author": "meta-llama",
      "description": "The highly anticipated 400B class of Llama3 is here! Clocking in at 128k context with impressive eval scores, the Meta AI team continues to push the frontier of open-source LLMs.\n\nMeta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 405B instruct-tuned version is optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models including GPT-4o and Claude 3.5 Sonnet in evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "1fd9d06b-aa20-4c7d-a0b1-d3d9b5aae712",
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.1-405b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ea74be37-05ac-4934-9734-709cef644954",
        "name": "DeepInfra | meta-llama/llama-3.1-405b-instruct",
        "contextLength": 32768,
        "model": {
          "slug": "meta-llama/llama-3.1-405b-instruct",
          "hfSlug": "meta-llama/Meta-Llama-3.1-405B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-07-23T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.1 405B Instruct",
          "shortName": "Llama 3.1 405B Instruct",
          "author": "meta-llama",
          "description": "The highly anticipated 400B class of Llama3 is here! Clocking in at 128k context with impressive eval scores, the Meta AI team continues to push the frontier of open-source LLMs.\n\nMeta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 405B instruct-tuned version is optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models including GPT-4o and Claude 3.5 Sonnet in evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": "1fd9d06b-aa20-4c7d-a0b1-d3d9b5aae712",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.1-405b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.1-405b-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3.1-405b-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "meta-llama/Meta-Llama-3.1-405B-Instruct",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 90,
        "newest": 231,
        "throughputHighToLow": 278,
        "latencyLowToHigh": 130,
        "pricingLowToHigh": 201,
        "pricingHighToLow": 117
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Meta-Llama-3.1-405B-Instruct",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 22.3215,
          "latency": 789
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.1-405b-instruct-fp8",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 35.068,
          "latency": 571.5
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-405B-Instruct",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 1,
          "outputCost": 3,
          "throughput": 33.813,
          "latency": 646
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama-v3p1-405b-instruct",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 3,
          "outputCost": 3,
          "throughput": 69.93,
          "latency": 585
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 130815,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.0000035",
            "completion": "0.0000035",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 3.5,
          "outputCost": 3.5,
          "throughput": 53.422,
          "latency": 453
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 131000,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-405B-Instruct",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 4,
          "outputCost": 4,
          "throughput": 72.291,
          "latency": 1408
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "Meta-Llama-3.1-405B-Instruct",
          "pricing": {
            "prompt": "0.000005",
            "completion": "0.00001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 5,
          "outputCost": 10,
          "throughput": 111.084,
          "latency": 2800.5
        }
      ]
    },
    {
      "slug": "qwen/qwen3-14b",
      "hfSlug": "Qwen/Qwen3-14B",
      "updatedAt": "2025-05-12T00:36:13.09542+00:00",
      "createdAt": "2025-04-28T21:41:18.320017+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 14B",
      "shortName": "Qwen3 14B",
      "author": "qwen",
      "description": "Qwen3-14B is a dense 14.8B parameter causal language model from the Qwen3 series, designed for both complex reasoning and efficient dialogue. It supports seamless switching between a \"thinking\" mode for tasks like math, programming, and logical inference, and a \"non-thinking\" mode for general-purpose conversation. The model is fine-tuned for instruction-following, agent tool use, creative writing, and multilingual tasks across 100+ languages and dialects. It natively handles 32K token contexts and can extend to 131K tokens using YaRN-based scaling.",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-14b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "778bdebf-d018-4a24-a34e-230fce0f2045",
        "name": "DeepInfra | qwen/qwen3-14b-04-28",
        "contextLength": 40960,
        "model": {
          "slug": "qwen/qwen3-14b",
          "hfSlug": "Qwen/Qwen3-14B",
          "updatedAt": "2025-05-12T00:36:13.09542+00:00",
          "createdAt": "2025-04-28T21:41:18.320017+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 14B",
          "shortName": "Qwen3 14B",
          "author": "qwen",
          "description": "Qwen3-14B is a dense 14.8B parameter causal language model from the Qwen3 series, designed for both complex reasoning and efficient dialogue. It supports seamless switching between a \"thinking\" mode for tasks like math, programming, and logical inference, and a \"non-thinking\" mode for general-purpose conversation. The model is fine-tuned for instruction-following, agent tool use, creative writing, and multilingual tasks across 100+ languages and dialects. It natively handles 32K token contexts and can extend to 131K tokens using YaRN-based scaling.",
          "modelVersionGroupId": null,
          "contextLength": 131702,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-14b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-14b",
        "modelVariantPermaslug": "qwen/qwen3-14b-04-28",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Qwen/Qwen3-14B",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 40960,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000007",
          "completion": "0.00000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 91,
        "newest": 26,
        "throughputHighToLow": 64,
        "latencyLowToHigh": 168,
        "pricingLowToHigh": 11,
        "pricingHighToLow": 212
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/Qwen3-14B",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.07,
          "outputCost": 0.24,
          "throughput": 75.5195,
          "latency": 1074
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-14b-fp8",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.000000275",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.07,
          "outputCost": 0.28,
          "throughput": 57.391,
          "latency": 787
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-14B",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.08,
          "outputCost": 0.24,
          "throughput": 93.2875,
          "latency": 271
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-prover-v2",
      "hfSlug": "deepseek-ai/DeepSeek-Prover-V2-671B",
      "updatedAt": "2025-04-30T13:01:50.865169+00:00",
      "createdAt": "2025-04-30T11:38:14.302503+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: DeepSeek Prover V2",
      "shortName": "DeepSeek Prover V2",
      "author": "deepseek",
      "description": "DeepSeek Prover V2 is a 671B parameter model, speculated to be geared towards logic and mathematics. Likely an upgrade from [DeepSeek-Prover-V1.5](https://huggingface.co/deepseek-ai/DeepSeek-Prover-V1.5-RL) Not much is known about the model yet, as DeepSeek released it on Hugging Face without an announcement or description.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-prover-v2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c70b9a14-2531-4ed0-ab12-b8935873c6c7",
        "name": "GMICloud | deepseek/deepseek-prover-v2",
        "contextLength": 131072,
        "model": {
          "slug": "deepseek/deepseek-prover-v2",
          "hfSlug": "deepseek-ai/DeepSeek-Prover-V2-671B",
          "updatedAt": "2025-04-30T13:01:50.865169+00:00",
          "createdAt": "2025-04-30T11:38:14.302503+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: DeepSeek Prover V2",
          "shortName": "DeepSeek Prover V2",
          "author": "deepseek",
          "description": "DeepSeek Prover V2 is a 671B parameter model, speculated to be geared towards logic and mathematics. Likely an upgrade from [DeepSeek-Prover-V1.5](https://huggingface.co/deepseek-ai/DeepSeek-Prover-V1.5-RL) Not much is known about the model yet, as DeepSeek released it on Hugging Face without an announcement or description.",
          "modelVersionGroupId": null,
          "contextLength": 163840,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-prover-v2",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "deepseek/deepseek-prover-v2",
        "modelVariantPermaslug": "deepseek/deepseek-prover-v2",
        "providerName": "GMICloud",
        "providerInfo": {
          "name": "GMICloud",
          "displayName": "GMICloud",
          "slug": "gmicloud",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://docs.gmicloud.ai/privacy",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "GMICloud",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "GMICloud",
        "providerModelId": "deepseek-ai/DeepSeek-Prover-V2-671B",
        "providerGroup": "GMICloud",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://docs.gmicloud.ai/privacy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.00000218",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 75,
        "newest": 19,
        "throughputHighToLow": 110,
        "latencyLowToHigh": 197,
        "pricingLowToHigh": 8,
        "pricingHighToLow": 123
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-Prover-V2-671B",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.00000218",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "seed"
          ],
          "inputCost": 0.5,
          "outputCost": 2.18,
          "throughput": 61.552,
          "latency": 1233.5
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-Prover-V2-671B",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.00000218",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.7,
          "outputCost": 2.18,
          "throughput": 52.661,
          "latency": 1227
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 160000,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek/deepseek-prover-v2-671b",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.7,
          "outputCost": 2.5,
          "throughput": 24.305,
          "latency": 1334
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3-70b-instruct",
      "hfSlug": "meta-llama/Meta-Llama-3-70B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-18T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3 70B Instruct",
      "shortName": "Llama 3 70B Instruct",
      "author": "meta-llama",
      "description": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 70B instruct-tuned version was optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3-70b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "65aab538-54e0-41fa-9b74-687e4552302f",
        "name": "DeepInfra | meta-llama/llama-3-70b-instruct",
        "contextLength": 8192,
        "model": {
          "slug": "meta-llama/llama-3-70b-instruct",
          "hfSlug": "meta-llama/Meta-Llama-3-70B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-04-18T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3 70B Instruct",
          "shortName": "Llama 3 70B Instruct",
          "author": "meta-llama",
          "description": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 70B instruct-tuned version was optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3-70b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3-70b-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3-70b-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "meta-llama/Meta-Llama-3-70B-Instruct",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000003",
          "completion": "0.0000004",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 93,
        "newest": 267,
        "throughputHighToLow": 240,
        "latencyLowToHigh": 117,
        "pricingLowToHigh": 165,
        "pricingHighToLow": 153
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 8192,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Meta-Llama-3-70B-Instruct",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.3,
          "outputCost": 0.4,
          "throughput": 31.9695,
          "latency": 676
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3-70B-Instruct",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 21.804,
          "latency": 1522
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "meta-llama/llama-3-70b-instruct",
          "pricing": {
            "prompt": "0.00000051",
            "completion": "0.00000074",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.51,
          "outputCost": 0.74,
          "throughput": 20.413,
          "latency": 1114
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "llama3-70b-8192",
          "pricing": {
            "prompt": "0.00000059",
            "completion": "0.00000079",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.59,
          "outputCost": 0.79,
          "throughput": 423.9025,
          "latency": 299
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000088",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.88,
          "outputCost": 0.88,
          "throughput": 68.918,
          "latency": 1012
        }
      ]
    },
    {
      "slug": "qwen/qwen3-30b-a3b",
      "hfSlug": "Qwen/Qwen3-30B-A3B",
      "updatedAt": "2025-05-12T00:33:13.151167+00:00",
      "createdAt": "2025-04-28T22:16:44.177326+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 30B A3B (free)",
      "shortName": "Qwen3 30B A3B (free)",
      "author": "qwen",
      "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-30b-a3b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "f31002e4-a626-4f70-9b11-f33e8102df39",
        "name": "Chutes | qwen/qwen3-30b-a3b-04-28:free",
        "contextLength": 40960,
        "model": {
          "slug": "qwen/qwen3-30b-a3b",
          "hfSlug": "Qwen/Qwen3-30B-A3B",
          "updatedAt": "2025-05-12T00:33:13.151167+00:00",
          "createdAt": "2025-04-28T22:16:44.177326+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 30B A3B",
          "shortName": "Qwen3 30B A3B",
          "author": "qwen",
          "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-30b-a3b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-30b-a3b:free",
        "modelVariantPermaslug": "qwen/qwen3-30b-a3b-04-28:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/Qwen3-30B-A3B",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 94,
        "newest": 22,
        "throughputHighToLow": 20,
        "latencyLowToHigh": 127,
        "pricingLowToHigh": 9,
        "pricingHighToLow": 193
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/Qwen3-30B-A3B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 45.6565,
          "latency": 763
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-30B-A3B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 96.9815,
          "latency": 350
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-30b-a3b-fp8",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.00000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.1,
          "outputCost": 0.45,
          "throughput": 97.842,
          "latency": 901
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "parasail-qwen3-30b-a3b",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.1,
          "outputCost": 0.5,
          "throughput": 123.1645,
          "latency": 773.5
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 40000,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwen3-30b-a3b",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 117.7655,
          "latency": 712
        }
      ]
    },
    {
      "slug": "mistralai/mistral-small-3.1-24b-instruct",
      "hfSlug": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-17T19:15:37.00423+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral Small 3.1 24B (free)",
      "shortName": "Mistral Small 3.1 24B (free)",
      "author": "mistralai",
      "description": "Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501), featuring 24 billion parameters with advanced multimodal capabilities. It provides state-of-the-art performance in text-based reasoning and vision tasks, including image analysis, programming, mathematical reasoning, and multilingual support across dozens of languages. Equipped with an extensive 128k token context window and optimized for efficient local inference, it supports use cases such as conversational agents, function calling, long-document comprehension, and privacy-sensitive deployments.",
      "modelVersionGroupId": null,
      "contextLength": 96000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "6aed58f7-0b3a-4693-b8c9-57d5eadec99f",
        "name": "Chutes | mistralai/mistral-small-3.1-24b-instruct-2503:free",
        "contextLength": 96000,
        "model": {
          "slug": "mistralai/mistral-small-3.1-24b-instruct",
          "hfSlug": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-17T19:15:37.00423+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral Small 3.1 24B",
          "shortName": "Mistral Small 3.1 24B",
          "author": "mistralai",
          "description": "Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501), featuring 24 billion parameters with advanced multimodal capabilities. It provides state-of-the-art performance in text-based reasoning and vision tasks, including image analysis, programming, mathematical reasoning, and multilingual support across dozens of languages. Equipped with an extensive 128k token context window and optimized for efficient local inference, it supports use cases such as conversational agents, function calling, long-document comprehension, and privacy-sensitive deployments.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-small-3.1-24b-instruct:free",
        "modelVariantPermaslug": "mistralai/mistral-small-3.1-24b-instruct-2503:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "chutesai/Mistral-Small-3.1-24B-Instruct-2503",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 96000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 64,
        "newest": 79,
        "throughputHighToLow": 104,
        "latencyLowToHigh": 33,
        "pricingLowToHigh": 35,
        "pricingHighToLow": 219
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.05,
          "outputCost": 0.15,
          "throughput": 56.904,
          "latency": 426
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": 128000,
          "providerModelId": "parasail-mistral-small-31-24b-instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0.000926",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 67.411,
          "latency": 1392
        },
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-small-2503",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0.0009264",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 140.296,
          "latency": 219
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/mistralai/mistral-small-3.1-24b-instruct",
          "pricing": {
            "prompt": "0.00000035",
            "completion": "0.00000056",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.35,
          "outputCost": 0.56,
          "throughput": 43.312,
          "latency": 376
        }
      ]
    },
    {
      "slug": "mistralai/codestral-2501",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-01-14T22:58:42.43034+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Codestral 2501",
      "shortName": "Codestral 2501",
      "author": "mistralai",
      "description": "[Mistral](/mistralai)'s cutting-edge language model for coding. Codestral specializes in low-latency, high-frequency tasks such as fill-in-the-middle (FIM), code correction and test generation. \n\nLearn more on their blog post: https://mistral.ai/news/codestral-2501/",
      "modelVersionGroupId": null,
      "contextLength": 262144,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "mistralai/codestral-2501",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7df94044-ae68-4b4f-b3eb-748ed262b778",
        "name": "Mistral | mistralai/codestral-2501",
        "contextLength": 262144,
        "model": {
          "slug": "mistralai/codestral-2501",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-01-14T22:58:42.43034+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Codestral 2501",
          "shortName": "Codestral 2501",
          "author": "mistralai",
          "description": "[Mistral](/mistralai)'s cutting-edge language model for coding. Codestral specializes in low-latency, high-frequency tasks such as fill-in-the-middle (FIM), code correction and test generation. \n\nLearn more on their blog post: https://mistral.ai/news/codestral-2501/",
          "modelVersionGroupId": null,
          "contextLength": 256000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "mistralai/codestral-2501",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/codestral-2501",
        "modelVariantPermaslug": "mistralai/codestral-2501",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "codestral-2501",
        "providerGroup": "Mistral",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000003",
          "completion": "0.0000009",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 96,
        "newest": 146,
        "throughputHighToLow": 74,
        "latencyLowToHigh": 32,
        "pricingLowToHigh": 171,
        "pricingHighToLow": 147
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 262144,
          "maxCompletionTokens": null,
          "providerModelId": "codestral-2501",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.3,
          "outputCost": 0.9,
          "throughput": 104.3605,
          "latency": 326
        }
      ]
    },
    {
      "slug": "qwen/qwen2.5-coder-7b-instruct",
      "hfSlug": "Qwen/Qwen2.5-Coder-7B-Instruct",
      "updatedAt": "2025-04-15T16:36:45.293973+00:00",
      "createdAt": "2025-04-15T16:34:47.067646+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen2.5 Coder 7B Instruct",
      "shortName": "Qwen2.5 Coder 7B Instruct",
      "author": "qwen",
      "description": "Qwen2.5-Coder-7B-Instruct is a 7B parameter instruction-tuned language model optimized for code-related tasks such as code generation, reasoning, and bug fixing. Based on the Qwen2.5 architecture, it incorporates enhancements like RoPE, SwiGLU, RMSNorm, and GQA attention with support for up to 128K tokens using YaRN-based extrapolation. It is trained on a large corpus of source code, synthetic data, and text-code grounding, providing robust performance across programming languages and agentic coding workflows.\n\nThis model is part of the Qwen2.5-Coder family and offers strong compatibility with tools like vLLM for efficient deployment. Released under the Apache 2.0 license.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen2.5-coder-7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f8e0be71-53c3-42d5-b579-7f8d7e7b55a7",
        "name": "Nebius | qwen/qwen2.5-coder-7b-instruct",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen2.5-coder-7b-instruct",
          "hfSlug": "Qwen/Qwen2.5-Coder-7B-Instruct",
          "updatedAt": "2025-04-15T16:36:45.293973+00:00",
          "createdAt": "2025-04-15T16:34:47.067646+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen2.5 Coder 7B Instruct",
          "shortName": "Qwen2.5 Coder 7B Instruct",
          "author": "qwen",
          "description": "Qwen2.5-Coder-7B-Instruct is a 7B parameter instruction-tuned language model optimized for code-related tasks such as code generation, reasoning, and bug fixing. Based on the Qwen2.5 architecture, it incorporates enhancements like RoPE, SwiGLU, RMSNorm, and GQA attention with support for up to 128K tokens using YaRN-based extrapolation. It is trained on a large corpus of source code, synthetic data, and text-code grounding, providing robust performance across programming languages and agentic coding workflows.\n\nThis model is part of the Qwen2.5-Coder family and offers strong compatibility with tools like vLLM for efficient deployment. Released under the Apache 2.0 license.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen2.5-coder-7b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen2.5-coder-7b-instruct",
        "modelVariantPermaslug": "qwen/qwen2.5-coder-7b-instruct",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "Qwen/Qwen2.5-Coder-7B-Instruct",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000001",
          "completion": "0.00000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 97,
        "newest": 47,
        "throughputHighToLow": 10,
        "latencyLowToHigh": 8,
        "pricingLowToHigh": 74,
        "pricingHighToLow": 244
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-Coder-7B-Instruct",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.01,
          "outputCost": 0.03,
          "throughput": 222.6585,
          "latency": 202
        }
      ]
    },
    {
      "slug": "sao10k/l3-lunaris-8b",
      "hfSlug": "Sao10K/L3-8B-Lunaris-v1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Sao10K: Llama 3 8B Lunaris",
      "shortName": "Llama 3 8B Lunaris",
      "author": "sao10k",
      "description": "Lunaris 8B is a versatile generalist and roleplaying model based on Llama 3. It's a strategic merge of multiple models, designed to balance creativity with improved logic and general knowledge.\n\nCreated by [Sao10k](https://huggingface.co/Sao10k), this model aims to offer an improved experience over Stheno v3.2, with enhanced creativity and logical reasoning.\n\nFor best results, use with Llama 3 Instruct context template, temperature 1.4, and min_p 0.1.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "sao10k/l3-lunaris-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cc4c8dc5-8b3f-4d54-84e2-8381184ff841",
        "name": "DeepInfra | sao10k/l3-lunaris-8b",
        "contextLength": 8192,
        "model": {
          "slug": "sao10k/l3-lunaris-8b",
          "hfSlug": "Sao10K/L3-8B-Lunaris-v1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-13T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Sao10K: Llama 3 8B Lunaris",
          "shortName": "Llama 3 8B Lunaris",
          "author": "sao10k",
          "description": "Lunaris 8B is a versatile generalist and roleplaying model based on Llama 3. It's a strategic merge of multiple models, designed to balance creativity with improved logic and general knowledge.\n\nCreated by [Sao10k](https://huggingface.co/Sao10k), this model aims to offer an improved experience over Stheno v3.2, with enhanced creativity and logical reasoning.\n\nFor best results, use with Llama 3 Instruct context template, temperature 1.4, and min_p 0.1.",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "sao10k/l3-lunaris-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "sao10k/l3-lunaris-8b",
        "modelVariantPermaslug": "sao10k/l3-lunaris-8b",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Sao10K/L3-8B-Lunaris-v1-Turbo",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000002",
          "completion": "0.00000005",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 98,
        "newest": 221,
        "throughputHighToLow": 115,
        "latencyLowToHigh": 18,
        "pricingLowToHigh": 78,
        "pricingHighToLow": 240
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "Sao10K/L3-8B-Lunaris-v1-Turbo",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.02,
          "outputCost": 0.05,
          "throughput": 65.573,
          "latency": 263
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "sao10k/l3-8b-lunaris",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.05,
          "outputCost": 0.05,
          "throughput": 76.0465,
          "latency": 735
        }
      ]
    },
    {
      "slug": "qwen/qwen3-8b",
      "hfSlug": "Qwen/Qwen3-8B",
      "updatedAt": "2025-05-12T00:35:52.624106+00:00",
      "createdAt": "2025-04-28T21:43:52.421936+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 8B",
      "shortName": "Qwen3 8B",
      "author": "qwen",
      "description": "Qwen3-8B is a dense 8.2B parameter causal language model from the Qwen3 series, designed for both reasoning-heavy tasks and efficient dialogue. It supports seamless switching between \"thinking\" mode for math, coding, and logical inference, and \"non-thinking\" mode for general conversation. The model is fine-tuned for instruction-following, agent integration, creative writing, and multilingual use across 100+ languages and dialects. It natively supports a 32K token context window and can extend to 131K tokens with YaRN scaling.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-8b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "25334f6f-1e4a-4177-abc3-26260f04e754",
        "name": "Novita | qwen/qwen3-8b-04-28",
        "contextLength": 128000,
        "model": {
          "slug": "qwen/qwen3-8b",
          "hfSlug": "Qwen/Qwen3-8B",
          "updatedAt": "2025-05-12T00:35:52.624106+00:00",
          "createdAt": "2025-04-28T21:43:52.421936+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 8B",
          "shortName": "Qwen3 8B",
          "author": "qwen",
          "description": "Qwen3-8B is a dense 8.2B parameter causal language model from the Qwen3 series, designed for both reasoning-heavy tasks and efficient dialogue. It supports seamless switching between \"thinking\" mode for math, coding, and logical inference, and \"non-thinking\" mode for general conversation. The model is fine-tuned for instruction-following, agent integration, creative writing, and multilingual use across 100+ languages and dialects. It natively supports a 32K token context window and can extend to 131K tokens with YaRN scaling.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-8b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-8b",
        "modelVariantPermaslug": "qwen/qwen3-8b-04-28",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "qwen/qwen3-8b-fp8",
        "providerGroup": "Novita",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000000035",
          "completion": "0.000000138",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 99,
        "newest": 24,
        "throughputHighToLow": 27,
        "latencyLowToHigh": 132,
        "pricingLowToHigh": 10,
        "pricingHighToLow": 229
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-8b-fp8",
          "pricing": {
            "prompt": "0.000000035",
            "completion": "0.000000138",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.04,
          "outputCost": 0.14,
          "throughput": 90.228,
          "latency": 748
        }
      ]
    },
    {
      "slug": "microsoft/phi-4",
      "hfSlug": "microsoft/phi-4",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-01-10T06:17:52.16346+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: Phi 4",
      "shortName": "Phi 4",
      "author": "microsoft",
      "description": "[Microsoft Research](/microsoft) Phi-4 is designed to perform well in complex reasoning tasks and can operate efficiently in situations with limited memory or where quick responses are needed. \n\nAt 14 billion parameters, it was trained on a mix of high-quality synthetic datasets, data from curated websites, and academic materials. It has undergone careful improvement to follow instructions accurately and maintain strong safety standards. It works best with English language inputs.\n\nFor more information, please see [Phi-4 Technical Report](https://arxiv.org/pdf/2412.08905)\n",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/phi-4",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8e48942d-17fc-4d00-a234-4723034fd971",
        "name": "DeepInfra | microsoft/phi-4",
        "contextLength": 16384,
        "model": {
          "slug": "microsoft/phi-4",
          "hfSlug": "microsoft/phi-4",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-01-10T06:17:52.16346+00:00",
          "hfUpdatedAt": null,
          "name": "Microsoft: Phi 4",
          "shortName": "Phi 4",
          "author": "microsoft",
          "description": "[Microsoft Research](/microsoft) Phi-4 is designed to perform well in complex reasoning tasks and can operate efficiently in situations with limited memory or where quick responses are needed. \n\nAt 14 billion parameters, it was trained on a mix of high-quality synthetic datasets, data from curated websites, and academic materials. It has undergone careful improvement to follow instructions accurately and maintain strong safety standards. It works best with English language inputs.\n\nFor more information, please see [Phi-4 Technical Report](https://arxiv.org/pdf/2412.08905)\n",
          "modelVersionGroupId": null,
          "contextLength": 16384,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/phi-4",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "microsoft/phi-4",
        "modelVariantPermaslug": "microsoft/phi-4",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "microsoft/phi-4",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": 4096,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000007",
          "completion": "0.00000014",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 100,
        "newest": 147,
        "throughputHighToLow": 215,
        "latencyLowToHigh": 114,
        "pricingLowToHigh": 104,
        "pricingHighToLow": 213
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "microsoft/phi-4",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.07,
          "outputCost": 0.14,
          "throughput": 39.368,
          "latency": 753.5
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": null,
          "providerModelId": "microsoft/phi-4",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 114.7235,
          "latency": 345
        }
      ]
    },
    {
      "slug": "google/gemma-2-9b-it",
      "hfSlug": "google/gemma-2-9b-it",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 2 9B",
      "shortName": "Gemma 2 9B",
      "author": "google",
      "description": "Gemma 2 9B by Google is an advanced, open-source language model that sets a new standard for efficiency and performance in its size class.\n\nDesigned for a wide variety of tasks, it empowers developers and researchers to build innovative applications, while maintaining accessibility, safety, and cost-effectiveness.\n\nSee the [launch announcement](https://blog.google/technology/developers/google-gemma-2/) for more details. Usage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms).",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemma-2-9b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "01c4c94a-14b7-4db3-a04b-c68e41a8df38",
        "name": "Nebius | google/gemma-2-9b-it",
        "contextLength": 8192,
        "model": {
          "slug": "google/gemma-2-9b-it",
          "hfSlug": "google/gemma-2-9b-it",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-06-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 2 9B",
          "shortName": "Gemma 2 9B",
          "author": "google",
          "description": "Gemma 2 9B by Google is an advanced, open-source language model that sets a new standard for efficiency and performance in its size class.\n\nDesigned for a wide variety of tasks, it empowers developers and researchers to build innovative applications, while maintaining accessibility, safety, and cost-effectiveness.\n\nSee the [launch announcement](https://blog.google/technology/developers/google-gemma-2/) for more details. Usage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms).",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemma-2-9b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-2-9b-it",
        "modelVariantPermaslug": "google/gemma-2-9b-it",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "google/gemma-2-9b-it",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000002",
          "completion": "0.00000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 101,
        "newest": 240,
        "throughputHighToLow": 40,
        "latencyLowToHigh": 6,
        "pricingLowToHigh": 69,
        "pricingHighToLow": 239
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-2-9b-it",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.02,
          "outputCost": 0.06,
          "throughput": 142.1235,
          "latency": 182
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-2-9b-it",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.08,
          "outputCost": 0.08,
          "throughput": 31.9895,
          "latency": 662
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemma2-9b-it",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 848.4545,
          "latency": 330.5
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "google/gemma-2-9b-it",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 116.9945,
          "latency": 345
        }
      ]
    },
    {
      "slug": "sao10k/l3.3-euryale-70b",
      "hfSlug": "Sao10K/L3.3-70B-Euryale-v2.3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-18T15:32:08.468786+00:00",
      "hfUpdatedAt": null,
      "name": "Sao10K: Llama 3.3 Euryale 70B",
      "shortName": "Llama 3.3 Euryale 70B",
      "author": "sao10k",
      "description": "Euryale L3.3 70B is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k). It is the successor of [Euryale L3 70B v2.2](/models/sao10k/l3-euryale-70b).",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "sao10k/l3.3-euryale-70b-v2.3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "6e3850b8-2305-4bda-990a-7aa06427bc83",
        "name": "DeepInfra | sao10k/l3.3-euryale-70b-v2.3",
        "contextLength": 131072,
        "model": {
          "slug": "sao10k/l3.3-euryale-70b",
          "hfSlug": "Sao10K/L3.3-70B-Euryale-v2.3",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-18T15:32:08.468786+00:00",
          "hfUpdatedAt": null,
          "name": "Sao10K: Llama 3.3 Euryale 70B",
          "shortName": "Llama 3.3 Euryale 70B",
          "author": "sao10k",
          "description": "Euryale L3.3 70B is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k). It is the successor of [Euryale L3 70B v2.2](/models/sao10k/l3-euryale-70b).",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "sao10k/l3.3-euryale-70b-v2.3",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "sao10k/l3.3-euryale-70b",
        "modelVariantPermaslug": "sao10k/l3.3-euryale-70b-v2.3",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Sao10K/L3.3-70B-Euryale-v2.3",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000007",
          "completion": "0.0000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 102,
        "newest": 150,
        "throughputHighToLow": 211,
        "latencyLowToHigh": 14,
        "pricingLowToHigh": 196,
        "pricingHighToLow": 121
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "Sao10K/L3.3-70B-Euryale-v2.3",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.7,
          "outputCost": 0.8,
          "throughput": 40.016,
          "latency": 228
        },
        {
          "name": "Infermatic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256",
          "slug": "infermatic",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": null,
          "providerModelId": "Sao10K-L3.3-70B-Euryale-v2.3-FP8-Dynamic",
          "pricing": {
            "prompt": "0.0000015",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 1.5,
          "outputCost": 1.5,
          "throughput": 49.6085,
          "latency": 552
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.2-11b-vision-instruct",
      "hfSlug": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.2 11B Vision Instruct",
      "shortName": "Llama 3.2 11B Vision Instruct",
      "author": "meta-llama",
      "description": "Llama 3.2 11B Vision is a multimodal model with 11 billion parameters, designed to handle tasks combining visual and textual data. It excels in tasks such as image captioning and visual question answering, bridging the gap between language generation and visual reasoning. Pre-trained on a massive dataset of image-text pairs, it performs well in complex, high-accuracy image analysis.\n\nIts ability to integrate visual understanding with language processing makes it an ideal solution for industries requiring comprehensive visual-linguistic AI applications, such as content creation, AI-driven customer service, and research.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.2-11b-vision-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4a07b512-e030-412d-b1d6-39773a8b8dcf",
        "name": "DeepInfra | meta-llama/llama-3.2-11b-vision-instruct",
        "contextLength": 131072,
        "model": {
          "slug": "meta-llama/llama-3.2-11b-vision-instruct",
          "hfSlug": "meta-llama/Llama-3.2-11B-Vision-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.2 11B Vision Instruct",
          "shortName": "Llama 3.2 11B Vision Instruct",
          "author": "meta-llama",
          "description": "Llama 3.2 11B Vision is a multimodal model with 11 billion parameters, designed to handle tasks combining visual and textual data. It excels in tasks such as image captioning and visual question answering, bridging the gap between language generation and visual reasoning. Pre-trained on a massive dataset of image-text pairs, it performs well in complex, high-accuracy image analysis.\n\nIts ability to integrate visual understanding with language processing makes it an ideal solution for industries requiring comprehensive visual-linguistic AI applications, such as content creation, AI-driven customer service, and research.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.2-11b-vision-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.2-11b-vision-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3.2-11b-vision-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "meta-llama/Llama-3.2-11B-Vision-Instruct",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000000049",
          "completion": "0.000000049",
          "image": "0.00007948",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 103,
        "newest": 202,
        "throughputHighToLow": 54,
        "latencyLowToHigh": 157,
        "pricingLowToHigh": 63,
        "pricingHighToLow": 223
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.2-11B-Vision-Instruct",
          "pricing": {
            "prompt": "0.000000049",
            "completion": "0.000000049",
            "image": "0.00007948",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.05,
          "outputCost": 0.05,
          "throughput": 13.236,
          "latency": 2793
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.2-11b-vision-instruct",
          "pricing": {
            "prompt": "0.000000049",
            "completion": "0.00000068",
            "image": "0.001281",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.05,
          "outputCost": 0.68,
          "throughput": 36.1495,
          "latency": 287
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.2-11b-vision-instruct",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.05,
          "outputCost": 0.05,
          "throughput": 119.6665,
          "latency": 249
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.2-11b-instruct/fp-16",
          "pricing": {
            "prompt": "0.000000055",
            "completion": "0.000000055",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.06,
          "outputCost": 0.06,
          "throughput": 35.308,
          "latency": 1398
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/llama-3.2-11b-vision-instruct",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.06,
          "outputCost": 0.06,
          "throughput": 60.662,
          "latency": 699
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000018",
            "image": "0.001156",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.18,
          "throughput": 140.8795,
          "latency": 407
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1-distill-llama-70b",
      "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-23T20:12:49.780212+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1 Distill Llama 70B (free)",
      "shortName": "R1 Distill Llama 70B (free)",
      "author": "deepseek",
      "description": "DeepSeek R1 Distill Llama 70B is a distilled large language model based on [Llama-3.3-70B-Instruct](/meta-llama/llama-3.3-70b-instruct), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). The model combines advanced distillation techniques to achieve high performance across multiple benchmarks, including:\n\n- AIME 2024 pass@1: 70.0\n- MATH-500 pass@1: 94.5\n- CodeForces Rating: 1633\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-r1-distill-llama-70b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "c4e973c5-aae4-4830-8e81-9f950e1e3e6c",
        "name": "Together | deepseek/deepseek-r1-distill-llama-70b:free",
        "contextLength": 8192,
        "model": {
          "slug": "deepseek/deepseek-r1-distill-llama-70b",
          "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-23T20:12:49.780212+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1 Distill Llama 70B",
          "shortName": "R1 Distill Llama 70B",
          "author": "deepseek",
          "description": "DeepSeek R1 Distill Llama 70B is a distilled large language model based on [Llama-3.3-70B-Instruct](/meta-llama/llama-3.3-70b-instruct), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). The model combines advanced distillation techniques to achieve high performance across multiple benchmarks, including:\n\n- AIME 2024 pass@1: 70.0\n- MATH-500 pass@1: 94.5\n- CodeForces Rating: 1633\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-r1-distill-llama-70b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1-distill-llama-70b:free",
        "modelVariantPermaslug": "deepseek/deepseek-r1-distill-llama-70b:free",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 21,
        "newest": 141,
        "throughputHighToLow": 162,
        "latencyLowToHigh": 39,
        "pricingLowToHigh": 52,
        "pricingHighToLow": 191
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.4,
          "throughput": 36.4015,
          "latency": 342.5
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "deepseek/r1-distill-llama-70b/fp-8",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.4,
          "throughput": 37.936,
          "latency": 754
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "deepseek-llama3.3-70b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 67.8005,
          "latency": 446
        },
        {
          "name": "Phala",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://phala.network/&size=256",
          "slug": "phala",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "phala/deepseek-r1-70b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.7,
          "throughput": 36.602,
          "latency": 608
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000075",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.25,
          "outputCost": 0.75,
          "throughput": 59.607,
          "latency": 485
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 4096,
          "providerModelId": "DeepSeek-R1-Distill-Llama-70B",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "stop"
          ],
          "inputCost": 0.7,
          "outputCost": 1.4,
          "throughput": 232.642,
          "latency": 2059
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "deepseek-r1-distill-llama-70b",
          "pricing": {
            "prompt": "0.00000075",
            "completion": "0.00000099",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.75,
          "outputCost": 0.99,
          "throughput": 293.08,
          "latency": 880
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "deepseek/deepseek-r1-distill-llama-70b",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 71.414,
          "latency": 891
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 2,
          "outputCost": 2,
          "throughput": 101.26,
          "latency": 690.5
        },
        {
          "name": "Cerebras",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cerebras.ai/&size=256",
          "slug": "cerebras",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "deepseek-r1-distill-llama-70b",
          "pricing": {
            "prompt": "0.0000022",
            "completion": "0.0000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "structured_outputs",
            "response_format",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 2.2,
          "outputCost": 2.5,
          "throughput": 1983.8895,
          "latency": 892
        }
      ]
    },
    {
      "slug": "qwen/qwen2.5-vl-72b-instruct",
      "hfSlug": "Qwen/Qwen2.5-VL-72B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-01T11:45:11.997326+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen2.5 VL 72B Instruct (free)",
      "shortName": "Qwen2.5 VL 72B Instruct (free)",
      "author": "qwen",
      "description": "Qwen2.5-VL is proficient in recognizing common objects such as flowers, birds, fish, and insects. It is also highly capable of analyzing texts, charts, icons, graphics, and layouts within images.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen2.5-vl-72b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "75b071e0-0415-4543-a28f-e8d8e28d4421",
        "name": "Alibaba | qwen/qwen2.5-vl-72b-instruct:free",
        "contextLength": 131072,
        "model": {
          "slug": "qwen/qwen2.5-vl-72b-instruct",
          "hfSlug": "Qwen/Qwen2.5-VL-72B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-01T11:45:11.997326+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen2.5 VL 72B Instruct",
          "shortName": "Qwen2.5 VL 72B Instruct",
          "author": "qwen",
          "description": "Qwen2.5-VL is proficient in recognizing common objects such as flowers, birds, fish, and insects. It is also highly capable of analyzing texts, charts, icons, graphics, and layouts within images.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen2.5-vl-72b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen2.5-vl-72b-instruct:free",
        "modelVariantPermaslug": "qwen/qwen2.5-vl-72b-instruct:free",
        "providerName": "Alibaba",
        "providerInfo": {
          "name": "Alibaba",
          "displayName": "Alibaba",
          "slug": "alibaba",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
            "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "CN",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Alibaba",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256"
          }
        },
        "providerDisplayName": "Alibaba",
        "providerModelId": "qwen2.5-vl-72b-instruct",
        "providerGroup": "Alibaba",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": false,
        "maxPromptTokens": 129024,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "seed",
          "response_format",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
          "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 71,
        "newest": 125,
        "throughputHighToLow": 249,
        "latencyLowToHigh": 257,
        "pricingLowToHigh": 48,
        "pricingHighToLow": 154
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-VL-72B-Instruct",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000075",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.25,
          "outputCost": 0.75,
          "throughput": 12.992,
          "latency": 2030
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": 128000,
          "providerModelId": "parasail-qwen25-vl-72b-instruct",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.7,
          "outputCost": 0.7,
          "throughput": 33.27,
          "latency": 1933.5
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 96000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen2.5-vl-72b-instruct",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 17.5275,
          "latency": 4803
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-VL-72B-Instruct",
          "pricing": {
            "prompt": "0.00000195",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.95,
          "outputCost": 8,
          "throughput": 31.412,
          "latency": 1338.5
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1-zero",
      "hfSlug": "deepseek-ai/DeepSeek-R1-Zero",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-03-06T21:43:54+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: DeepSeek R1 Zero (free)",
      "shortName": "DeepSeek R1 Zero (free)",
      "author": "deepseek",
      "description": "DeepSeek-R1-Zero is a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step. It's 671B parameters in size, with 37B active in an inference pass.\n\nIt demonstrates remarkable performance on reasoning. With RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\n\nDeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. See [DeepSeek R1](/deepseek/deepseek-r1) for the SFT model.\n\n",
      "modelVersionGroupId": null,
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-r1-zero",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "e6321a1b-b8fc-4759-976c-5fc6ac916e8b",
        "name": "Chutes | deepseek/deepseek-r1-zero:free",
        "contextLength": 163840,
        "model": {
          "slug": "deepseek/deepseek-r1-zero",
          "hfSlug": "deepseek-ai/DeepSeek-R1-Zero",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-03-06T21:43:54+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: DeepSeek R1 Zero",
          "shortName": "DeepSeek R1 Zero",
          "author": "deepseek",
          "description": "DeepSeek-R1-Zero is a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step. It's 671B parameters in size, with 37B active in an inference pass.\n\nIt demonstrates remarkable performance on reasoning. With RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\n\nDeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. See [DeepSeek R1](/deepseek/deepseek-r1) for the SFT model.\n\n",
          "modelVersionGroupId": null,
          "contextLength": 163840,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-r1-zero",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1-zero:free",
        "modelVariantPermaslug": "deepseek/deepseek-r1-zero:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "deepseek-ai/DeepSeek-R1-Zero",
        "providerGroup": "Chutes",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 106,
        "newest": 101,
        "throughputHighToLow": 132,
        "latencyLowToHigh": 204,
        "pricingLowToHigh": 42,
        "pricingHighToLow": 290
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": []
    },
    {
      "slug": "deepseek/deepseek-v3-base",
      "hfSlug": "deepseek-ai/Deepseek-v3-base",
      "updatedAt": "2025-03-29T18:19:47.595899+00:00",
      "createdAt": "2025-03-29T18:13:43.339174+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: DeepSeek V3 Base (free)",
      "shortName": "DeepSeek V3 Base (free)",
      "author": "deepseek",
      "description": "Note that this is a base model mostly meant for testing, you need to provide detailed prompts for the model to return useful responses. \n\nDeepSeek-V3 Base is a 671B parameter open Mixture-of-Experts (MoE) language model with 37B active parameters per forward pass and a context length of 128K tokens. Trained on 14.8T tokens using FP8 mixed precision, it achieves high training efficiency and stability, with strong performance across language, reasoning, math, and coding tasks. \n\nDeepSeek-V3 Base is the pre-trained model behind [DeepSeek V3](/deepseek/deepseek-chat-v3)",
      "modelVersionGroupId": null,
      "contextLength": 163840,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-v3-base",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c20782a8-abb2-4a2d-9519-d6bfa4b08d7e",
        "name": "Chutes | deepseek/deepseek-v3-base:free",
        "contextLength": 163840,
        "model": {
          "slug": "deepseek/deepseek-v3-base",
          "hfSlug": "deepseek-ai/Deepseek-v3-base",
          "updatedAt": "2025-03-29T18:19:47.595899+00:00",
          "createdAt": "2025-03-29T18:13:43.339174+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: DeepSeek V3 Base",
          "shortName": "DeepSeek V3 Base",
          "author": "deepseek",
          "description": "Note that this is a base model mostly meant for testing, you need to provide detailed prompts for the model to return useful responses. \n\nDeepSeek-V3 Base is a 671B parameter open Mixture-of-Experts (MoE) language model with 37B active parameters per forward pass and a context length of 128K tokens. Trained on 14.8T tokens using FP8 mixed precision, it achieves high training efficiency and stability, with strong performance across language, reasoning, math, and coding tasks. \n\nDeepSeek-V3 Base is the pre-trained model behind [DeepSeek V3](/deepseek/deepseek-chat-v3)",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-v3-base",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "deepseek/deepseek-v3-base:free",
        "modelVariantPermaslug": "deepseek/deepseek-v3-base:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "deepseek-ai/DeepSeek-V3-Base",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 107,
        "newest": 67,
        "throughputHighToLow": 220,
        "latencyLowToHigh": 205,
        "pricingLowToHigh": 28,
        "pricingHighToLow": 276
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": []
    },
    {
      "slug": "qwen/qwen3-30b-a3b",
      "hfSlug": "Qwen/Qwen3-30B-A3B",
      "updatedAt": "2025-05-12T00:33:13.151167+00:00",
      "createdAt": "2025-04-28T22:16:44.177326+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 30B A3B",
      "shortName": "Qwen3 30B A3B",
      "author": "qwen",
      "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-30b-a3b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "efdfff77-9574-4695-8e08-32d968a43376",
        "name": "DeepInfra | qwen/qwen3-30b-a3b-04-28",
        "contextLength": 40960,
        "model": {
          "slug": "qwen/qwen3-30b-a3b",
          "hfSlug": "Qwen/Qwen3-30B-A3B",
          "updatedAt": "2025-05-12T00:33:13.151167+00:00",
          "createdAt": "2025-04-28T22:16:44.177326+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 30B A3B",
          "shortName": "Qwen3 30B A3B",
          "author": "qwen",
          "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-30b-a3b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-30b-a3b",
        "modelVariantPermaslug": "qwen/qwen3-30b-a3b-04-28",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "Qwen/Qwen3-30B-A3B",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 40960,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 94,
        "newest": 22,
        "throughputHighToLow": 20,
        "latencyLowToHigh": 127,
        "pricingLowToHigh": 9,
        "pricingHighToLow": 193
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/Qwen3-30B-A3B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 45.6565,
          "latency": 763
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-30B-A3B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 96.9815,
          "latency": 350
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-30b-a3b-fp8",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.00000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.1,
          "outputCost": 0.45,
          "throughput": 97.842,
          "latency": 901
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "parasail-qwen3-30b-a3b",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.1,
          "outputCost": 0.5,
          "throughput": 123.1645,
          "latency": 773.5
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 40000,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwen3-30b-a3b",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 117.7655,
          "latency": 712
        }
      ]
    },
    {
      "slug": "mistral/ministral-8b",
      "hfSlug": "mistralai/Ministral-8B-Instruct-2410",
      "updatedAt": "2025-04-05T20:00:23.966407+00:00",
      "createdAt": "2025-03-31T14:07:01.87388+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Ministral 8B",
      "shortName": "Ministral 8B",
      "author": "mistral",
      "description": "Ministral 8B is a state-of-the-art language model optimized for on-device and edge computing. Designed for efficiency in knowledge-intensive tasks, commonsense reasoning, and function-calling, it features a specialized interleaved sliding-window attention mechanism, enabling faster and more memory-efficient inference. Ministral 8B excels in local, low-latency applications such as offline translation, smart assistants, autonomous robotics, and local analytics.\n\nThe model supports up to 128k context length and can function as a performant intermediary in multi-step agentic workflows, efficiently handling tasks like input parsing, API calls, and task routing. It consistently outperforms comparable models like Mistral 7B across benchmarks, making it particularly suitable for compute-efficient, privacy-focused scenarios.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistral/ministral-8b-2410",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "070490ef-6982-4a3e-86c5-92f092506f22",
        "name": "Mistral | mistral/ministral-8b-2410",
        "contextLength": 131072,
        "model": {
          "slug": "mistral/ministral-8b",
          "hfSlug": "mistralai/Ministral-8B-Instruct-2410",
          "updatedAt": "2025-04-05T20:00:23.966407+00:00",
          "createdAt": "2025-03-31T14:07:01.87388+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Ministral 8B",
          "shortName": "Ministral 8B",
          "author": "mistral",
          "description": "Ministral 8B is a state-of-the-art language model optimized for on-device and edge computing. Designed for efficiency in knowledge-intensive tasks, commonsense reasoning, and function-calling, it features a specialized interleaved sliding-window attention mechanism, enabling faster and more memory-efficient inference. Ministral 8B excels in local, low-latency applications such as offline translation, smart assistants, autonomous robotics, and local analytics.\n\nThe model supports up to 128k context length and can function as a performant intermediary in multi-step agentic workflows, efficiently handling tasks like input parsing, API calls, and task routing. It consistently outperforms comparable models like Mistral 7B across benchmarks, making it particularly suitable for compute-efficient, privacy-focused scenarios.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistral/ministral-8b-2410",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistral/ministral-8b",
        "modelVariantPermaslug": "mistral/ministral-8b-2410",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "ministral-8b-2410",
        "providerGroup": "Mistral",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 109,
        "newest": 66,
        "throughputHighToLow": 60,
        "latencyLowToHigh": 19,
        "pricingLowToHigh": 114,
        "pricingHighToLow": 202
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "ministral-8b-2410",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 116.936,
          "latency": 266
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.1-405b",
      "hfSlug": "meta-llama/llama-3.1-405B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.1 405B (base)",
      "shortName": "Llama 3.1 405B (base)",
      "author": "meta-llama",
      "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This is the base 405B pre-trained version.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "1fd9d06b-aa20-4c7d-a0b1-d3d9b5aae712",
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "none",
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.1-405b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "bb803d06-6890-42a0-95b6-5541c825e8cc",
        "name": "Hyperbolic | meta-llama/llama-3.1-405b",
        "contextLength": 32768,
        "model": {
          "slug": "meta-llama/llama-3.1-405b",
          "hfSlug": "meta-llama/llama-3.1-405B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-02T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.1 405B (base)",
          "shortName": "Llama 3.1 405B (base)",
          "author": "meta-llama",
          "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This is the base 405B pre-trained version.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": "1fd9d06b-aa20-4c7d-a0b1-d3d9b5aae712",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "none",
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.1-405b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.1-405b",
        "modelVariantPermaslug": "meta-llama/llama-3.1-405b",
        "providerName": "Hyperbolic",
        "providerInfo": {
          "name": "Hyperbolic",
          "displayName": "Hyperbolic",
          "slug": "hyperbolic",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://hyperbolic.xyz/privacy",
            "termsOfServiceUrl": "https://hyperbolic.xyz/terms",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Hyperbolic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256"
          }
        },
        "providerDisplayName": "Hyperbolic",
        "providerModelId": "meta-llama/Meta-Llama-3.1-405B-FP8",
        "providerGroup": "Hyperbolic",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "logprobs",
          "top_logprobs",
          "seed",
          "logit_bias",
          "top_k",
          "min_p",
          "repetition_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://hyperbolic.xyz/privacy",
          "termsOfServiceUrl": "https://hyperbolic.xyz/terms",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 110,
        "newest": 224,
        "throughputHighToLow": 270,
        "latencyLowToHigh": 292,
        "pricingLowToHigh": 66,
        "pricingHighToLow": 78
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-405B-FP8",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 2,
          "outputCost": 2
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "meta-llama/Meta-Llama-3.1-405B",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 4,
          "outputCost": 4,
          "throughput": 11.997,
          "latency": 1134.5
        }
      ]
    },
    {
      "slug": "openai/gpt-4o-2024-08-06",
      "hfSlug": null,
      "updatedAt": "2025-04-23T22:07:33.89959+00:00",
      "createdAt": "2024-08-06T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4o (2024-08-06)",
      "shortName": "GPT-4o (2024-08-06)",
      "author": "openai",
      "description": "The 2024-08-06 version of GPT-4o offers improved performance in structured outputs, with the ability to supply a JSON schema in the respone_format. Read more [here](https://openai.com/index/introducing-structured-outputs-in-the-api/).\n\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)",
      "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4o-2024-08-06",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9d15935a-34e6-4a5e-a5bc-c7dda213e876",
        "name": "OpenAI | openai/gpt-4o-2024-08-06",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4o-2024-08-06",
          "hfSlug": null,
          "updatedAt": "2025-04-23T22:07:33.89959+00:00",
          "createdAt": "2024-08-06T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4o (2024-08-06)",
          "shortName": "GPT-4o (2024-08-06)",
          "author": "openai",
          "description": "The 2024-08-06 version of GPT-4o offers improved performance in structured outputs, with the ability to supply a JSON schema in the respone_format. Read more [here](https://openai.com/index/introducing-structured-outputs-in-the-api/).\n\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)",
          "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4o-2024-08-06",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4o-2024-08-06",
        "modelVariantPermaslug": "openai/gpt-4o-2024-08-06",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4o-2024-08-06",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "web_search_options",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000025",
          "completion": "0.00001",
          "image": "0.003613",
          "request": "0",
          "inputCacheRead": "0.00000125",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.05"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.035"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.03"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 111,
        "newest": 223,
        "throughputHighToLow": 152,
        "latencyLowToHigh": 106,
        "pricingLowToHigh": 264,
        "pricingHighToLow": 58
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o-2024-08-06",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0.003613",
            "request": "0",
            "inputCacheRead": "0.00000125",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 55.8565,
          "latency": 637
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0.003613",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 130.434,
          "latency": 1228
        }
      ]
    },
    {
      "slug": "qwen/qwen-vl-plus",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-05T04:54:15.216448+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen VL Plus",
      "shortName": "Qwen VL Plus",
      "author": "qwen",
      "description": "Qwen's Enhanced Large Visual Language Model. Significantly upgraded for detailed recognition capabilities and text recognition abilities, supporting ultra-high pixel resolutions up to millions of pixels and extreme aspect ratios for image input. It delivers significant performance across a broad range of visual tasks.\n",
      "modelVersionGroupId": null,
      "contextLength": 7500,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-vl-plus",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "df9c15ac-870b-40e5-aa43-e4b3b44951f7",
        "name": "Alibaba | qwen/qwen-vl-plus",
        "contextLength": 7500,
        "model": {
          "slug": "qwen/qwen-vl-plus",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-05T04:54:15.216448+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen VL Plus",
          "shortName": "Qwen VL Plus",
          "author": "qwen",
          "description": "Qwen's Enhanced Large Visual Language Model. Significantly upgraded for detailed recognition capabilities and text recognition abilities, supporting ultra-high pixel resolutions up to millions of pixels and extreme aspect ratios for image input. It delivers significant performance across a broad range of visual tasks.\n",
          "modelVersionGroupId": null,
          "contextLength": 7500,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-vl-plus",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-vl-plus",
        "modelVariantPermaslug": "qwen/qwen-vl-plus",
        "providerName": "Alibaba",
        "providerInfo": {
          "name": "Alibaba",
          "displayName": "Alibaba",
          "slug": "alibaba",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
            "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "CN",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Alibaba",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256"
          }
        },
        "providerDisplayName": "Alibaba",
        "providerModelId": "qwen-vl-plus",
        "providerGroup": "Alibaba",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": 6000,
        "maxCompletionTokens": 1500,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "seed",
          "response_format",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
          "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000021",
          "completion": "0.00000063",
          "image": "0.0002688",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 112,
        "newest": 119,
        "throughputHighToLow": 95,
        "latencyLowToHigh": 155,
        "pricingLowToHigh": 159,
        "pricingHighToLow": 159
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Alibaba",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256",
          "slug": "alibaba",
          "quantization": null,
          "context": 7500,
          "maxCompletionTokens": 1500,
          "providerModelId": "qwen-vl-plus",
          "pricing": {
            "prompt": "0.00000021",
            "completion": "0.00000063",
            "image": "0.0002688",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "seed",
            "response_format",
            "presence_penalty"
          ],
          "inputCost": 0.21,
          "outputCost": 0.63,
          "throughput": 81.893,
          "latency": 966
        }
      ]
    },
    {
      "slug": "openai/o3",
      "hfSlug": "",
      "updatedAt": "2025-05-02T21:34:35.534922+00:00",
      "createdAt": "2025-04-16T17:10:57.049467+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o3",
      "shortName": "o3",
      "author": "openai",
      "description": "o3 is a well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks. It also excels at technical writing and instruction-following. Use it to think through multi-step problems that involve analysis across text, code, and images. Note that BYOK is required for this model. Set up here: https://openrouter.ai/settings/integrations",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "image",
        "text",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "OpenAI requires bringing your own API key to use o3 over the API. Set up here: https://openrouter.ai/settings/integrations",
      "permaslug": "openai/o3-2025-04-16",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "42e72619-d01c-411c-a201-f991644768b7",
        "name": "OpenAI | openai/o3-2025-04-16",
        "contextLength": 200000,
        "model": {
          "slug": "openai/o3",
          "hfSlug": "",
          "updatedAt": "2025-05-02T21:34:35.534922+00:00",
          "createdAt": "2025-04-16T17:10:57.049467+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o3",
          "shortName": "o3",
          "author": "openai",
          "description": "o3 is a well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks. It also excels at technical writing and instruction-following. Use it to think through multi-step problems that involve analysis across text, code, and images. Note that BYOK is required for this model. Set up here: https://openrouter.ai/settings/integrations",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "image",
            "text",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "OpenAI requires bringing your own API key to use o3 over the API. Set up here: https://openrouter.ai/settings/integrations",
          "permaslug": "openai/o3-2025-04-16",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o3",
        "modelVariantPermaslug": "openai/o3-2025-04-16",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o3-2025-04-16",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 100000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "seed",
          "max_tokens",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00001",
          "completion": "0.00004",
          "image": "0.00765",
          "request": "0",
          "inputCacheRead": "0.0000025",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {
            "responseFormat": true,
            "structuredOutputs": true
          },
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 113,
        "newest": 44,
        "throughputHighToLow": 205,
        "latencyLowToHigh": 304,
        "pricingLowToHigh": 305,
        "pricingHighToLow": 13
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 100000,
          "providerModelId": "o3-2025-04-16",
          "pricing": {
            "prompt": "0.00001",
            "completion": "0.00004",
            "image": "0.00765",
            "request": "0",
            "inputCacheRead": "0.0000025",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "seed",
            "max_tokens",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 10,
          "outputCost": 40,
          "throughput": 39.0565,
          "latency": 6113
        }
      ]
    },
    {
      "slug": "qwen/qwen2.5-vl-32b-instruct",
      "hfSlug": "Qwen/Qwen2.5-VL-32B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-24T18:10:38.542849+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen2.5 VL 32B Instruct",
      "shortName": "Qwen2.5 VL 32B Instruct",
      "author": "qwen",
      "description": "Qwen2.5-VL-32B is a multimodal vision-language model fine-tuned through reinforcement learning for enhanced mathematical reasoning, structured outputs, and visual problem-solving capabilities. It excels at visual analysis tasks, including object recognition, textual interpretation within images, and precise event localization in extended videos. Qwen2.5-VL-32B demonstrates state-of-the-art performance across multimodal benchmarks such as MMMU, MathVista, and VideoMME, while maintaining strong reasoning and clarity in text-based tasks like MMLU, mathematical problem-solving, and code generation.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen2.5-vl-32b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "aac76f56-eedb-405f-a07c-5bc66b877c1e",
        "name": "Fireworks | qwen/qwen2.5-vl-32b-instruct",
        "contextLength": 128000,
        "model": {
          "slug": "qwen/qwen2.5-vl-32b-instruct",
          "hfSlug": "Qwen/Qwen2.5-VL-32B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-24T18:10:38.542849+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen2.5 VL 32B Instruct",
          "shortName": "Qwen2.5 VL 32B Instruct",
          "author": "qwen",
          "description": "Qwen2.5-VL-32B is a multimodal vision-language model fine-tuned through reinforcement learning for enhanced mathematical reasoning, structured outputs, and visual problem-solving capabilities. It excels at visual analysis tasks, including object recognition, textual interpretation within images, and precise event localization in extended videos. Qwen2.5-VL-32B demonstrates state-of-the-art performance across multimodal benchmarks such as MMMU, MathVista, and VideoMME, while maintaining strong reasoning and clarity in text-based tasks like MMLU, mathematical problem-solving, and code generation.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen2.5-vl-32b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen2.5-vl-32b-instruct",
        "modelVariantPermaslug": "qwen/qwen2.5-vl-32b-instruct",
        "providerName": "Fireworks",
        "providerInfo": {
          "name": "Fireworks",
          "displayName": "Fireworks",
          "slug": "fireworks",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://fireworks.ai/terms-of-service",
            "privacyPolicyUrl": "https://fireworks.ai/privacy-policy",
            "dataPolicyUrl": "https://docs.fireworks.ai/guides/security_compliance/data_handling",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Fireworks",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.fireworks.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Fireworks.png"
          }
        },
        "providerDisplayName": "Fireworks",
        "providerModelId": "accounts/fireworks/models/qwen2p5-vl-32b-instruct",
        "providerGroup": "Fireworks",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "response_format",
          "structured_outputs",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://fireworks.ai/terms-of-service",
          "privacyPolicyUrl": "https://fireworks.ai/privacy-policy",
          "dataPolicyUrl": "https://docs.fireworks.ai/guides/security_compliance/data_handling",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000009",
          "completion": "0.0000009",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 114,
        "newest": 73,
        "throughputHighToLow": 129,
        "latencyLowToHigh": 161,
        "pricingLowToHigh": 32,
        "pricingHighToLow": 103
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwen2p5-vl-32b-instruct",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 61.1,
          "latency": 950
        },
        {
          "name": "InoCloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inocloud.com/&size=256",
          "slug": "inoCloud",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": 128000,
          "providerModelId": "qwen/qwen2.5-vl-32b-instruct",
          "pricing": {
            "prompt": "0.0000011",
            "completion": "0.0000011",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 1.1,
          "outputCost": 1.1,
          "throughput": 26.459,
          "latency": 3078
        }
      ]
    },
    {
      "slug": "qwen/qwen-2.5-vl-7b-instruct",
      "hfSlug": "Qwen/Qwen2.5-VL-7B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen2.5-VL 7B Instruct",
      "shortName": "Qwen2.5-VL 7B Instruct",
      "author": "qwen",
      "description": "Qwen2.5 VL 7B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Understanding videos of 20min+: Qwen2.5-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2.5-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2-vl-7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "fae5bc3c-f799-4657-8d05-3cf6f489ed0c",
        "name": "Hyperbolic | qwen/qwen-2-vl-7b-instruct",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen-2.5-vl-7b-instruct",
          "hfSlug": "Qwen/Qwen2.5-VL-7B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen2.5-VL 7B Instruct",
          "shortName": "Qwen2.5-VL 7B Instruct",
          "author": "qwen",
          "description": "Qwen2.5 VL 7B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Understanding videos of 20min+: Qwen2.5-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2.5-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-2-vl-7b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-2.5-vl-7b-instruct",
        "modelVariantPermaslug": "qwen/qwen-2-vl-7b-instruct",
        "providerName": "Hyperbolic",
        "providerInfo": {
          "name": "Hyperbolic",
          "displayName": "Hyperbolic",
          "slug": "hyperbolic",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://hyperbolic.xyz/privacy",
            "termsOfServiceUrl": "https://hyperbolic.xyz/terms",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Hyperbolic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256"
          }
        },
        "providerDisplayName": "Hyperbolic",
        "providerModelId": "Qwen/Qwen2.5-VL-7B-Instruct",
        "providerGroup": "Hyperbolic",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "logprobs",
          "top_logprobs",
          "seed",
          "logit_bias",
          "top_k",
          "min_p",
          "repetition_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://hyperbolic.xyz/privacy",
          "termsOfServiceUrl": "https://hyperbolic.xyz/terms",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000002",
          "completion": "0.0000002",
          "image": "0.0001445",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 115,
        "newest": 214,
        "throughputHighToLow": 80,
        "latencyLowToHigh": 153,
        "pricingLowToHigh": 65,
        "pricingHighToLow": 171
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-VL-7B-Instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0.0001445",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 49.2875,
          "latency": 2055
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": 8192,
          "providerModelId": "qwen/qwen2.5-7b-instruct/bf-16",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 58.101,
          "latency": 3841
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "Qwen/Qwen2.5-VL-7B-Instruct",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 39.56,
          "latency": 2826
        }
      ]
    },
    {
      "slug": "mistralai/mistral-large-2411",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-19T01:11:25.108028+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral Large 2411",
      "shortName": "Mistral Large 2411",
      "author": "mistralai",
      "description": "Mistral Large 2 2411 is an update of [Mistral Large 2](/mistralai/mistral-large) released together with [Pixtral Large 2411](/mistralai/pixtral-large-2411)\n\nIt provides a significant upgrade on the previous [Mistral Large 24.07](/mistralai/mistral-large-2407), with notable improvements in long context understanding, a new system prompt, and more accurate function calling.",
      "modelVersionGroupId": "83129748-0564-4485-982a-d7a37a1ef3ec",
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-large-2411",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "26f5ecd0-44cb-43e8-8cfc-7b155c2e8c05",
        "name": "Mistral | mistralai/mistral-large-2411",
        "contextLength": 131072,
        "model": {
          "slug": "mistralai/mistral-large-2411",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-19T01:11:25.108028+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral Large 2411",
          "shortName": "Mistral Large 2411",
          "author": "mistralai",
          "description": "Mistral Large 2 2411 is an update of [Mistral Large 2](/mistralai/mistral-large) released together with [Pixtral Large 2411](/mistralai/pixtral-large-2411)\n\nIt provides a significant upgrade on the previous [Mistral Large 24.07](/mistralai/mistral-large-2407), with notable improvements in long context understanding, a new system prompt, and more accurate function calling.",
          "modelVersionGroupId": "83129748-0564-4485-982a-d7a37a1ef3ec",
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-large-2411",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-large-2411",
        "modelVariantPermaslug": "mistralai/mistral-large-2411",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "mistral-large-2411",
        "providerGroup": "Mistral",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 116,
        "newest": 167,
        "throughputHighToLow": 131,
        "latencyLowToHigh": 97,
        "pricingLowToHigh": 243,
        "pricingHighToLow": 72
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-large-2411",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 2,
          "outputCost": 6,
          "throughput": 60.332,
          "latency": 628
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1-distill-qwen-32b",
      "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-29T23:53:50.865297+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1 Distill Qwen 32B",
      "shortName": "R1 Distill Qwen 32B",
      "author": "deepseek",
      "description": "DeepSeek R1 Distill Qwen 32B is a distilled large language model based on [Qwen 2.5 32B](https://huggingface.co/Qwen/Qwen2.5-32B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 72.6\n- MATH-500 pass@1: 94.3\n- CodeForces Rating: 1691\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-r1-distill-qwen-32b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "ce318fe0-48e0-444d-af14-08708e9e1f76",
        "name": "DeepInfra | deepseek/deepseek-r1-distill-qwen-32b",
        "contextLength": 131072,
        "model": {
          "slug": "deepseek/deepseek-r1-distill-qwen-32b",
          "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-29T23:53:50.865297+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1 Distill Qwen 32B",
          "shortName": "R1 Distill Qwen 32B",
          "author": "deepseek",
          "description": "DeepSeek R1 Distill Qwen 32B is a distilled large language model based on [Qwen 2.5 32B](https://huggingface.co/Qwen/Qwen2.5-32B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 72.6\n- MATH-500 pass@1: 94.3\n- CodeForces Rating: 1691\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-r1-distill-qwen-32b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1-distill-qwen-32b",
        "modelVariantPermaslug": "deepseek/deepseek-r1-distill-qwen-32b",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "providerGroup": "DeepInfra",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000012",
          "completion": "0.00000018",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 117,
        "newest": 133,
        "throughputHighToLow": 53,
        "latencyLowToHigh": 118,
        "pricingLowToHigh": 50,
        "pricingHighToLow": 192
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.12,
          "outputCost": 0.18,
          "throughput": 45.471,
          "latency": 661
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 64000,
          "providerModelId": "deepseek/deepseek-r1-distill-qwen-32b",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 19.1495,
          "latency": 2299.5
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 80000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.00000488",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.5,
          "outputCost": 4.88,
          "throughput": 32.744,
          "latency": 864
        }
      ]
    },
    {
      "slug": "thedrummer/skyfall-36b-v2",
      "hfSlug": "TheDrummer/Skyfall-36B-v2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-10T19:56:06.00791+00:00",
      "hfUpdatedAt": null,
      "name": "TheDrummer: Skyfall 36B V2",
      "shortName": "Skyfall 36B V2",
      "author": "thedrummer",
      "description": "Skyfall 36B v2 is an enhanced iteration of Mistral Small 2501, specifically fine-tuned for improved creativity, nuanced writing, role-playing, and coherent storytelling.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thedrummer/skyfall-36b-v2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "1eb01ded-ae11-49e6-8aa6-3067584070bd",
        "name": "Parasail | thedrummer/skyfall-36b-v2",
        "contextLength": 32768,
        "model": {
          "slug": "thedrummer/skyfall-36b-v2",
          "hfSlug": "TheDrummer/Skyfall-36B-v2",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-10T19:56:06.00791+00:00",
          "hfUpdatedAt": null,
          "name": "TheDrummer: Skyfall 36B V2",
          "shortName": "Skyfall 36B V2",
          "author": "thedrummer",
          "description": "Skyfall 36B v2 is an enhanced iteration of Mistral Small 2501, specifically fine-tuned for improved creativity, nuanced writing, role-playing, and coherent storytelling.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thedrummer/skyfall-36b-v2",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "thedrummer/skyfall-36b-v2",
        "modelVariantPermaslug": "thedrummer/skyfall-36b-v2",
        "providerName": "Parasail",
        "providerInfo": {
          "name": "Parasail",
          "displayName": "Parasail",
          "slug": "parasail",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.parasail.io/legal/terms",
            "privacyPolicyUrl": "https://www.parasail.io/legal/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Parasail",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256"
          }
        },
        "providerDisplayName": "Parasail",
        "providerModelId": "parasail-skyfall-36b-v2-fp8",
        "providerGroup": "Parasail",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "presence_penalty",
          "frequency_penalty",
          "repetition_penalty",
          "top_k"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.parasail.io/legal/terms",
          "privacyPolicyUrl": "https://www.parasail.io/legal/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true
          },
          "training": false,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 118,
        "newest": 96,
        "throughputHighToLow": 118,
        "latencyLowToHigh": 124,
        "pricingLowToHigh": 184,
        "pricingHighToLow": 136
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "parasail-skyfall-36b-v2-fp8",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.5,
          "outputCost": 0.8,
          "throughput": 66.597,
          "latency": 728
        }
      ]
    },
    {
      "slug": "qwen/qwen3-32b",
      "hfSlug": "Qwen/Qwen3-32B",
      "updatedAt": "2025-05-11T22:45:44.273213+00:00",
      "createdAt": "2025-04-28T21:32:25.189881+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 32B (free)",
      "shortName": "Qwen3 32B (free)",
      "author": "qwen",
      "description": "Qwen3-32B is a dense 32.8B parameter causal language model from the Qwen3 series, optimized for both complex reasoning and efficient dialogue. It supports seamless switching between a \"thinking\" mode for tasks like math, coding, and logical inference, and a \"non-thinking\" mode for faster, general-purpose conversation. The model demonstrates strong performance in instruction-following, agent tool use, creative writing, and multilingual tasks across 100+ languages and dialects. It natively handles 32K token contexts and can extend to 131K tokens using YaRN-based scaling. ",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-32b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "9021227d-9e2a-4718-83d7-3423c7031b49",
        "name": "Chutes | qwen/qwen3-32b-04-28:free",
        "contextLength": 40960,
        "model": {
          "slug": "qwen/qwen3-32b",
          "hfSlug": "Qwen/Qwen3-32B",
          "updatedAt": "2025-05-11T22:45:44.273213+00:00",
          "createdAt": "2025-04-28T21:32:25.189881+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 32B",
          "shortName": "Qwen3 32B",
          "author": "qwen",
          "description": "Qwen3-32B is a dense 32.8B parameter causal language model from the Qwen3 series, optimized for both complex reasoning and efficient dialogue. It supports seamless switching between a \"thinking\" mode for tasks like math, coding, and logical inference, and a \"non-thinking\" mode for faster, general-purpose conversation. The model demonstrates strong performance in instruction-following, agent tool use, creative writing, and multilingual tasks across 100+ languages and dialects. It natively handles 32K token contexts and can extend to 131K tokens using YaRN-based scaling. ",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-32b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-32b:free",
        "modelVariantPermaslug": "qwen/qwen3-32b-04-28:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/Qwen3-32B",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 43,
        "newest": 28,
        "throughputHighToLow": 133,
        "latencyLowToHigh": 142,
        "pricingLowToHigh": 12,
        "pricingHighToLow": 194
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-32B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 45.37,
          "latency": 873
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-32B",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 31.8995,
          "latency": 801
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-32b-fp8",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.00000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.1,
          "outputCost": 0.45,
          "throughput": 30.4325,
          "latency": 975
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "parasail-qwen3-32b",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.1,
          "outputCost": 0.5,
          "throughput": 49.746,
          "latency": 813
        },
        {
          "name": "GMICloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "slug": "gmiCloud",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-32B-FP8",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "seed"
          ],
          "inputCost": 0.3,
          "outputCost": 0.6,
          "throughput": 57.57,
          "latency": 734.5
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": 4096,
          "providerModelId": "Qwen3-32B",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "stop"
          ],
          "inputCost": 0.4,
          "outputCost": 0.8,
          "throughput": 320.3015,
          "latency": 1143
        }
      ]
    },
    {
      "slug": "microsoft/phi-3.5-mini-128k-instruct",
      "hfSlug": "microsoft/Phi-3.5-mini-instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-21T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: Phi-3.5 Mini 128K Instruct",
      "shortName": "Phi-3.5 Mini 128K Instruct",
      "author": "microsoft",
      "description": "Phi-3.5 models are lightweight, state-of-the-art open models. These models were trained with Phi-3 datasets that include both synthetic data and the filtered, publicly available websites data, with a focus on high quality and reasoning-dense properties. Phi-3.5 Mini uses 3.8B parameters, and is a dense decoder-only transformer model using the same tokenizer as [Phi-3 Mini](/models/microsoft/phi-3-mini-128k-instruct).\n\nThe models underwent a rigorous enhancement process, incorporating both supervised fine-tuning, proximal policy optimization, and direct preference optimization to ensure precise instruction adherence and robust safety measures. When assessed against benchmarks that test common sense, language understanding, math, code, long context and logical reasoning, Phi-3.5 models showcased robust and state-of-the-art performance among models with less than 13 billion parameters.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "phi3",
      "defaultSystem": null,
      "defaultStops": [
        "<|end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/phi-3.5-mini-128k-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c284390d-1916-4a33-9bd7-b49c8165c2ca",
        "name": "Nebius | microsoft/phi-3.5-mini-128k-instruct",
        "contextLength": 131072,
        "model": {
          "slug": "microsoft/phi-3.5-mini-128k-instruct",
          "hfSlug": "microsoft/Phi-3.5-mini-instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-21T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Microsoft: Phi-3.5 Mini 128K Instruct",
          "shortName": "Phi-3.5 Mini 128K Instruct",
          "author": "microsoft",
          "description": "Phi-3.5 models are lightweight, state-of-the-art open models. These models were trained with Phi-3 datasets that include both synthetic data and the filtered, publicly available websites data, with a focus on high quality and reasoning-dense properties. Phi-3.5 Mini uses 3.8B parameters, and is a dense decoder-only transformer model using the same tokenizer as [Phi-3 Mini](/models/microsoft/phi-3-mini-128k-instruct).\n\nThe models underwent a rigorous enhancement process, incorporating both supervised fine-tuning, proximal policy optimization, and direct preference optimization to ensure precise instruction adherence and robust safety measures. When assessed against benchmarks that test common sense, language understanding, math, code, long context and logical reasoning, Phi-3.5 models showcased robust and state-of-the-art performance among models with less than 13 billion parameters.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "phi3",
          "defaultSystem": null,
          "defaultStops": [
            "<|end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/phi-3.5-mini-128k-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "microsoft/phi-3.5-mini-128k-instruct",
        "modelVariantPermaslug": "microsoft/phi-3.5-mini-128k-instruct",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "microsoft/Phi-3.5-mini-instruct",
        "providerGroup": "Nebius",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000003",
          "completion": "0.00000009",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 120,
        "newest": 217,
        "throughputHighToLow": 16,
        "latencyLowToHigh": 24,
        "pricingLowToHigh": 86,
        "pricingHighToLow": 232
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "microsoft/Phi-3.5-mini-instruct",
          "pricing": {
            "prompt": "0.00000003",
            "completion": "0.00000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.09,
          "throughput": 154.02,
          "latency": 424
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "phi-35-mini-128k-instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 17.745,
          "latency": 1450
        }
      ]
    },
    {
      "slug": "qwen/qwq-32b",
      "hfSlug": "Qwen/QwQ-32B",
      "updatedAt": "2025-05-02T17:24:23.70143+00:00",
      "createdAt": "2025-03-05T21:06:54.875499+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: QwQ 32B (free)",
      "shortName": "QwQ 32B (free)",
      "author": "qwen",
      "description": "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.",
      "modelVersionGroupId": null,
      "contextLength": 40000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "qwq",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwq-32b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "bdb92948-0d84-423b-8204-ecc8df0669ef",
        "name": "Nineteen | qwen/qwq-32b:free",
        "contextLength": 40000,
        "model": {
          "slug": "qwen/qwq-32b",
          "hfSlug": "Qwen/QwQ-32B",
          "updatedAt": "2025-05-02T17:24:23.70143+00:00",
          "createdAt": "2025-03-05T21:06:54.875499+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: QwQ 32B",
          "shortName": "QwQ 32B",
          "author": "qwen",
          "description": "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "qwq",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwq-32b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwq-32b:free",
        "modelVariantPermaslug": "qwen/qwq-32b:free",
        "providerName": "Nineteen",
        "providerInfo": {
          "name": "Nineteen",
          "displayName": "Nineteen",
          "slug": "nineteen",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://nineteen.ai/tos",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Nineteen",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nineteen.ai/&size=256"
          }
        },
        "providerDisplayName": "Nineteen",
        "providerModelId": "Qwen/QwQ-32B",
        "providerGroup": "Nineteen",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 40000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://nineteen.ai/tos",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 65,
        "newest": 102,
        "throughputHighToLow": 51,
        "latencyLowToHigh": 83,
        "pricingLowToHigh": 43,
        "pricingHighToLow": 183
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.15,
          "outputCost": 0.2,
          "throughput": 39.222,
          "latency": 358
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.00000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.45,
          "throughput": 32.054,
          "latency": 407
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 16000,
          "providerModelId": "qwen/qwq-32b",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.18,
          "outputCost": 0.2,
          "throughput": 33.979,
          "latency": 715
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "qwen/qwq-32b/fp-8",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "qwen-qwq-32b",
          "pricing": {
            "prompt": "0.00000029",
            "completion": "0.00000039",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.29,
          "outputCost": 0.39,
          "throughput": 564.2155,
          "latency": 692
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 33.561,
          "latency": 1027
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "QwQ-32B",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "stop"
          ],
          "inputCost": 0.5,
          "outputCost": 1,
          "throughput": 262.86,
          "latency": 680
        },
        {
          "name": "Nebius AI Studio (Fast)",
          "icon": "",
          "slug": "nebiusAiStudio (fast)",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B-fast",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 75.183,
          "latency": 285
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "fp16",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.00000065",
            "completion": "0.00000065",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.65,
          "outputCost": 0.65,
          "throughput": 58.471,
          "latency": 606
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwq-32b",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 132.269,
          "latency": 700
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "Qwen/QwQ-32B",
          "pricing": {
            "prompt": "0.0000012",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.2,
          "outputCost": 1.2,
          "throughput": 88.4365,
          "latency": 965.5
        }
      ]
    },
    {
      "slug": "mistralai/ministral-3b",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-17T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Ministral 3B",
      "shortName": "Ministral 3B",
      "author": "mistralai",
      "description": "Ministral 3B is a 3B parameter model optimized for on-device and edge computing. It excels in knowledge, commonsense reasoning, and function-calling, outperforming larger models like Mistral 7B on most benchmarks. Supporting up to 128k context length, it’s ideal for orchestrating agentic workflows and specialist tasks with efficient inference.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/ministral-3b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "71ce5f13-6ef2-4cbe-a650-66d2f11a4ecb",
        "name": "Mistral | mistralai/ministral-3b",
        "contextLength": 131072,
        "model": {
          "slug": "mistralai/ministral-3b",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-17T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Ministral 3B",
          "shortName": "Ministral 3B",
          "author": "mistralai",
          "description": "Ministral 3B is a 3B parameter model optimized for on-device and edge computing. It excels in knowledge, commonsense reasoning, and function-calling, outperforming larger models like Mistral 7B on most benchmarks. Supporting up to 128k context length, it’s ideal for orchestrating agentic workflows and specialist tasks with efficient inference.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/ministral-3b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/ministral-3b",
        "modelVariantPermaslug": "mistralai/ministral-3b",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "ministral-3b-2410",
        "providerGroup": "Mistral",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000004",
          "completion": "0.00000004",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 122,
        "newest": 187,
        "throughputHighToLow": 7,
        "latencyLowToHigh": 4,
        "pricingLowToHigh": 88,
        "pricingHighToLow": 231
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "ministral-3b-2410",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.04,
          "outputCost": 0.04,
          "throughput": 245.09,
          "latency": 167
        }
      ]
    },
    {
      "slug": "openai/gpt-3.5-turbo",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-05-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-3.5 Turbo",
      "shortName": "GPT-3.5 Turbo",
      "author": "openai",
      "description": "GPT-3.5 Turbo is OpenAI's fastest model. It can understand and generate natural language or code, and is optimized for chat and traditional completion tasks.\n\nTraining data up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 16385,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-3.5-turbo",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3a632f37-731d-4200-9e38-413a5f5dd39d",
        "name": "OpenAI | openai/gpt-3.5-turbo",
        "contextLength": 16385,
        "model": {
          "slug": "openai/gpt-3.5-turbo",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-05-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-3.5 Turbo",
          "shortName": "GPT-3.5 Turbo",
          "author": "openai",
          "description": "GPT-3.5 Turbo is OpenAI's fastest model. It can understand and generate natural language or code, and is optimized for chat and traditional completion tasks.\n\nTraining data up to Sep 2021.",
          "modelVersionGroupId": null,
          "contextLength": 16385,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-3.5-turbo",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-3.5-turbo",
        "modelVariantPermaslug": "openai/gpt-3.5-turbo",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-3.5-turbo",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 123,
        "newest": 315,
        "throughputHighToLow": 48,
        "latencyLowToHigh": 54,
        "pricingLowToHigh": 190,
        "pricingHighToLow": 129
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 16385,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-3.5-turbo",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 128.475,
          "latency": 421
        }
      ]
    },
    {
      "slug": "openai/o3-mini-high",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-12T15:03:31.504126+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o3 Mini High",
      "shortName": "o3 Mini High",
      "author": "openai",
      "description": "OpenAI o3-mini-high is the same model as [o3-mini](/openai/o3-mini) with reasoning_effort set to high. \n\no3-mini is a cost-efficient language model optimized for STEM reasoning tasks, particularly excelling in science, mathematics, and coding. The model features three adjustable reasoning effort levels and supports key developer capabilities including function calling, structured outputs, and streaming, though it does not include vision processing capabilities.\n\nThe model demonstrates significant improvements over its predecessor, with expert testers preferring its responses 56% of the time and noting a 39% reduction in major errors on complex questions. With medium reasoning effort settings, o3-mini matches the performance of the larger o1 model on challenging reasoning evaluations like AIME and GPQA, while maintaining lower latency and cost.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/o3-mini-high-2025-01-31",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4a8663f2-89f3-40e9-9b50-e4838fff0155",
        "name": "OpenAI | openai/o3-mini-high-2025-01-31",
        "contextLength": 200000,
        "model": {
          "slug": "openai/o3-mini-high",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-12T15:03:31.504126+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o3 Mini High",
          "shortName": "o3 Mini High",
          "author": "openai",
          "description": "OpenAI o3-mini-high is the same model as [o3-mini](/openai/o3-mini) with reasoning_effort set to high. \n\no3-mini is a cost-efficient language model optimized for STEM reasoning tasks, particularly excelling in science, mathematics, and coding. The model features three adjustable reasoning effort levels and supports key developer capabilities including function calling, structured outputs, and streaming, though it does not include vision processing capabilities.\n\nThe model demonstrates significant improvements over its predecessor, with expert testers preferring its responses 56% of the time and noting a 39% reduction in major errors on complex questions. With medium reasoning effort settings, o3-mini matches the performance of the larger o1 model on challenging reasoning evaluations like AIME and GPQA, while maintaining lower latency and cost.",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/o3-mini-high-2025-01-31",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o3-mini-high",
        "modelVariantPermaslug": "openai/o3-mini-high-2025-01-31",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o3-mini-2025-01-31",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 100000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "seed",
          "max_tokens",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000011",
          "completion": "0.0000044",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.00000055",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 124,
        "newest": 116,
        "throughputHighToLow": 312,
        "latencyLowToHigh": 303,
        "pricingLowToHigh": 231,
        "pricingHighToLow": 86
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 100000,
          "providerModelId": "o3-mini-2025-01-31",
          "pricing": {
            "prompt": "0.0000011",
            "completion": "0.0000044",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000055",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "seed",
            "max_tokens",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1.1,
          "outputCost": 4.4,
          "throughput": 95.2735,
          "latency": 8191
        }
      ]
    },
    {
      "slug": "openai/o1",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-17T18:26:39.576639+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o1",
      "shortName": "o1",
      "author": "openai",
      "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding. The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. \n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "openai/o1-2024-12-17",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "82738f61-f3cb-44a5-b5d1-e6787ae64e3b",
        "name": "OpenAI | openai/o1-2024-12-17",
        "contextLength": 200000,
        "model": {
          "slug": "openai/o1",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-17T18:26:39.576639+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o1",
          "shortName": "o1",
          "author": "openai",
          "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding. The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. \n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "openai/o1-2024-12-17",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o1",
        "modelVariantPermaslug": "openai/o1-2024-12-17",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o1-2024-12-17",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 100000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "seed",
          "max_tokens",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000015",
          "completion": "0.00006",
          "image": "0.021675",
          "request": "0",
          "inputCacheRead": "0.0000075",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 125,
        "newest": 151,
        "throughputHighToLow": 314,
        "latencyLowToHigh": 312,
        "pricingLowToHigh": 306,
        "pricingHighToLow": 10
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 100000,
          "providerModelId": "o1-2024-12-17",
          "pricing": {
            "prompt": "0.000015",
            "completion": "0.00006",
            "image": "0.021675",
            "request": "0",
            "inputCacheRead": "0.0000075",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "seed",
            "max_tokens",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 15,
          "outputCost": 60,
          "throughput": 25.438,
          "latency": 17981
        }
      ]
    },
    {
      "slug": "qwen/qwen-2.5-72b-instruct",
      "hfSlug": "Qwen/Qwen2.5-72B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-19T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen2.5 72B Instruct (free)",
      "shortName": "Qwen2.5 72B Instruct (free)",
      "author": "qwen",
      "description": "Qwen2.5 72B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2.5-72b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e0e08390-a346-4bbf-a641-0ccdedface29",
        "name": "Chutes | qwen/qwen-2.5-72b-instruct:free",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen-2.5-72b-instruct",
          "hfSlug": "Qwen/Qwen2.5-72B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-19T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen2.5 72B Instruct",
          "shortName": "Qwen2.5 72B Instruct",
          "author": "qwen",
          "description": "Qwen2.5 72B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-2.5-72b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-2.5-72b-instruct:free",
        "modelVariantPermaslug": "qwen/qwen-2.5-72b-instruct:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/Qwen2.5-72B-Instruct",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 31,
        "newest": 204,
        "throughputHighToLow": 221,
        "latencyLowToHigh": 135,
        "pricingLowToHigh": 64,
        "pricingHighToLow": 186
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "Qwen/Qwen2.5-72B-Instruct",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.00000039",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.12,
          "outputCost": 0.39,
          "throughput": 33.5375,
          "latency": 656.5
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-72B-Instruct",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.13,
          "outputCost": 0.4,
          "throughput": 19.7725,
          "latency": 1949
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 32000,
          "maxCompletionTokens": 4096,
          "providerModelId": "qwen/qwen-2.5-72b-instruct",
          "pricing": {
            "prompt": "0.00000038",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.38,
          "outputCost": 0.4,
          "throughput": 21.3505,
          "latency": 4114.5
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-72B-Instruct",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 32.5955,
          "latency": 2151.5
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwen2p5-72b-instruct",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 70.528,
          "latency": 354
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 2048,
          "providerModelId": "Qwen/Qwen2.5-72B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.0000012",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.2,
          "outputCost": 1.2,
          "throughput": 95.3675,
          "latency": 805
        }
      ]
    },
    {
      "slug": "qwen/qwen-2.5-7b-instruct",
      "hfSlug": "Qwen/Qwen2.5-7B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen2.5 7B Instruct (free)",
      "shortName": "Qwen2.5 7B Instruct (free)",
      "author": "qwen",
      "description": "Qwen2.5 7B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2.5-7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8a40a3b8-80d8-4f75-bb8a-c0c710b31eb5",
        "name": "Nineteen | qwen/qwen-2.5-7b-instruct:free",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen-2.5-7b-instruct",
          "hfSlug": "Qwen/Qwen2.5-7B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-16T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen2.5 7B Instruct",
          "shortName": "Qwen2.5 7B Instruct",
          "author": "qwen",
          "description": "Qwen2.5 7B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly more knowledge and has greatly improved capabilities in coding and mathematics, thanks to our specialized expert models in these domains.\n\n- Significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. More resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots.\n\n- Long-context Support up to 128K tokens and can generate up to 8K tokens.\n\n- Multilingual support for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-2.5-7b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-2.5-7b-instruct:free",
        "modelVariantPermaslug": "qwen/qwen-2.5-7b-instruct:free",
        "providerName": "Nineteen",
        "providerInfo": {
          "name": "Nineteen",
          "displayName": "Nineteen",
          "slug": "nineteen",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://nineteen.ai/tos",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Nineteen",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nineteen.ai/&size=256"
          }
        },
        "providerDisplayName": "Nineteen",
        "providerModelId": "Qwen/Qwen2.5-7B-Instruct",
        "providerGroup": "Nineteen",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://nineteen.ai/tos",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 22,
        "newest": 188,
        "throughputHighToLow": 5,
        "latencyLowToHigh": 89,
        "pricingLowToHigh": 60,
        "pricingHighToLow": 227
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "qwen:2-5-7b",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.04,
          "outputCost": 0.1,
          "throughput": 5.301,
          "latency": 1961
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "Qwen/Qwen2.5-7B-Instruct",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.05,
          "outputCost": 0.1,
          "throughput": 53.032,
          "latency": 240
        },
        {
          "name": "nCompass",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://console.ncompass.tech/&size=256",
          "slug": "nCompass",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "Qwen/Qwen2.5-7B-Instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 145.933,
          "latency": 113
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "Qwen/Qwen2.5-7B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 179.5095,
          "latency": 201
        }
      ]
    },
    {
      "slug": "thudm/glm-4-32b",
      "hfSlug": "THUDM/GLM-4-32B-0414",
      "updatedAt": "2025-04-17T21:06:30.647205+00:00",
      "createdAt": "2025-04-17T20:15:15.766619+00:00",
      "hfUpdatedAt": null,
      "name": "THUDM: GLM 4 32B (free)",
      "shortName": "GLM 4 32B (free)",
      "author": "thudm",
      "description": "GLM-4-32B-0414 is a 32B bilingual (Chinese-English) open-weight language model optimized for code generation, function calling, and agent-style tasks. Pretrained on 15T of high-quality and reasoning-heavy data, it was further refined using human preference alignment, rejection sampling, and reinforcement learning. The model excels in complex reasoning, artifact generation, and structured output tasks, achieving performance comparable to GPT-4o and DeepSeek-V3-0324 across several benchmarks.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thudm/glm-4-32b-0414",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "6efe0199-f563-4df0-8bbe-1e68a6aea086",
        "name": "Chutes | thudm/glm-4-32b-0414:free",
        "contextLength": 32768,
        "model": {
          "slug": "thudm/glm-4-32b",
          "hfSlug": "THUDM/GLM-4-32B-0414",
          "updatedAt": "2025-04-17T21:06:30.647205+00:00",
          "createdAt": "2025-04-17T20:15:15.766619+00:00",
          "hfUpdatedAt": null,
          "name": "THUDM: GLM 4 32B",
          "shortName": "GLM 4 32B",
          "author": "thudm",
          "description": "GLM-4-32B-0414 is a 32B bilingual (Chinese-English) open-weight language model optimized for code generation, function calling, and agent-style tasks. Pretrained on 15T of high-quality and reasoning-heavy data, it was further refined using human preference alignment, rejection sampling, and reinforcement learning. The model excels in complex reasoning, artifact generation, and structured output tasks, achieving performance comparable to GPT-4o and DeepSeek-V3-0324 across several benchmarks.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thudm/glm-4-32b-0414",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "thudm/glm-4-32b:free",
        "modelVariantPermaslug": "thudm/glm-4-32b-0414:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "THUDM/GLM-4-32B-0414",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 128,
        "newest": 39,
        "throughputHighToLow": 192,
        "latencyLowToHigh": 112,
        "pricingLowToHigh": 19,
        "pricingHighToLow": 162
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "thudm/glm-4-32b-0414",
          "pricing": {
            "prompt": "0.00000024",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.24,
          "outputCost": 0.24,
          "throughput": 22.123,
          "latency": 1095
        }
      ]
    },
    {
      "slug": "mistralai/mistral-7b-instruct",
      "hfSlug": "mistralai/Mistral-7B-Instruct-v0.3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-27T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral 7B Instruct",
      "shortName": "Mistral 7B Instruct",
      "author": "mistralai",
      "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*",
      "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "54a41d98-d92a-4ec1-a68c-a1da232e0946",
        "name": "Enfer | mistralai/mistral-7b-instruct",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mistral-7b-instruct",
          "hfSlug": "mistralai/Mistral-7B-Instruct-v0.3",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-27T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral 7B Instruct",
          "shortName": "Mistral 7B Instruct",
          "author": "mistralai",
          "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*",
          "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-7b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-7b-instruct",
        "modelVariantPermaslug": "mistralai/mistral-7b-instruct",
        "providerName": "Enfer",
        "providerInfo": {
          "name": "Enfer",
          "displayName": "Enfer",
          "slug": "enfer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://enfer.ai/privacy-policy",
            "privacyPolicyUrl": "https://enfer.ai/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Enfer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256"
          }
        },
        "providerDisplayName": "Enfer",
        "providerModelId": "mistralai/mistral-7b-instruct-v0-3",
        "providerGroup": "Enfer",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "logit_bias",
          "logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://enfer.ai/privacy-policy",
          "privacyPolicyUrl": "https://enfer.ai/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000000028",
          "completion": "0.000000054",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 129,
        "newest": 249,
        "throughputHighToLow": 36,
        "latencyLowToHigh": 74,
        "pricingLowToHigh": 70,
        "pricingHighToLow": 234
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Enfer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256",
          "slug": "enfer",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/mistral-7b-instruct-v0-3",
          "pricing": {
            "prompt": "0.000000028",
            "completion": "0.000000054",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logit_bias",
            "logprobs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.05,
          "throughput": 111.7105,
          "latency": 4286
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/Mistral-7B-Instruct-v0.3",
          "pricing": {
            "prompt": "0.000000029",
            "completion": "0.000000055",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 106.681,
          "latency": 598
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral:7b",
          "pricing": {
            "prompt": "0.000000029",
            "completion": "0.000000058",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 79.0705,
          "latency": 1218
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/mistral-7b-instruct",
          "pricing": {
            "prompt": "0.000000029",
            "completion": "0.000000059",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 142.638,
          "latency": 768
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": 4096,
          "providerModelId": "mistralai/Mistral-7B-Instruct-v0.3",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 211.91,
          "latency": 275
        }
      ]
    },
    {
      "slug": "perplexity/sonar-deep-research",
      "hfSlug": "",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-03-07T01:34:06+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Sonar Deep Research",
      "shortName": "Sonar Deep Research",
      "author": "perplexity",
      "description": "Sonar Deep Research is a research-focused model designed for multi-step retrieval, synthesis, and reasoning across complex topics. It autonomously searches, reads, and evaluates sources, refining its approach as it gathers information. This enables comprehensive report generation across domains like finance, technology, health, and current events.\n\nNotes on Pricing ([Source](https://docs.perplexity.ai/guides/pricing#detailed-pricing-breakdown-for-sonar-deep-research)) \n- Input tokens comprise of Prompt tokens (user prompt) + Citation tokens (these are processed tokens from running searches)\n- Deep Research runs multiple searches to conduct exhaustive research. Searches are priced at $5/1000 searches. A request that does 30 searches will cost $0.15 in this step.\n- Reasoning is a distinct step in Deep Research since it does extensive automated reasoning through all the material it gathers during its research phase. Reasoning tokens here are a bit different than the CoTs in the answer - these are tokens that we use to reason through the research material prior to generating the outputs via the CoTs. Reasoning tokens are priced at $3/1M tokens",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "perplexity/sonar-deep-research",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "47dadaf5-a2e7-4c17-ac4b-e4811f3c0a28",
        "name": "Perplexity | perplexity/sonar-deep-research",
        "contextLength": 128000,
        "model": {
          "slug": "perplexity/sonar-deep-research",
          "hfSlug": "",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-03-07T01:34:06+00:00",
          "hfUpdatedAt": null,
          "name": "Perplexity: Sonar Deep Research",
          "shortName": "Sonar Deep Research",
          "author": "perplexity",
          "description": "Sonar Deep Research is a research-focused model designed for multi-step retrieval, synthesis, and reasoning across complex topics. It autonomously searches, reads, and evaluates sources, refining its approach as it gathers information. This enables comprehensive report generation across domains like finance, technology, health, and current events.\n\nNotes on Pricing ([Source](https://docs.perplexity.ai/guides/pricing#detailed-pricing-breakdown-for-sonar-deep-research)) \n- Input tokens comprise of Prompt tokens (user prompt) + Citation tokens (these are processed tokens from running searches)\n- Deep Research runs multiple searches to conduct exhaustive research. Searches are priced at $5/1000 searches. A request that does 30 searches will cost $0.15 in this step.\n- Reasoning is a distinct step in Deep Research since it does extensive automated reasoning through all the material it gathers during its research phase. Reasoning tokens here are a bit different than the CoTs in the answer - these are tokens that we use to reason through the research material prior to generating the outputs via the CoTs. Reasoning tokens are priced at $3/1M tokens",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "perplexity/sonar-deep-research",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "perplexity/sonar-deep-research",
        "modelVariantPermaslug": "perplexity/sonar-deep-research",
        "providerName": "Perplexity",
        "providerInfo": {
          "name": "Perplexity",
          "displayName": "Perplexity",
          "slug": "perplexity",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
            "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Perplexity",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.perplexity.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Perplexity.svg"
          }
        },
        "providerDisplayName": "Perplexity",
        "providerModelId": "sonar-deep-research",
        "providerGroup": "Perplexity",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "top_k",
          "frequency_penalty",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
          "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000008",
          "image": "0",
          "request": "0",
          "webSearch": "0.005",
          "internalReasoning": "0.000003",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 130,
        "newest": 100,
        "throughputHighToLow": 167,
        "latencyLowToHigh": 313,
        "pricingLowToHigh": 250,
        "pricingHighToLow": 70
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": [
        {
          "name": "Perplexity",
          "icon": "https://openrouter.ai/images/icons/Perplexity.svg",
          "slug": "perplexity",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "sonar-deep-research",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0.005",
            "internalReasoning": "0.000003",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 2,
          "outputCost": 8,
          "throughput": 51.3795,
          "latency": 33809
        }
      ]
    },
    {
      "slug": "nvidia/llama-3.1-nemotron-70b-instruct",
      "hfSlug": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-15T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "NVIDIA: Llama 3.1 Nemotron 70B Instruct",
      "shortName": "Llama 3.1 Nemotron 70B Instruct",
      "author": "nvidia",
      "description": "NVIDIA's Llama 3.1 Nemotron 70B is a language model designed for generating precise and useful responses. Leveraging [Llama 3.1 70B](/models/meta-llama/llama-3.1-70b-instruct) architecture and Reinforcement Learning from Human Feedback (RLHF), it excels in automatic alignment benchmarks. This model is tailored for applications requiring high accuracy in helpfulness and response generation, suitable for diverse user queries across multiple domains.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nvidia/llama-3.1-nemotron-70b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b927c681-9d7b-42db-8bb4-d13bd706031b",
        "name": "Lambda | nvidia/llama-3.1-nemotron-70b-instruct",
        "contextLength": 131072,
        "model": {
          "slug": "nvidia/llama-3.1-nemotron-70b-instruct",
          "hfSlug": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-15T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "NVIDIA: Llama 3.1 Nemotron 70B Instruct",
          "shortName": "Llama 3.1 Nemotron 70B Instruct",
          "author": "nvidia",
          "description": "NVIDIA's Llama 3.1 Nemotron 70B is a language model designed for generating precise and useful responses. Leveraging [Llama 3.1 70B](/models/meta-llama/llama-3.1-70b-instruct) architecture and Reinforcement Learning from Human Feedback (RLHF), it excels in automatic alignment benchmarks. This model is tailored for applications requiring high accuracy in helpfulness and response generation, suitable for diverse user queries across multiple domains.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nvidia/llama-3.1-nemotron-70b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nvidia/llama-3.1-nemotron-70b-instruct",
        "modelVariantPermaslug": "nvidia/llama-3.1-nemotron-70b-instruct",
        "providerName": "Lambda",
        "providerInfo": {
          "name": "Lambda",
          "displayName": "Lambda",
          "slug": "lambda",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
            "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Lambda",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256"
          }
        },
        "providerDisplayName": "Lambda",
        "providerModelId": "llama3.1-nemotron-70b-instruct-fp8",
        "providerGroup": "Lambda",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 131072,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://lambda.ai/legal/privacy-policy",
          "termsOfServiceUrl": "https://lambda.ai/legal/terms-of-service",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000012",
          "completion": "0.0000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 131,
        "newest": 190,
        "throughputHighToLow": 165,
        "latencyLowToHigh": 69,
        "pricingLowToHigh": 130,
        "pricingHighToLow": 187
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nvidia.com/\\u0026size=256",
      "providers": [
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.1-nemotron-70b-instruct-fp8",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.12,
          "outputCost": 0.3,
          "throughput": 51.821,
          "latency": 780
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "nvidia/Llama-3.1-Nemotron-70B-Instruct",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.12,
          "outputCost": 0.3,
          "throughput": 26.1905,
          "latency": 1100
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.13,
          "outputCost": 0.4,
          "throughput": 40.437,
          "latency": 783
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
          "pricing": {
            "prompt": "0.00000088",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.88,
          "outputCost": 0.88,
          "throughput": 68.8815,
          "latency": 729
        },
        {
          "name": "Infermatic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256",
          "slug": "infermatic",
          "quantization": "unknown",
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "nvidia-Llama-3.1-Nemotron-70B-Instruct-HF",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 1,
          "outputCost": 1
        }
      ]
    },
    {
      "slug": "qwen/qwen-2.5-coder-32b-instruct",
      "hfSlug": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-11T23:40:00.276653+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen2.5 Coder 32B Instruct (free)",
      "shortName": "Qwen2.5 Coder 32B Instruct (free)",
      "author": "qwen",
      "description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:\n\n- Significantly improvements in **code generation**, **code reasoning** and **code fixing**. \n- A more comprehensive foundation for real-world applications such as **Code Agents**. Not only enhancing coding capabilities but also maintaining its strengths in mathematics and general competencies.\n\nTo read more about its evaluation results, check out [Qwen 2.5 Coder's blog](https://qwenlm.github.io/blog/qwen2.5-coder-family/).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2.5-coder-32b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7a16bd75-9432-4a37-8540-baec55a293c0",
        "name": "Chutes | qwen/qwen-2.5-coder-32b-instruct:free",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen-2.5-coder-32b-instruct",
          "hfSlug": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-11T23:40:00.276653+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen2.5 Coder 32B Instruct",
          "shortName": "Qwen2.5 Coder 32B Instruct",
          "author": "qwen",
          "description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:\n\n- Significantly improvements in **code generation**, **code reasoning** and **code fixing**. \n- A more comprehensive foundation for real-world applications such as **Code Agents**. Not only enhancing coding capabilities but also maintaining its strengths in mathematics and general competencies.\n\nTo read more about its evaluation results, check out [Qwen 2.5 Coder's blog](https://qwenlm.github.io/blog/qwen2.5-coder-family/).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-2.5-coder-32b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-2.5-coder-32b-instruct:free",
        "modelVariantPermaslug": "qwen/qwen-2.5-coder-32b-instruct:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 86,
        "newest": 172,
        "throughputHighToLow": 159,
        "latencyLowToHigh": 66,
        "pricingLowToHigh": 59,
        "pricingHighToLow": 215
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.06,
          "outputCost": 0.15,
          "throughput": 53.256,
          "latency": 392
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.06,
          "outputCost": 0.18,
          "throughput": 52.042,
          "latency": 467
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "qwen25-coder-32b-instruct",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000016",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.07,
          "outputCost": 0.16,
          "throughput": 44.4645,
          "latency": 517
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 8192,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 53.4815,
          "latency": 1119
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-qwen-coder32b-longcontext-128",
          "pricing": {
            "prompt": "0.00000035",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.35,
          "outputCost": 0.5,
          "throughput": 56.927,
          "latency": 562.5
        },
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "qwen2.5-coder-32b",
          "pricing": {
            "prompt": "0.000000375",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.38,
          "outputCost": 1.5,
          "throughput": 31.565,
          "latency": 807
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "qwen2.5-coder-32b",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.5,
          "outputCost": 2,
          "throughput": 31.802,
          "latency": 1431
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/qwen/qwen2.5-coder-32b-instruct",
          "pricing": {
            "prompt": "0.00000066",
            "completion": "0.000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.66,
          "outputCost": 1,
          "throughput": 34.9445,
          "latency": 1051
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 2048,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 91.863,
          "latency": 803
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "pricing": {
            "prompt": "0.0000026",
            "completion": "0.0000034",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 2.6,
          "outputCost": 3.4
        }
      ]
    },
    {
      "slug": "x-ai/grok-2-vision-1212",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-15T04:35:38.489105+00:00",
      "hfUpdatedAt": null,
      "name": "xAI: Grok 2 Vision 1212",
      "shortName": "Grok 2 Vision 1212",
      "author": "x-ai",
      "description": "Grok 2 Vision 1212 advances image-based AI with stronger visual comprehension, refined instruction-following, and multilingual support. From object recognition to style analysis, it empowers developers to build more intuitive, visually aware applications. Its enhanced steerability and reasoning establish a robust foundation for next-generation image solutions.\n\nTo read more about this model, check out [xAI's announcement](https://x.ai/blog/grok-1212).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Grok",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "x-ai/grok-2-vision-1212",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "088736e1-6d9a-49c8-ae86-f7b87c100a32",
        "name": "xAI | x-ai/grok-2-vision-1212",
        "contextLength": 32768,
        "model": {
          "slug": "x-ai/grok-2-vision-1212",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-15T04:35:38.489105+00:00",
          "hfUpdatedAt": null,
          "name": "xAI: Grok 2 Vision 1212",
          "shortName": "Grok 2 Vision 1212",
          "author": "x-ai",
          "description": "Grok 2 Vision 1212 advances image-based AI with stronger visual comprehension, refined instruction-following, and multilingual support. From object recognition to style analysis, it empowers developers to build more intuitive, visually aware applications. Its enhanced steerability and reasoning establish a robust foundation for next-generation image solutions.\n\nTo read more about this model, check out [xAI's announcement](https://x.ai/blog/grok-1212).",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Grok",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "x-ai/grok-2-vision-1212",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "x-ai/grok-2-vision-1212",
        "modelVariantPermaslug": "x-ai/grok-2-vision-1212",
        "providerName": "xAI",
        "providerInfo": {
          "name": "xAI",
          "displayName": "xAI",
          "slug": "xai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "xAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.x.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256"
          }
        },
        "providerDisplayName": "xAI",
        "providerModelId": "grok-2-vision-1212",
        "providerGroup": "xAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.00001",
          "image": "0.0036",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 133,
        "newest": 153,
        "throughputHighToLow": 158,
        "latencyLowToHigh": 150,
        "pricingLowToHigh": 254,
        "pricingHighToLow": 63
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://x.ai/\\u0026size=256",
      "providers": [
        {
          "name": "xAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256",
          "slug": "xAi",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "grok-2-vision-1212",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.00001",
            "image": "0.0036",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 2,
          "outputCost": 10,
          "throughput": 53.0415,
          "latency": 904
        }
      ]
    },
    {
      "slug": "anthropic/claude-3-sonnet",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-05T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3 Sonnet",
      "shortName": "Claude 3 Sonnet",
      "author": "anthropic",
      "description": "Claude 3 Sonnet is an ideal balance of intelligence and speed for enterprise workloads. Maximum utility at a lower price, dependable, balanced for scaled deployments.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
      "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-sonnet",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "dc39604a-e702-4a0c-8bd8-0f2578f14a2d",
        "name": "Anthropic | anthropic/claude-3-sonnet",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3-sonnet",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-05T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3 Sonnet",
          "shortName": "Claude 3 Sonnet",
          "author": "anthropic",
          "description": "Claude 3 Sonnet is an ideal balance of intelligence and speed for enterprise workloads. Maximum utility at a lower price, dependable, balanced for scaled deployments.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
          "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-sonnet",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3-sonnet",
        "modelVariantPermaslug": "anthropic/claude-3-sonnet",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-sonnet-20240229",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0.0048",
          "request": "0",
          "inputCacheRead": "0.0000003",
          "inputCacheWrite": "0.00000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 134,
        "newest": 281,
        "throughputHighToLow": 116,
        "latencyLowToHigh": 128,
        "pricingLowToHigh": 278,
        "pricingHighToLow": 50
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-sonnet-20240229",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 66.867,
          "latency": 756.5
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-sonnet@20240229",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 68.078,
          "latency": 1041
        }
      ]
    },
    {
      "slug": "anthropic/claude-3-opus",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-05T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3 Opus",
      "shortName": "Claude 3 Opus",
      "author": "anthropic",
      "description": "Claude 3 Opus is Anthropic's most powerful model for highly complex tasks. It boasts top-level performance, intelligence, fluency, and understanding.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-opus",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ee74a4e0-2863-4f51-99a5-997c31c48ae7",
        "name": "Anthropic | anthropic/claude-3-opus",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3-opus",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-05T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3 Opus",
          "shortName": "Claude 3 Opus",
          "author": "anthropic",
          "description": "Claude 3 Opus is Anthropic's most powerful model for highly complex tasks. It boasts top-level performance, intelligence, fluency, and understanding.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-opus",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3-opus",
        "modelVariantPermaslug": "anthropic/claude-3-opus",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-opus-20240229",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000015",
          "completion": "0.000075",
          "image": "0.024",
          "request": "0",
          "inputCacheRead": "0.0000015",
          "inputCacheWrite": "0.00001875",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 135,
        "newest": 279,
        "throughputHighToLow": 247,
        "latencyLowToHigh": 232,
        "pricingLowToHigh": 309,
        "pricingHighToLow": 8
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-opus-20240229",
          "pricing": {
            "prompt": "0.000015",
            "completion": "0.000075",
            "image": "0.024",
            "request": "0",
            "inputCacheRead": "0.0000015",
            "inputCacheWrite": "0.00001875",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 15,
          "outputCost": 75,
          "throughput": 30.081,
          "latency": 1625
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-opus@20240229",
          "pricing": {
            "prompt": "0.000015",
            "completion": "0.000075",
            "image": "0.024",
            "request": "0",
            "inputCacheRead": "0.0000015",
            "inputCacheWrite": "0.00001875",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 15,
          "outputCost": 75,
          "throughput": 17.371,
          "latency": 3104
        }
      ]
    },
    {
      "slug": "thedrummer/anubis-pro-105b-v1",
      "hfSlug": "TheDrummer/Anubis-Pro-105B-v1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-10T21:31:30.605266+00:00",
      "hfUpdatedAt": null,
      "name": "TheDrummer: Anubis Pro 105B V1",
      "shortName": "Anubis Pro 105B V1",
      "author": "thedrummer",
      "description": "Anubis Pro 105B v1 is an expanded and refined variant of Meta’s Llama 3.3 70B, featuring 50% additional layers and further fine-tuning to leverage its increased capacity. Designed for advanced narrative, roleplay, and instructional tasks, it demonstrates enhanced emotional intelligence, creativity, nuanced character portrayal, and superior prompt adherence compared to smaller models. Its larger parameter count allows for deeper contextual understanding and extended reasoning capabilities, optimized for engaging, intelligent, and coherent interactions.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thedrummer/anubis-pro-105b-v1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "5ce38f41-4ec0-4549-ac87-5c33f410f090",
        "name": "Parasail | thedrummer/anubis-pro-105b-v1",
        "contextLength": 131072,
        "model": {
          "slug": "thedrummer/anubis-pro-105b-v1",
          "hfSlug": "TheDrummer/Anubis-Pro-105B-v1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-10T21:31:30.605266+00:00",
          "hfUpdatedAt": null,
          "name": "TheDrummer: Anubis Pro 105B V1",
          "shortName": "Anubis Pro 105B V1",
          "author": "thedrummer",
          "description": "Anubis Pro 105B v1 is an expanded and refined variant of Meta’s Llama 3.3 70B, featuring 50% additional layers and further fine-tuning to leverage its increased capacity. Designed for advanced narrative, roleplay, and instructional tasks, it demonstrates enhanced emotional intelligence, creativity, nuanced character portrayal, and superior prompt adherence compared to smaller models. Its larger parameter count allows for deeper contextual understanding and extended reasoning capabilities, optimized for engaging, intelligent, and coherent interactions.",
          "modelVersionGroupId": null,
          "contextLength": 64000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thedrummer/anubis-pro-105b-v1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "thedrummer/anubis-pro-105b-v1",
        "modelVariantPermaslug": "thedrummer/anubis-pro-105b-v1",
        "providerName": "Parasail",
        "providerInfo": {
          "name": "Parasail",
          "displayName": "Parasail",
          "slug": "parasail",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.parasail.io/legal/terms",
            "privacyPolicyUrl": "https://www.parasail.io/legal/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Parasail",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256"
          }
        },
        "providerDisplayName": "Parasail",
        "providerModelId": "parasail-anubis-pro",
        "providerGroup": "Parasail",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 131072,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "presence_penalty",
          "frequency_penalty",
          "repetition_penalty",
          "top_k"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.parasail.io/legal/terms",
          "privacyPolicyUrl": "https://www.parasail.io/legal/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true
          },
          "training": false,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.000001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 136,
        "newest": 95,
        "throughputHighToLow": 257,
        "latencyLowToHigh": 165,
        "pricingLowToHigh": 203,
        "pricingHighToLow": 115
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-anubis-pro",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.8,
          "outputCost": 1,
          "throughput": 25.5305,
          "latency": 1024
        }
      ]
    },
    {
      "slug": "mistralai/ministral-8b",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-17T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Ministral 8B",
      "shortName": "Ministral 8B",
      "author": "mistralai",
      "description": "Ministral 8B is an 8B parameter model featuring a unique interleaved sliding-window attention pattern for faster, memory-efficient inference. Designed for edge use cases, it supports up to 128k context length and excels in knowledge and reasoning tasks. It outperforms peers in the sub-10B category, making it perfect for low-latency, privacy-first applications.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/ministral-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c70696c7-73c0-47c3-96b4-20c44b17101b",
        "name": "Mistral | mistralai/ministral-8b",
        "contextLength": 128000,
        "model": {
          "slug": "mistralai/ministral-8b",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-17T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Ministral 8B",
          "shortName": "Ministral 8B",
          "author": "mistralai",
          "description": "Ministral 8B is an 8B parameter model featuring a unique interleaved sliding-window attention pattern for faster, memory-efficient inference. Designed for edge use cases, it supports up to 128k context length and excels in knowledge and reasoning tasks. It outperforms peers in the sub-10B category, making it perfect for low-latency, privacy-first applications.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/ministral-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/ministral-8b",
        "modelVariantPermaslug": "mistralai/ministral-8b",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "ministral-8b-2410",
        "providerGroup": "Mistral",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 137,
        "newest": 186,
        "throughputHighToLow": 58,
        "latencyLowToHigh": 2,
        "pricingLowToHigh": 115,
        "pricingHighToLow": 203
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "ministral-8b-2410",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 120.5965,
          "latency": 133
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1-distill-llama-8b",
      "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-02-07T14:15:18.18663+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1 Distill Llama 8B",
      "shortName": "R1 Distill Llama 8B",
      "author": "deepseek",
      "description": "DeepSeek R1 Distill Llama 8B is a distilled large language model based on [Llama-3.1-8B-Instruct](/meta-llama/llama-3.1-8b-instruct), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). The model combines advanced distillation techniques to achieve high performance across multiple benchmarks, including:\n\n- AIME 2024 pass@1: 50.4\n- MATH-500 pass@1: 89.1\n- CodeForces Rating: 1205\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.\n\nHugging Face: \n- [Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B) \n- [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)   |",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-r1-distill-llama-8b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "fbc63cef-f2e8-4e4b-a135-9b45485e0eaf",
        "name": "Novita | deepseek/deepseek-r1-distill-llama-8b",
        "contextLength": 32000,
        "model": {
          "slug": "deepseek/deepseek-r1-distill-llama-8b",
          "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-02-07T14:15:18.18663+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1 Distill Llama 8B",
          "shortName": "R1 Distill Llama 8B",
          "author": "deepseek",
          "description": "DeepSeek R1 Distill Llama 8B is a distilled large language model based on [Llama-3.1-8B-Instruct](/meta-llama/llama-3.1-8b-instruct), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). The model combines advanced distillation techniques to achieve high performance across multiple benchmarks, including:\n\n- AIME 2024 pass@1: 50.4\n- MATH-500 pass@1: 89.1\n- CodeForces Rating: 1205\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.\n\nHugging Face: \n- [Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B) \n- [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)   |",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 0,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-r1-distill-llama-8b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1-distill-llama-8b",
        "modelVariantPermaslug": "deepseek/deepseek-r1-distill-llama-8b",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "deepseek/deepseek-r1-distill-llama-8b",
        "providerGroup": "Novita",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000004",
          "completion": "0.00000004",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 138,
        "newest": 117,
        "throughputHighToLow": 194,
        "latencyLowToHigh": 208,
        "pricingLowToHigh": 87,
        "pricingHighToLow": 230
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "deepseek/deepseek-r1-distill-llama-8b",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.04,
          "outputCost": 0.04,
          "throughput": 43.8785,
          "latency": 1501.5
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.3-70b-instruct",
      "hfSlug": "meta-llama/Llama-3.3-70B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-06T17:28:57.828422+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.3 70B Instruct (free)",
      "shortName": "Llama 3.3 70B Instruct (free)",
      "author": "meta-llama",
      "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n\nSupported languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n\n[Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)",
      "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.3-70b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4625027b-9188-4d61-b21a-ae6808bd4e5d",
        "name": "Crusoe | meta-llama/llama-3.3-70b-instruct:free",
        "contextLength": 131072,
        "model": {
          "slug": "meta-llama/llama-3.3-70b-instruct",
          "hfSlug": "meta-llama/Llama-3.3-70B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-06T17:28:57.828422+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.3 70B Instruct",
          "shortName": "Llama 3.3 70B Instruct",
          "author": "meta-llama",
          "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n\nSupported languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n\n[Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)",
          "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.3-70b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.3-70b-instruct:free",
        "modelVariantPermaslug": "meta-llama/llama-3.3-70b-instruct:free",
        "providerName": "Crusoe",
        "providerInfo": {
          "name": "Crusoe",
          "displayName": "Crusoe",
          "slug": "crusoe",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://legal.crusoe.ai/open-router#cloud-privacy-policy",
            "termsOfServiceUrl": "https://legal.crusoe.ai/open-router#managed-inference-tos-open-router",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Crusoe",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://crusoe.ai/&size=256"
          }
        },
        "providerDisplayName": "Crusoe",
        "providerModelId": "meta-llama/Llama-3.3-70B-Instruct",
        "providerGroup": "Crusoe",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://legal.crusoe.ai/open-router#cloud-privacy-policy",
          "termsOfServiceUrl": "https://legal.crusoe.ai/open-router#managed-inference-tos-open-router",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 8,
        "newest": 157,
        "throughputHighToLow": 235,
        "latencyLowToHigh": 88,
        "pricingLowToHigh": 56,
        "pricingHighToLow": 211
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 131000,
          "maxCompletionTokens": 131000,
          "providerModelId": "klusterai/Meta-Llama-3.3-70B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000033",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.07,
          "outputCost": 0.33,
          "throughput": 33.086,
          "latency": 567.5
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.08,
          "outputCost": 0.25,
          "throughput": 34.006,
          "latency": 269
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.3-70b-instruct-fp8",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.12,
          "outputCost": 0.3,
          "throughput": 60.497,
          "latency": 517
        },
        {
          "name": "Phala",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://phala.network/&size=256",
          "slug": "phala",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "phala/llama-3.3-70b-instruct",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.00000035",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.12,
          "outputCost": 0.35,
          "throughput": 29.951,
          "latency": 741
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/llama-3.3-70b-instruct",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.00000039",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.13,
          "outputCost": 0.39,
          "throughput": 76.1375,
          "latency": 798
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.13,
          "outputCost": 0.4,
          "throughput": 38.655,
          "latency": 661
        },
        {
          "name": "Parasail",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256",
          "slug": "parasail",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "parasail-llama-33-70b-fp8",
          "pricing": {
            "prompt": "0.00000028",
            "completion": "0.00000078",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "presence_penalty",
            "frequency_penalty",
            "repetition_penalty",
            "top_k"
          ],
          "inputCost": 0.28,
          "outputCost": 0.78,
          "throughput": 81.65,
          "latency": 548
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": "fp8",
          "context": 24000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
          "pricing": {
            "prompt": "0.00000029",
            "completion": "0.00000225",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.29,
          "outputCost": 2.25,
          "throughput": 35.862,
          "latency": 663
        },
        {
          "name": "CentML",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256",
          "slug": "centMl",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct",
          "pricing": {
            "prompt": "0.00000035",
            "completion": "0.00000035",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.35,
          "outputCost": 0.35,
          "throughput": 69.9225,
          "latency": 740.5
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 36.3885,
          "latency": 1271
        },
        {
          "name": "Atoma",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://atoma.network/&size=256",
          "slug": "atoma",
          "quantization": "fp8",
          "context": 104962,
          "maxCompletionTokens": 100000,
          "providerModelId": "Infermatic/Llama-3.3-70B-Instruct-FP8-Dynamic",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p"
          ],
          "inputCost": 0.4,
          "outputCost": 0.4,
          "throughput": 28.22,
          "latency": 937
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "llama-3.3-70b-versatile",
          "pricing": {
            "prompt": "0.00000059",
            "completion": "0.00000079",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.59,
          "outputCost": 0.79,
          "throughput": 342.9925,
          "latency": 460
        },
        {
          "name": "Friendli",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://friendli.ai/&size=256",
          "slug": "friendli",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "meta-llama-3.3-70b-instruct",
          "pricing": {
            "prompt": "0.0000006",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.6,
          "outputCost": 0.6,
          "throughput": 95.7715,
          "latency": 819
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "llama3.3:70b",
          "pricing": {
            "prompt": "0.0000006",
            "completion": "0.00000075",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.6,
          "outputCost": 0.75,
          "throughput": 32.632,
          "latency": 2378
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 3072,
          "providerModelId": "Meta-Llama-3.3-70B-Instruct",
          "pricing": {
            "prompt": "0.0000006",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.6,
          "outputCost": 1.2,
          "throughput": 308.397,
          "latency": 2227
        },
        {
          "name": "Cerebras",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cerebras.ai/&size=256",
          "slug": "cerebras",
          "quantization": "fp16",
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "llama-3.3-70b",
          "pricing": {
            "prompt": "0.00000085",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.85,
          "outputCost": 1.2,
          "throughput": 4600,
          "latency": 272
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 2048,
          "providerModelId": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000088",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.88,
          "outputCost": 0.88,
          "throughput": 95.525,
          "latency": 556
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "fp16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama-v3p3-70b-instruct",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 109.5455,
          "latency": 3204.5
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.3-70b-instruct/fp-8",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.00000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.25,
          "throughput": 13.1625,
          "latency": 1625.5
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.2-90b-vision-instruct",
      "hfSlug": "meta-llama/Llama-3.2-90B-Vision-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.2 90B Vision Instruct",
      "shortName": "Llama 3.2 90B Vision Instruct",
      "author": "meta-llama",
      "description": "The Llama 90B Vision model is a top-tier, 90-billion-parameter multimodal model designed for the most challenging visual reasoning and language tasks. It offers unparalleled accuracy in image captioning, visual question answering, and advanced image-text comprehension. Pre-trained on vast multimodal datasets and fine-tuned with human feedback, the Llama 90B Vision is engineered to handle the most demanding image-based AI tasks.\n\nThis model is perfect for industries requiring cutting-edge multimodal AI capabilities, particularly those dealing with complex, real-time visual and textual analysis.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.2-90b-vision-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "6fa97646-3631-4446-beaa-8a24dd07ddb1",
        "name": "Together | meta-llama/llama-3.2-90b-vision-instruct",
        "contextLength": 131072,
        "model": {
          "slug": "meta-llama/llama-3.2-90b-vision-instruct",
          "hfSlug": "meta-llama/Llama-3.2-90B-Vision-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.2 90B Vision Instruct",
          "shortName": "Llama 3.2 90B Vision Instruct",
          "author": "meta-llama",
          "description": "The Llama 90B Vision model is a top-tier, 90-billion-parameter multimodal model designed for the most challenging visual reasoning and language tasks. It offers unparalleled accuracy in image captioning, visual question answering, and advanced image-text comprehension. Pre-trained on vast multimodal datasets and fine-tuned with human feedback, the Llama 90B Vision is engineered to handle the most demanding image-based AI tasks.\n\nThis model is perfect for industries requiring cutting-edge multimodal AI capabilities, particularly those dealing with complex, real-time visual and textual analysis.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.2-90b-vision-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.2-90b-vision-instruct",
        "modelVariantPermaslug": "meta-llama/llama-3.2-90b-vision-instruct",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
        "providerGroup": "Together",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000012",
          "completion": "0.0000012",
          "image": "0.001734",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 140,
        "newest": 201,
        "throughputHighToLow": 261,
        "latencyLowToHigh": 98,
        "pricingLowToHigh": 228,
        "pricingHighToLow": 90
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 2048,
          "providerModelId": "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
          "pricing": {
            "prompt": "0.0000012",
            "completion": "0.0000012",
            "image": "0.001734",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.2,
          "outputCost": 1.2,
          "throughput": 25.164,
          "latency": 724
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.2-90B-Vision-Instruct",
          "pricing": {
            "prompt": "0.00000035",
            "completion": "0.0000004",
            "image": "0.0005058",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.35,
          "outputCost": 0.4,
          "throughput": 19.3805,
          "latency": 1697.5
        }
      ]
    },
    {
      "slug": "undi95/remm-slerp-l2-13b",
      "hfSlug": "Undi95/ReMM-SLERP-L2-13B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "ReMM SLERP 13B",
      "shortName": "ReMM SLERP 13B",
      "author": "undi95",
      "description": "A recreation trial of the original MythoMax-L2-B13 but with updated models. #merge",
      "modelVersionGroupId": null,
      "contextLength": 6144,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "undi95/remm-slerp-l2-13b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "989a7c1b-f4c8-4d78-b0e3-caf0adb687c5",
        "name": "Mancer | undi95/remm-slerp-l2-13b",
        "contextLength": 6144,
        "model": {
          "slug": "undi95/remm-slerp-l2-13b",
          "hfSlug": "Undi95/ReMM-SLERP-L2-13B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-07-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "ReMM SLERP 13B",
          "shortName": "ReMM SLERP 13B",
          "author": "undi95",
          "description": "A recreation trial of the original MythoMax-L2-B13 but with updated models. #merge",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "alpaca",
          "defaultSystem": null,
          "defaultStops": [
            "###",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "undi95/remm-slerp-l2-13b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "undi95/remm-slerp-l2-13b",
        "modelVariantPermaslug": "undi95/remm-slerp-l2-13b",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "remm-slerp",
        "providerGroup": "Mancer",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 1024,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.0000005625",
          "completion": "0.00000084375",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 141,
        "newest": 312,
        "throughputHighToLow": 200,
        "latencyLowToHigh": 154,
        "pricingLowToHigh": 187,
        "pricingHighToLow": 131
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "unknown",
          "context": 6144,
          "maxCompletionTokens": 1024,
          "providerModelId": "remm-slerp",
          "pricing": {
            "prompt": "0.0000005625",
            "completion": "0.00000084375",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.56,
          "outputCost": 0.84,
          "throughput": 41.7145,
          "latency": 888.5
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "Undi95/ReMM-SLERP-L2-13B",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 15.7335,
          "latency": 1280
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "unknown",
          "context": 6144,
          "maxCompletionTokens": 1024,
          "providerModelId": "remm-slerp",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 1,
          "outputCost": 1.5,
          "throughput": 42.2345,
          "latency": 721
        }
      ]
    },
    {
      "slug": "x-ai/grok-2-1212",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-15T03:20:14.161318+00:00",
      "hfUpdatedAt": null,
      "name": "xAI: Grok 2 1212",
      "shortName": "Grok 2 1212",
      "author": "x-ai",
      "description": "Grok 2 1212 introduces significant enhancements to accuracy, instruction adherence, and multilingual support, making it a powerful and flexible choice for developers seeking a highly steerable, intelligent model.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Grok",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "x-ai/grok-2-1212",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9d94b368-75f7-44b1-a056-f8a1240da545",
        "name": "xAI | x-ai/grok-2-1212",
        "contextLength": 131072,
        "model": {
          "slug": "x-ai/grok-2-1212",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-15T03:20:14.161318+00:00",
          "hfUpdatedAt": null,
          "name": "xAI: Grok 2 1212",
          "shortName": "Grok 2 1212",
          "author": "x-ai",
          "description": "Grok 2 1212 introduces significant enhancements to accuracy, instruction adherence, and multilingual support, making it a powerful and flexible choice for developers seeking a highly steerable, intelligent model.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Grok",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "x-ai/grok-2-1212",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "x-ai/grok-2-1212",
        "modelVariantPermaslug": "x-ai/grok-2-1212",
        "providerName": "xAI",
        "providerInfo": {
          "name": "xAI",
          "displayName": "xAI",
          "slug": "xai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "xAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.x.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256"
          }
        },
        "providerDisplayName": "xAI",
        "providerModelId": "grok-2-1212",
        "providerGroup": "xAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.00001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 142,
        "newest": 154,
        "throughputHighToLow": 92,
        "latencyLowToHigh": 34,
        "pricingLowToHigh": 255,
        "pricingHighToLow": 64
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://x.ai/\\u0026size=256",
      "providers": [
        {
          "name": "xAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256",
          "slug": "xAi",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "grok-2-1212",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.00001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 2,
          "outputCost": 10,
          "throughput": 87.6665,
          "latency": 322.5
        }
      ]
    },
    {
      "slug": "anthropic/claude-3-haiku",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3 Haiku (self-moderated)",
      "shortName": "Claude 3 Haiku (self-moderated)",
      "author": "anthropic",
      "description": "Claude 3 Haiku is Anthropic's fastest and most compact model for\nnear-instant responsiveness. Quick and accurate targeted performance.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-haiku)\n\n#multimodal",
      "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-haiku",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8661a1db-b0cf-4eb2-ba04-c2a79f698682",
        "name": "Anthropic | anthropic/claude-3-haiku:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3-haiku",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-13T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3 Haiku",
          "shortName": "Claude 3 Haiku",
          "author": "anthropic",
          "description": "Claude 3 Haiku is Anthropic's fastest and most compact model for\nnear-instant responsiveness. Quick and accurate targeted performance.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-haiku)\n\n#multimodal",
          "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-haiku",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3-haiku:beta",
        "modelVariantPermaslug": "anthropic/claude-3-haiku:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-haiku-20240307",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000025",
          "completion": "0.00000125",
          "image": "0.0004",
          "request": "0",
          "inputCacheRead": "0.00000003",
          "inputCacheWrite": "0.0000003",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 62,
        "newest": 277,
        "throughputHighToLow": 28,
        "latencyLowToHigh": 133,
        "pricingLowToHigh": 168,
        "pricingHighToLow": 149
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-haiku-20240307",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000125",
            "image": "0.0004",
            "request": "0",
            "inputCacheRead": "0.00000003",
            "inputCacheWrite": "0.0000003",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.25,
          "outputCost": 1.25,
          "throughput": 152.6455,
          "latency": 813
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-haiku@20240307",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000125",
            "image": "0.0004",
            "request": "0",
            "inputCacheRead": "0.00000003",
            "inputCacheWrite": "0.0000003",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.25,
          "outputCost": 1.25,
          "throughput": 152.907,
          "latency": 1524
        }
      ]
    },
    {
      "slug": "qwen/qwen-vl-max",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-01T18:25:04.223655+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen VL Max",
      "shortName": "Qwen VL Max",
      "author": "qwen",
      "description": "Qwen VL Max is a visual understanding model with 7500 tokens context length. It excels in delivering optimal performance for a broader spectrum of complex tasks.\n",
      "modelVersionGroupId": null,
      "contextLength": 7500,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-vl-max-2025-01-25",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "40a33c72-3801-49f3-ac2a-966d0b249981",
        "name": "Alibaba | qwen/qwen-vl-max-2025-01-25",
        "contextLength": 7500,
        "model": {
          "slug": "qwen/qwen-vl-max",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-01T18:25:04.223655+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen VL Max",
          "shortName": "Qwen VL Max",
          "author": "qwen",
          "description": "Qwen VL Max is a visual understanding model with 7500 tokens context length. It excels in delivering optimal performance for a broader spectrum of complex tasks.\n",
          "modelVersionGroupId": null,
          "contextLength": 7500,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-vl-max-2025-01-25",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-vl-max",
        "modelVariantPermaslug": "qwen/qwen-vl-max-2025-01-25",
        "providerName": "Alibaba",
        "providerInfo": {
          "name": "Alibaba",
          "displayName": "Alibaba",
          "slug": "alibaba",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
            "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "CN",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Alibaba",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256"
          }
        },
        "providerDisplayName": "Alibaba",
        "providerModelId": "qwen-vl-max",
        "providerGroup": "Alibaba",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": 6000,
        "maxCompletionTokens": 1500,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "seed",
          "response_format",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
          "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000032",
          "image": "0.001024",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 144,
        "newest": 123,
        "throughputHighToLow": 204,
        "latencyLowToHigh": 243,
        "pricingLowToHigh": 217,
        "pricingHighToLow": 100
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Alibaba",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256",
          "slug": "alibaba",
          "quantization": null,
          "context": 7500,
          "maxCompletionTokens": 1500,
          "providerModelId": "qwen-vl-max",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000032",
            "image": "0.001024",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "seed",
            "response_format",
            "presence_penalty"
          ],
          "inputCost": 0.8,
          "outputCost": 3.2,
          "throughput": 38.904,
          "latency": 1905
        }
      ]
    },
    {
      "slug": "nousresearch/deephermes-3-mistral-24b-preview",
      "hfSlug": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
      "updatedAt": "2025-05-09T23:02:10.58499+00:00",
      "createdAt": "2025-05-09T22:48:24.165453+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: DeepHermes 3 Mistral 24B Preview (free)",
      "shortName": "DeepHermes 3 Mistral 24B Preview (free)",
      "author": "nousresearch",
      "description": "DeepHermes 3 (Mistral 24B Preview) is an instruction-tuned language model by Nous Research based on Mistral-Small-24B, designed for chat, function calling, and advanced multi-turn reasoning. It introduces a dual-mode system that toggles between intuitive chat responses and structured “deep reasoning” mode using special system prompts. Fine-tuned via distillation from R1, it supports structured output (JSON mode) and function call syntax for agent-based applications.\n\nDeepHermes 3 supports a **reasoning toggle via system prompt**, allowing users to switch between fast, intuitive responses and deliberate, multi-step reasoning. When activated with the following specific system instruction, the model enters a *\"deep thinking\"* mode—generating extended chains of thought wrapped in `<think></think>` tags before delivering a final answer. \n\nSystem Prompt: You are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside <think> </think> tags, and then provide your solution or response to the problem.\n",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/deephermes-3-mistral-24b-preview",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "90728530-42b4-4bcf-bc67-167eee5bbac4",
        "name": "Chutes | nousresearch/deephermes-3-mistral-24b-preview:free",
        "contextLength": 32768,
        "model": {
          "slug": "nousresearch/deephermes-3-mistral-24b-preview",
          "hfSlug": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
          "updatedAt": "2025-05-09T23:02:10.58499+00:00",
          "createdAt": "2025-05-09T22:48:24.165453+00:00",
          "hfUpdatedAt": null,
          "name": "Nous: DeepHermes 3 Mistral 24B Preview",
          "shortName": "DeepHermes 3 Mistral 24B Preview",
          "author": "nousresearch",
          "description": "DeepHermes 3 (Mistral 24B Preview) is an instruction-tuned language model by Nous Research based on Mistral-Small-24B, designed for chat, function calling, and advanced multi-turn reasoning. It introduces a dual-mode system that toggles between intuitive chat responses and structured “deep reasoning” mode using special system prompts. Fine-tuned via distillation from R1, it supports structured output (JSON mode) and function call syntax for agent-based applications.\n\nDeepHermes 3 supports a **reasoning toggle via system prompt**, allowing users to switch between fast, intuitive responses and deliberate, multi-step reasoning. When activated with the following specific system instruction, the model enters a *\"deep thinking\"* mode—generating extended chains of thought wrapped in `<think></think>` tags before delivering a final answer. \n\nSystem Prompt: You are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside <think> </think> tags, and then provide your solution or response to the problem.\n",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nousresearch/deephermes-3-mistral-24b-preview",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nousresearch/deephermes-3-mistral-24b-preview:free",
        "modelVariantPermaslug": "nousresearch/deephermes-3-mistral-24b-preview:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 145,
        "newest": 0,
        "throughputHighToLow": 99,
        "latencyLowToHigh": 175,
        "pricingLowToHigh": 0,
        "pricingHighToLow": 248
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "qwen/qwen3-14b",
      "hfSlug": "Qwen/Qwen3-14B",
      "updatedAt": "2025-05-12T00:36:13.09542+00:00",
      "createdAt": "2025-04-28T21:41:18.320017+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 14B (free)",
      "shortName": "Qwen3 14B (free)",
      "author": "qwen",
      "description": "Qwen3-14B is a dense 14.8B parameter causal language model from the Qwen3 series, designed for both complex reasoning and efficient dialogue. It supports seamless switching between a \"thinking\" mode for tasks like math, programming, and logical inference, and a \"non-thinking\" mode for general-purpose conversation. The model is fine-tuned for instruction-following, agent tool use, creative writing, and multilingual tasks across 100+ languages and dialects. It natively handles 32K token contexts and can extend to 131K tokens using YaRN-based scaling.",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-14b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "a02a8b3c-2cec-4785-953d-88c1cdf9a8f7",
        "name": "Chutes | qwen/qwen3-14b-04-28:free",
        "contextLength": 40960,
        "model": {
          "slug": "qwen/qwen3-14b",
          "hfSlug": "Qwen/Qwen3-14B",
          "updatedAt": "2025-05-12T00:36:13.09542+00:00",
          "createdAt": "2025-04-28T21:41:18.320017+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 14B",
          "shortName": "Qwen3 14B",
          "author": "qwen",
          "description": "Qwen3-14B is a dense 14.8B parameter causal language model from the Qwen3 series, designed for both complex reasoning and efficient dialogue. It supports seamless switching between a \"thinking\" mode for tasks like math, programming, and logical inference, and a \"non-thinking\" mode for general-purpose conversation. The model is fine-tuned for instruction-following, agent tool use, creative writing, and multilingual tasks across 100+ languages and dialects. It natively handles 32K token contexts and can extend to 131K tokens using YaRN-based scaling.",
          "modelVersionGroupId": null,
          "contextLength": 131702,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-14b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-14b:free",
        "modelVariantPermaslug": "qwen/qwen3-14b-04-28:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/Qwen3-14B",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 91,
        "newest": 26,
        "throughputHighToLow": 64,
        "latencyLowToHigh": 168,
        "pricingLowToHigh": 11,
        "pricingHighToLow": 212
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": 40960,
          "providerModelId": "Qwen/Qwen3-14B",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.07,
          "outputCost": 0.24,
          "throughput": 75.5195,
          "latency": 1074
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-14b-fp8",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.000000275",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.07,
          "outputCost": 0.28,
          "throughput": 57.391,
          "latency": 787
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 40960,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen3-14B",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.08,
          "outputCost": 0.24,
          "throughput": 93.2875,
          "latency": 271
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.5-sonnet-20240620",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.5 Sonnet (2024-06-20) (self-moderated)",
      "shortName": "Claude 3.5 Sonnet (2024-06-20) (self-moderated)",
      "author": "anthropic",
      "description": "Claude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Autonomously writes, edits, and runs code with reasoning and troubleshooting\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\nFor the latest version (2024-10-23), check out [Claude 3.5 Sonnet](/anthropic/claude-3.5-sonnet).\n\n#multimodal",
      "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3.5-sonnet-20240620",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "20a76230-7394-42f9-bcac-76081ff24cd8",
        "name": "Anthropic | anthropic/claude-3.5-sonnet-20240620:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.5-sonnet-20240620",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-06-20T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.5 Sonnet (2024-06-20)",
          "shortName": "Claude 3.5 Sonnet (2024-06-20)",
          "author": "anthropic",
          "description": "Claude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Autonomously writes, edits, and runs code with reasoning and troubleshooting\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\nFor the latest version (2024-10-23), check out [Claude 3.5 Sonnet](/anthropic/claude-3.5-sonnet).\n\n#multimodal",
          "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3.5-sonnet-20240620",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.5-sonnet-20240620:beta",
        "modelVariantPermaslug": "anthropic/claude-3.5-sonnet-20240620:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-5-sonnet-20240620",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0.0048",
          "request": "0",
          "inputCacheRead": "0.0000003",
          "inputCacheWrite": "0.00000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 147,
        "newest": 244,
        "throughputHighToLow": 134,
        "latencyLowToHigh": 280,
        "pricingLowToHigh": 274,
        "pricingHighToLow": 46
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet-20240620",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 60.051,
          "latency": 2892.5
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet@20240620",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 62.2995,
          "latency": 992
        }
      ]
    },
    {
      "slug": "mistralai/pixtral-12b",
      "hfSlug": "mistralai/Pixtral-12B-2409",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Pixtral 12B",
      "shortName": "Pixtral 12B",
      "author": "mistralai",
      "description": "The first multi-modal, text+image-to-text model from Mistral AI. Its weights were launched via torrent: https://x.com/mistralai/status/1833758285167722836.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/pixtral-12b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b550f7af-571a-45fd-b442-b3327afaf38c",
        "name": "Hyperbolic | mistralai/pixtral-12b",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/pixtral-12b",
          "hfSlug": "mistralai/Pixtral-12B-2409",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-10T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Pixtral 12B",
          "shortName": "Pixtral 12B",
          "author": "mistralai",
          "description": "The first multi-modal, text+image-to-text model from Mistral AI. Its weights were launched via torrent: https://x.com/mistralai/status/1833758285167722836.",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/pixtral-12b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/pixtral-12b",
        "modelVariantPermaslug": "mistralai/pixtral-12b",
        "providerName": "Hyperbolic",
        "providerInfo": {
          "name": "Hyperbolic",
          "displayName": "Hyperbolic",
          "slug": "hyperbolic",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://hyperbolic.xyz/privacy",
            "termsOfServiceUrl": "https://hyperbolic.xyz/terms",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Hyperbolic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256"
          }
        },
        "providerDisplayName": "Hyperbolic",
        "providerModelId": "mistralai/Pixtral-12B-2409",
        "providerGroup": "Hyperbolic",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "logprobs",
          "top_logprobs",
          "seed",
          "logit_bias",
          "top_k",
          "min_p",
          "repetition_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://hyperbolic.xyz/privacy",
          "termsOfServiceUrl": "https://hyperbolic.xyz/terms",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000001",
          "image": "0.0001445",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 148,
        "newest": 211,
        "throughputHighToLow": 225,
        "latencyLowToHigh": 227,
        "pricingLowToHigh": 116,
        "pricingHighToLow": 204
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/Pixtral-12B-2409",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0.0001445",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 55.63,
          "latency": 1584
        },
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "pixtral-12b-2409",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.00000015",
            "image": "0.0002168",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.15,
          "outputCost": 0.15,
          "throughput": 83.088,
          "latency": 392
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.5-sonnet-20240620",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.5 Sonnet (2024-06-20)",
      "shortName": "Claude 3.5 Sonnet (2024-06-20)",
      "author": "anthropic",
      "description": "Claude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Autonomously writes, edits, and runs code with reasoning and troubleshooting\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\nFor the latest version (2024-10-23), check out [Claude 3.5 Sonnet](/anthropic/claude-3.5-sonnet).\n\n#multimodal",
      "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3.5-sonnet-20240620",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "20a76230-7394-42f9-bcac-76081ff24cd8",
        "name": "Anthropic | anthropic/claude-3.5-sonnet-20240620",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.5-sonnet-20240620",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-06-20T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.5 Sonnet (2024-06-20)",
          "shortName": "Claude 3.5 Sonnet (2024-06-20)",
          "author": "anthropic",
          "description": "Claude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet speeds, at the same Sonnet prices. Sonnet is particularly good at:\n\n- Coding: Autonomously writes, edits, and runs code with reasoning and troubleshooting\n- Data science: Augments human data science expertise; navigates unstructured data while using multiple tools for insights\n- Visual processing: excelling at interpreting charts, graphs, and images, accurately transcribing text to derive insights beyond just the text alone\n- Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e. complex, multi-step problem solving tasks that require engaging with other systems)\n\nFor the latest version (2024-10-23), check out [Claude 3.5 Sonnet](/anthropic/claude-3.5-sonnet).\n\n#multimodal",
          "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3.5-sonnet-20240620",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.5-sonnet-20240620",
        "modelVariantPermaslug": "anthropic/claude-3.5-sonnet-20240620",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-5-sonnet-20240620",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0.0048",
          "request": "0",
          "inputCacheRead": "0.0000003",
          "inputCacheWrite": "0.00000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 147,
        "newest": 244,
        "throughputHighToLow": 134,
        "latencyLowToHigh": 280,
        "pricingLowToHigh": 274,
        "pricingHighToLow": 46
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet-20240620",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 60.051,
          "latency": 2892.5
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-sonnet@20240620",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 62.2995,
          "latency": 992
        }
      ]
    },
    {
      "slug": "mistralai/mistral-large",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-02-26T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral Large",
      "shortName": "Mistral Large",
      "author": "mistralai",
      "description": "This is Mistral AI's flagship model, Mistral Large 2 (version `mistral-large-2407`). It's a proprietary weights-available model and excels at reasoning, code, JSON, chat, and more. Read the launch announcement [here](https://mistral.ai/news/mistral-large-2407/).\n\nIt supports dozens of languages including French, German, Spanish, Italian, Portuguese, Arabic, Hindi, Russian, Chinese, Japanese, and Korean, along with 80+ coding languages including Python, Java, C, C++, JavaScript, and Bash. Its long context window allows precise information recall from large documents.",
      "modelVersionGroupId": "83129748-0564-4485-982a-d7a37a1ef3ec",
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-large",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f1a57233-f872-4fa0-ad37-66c9a6b00469",
        "name": "Mistral | mistralai/mistral-large",
        "contextLength": 128000,
        "model": {
          "slug": "mistralai/mistral-large",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-02-26T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral Large",
          "shortName": "Mistral Large",
          "author": "mistralai",
          "description": "This is Mistral AI's flagship model, Mistral Large 2 (version `mistral-large-2407`). It's a proprietary weights-available model and excels at reasoning, code, JSON, chat, and more. Read the launch announcement [here](https://mistral.ai/news/mistral-large-2407/).\n\nIt supports dozens of languages including French, German, Spanish, Italian, Portuguese, Arabic, Hindi, Russian, Chinese, Japanese, and Korean, along with 80+ coding languages including Python, Java, C, C++, JavaScript, and Bash. Its long context window allows precise information recall from large documents.",
          "modelVersionGroupId": "83129748-0564-4485-982a-d7a37a1ef3ec",
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-large",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-large",
        "modelVariantPermaslug": "mistralai/mistral-large",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "mistral-large-2407",
        "providerGroup": "Mistral",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 150,
        "newest": 284,
        "throughputHighToLow": 199,
        "latencyLowToHigh": 68,
        "pricingLowToHigh": 246,
        "pricingHighToLow": 75
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-large-2407",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 2,
          "outputCost": 6,
          "throughput": 43.43,
          "latency": 478
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-large",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "response_format",
            "stop",
            "seed"
          ],
          "inputCost": 3,
          "outputCost": 9,
          "throughput": 39.9965,
          "latency": 790.5
        }
      ]
    },
    {
      "slug": "nvidia/llama-3.3-nemotron-super-49b-v1",
      "hfSlug": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",
      "updatedAt": "2025-04-08T14:53:49.407401+00:00",
      "createdAt": "2025-04-08T13:38:14.544231+00:00",
      "hfUpdatedAt": null,
      "name": "NVIDIA: Llama 3.3 Nemotron Super 49B v1 (free)",
      "shortName": "Llama 3.3 Nemotron Super 49B v1 (free)",
      "author": "nvidia",
      "description": "Llama-3.3-Nemotron-Super-49B-v1 is a large language model (LLM) optimized for advanced reasoning, conversational interactions, retrieval-augmented generation (RAG), and tool-calling tasks. Derived from Meta's Llama-3.3-70B-Instruct, it employs a Neural Architecture Search (NAS) approach, significantly enhancing efficiency and reducing memory requirements. This allows the model to support a context length of up to 128K tokens and fit efficiently on single high-performance GPUs, such as NVIDIA H200.\n\nNote: you must include `detailed thinking on` in the system prompt to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations) for more.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nvidia/llama-3.3-nemotron-super-49b-v1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "d4a7aa46-e0f4-47ce-945a-47f2ed715cbb",
        "name": "Chutes | nvidia/llama-3.3-nemotron-super-49b-v1:free",
        "contextLength": 131072,
        "model": {
          "slug": "nvidia/llama-3.3-nemotron-super-49b-v1",
          "hfSlug": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",
          "updatedAt": "2025-04-08T14:53:49.407401+00:00",
          "createdAt": "2025-04-08T13:38:14.544231+00:00",
          "hfUpdatedAt": null,
          "name": "NVIDIA: Llama 3.3 Nemotron Super 49B v1",
          "shortName": "Llama 3.3 Nemotron Super 49B v1",
          "author": "nvidia",
          "description": "Llama-3.3-Nemotron-Super-49B-v1 is a large language model (LLM) optimized for advanced reasoning, conversational interactions, retrieval-augmented generation (RAG), and tool-calling tasks. Derived from Meta's Llama-3.3-70B-Instruct, it employs a Neural Architecture Search (NAS) approach, significantly enhancing efficiency and reducing memory requirements. This allows the model to support a context length of up to 128K tokens and fit efficiently on single high-performance GPUs, such as NVIDIA H200.\n\nNote: you must include `detailed thinking on` in the system prompt to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations) for more.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nvidia/llama-3.3-nemotron-super-49b-v1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nvidia/llama-3.3-nemotron-super-49b-v1:free",
        "modelVariantPermaslug": "nvidia/llama-3.3-nemotron-super-49b-v1:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 151,
        "newest": 58,
        "throughputHighToLow": 172,
        "latencyLowToHigh": 20,
        "pricingLowToHigh": 24,
        "pricingHighToLow": 182
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nvidia.com/\\u0026size=256",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.13,
          "outputCost": 0.4,
          "throughput": 47.232,
          "latency": 317
        }
      ]
    },
    {
      "slug": "qwen/qwen-max",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-01T09:31:29.206961+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen-Max ",
      "shortName": "Qwen-Max ",
      "author": "qwen",
      "description": "Qwen-Max, based on Qwen2.5, provides the best inference performance among [Qwen models](/qwen), especially for complex multi-step tasks. It's a large-scale MoE model that has been pretrained on over 20 trillion tokens and further post-trained with curated Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) methodologies. The parameter count is unknown.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-max-2025-01-25",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8cf90481-400f-473d-b188-1bed01001a01",
        "name": "Alibaba | qwen/qwen-max-2025-01-25",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen-max",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-01T09:31:29.206961+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen-Max ",
          "shortName": "Qwen-Max ",
          "author": "qwen",
          "description": "Qwen-Max, based on Qwen2.5, provides the best inference performance among [Qwen models](/qwen), especially for complex multi-step tasks. It's a large-scale MoE model that has been pretrained on over 20 trillion tokens and further post-trained with curated Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) methodologies. The parameter count is unknown.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-max-2025-01-25",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-max",
        "modelVariantPermaslug": "qwen/qwen-max-2025-01-25",
        "providerName": "Alibaba",
        "providerInfo": {
          "name": "Alibaba",
          "displayName": "Alibaba",
          "slug": "alibaba",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
            "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "CN",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Alibaba",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256"
          }
        },
        "providerDisplayName": "Alibaba",
        "providerModelId": "qwen-max",
        "providerGroup": "Alibaba",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": 30720,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "seed",
          "response_format",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
          "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000016",
          "completion": "0.0000064",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 152,
        "newest": 128,
        "throughputHighToLow": 212,
        "latencyLowToHigh": 214,
        "pricingLowToHigh": 241,
        "pricingHighToLow": 77
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Alibaba",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256",
          "slug": "alibaba",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 8192,
          "providerModelId": "qwen-max",
          "pricing": {
            "prompt": "0.0000016",
            "completion": "0.0000064",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "seed",
            "response_format",
            "presence_penalty"
          ],
          "inputCost": 1.6,
          "outputCost": 6.4,
          "throughput": 40.3095,
          "latency": 1418.5
        }
      ]
    },
    {
      "slug": "microsoft/phi-4-reasoning-plus",
      "hfSlug": "microsoft/Phi-4-reasoning-plus",
      "updatedAt": "2025-05-02T05:32:14.23708+00:00",
      "createdAt": "2025-05-01T20:22:41.235613+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: Phi 4 Reasoning Plus",
      "shortName": "Phi 4 Reasoning Plus",
      "author": "microsoft",
      "description": "Phi-4-reasoning-plus is an enhanced 14B parameter model from Microsoft, fine-tuned from Phi-4 with additional reinforcement learning to boost accuracy on math, science, and code reasoning tasks. It uses the same dense decoder-only transformer architecture as Phi-4, but generates longer, more comprehensive outputs structured into a step-by-step reasoning trace and final answer.\n\nWhile it offers improved benchmark scores over Phi-4-reasoning across tasks like AIME, OmniMath, and HumanEvalPlus, its responses are typically ~50% longer, resulting in higher latency. Designed for English-only applications, it is well-suited for structured reasoning workflows where output quality takes priority over response speed.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/phi-4-reasoning-plus-04-30",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "88e7bba7-808f-4eb7-8964-040e99d53e72",
        "name": "DeepInfra | microsoft/phi-4-reasoning-plus-04-30",
        "contextLength": 32768,
        "model": {
          "slug": "microsoft/phi-4-reasoning-plus",
          "hfSlug": "microsoft/Phi-4-reasoning-plus",
          "updatedAt": "2025-05-02T05:32:14.23708+00:00",
          "createdAt": "2025-05-01T20:22:41.235613+00:00",
          "hfUpdatedAt": null,
          "name": "Microsoft: Phi 4 Reasoning Plus",
          "shortName": "Phi 4 Reasoning Plus",
          "author": "microsoft",
          "description": "Phi-4-reasoning-plus is an enhanced 14B parameter model from Microsoft, fine-tuned from Phi-4 with additional reinforcement learning to boost accuracy on math, science, and code reasoning tasks. It uses the same dense decoder-only transformer architecture as Phi-4, but generates longer, more comprehensive outputs structured into a step-by-step reasoning trace and final answer.\n\nWhile it offers improved benchmark scores over Phi-4-reasoning across tasks like AIME, OmniMath, and HumanEvalPlus, its responses are typically ~50% longer, resulting in higher latency. Designed for English-only applications, it is well-suited for structured reasoning workflows where output quality takes priority over response speed.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/phi-4-reasoning-plus-04-30",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "microsoft/phi-4-reasoning-plus",
        "modelVariantPermaslug": "microsoft/phi-4-reasoning-plus-04-30",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "microsoft/phi-4-reasoning-plus",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000007",
          "completion": "0.00000035",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 153,
        "newest": 10,
        "throughputHighToLow": 26,
        "latencyLowToHigh": 120,
        "pricingLowToHigh": 1,
        "pricingHighToLow": 206
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "microsoft/phi-4-reasoning-plus",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000035",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.07,
          "outputCost": 0.35,
          "throughput": 44.1635,
          "latency": 714
        }
      ]
    },
    {
      "slug": "qwen/qwen3-4b",
      "hfSlug": "Qwen/Qwen3-4B",
      "updatedAt": "2025-05-12T00:35:27.640755+00:00",
      "createdAt": "2025-04-30T16:38:24.032465+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 4B (free)",
      "shortName": "Qwen3 4B (free)",
      "author": "qwen",
      "description": "Qwen3-4B is a 4 billion parameter dense language model from the Qwen3 series, designed to support both general-purpose and reasoning-intensive tasks. It introduces a dual-mode architecture—thinking and non-thinking—allowing dynamic switching between high-precision logical reasoning and efficient dialogue generation. This makes it well-suited for multi-turn chat, instruction following, and complex agent workflows.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-4b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "b1d65b01-eded-4bfd-92ac-0deaac309a5e",
        "name": "Novita | qwen/qwen3-4b-04-28:free",
        "contextLength": 128000,
        "model": {
          "slug": "qwen/qwen3-4b",
          "hfSlug": "Qwen/Qwen3-4B",
          "updatedAt": "2025-05-12T00:35:27.640755+00:00",
          "createdAt": "2025-04-30T16:38:24.032465+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 4B",
          "shortName": "Qwen3 4B",
          "author": "qwen",
          "description": "Qwen3-4B is a 4 billion parameter dense language model from the Qwen3 series, designed to support both general-purpose and reasoning-intensive tasks. It introduces a dual-mode architecture—thinking and non-thinking—allowing dynamic switching between high-precision logical reasoning and efficient dialogue generation. This makes it well-suited for multi-turn chat, instruction following, and complex agent workflows.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-4b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-4b:free",
        "modelVariantPermaslug": "qwen/qwen3-4b-04-28:free",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "qwen/qwen3-4b-fp8",
        "providerGroup": "Novita",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 154,
        "newest": 16,
        "throughputHighToLow": 34,
        "latencyLowToHigh": 103,
        "pricingLowToHigh": 5,
        "pricingHighToLow": 253
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "agentica-org/deepcoder-14b-preview",
      "hfSlug": "agentica-org/DeepCoder-14B-Preview",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-04-13T14:43:15.533943+00:00",
      "hfUpdatedAt": null,
      "name": "Agentica: Deepcoder 14B Preview (free)",
      "shortName": "Deepcoder 14B Preview (free)",
      "author": "agentica-org",
      "description": "DeepCoder-14B-Preview is a 14B parameter code generation model fine-tuned from DeepSeek-R1-Distill-Qwen-14B using reinforcement learning with GRPO+ and iterative context lengthening. It is optimized for long-context program synthesis and achieves strong performance across coding benchmarks, including 60.6% on LiveCodeBench v5, competitive with models like o3-Mini",
      "modelVersionGroupId": null,
      "contextLength": 96000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "agentica-org/deepcoder-14b-preview",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "491302ef-8014-45e5-9c32-5c9a02ebc055",
        "name": "Chutes | agentica-org/deepcoder-14b-preview:free",
        "contextLength": 96000,
        "model": {
          "slug": "agentica-org/deepcoder-14b-preview",
          "hfSlug": "agentica-org/DeepCoder-14B-Preview",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-04-13T14:43:15.533943+00:00",
          "hfUpdatedAt": null,
          "name": "Agentica: Deepcoder 14B Preview",
          "shortName": "Deepcoder 14B Preview",
          "author": "agentica-org",
          "description": "DeepCoder-14B-Preview is a 14B parameter code generation model fine-tuned from DeepSeek-R1-Distill-Qwen-14B using reinforcement learning with GRPO+ and iterative context lengthening. It is optimized for long-context program synthesis and achieves strong performance across coding benchmarks, including 60.6% on LiveCodeBench v5, competitive with models like o3-Mini",
          "modelVersionGroupId": null,
          "contextLength": 96000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "agentica-org/deepcoder-14b-preview",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "agentica-org/deepcoder-14b-preview:free",
        "modelVariantPermaslug": "agentica-org/deepcoder-14b-preview:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "agentica-org/DeepCoder-14B-Preview",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 155,
        "newest": 54,
        "throughputHighToLow": 100,
        "latencyLowToHigh": 234,
        "pricingLowToHigh": 22,
        "pricingHighToLow": 270
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "perplexity/sonar",
      "hfSlug": "",
      "updatedAt": "2025-05-05T14:39:01.632671+00:00",
      "createdAt": "2025-01-27T21:36:48.666939+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Sonar",
      "shortName": "Sonar",
      "author": "perplexity",
      "description": "Sonar is lightweight, affordable, fast, and simple to use — now featuring citations and the ability to customize sources. It is designed for companies seeking to integrate lightweight question-and-answer features optimized for speed.",
      "modelVersionGroupId": null,
      "contextLength": 127072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "perplexity/sonar",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "5f831e7a-c555-4d3a-b228-88286347558a",
        "name": "Perplexity | perplexity/sonar",
        "contextLength": 127072,
        "model": {
          "slug": "perplexity/sonar",
          "hfSlug": "",
          "updatedAt": "2025-05-05T14:39:01.632671+00:00",
          "createdAt": "2025-01-27T21:36:48.666939+00:00",
          "hfUpdatedAt": null,
          "name": "Perplexity: Sonar",
          "shortName": "Sonar",
          "author": "perplexity",
          "description": "Sonar is lightweight, affordable, fast, and simple to use — now featuring citations and the ability to customize sources. It is designed for companies seeking to integrate lightweight question-and-answer features optimized for speed.",
          "modelVersionGroupId": null,
          "contextLength": 127072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "perplexity/sonar",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "perplexity/sonar",
        "modelVariantPermaslug": "perplexity/sonar",
        "providerName": "Perplexity",
        "providerInfo": {
          "name": "Perplexity",
          "displayName": "Perplexity",
          "slug": "perplexity",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
            "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Perplexity",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.perplexity.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Perplexity.svg"
          }
        },
        "providerDisplayName": "Perplexity",
        "providerModelId": "sonar",
        "providerGroup": "Perplexity",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "web_search_options",
          "top_k",
          "frequency_penalty",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
          "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000001",
          "completion": "0.000001",
          "image": "0",
          "request": "0.005",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.012"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.008"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.005"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 156,
        "newest": 138,
        "throughputHighToLow": 62,
        "latencyLowToHigh": 252,
        "pricingLowToHigh": 287,
        "pricingHighToLow": 30
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": [
        {
          "name": "Perplexity",
          "icon": "https://openrouter.ai/images/icons/Perplexity.svg",
          "slug": "perplexity",
          "quantization": "unknown",
          "context": 127072,
          "maxCompletionTokens": null,
          "providerModelId": "sonar",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000001",
            "image": "0",
            "request": "0.005",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "web_search_options",
            "top_k",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 1,
          "outputCost": 1,
          "throughput": 108.2725,
          "latency": 1943
        }
      ]
    },
    {
      "slug": "microsoft/phi-4-reasoning-plus",
      "hfSlug": "microsoft/Phi-4-reasoning-plus",
      "updatedAt": "2025-05-02T05:32:14.23708+00:00",
      "createdAt": "2025-05-01T20:22:41.235613+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: Phi 4 Reasoning Plus (free)",
      "shortName": "Phi 4 Reasoning Plus (free)",
      "author": "microsoft",
      "description": "Phi-4-reasoning-plus is an enhanced 14B parameter model from Microsoft, fine-tuned from Phi-4 with additional reinforcement learning to boost accuracy on math, science, and code reasoning tasks. It uses the same dense decoder-only transformer architecture as Phi-4, but generates longer, more comprehensive outputs structured into a step-by-step reasoning trace and final answer.\n\nWhile it offers improved benchmark scores over Phi-4-reasoning across tasks like AIME, OmniMath, and HumanEvalPlus, its responses are typically ~50% longer, resulting in higher latency. Designed for English-only applications, it is well-suited for structured reasoning workflows where output quality takes priority over response speed.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/phi-4-reasoning-plus-04-30",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "bbc205d3-b5e1-457f-8b74-771855206a98",
        "name": "Chutes | microsoft/phi-4-reasoning-plus-04-30:free",
        "contextLength": 32768,
        "model": {
          "slug": "microsoft/phi-4-reasoning-plus",
          "hfSlug": "microsoft/Phi-4-reasoning-plus",
          "updatedAt": "2025-05-02T05:32:14.23708+00:00",
          "createdAt": "2025-05-01T20:22:41.235613+00:00",
          "hfUpdatedAt": null,
          "name": "Microsoft: Phi 4 Reasoning Plus",
          "shortName": "Phi 4 Reasoning Plus",
          "author": "microsoft",
          "description": "Phi-4-reasoning-plus is an enhanced 14B parameter model from Microsoft, fine-tuned from Phi-4 with additional reinforcement learning to boost accuracy on math, science, and code reasoning tasks. It uses the same dense decoder-only transformer architecture as Phi-4, but generates longer, more comprehensive outputs structured into a step-by-step reasoning trace and final answer.\n\nWhile it offers improved benchmark scores over Phi-4-reasoning across tasks like AIME, OmniMath, and HumanEvalPlus, its responses are typically ~50% longer, resulting in higher latency. Designed for English-only applications, it is well-suited for structured reasoning workflows where output quality takes priority over response speed.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/phi-4-reasoning-plus-04-30",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "microsoft/phi-4-reasoning-plus:free",
        "modelVariantPermaslug": "microsoft/phi-4-reasoning-plus-04-30:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "microsoft/Phi-4-reasoning-plus",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 153,
        "newest": 10,
        "throughputHighToLow": 26,
        "latencyLowToHigh": 120,
        "pricingLowToHigh": 1,
        "pricingHighToLow": 206
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "microsoft/phi-4-reasoning-plus",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000035",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.07,
          "outputCost": 0.35,
          "throughput": 44.1635,
          "latency": 714
        }
      ]
    },
    {
      "slug": "openai/gpt-4-turbo",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4 Turbo",
      "shortName": "GPT-4 Turbo",
      "author": "openai",
      "description": "The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.\n\nTraining data: up to December 2023.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4-turbo",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "da16824f-3ba0-43a1-86f8-a6131837f457",
        "name": "OpenAI | openai/gpt-4-turbo",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4-turbo",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-04-09T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4 Turbo",
          "shortName": "GPT-4 Turbo",
          "author": "openai",
          "description": "The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.\n\nTraining data: up to December 2023.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4-turbo",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4-turbo",
        "modelVariantPermaslug": "openai/gpt-4-turbo",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4-turbo",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00001",
          "completion": "0.00003",
          "image": "0.01445",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 158,
        "newest": 271,
        "throughputHighToLow": 229,
        "latencyLowToHigh": 136,
        "pricingLowToHigh": 302,
        "pricingHighToLow": 14
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4-turbo",
          "pricing": {
            "prompt": "0.00001",
            "completion": "0.00003",
            "image": "0.01445",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 10,
          "outputCost": 30,
          "throughput": 32.239,
          "latency": 846.5
        }
      ]
    },
    {
      "slug": "openai/gpt-4.5-preview",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-27T20:23:30.841555+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4.5 (Preview)",
      "shortName": "GPT-4.5 (Preview)",
      "author": "openai",
      "description": "GPT-4.5 (Preview) is a research preview of OpenAI’s latest language model, designed to advance capabilities in reasoning, creativity, and multi-turn conversation. It builds on previous iterations with improvements in world knowledge, contextual coherence, and the ability to follow user intent more effectively.\n\nThe model demonstrates enhanced performance in tasks that require open-ended thinking, problem-solving, and communication. Early testing suggests it is better at generating nuanced responses, maintaining long-context coherence, and reducing hallucinations compared to earlier versions.\n\nThis research preview is intended to help evaluate GPT-4.5’s strengths and limitations in real-world use cases as OpenAI continues to refine and develop future models. Read more at the [blog post here.](https://openai.com/index/introducing-gpt-4-5/)",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4.5-preview-2025-02-27",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "dc592ff9-2fc9-4a5e-b910-27a57bb7bfdd",
        "name": "OpenAI | openai/gpt-4.5-preview-2025-02-27",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4.5-preview",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-27T20:23:30.841555+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4.5 (Preview)",
          "shortName": "GPT-4.5 (Preview)",
          "author": "openai",
          "description": "GPT-4.5 (Preview) is a research preview of OpenAI’s latest language model, designed to advance capabilities in reasoning, creativity, and multi-turn conversation. It builds on previous iterations with improvements in world knowledge, contextual coherence, and the ability to follow user intent more effectively.\n\nThe model demonstrates enhanced performance in tasks that require open-ended thinking, problem-solving, and communication. Early testing suggests it is better at generating nuanced responses, maintaining long-context coherence, and reducing hallucinations compared to earlier versions.\n\nThis research preview is intended to help evaluate GPT-4.5’s strengths and limitations in real-world use cases as OpenAI continues to refine and develop future models. Read more at the [blog post here.](https://openai.com/index/introducing-gpt-4-5/)",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4.5-preview-2025-02-27",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4.5-preview",
        "modelVariantPermaslug": "openai/gpt-4.5-preview-2025-02-27",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4.5-preview-2025-02-27",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000075",
          "completion": "0.00015",
          "image": "0.108375",
          "request": "0",
          "inputCacheRead": "0.0000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 159,
        "newest": 106,
        "throughputHighToLow": 256,
        "latencyLowToHigh": 190,
        "pricingLowToHigh": 317,
        "pricingHighToLow": 1
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4.5-preview-2025-02-27",
          "pricing": {
            "prompt": "0.000075",
            "completion": "0.00015",
            "image": "0.108375",
            "request": "0",
            "inputCacheRead": "0.0000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 75,
          "outputCost": 150,
          "throughput": 27.468,
          "latency": 1213.5
        }
      ]
    },
    {
      "slug": "qwen/qwen-plus",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-01T11:37:20.886831+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen-Plus",
      "shortName": "Qwen-Plus",
      "author": "qwen",
      "description": "Qwen-Plus, based on the Qwen2.5 foundation model, is a 131K context model with a balanced performance, speed, and cost combination.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "qwen/qwen-plus-2025-01-25",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "47e88ae3-94ed-4d6a-96bb-a150dd354853",
        "name": "Alibaba | qwen/qwen-plus-2025-01-25",
        "contextLength": 131072,
        "model": {
          "slug": "qwen/qwen-plus",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-01T11:37:20.886831+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen-Plus",
          "shortName": "Qwen-Plus",
          "author": "qwen",
          "description": "Qwen-Plus, based on the Qwen2.5 foundation model, is a 131K context model with a balanced performance, speed, and cost combination.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "qwen/qwen-plus-2025-01-25",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-plus",
        "modelVariantPermaslug": "qwen/qwen-plus-2025-01-25",
        "providerName": "Alibaba",
        "providerInfo": {
          "name": "Alibaba",
          "displayName": "Alibaba",
          "slug": "alibaba",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
            "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "CN",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Alibaba",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256"
          }
        },
        "providerDisplayName": "Alibaba",
        "providerModelId": "qwen-plus",
        "providerGroup": "Alibaba",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": 129024,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "seed",
          "response_format",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
          "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000004",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 160,
        "newest": 127,
        "throughputHighToLow": 231,
        "latencyLowToHigh": 189,
        "pricingLowToHigh": 175,
        "pricingHighToLow": 142
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Alibaba",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256",
          "slug": "alibaba",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 8192,
          "providerModelId": "qwen-plus",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "seed",
            "response_format",
            "presence_penalty"
          ],
          "inputCost": 0.4,
          "outputCost": 1.2,
          "throughput": 33.044,
          "latency": 985
        }
      ]
    },
    {
      "slug": "opengvlab/internvl3-14b",
      "hfSlug": "OpenGVLab/InternVL3-14B",
      "updatedAt": "2025-04-30T14:14:32.387955+00:00",
      "createdAt": "2025-04-30T13:55:55.014183+00:00",
      "hfUpdatedAt": null,
      "name": "OpenGVLab: InternVL3 14B (free)",
      "shortName": "InternVL3 14B (free)",
      "author": "opengvlab",
      "description": "The 14b version of the InternVL3 series. An advanced multimodal large language model (MLLM) series that demonstrates superior overall performance. Compared to InternVL 2.5, InternVL3 exhibits superior multimodal perception and reasoning capabilities, while further extending its multimodal capabilities to encompass tool usage, GUI agents, industrial image analysis, 3D vision perception, and more.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "image",
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "opengvlab/internvl3-14b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3be27401-83ab-4e46-9418-462abbc1c8af",
        "name": "Nineteen | opengvlab/internvl3-14b:free",
        "contextLength": 32000,
        "model": {
          "slug": "opengvlab/internvl3-14b",
          "hfSlug": "OpenGVLab/InternVL3-14B",
          "updatedAt": "2025-04-30T14:14:32.387955+00:00",
          "createdAt": "2025-04-30T13:55:55.014183+00:00",
          "hfUpdatedAt": null,
          "name": "OpenGVLab: InternVL3 14B",
          "shortName": "InternVL3 14B",
          "author": "opengvlab",
          "description": "The 14b version of the InternVL3 series. An advanced multimodal large language model (MLLM) series that demonstrates superior overall performance. Compared to InternVL 2.5, InternVL3 exhibits superior multimodal perception and reasoning capabilities, while further extending its multimodal capabilities to encompass tool usage, GUI agents, industrial image analysis, 3D vision perception, and more.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "image",
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "opengvlab/internvl3-14b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "opengvlab/internvl3-14b:free",
        "modelVariantPermaslug": "opengvlab/internvl3-14b:free",
        "providerName": "Nineteen",
        "providerInfo": {
          "name": "Nineteen",
          "displayName": "Nineteen",
          "slug": "nineteen",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://nineteen.ai/tos",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Nineteen",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nineteen.ai/&size=256"
          }
        },
        "providerDisplayName": "Nineteen",
        "providerModelId": "OpenGVLab/InternVL3-14B",
        "providerGroup": "Nineteen",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://nineteen.ai/tos",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 161,
        "newest": 17,
        "throughputHighToLow": 25,
        "latencyLowToHigh": 176,
        "pricingLowToHigh": 6,
        "pricingHighToLow": 254
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "mistralai/mixtral-8x22b-instruct",
      "hfSlug": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-17T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mixtral 8x22B Instruct",
      "shortName": "Mixtral 8x22B Instruct",
      "author": "mistralai",
      "description": "Mistral's official instruct fine-tuned version of [Mixtral 8x22B](/models/mistralai/mixtral-8x22b). It uses 39B active parameters out of 141B, offering unparalleled cost efficiency for its size. Its strengths include:\n- strong math, coding, and reasoning\n- large context length (64k)\n- fluency in English, French, Italian, German, and Spanish\n\nSee benchmarks on the launch announcement [here](https://mistral.ai/news/mixtral-8x22b/).\n#moe",
      "modelVersionGroupId": null,
      "contextLength": 65536,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mixtral-8x22b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c26356d7-ec87-4537-b049-61870b15cf3c",
        "name": "Nebius | mistralai/mixtral-8x22b-instruct",
        "contextLength": 65536,
        "model": {
          "slug": "mistralai/mixtral-8x22b-instruct",
          "hfSlug": "mistralai/Mixtral-8x22B-Instruct-v0.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-04-17T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mixtral 8x22B Instruct",
          "shortName": "Mixtral 8x22B Instruct",
          "author": "mistralai",
          "description": "Mistral's official instruct fine-tuned version of [Mixtral 8x22B](/models/mistralai/mixtral-8x22b). It uses 39B active parameters out of 141B, offering unparalleled cost efficiency for its size. Its strengths include:\n- strong math, coding, and reasoning\n- large context length (64k)\n- fluency in English, French, Italian, German, and Spanish\n\nSee benchmarks on the launch announcement [here](https://mistral.ai/news/mixtral-8x22b/).\n#moe",
          "modelVersionGroupId": null,
          "contextLength": 65536,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mixtral-8x22b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mixtral-8x22b-instruct",
        "modelVariantPermaslug": "mistralai/mixtral-8x22b-instruct",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "mistralai/Mixtral-8x22B-Instruct-v0.1",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000004",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 162,
        "newest": 268,
        "throughputHighToLow": 188,
        "latencyLowToHigh": 51,
        "pricingLowToHigh": 176,
        "pricingHighToLow": 143
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 65536,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/Mixtral-8x22B-Instruct-v0.1",
          "pricing": {
            "prompt": "0.0000004",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.4,
          "outputCost": 1.2,
          "throughput": 46.841,
          "latency": 409
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "unknown",
          "context": 65536,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/mixtral-8x22b-instruct",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 81.168,
          "latency": 432
        },
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 65536,
          "maxCompletionTokens": null,
          "providerModelId": "open-mixtral-8x22b",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 2,
          "outputCost": 6,
          "throughput": 63.068,
          "latency": 360
        }
      ]
    },
    {
      "slug": "qwen/qwen-2-72b-instruct",
      "hfSlug": "Qwen/Qwen2-72B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-07T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen 2 72B Instruct",
      "shortName": "Qwen 2 72B Instruct",
      "author": "qwen",
      "description": "Qwen2 72B is a transformer-based model that excels in language understanding, multilingual capabilities, coding, mathematics, and reasoning.\n\nIt features SwiGLU activation, attention QKV bias, and group query attention. It is pretrained on extensive data with supervised finetuning and direct preference optimization.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2/) and [GitHub repo](https://github.com/QwenLM/Qwen2).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2-72b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "89dce4f1-1836-4539-88f3-ee86d594d7a5",
        "name": "Together | qwen/qwen-2-72b-instruct",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwen-2-72b-instruct",
          "hfSlug": "Qwen/Qwen2-72B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-06-07T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen 2 72B Instruct",
          "shortName": "Qwen 2 72B Instruct",
          "author": "qwen",
          "description": "Qwen2 72B is a transformer-based model that excels in language understanding, multilingual capabilities, coding, mathematics, and reasoning.\n\nIt features SwiGLU activation, attention QKV bias, and group query attention. It is pretrained on extensive data with supervised finetuning and direct preference optimization.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2/) and [GitHub repo](https://github.com/QwenLM/Qwen2).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-2-72b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-2-72b-instruct",
        "modelVariantPermaslug": "qwen/qwen-2-72b-instruct",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "Qwen/Qwen2-72B-Instruct",
        "providerGroup": "Together",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000009",
          "completion": "0.0000009",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 163,
        "newest": 248,
        "throughputHighToLow": 206,
        "latencyLowToHigh": 93,
        "pricingLowToHigh": 214,
        "pricingHighToLow": 105
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": 4096,
          "providerModelId": "Qwen/Qwen2-72B-Instruct",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 39.81,
          "latency": 629
        }
      ]
    },
    {
      "slug": "nvidia/llama-3.3-nemotron-super-49b-v1",
      "hfSlug": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",
      "updatedAt": "2025-04-08T14:53:49.407401+00:00",
      "createdAt": "2025-04-08T13:38:14.544231+00:00",
      "hfUpdatedAt": null,
      "name": "NVIDIA: Llama 3.3 Nemotron Super 49B v1",
      "shortName": "Llama 3.3 Nemotron Super 49B v1",
      "author": "nvidia",
      "description": "Llama-3.3-Nemotron-Super-49B-v1 is a large language model (LLM) optimized for advanced reasoning, conversational interactions, retrieval-augmented generation (RAG), and tool-calling tasks. Derived from Meta's Llama-3.3-70B-Instruct, it employs a Neural Architecture Search (NAS) approach, significantly enhancing efficiency and reducing memory requirements. This allows the model to support a context length of up to 128K tokens and fit efficiently on single high-performance GPUs, such as NVIDIA H200.\n\nNote: you must include `detailed thinking on` in the system prompt to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations) for more.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nvidia/llama-3.3-nemotron-super-49b-v1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "1b7717f4-53d6-4a42-96ea-a58872ef08a0",
        "name": "Nebius | nvidia/llama-3.3-nemotron-super-49b-v1",
        "contextLength": 131072,
        "model": {
          "slug": "nvidia/llama-3.3-nemotron-super-49b-v1",
          "hfSlug": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",
          "updatedAt": "2025-04-08T14:53:49.407401+00:00",
          "createdAt": "2025-04-08T13:38:14.544231+00:00",
          "hfUpdatedAt": null,
          "name": "NVIDIA: Llama 3.3 Nemotron Super 49B v1",
          "shortName": "Llama 3.3 Nemotron Super 49B v1",
          "author": "nvidia",
          "description": "Llama-3.3-Nemotron-Super-49B-v1 is a large language model (LLM) optimized for advanced reasoning, conversational interactions, retrieval-augmented generation (RAG), and tool-calling tasks. Derived from Meta's Llama-3.3-70B-Instruct, it employs a Neural Architecture Search (NAS) approach, significantly enhancing efficiency and reducing memory requirements. This allows the model to support a context length of up to 128K tokens and fit efficiently on single high-performance GPUs, such as NVIDIA H200.\n\nNote: you must include `detailed thinking on` in the system prompt to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations) for more.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nvidia/llama-3.3-nemotron-super-49b-v1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nvidia/llama-3.3-nemotron-super-49b-v1",
        "modelVariantPermaslug": "nvidia/llama-3.3-nemotron-super-49b-v1",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000013",
          "completion": "0.0000004",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 151,
        "newest": 58,
        "throughputHighToLow": 172,
        "latencyLowToHigh": 20,
        "pricingLowToHigh": 24,
        "pricingHighToLow": 182
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nvidia.com/\\u0026size=256",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "nvidia/Llama-3_3-Nemotron-Super-49B-v1",
          "pricing": {
            "prompt": "0.00000013",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.13,
          "outputCost": 0.4,
          "throughput": 47.232,
          "latency": 317
        }
      ]
    },
    {
      "slug": "microsoft/phi-4-multimodal-instruct",
      "hfSlug": "microsoft/Phi-4-multimodal-instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-08T01:11:24.652063+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: Phi 4 Multimodal Instruct",
      "shortName": "Phi 4 Multimodal Instruct",
      "author": "microsoft",
      "description": "Phi-4 Multimodal Instruct is a versatile 5.6B parameter foundation model that combines advanced reasoning and instruction-following capabilities across both text and visual inputs, providing accurate text outputs. The unified architecture enables efficient, low-latency inference, suitable for edge and mobile deployments. Phi-4 Multimodal Instruct supports text inputs in multiple languages including Arabic, Chinese, English, French, German, Japanese, Spanish, and more, with visual input optimized primarily for English. It delivers impressive performance on multimodal tasks involving mathematical, scientific, and document reasoning, providing developers and enterprises a powerful yet compact model for sophisticated interactive applications. For more information, see the [Phi-4 Multimodal blog post](https://azure.microsoft.com/en-us/blog/empowering-innovation-the-next-generation-of-the-phi-family/).\n",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/phi-4-multimodal-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "345f416d-3f33-4530-8033-614ac900a8fd",
        "name": "DeepInfra | microsoft/phi-4-multimodal-instruct",
        "contextLength": 131072,
        "model": {
          "slug": "microsoft/phi-4-multimodal-instruct",
          "hfSlug": "microsoft/Phi-4-multimodal-instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-08T01:11:24.652063+00:00",
          "hfUpdatedAt": null,
          "name": "Microsoft: Phi 4 Multimodal Instruct",
          "shortName": "Phi 4 Multimodal Instruct",
          "author": "microsoft",
          "description": "Phi-4 Multimodal Instruct is a versatile 5.6B parameter foundation model that combines advanced reasoning and instruction-following capabilities across both text and visual inputs, providing accurate text outputs. The unified architecture enables efficient, low-latency inference, suitable for edge and mobile deployments. Phi-4 Multimodal Instruct supports text inputs in multiple languages including Arabic, Chinese, English, French, German, Japanese, Spanish, and more, with visual input optimized primarily for English. It delivers impressive performance on multimodal tasks involving mathematical, scientific, and document reasoning, providing developers and enterprises a powerful yet compact model for sophisticated interactive applications. For more information, see the [Phi-4 Multimodal blog post](https://azure.microsoft.com/en-us/blog/empowering-innovation-the-next-generation-of-the-phi-family/).\n",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/phi-4-multimodal-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "microsoft/phi-4-multimodal-instruct",
        "modelVariantPermaslug": "microsoft/phi-4-multimodal-instruct",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "microsoft/Phi-4-multimodal-instruct",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": 1,
        "maxTokensPerImage": 3537,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000005",
          "completion": "0.0000001",
          "image": "0.00017685",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 165,
        "newest": 97,
        "throughputHighToLow": 259,
        "latencyLowToHigh": 265,
        "pricingLowToHigh": 98,
        "pricingHighToLow": 221
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "microsoft/Phi-4-multimodal-instruct",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.0000001",
            "image": "0.00017685",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.05,
          "outputCost": 0.1,
          "throughput": 23.491,
          "latency": 2608
        }
      ]
    },
    {
      "slug": "mistralai/mistral-7b-instruct",
      "hfSlug": "mistralai/Mistral-7B-Instruct-v0.3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-27T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral 7B Instruct (free)",
      "shortName": "Mistral 7B Instruct (free)",
      "author": "mistralai",
      "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*",
      "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "d09ade5a-2aaf-4a93-9881-3db42f1ba63a",
        "name": "DeepInfra | mistralai/mistral-7b-instruct:free",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mistral-7b-instruct",
          "hfSlug": "mistralai/Mistral-7B-Instruct-v0.3",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-27T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral 7B Instruct",
          "shortName": "Mistral 7B Instruct",
          "author": "mistralai",
          "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*",
          "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-7b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-7b-instruct:free",
        "modelVariantPermaslug": "mistralai/mistral-7b-instruct:free",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "mistralai/Mistral-7B-Instruct-v0.3",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 129,
        "newest": 249,
        "throughputHighToLow": 36,
        "latencyLowToHigh": 74,
        "pricingLowToHigh": 70,
        "pricingHighToLow": 234
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Enfer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256",
          "slug": "enfer",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/mistral-7b-instruct-v0-3",
          "pricing": {
            "prompt": "0.000000028",
            "completion": "0.000000054",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logit_bias",
            "logprobs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.05,
          "throughput": 111.7105,
          "latency": 4286
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/Mistral-7B-Instruct-v0.3",
          "pricing": {
            "prompt": "0.000000029",
            "completion": "0.000000055",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 106.681,
          "latency": 598
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral:7b",
          "pricing": {
            "prompt": "0.000000029",
            "completion": "0.000000058",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 79.0705,
          "latency": 1218
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/mistral-7b-instruct",
          "pricing": {
            "prompt": "0.000000029",
            "completion": "0.000000059",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 142.638,
          "latency": 768
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": 4096,
          "providerModelId": "mistralai/Mistral-7B-Instruct-v0.3",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 211.91,
          "latency": 275
        }
      ]
    },
    {
      "slug": "openai/gpt-4o-search-preview",
      "hfSlug": "",
      "updatedAt": "2025-04-22T22:33:59.221907+00:00",
      "createdAt": "2025-03-12T22:19:09.996816+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4o Search Preview",
      "shortName": "GPT-4o Search Preview",
      "author": "openai",
      "description": "GPT-4o Search Previewis a specialized model for web search in Chat Completions. It is trained to understand and execute web search queries.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "openai/gpt-4o-search-preview-2025-03-11",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f37536d3-fa09-47a3-b63c-831a1965253e",
        "name": "OpenAI | openai/gpt-4o-search-preview-2025-03-11",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4o-search-preview",
          "hfSlug": "",
          "updatedAt": "2025-04-22T22:33:59.221907+00:00",
          "createdAt": "2025-03-12T22:19:09.996816+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4o Search Preview",
          "shortName": "GPT-4o Search Preview",
          "author": "openai",
          "description": "GPT-4o Search Previewis a specialized model for web search in Chat Completions. It is trained to understand and execute web search queries.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "openai/gpt-4o-search-preview-2025-03-11",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4o-search-preview",
        "modelVariantPermaslug": "openai/gpt-4o-search-preview-2025-03-11",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4o-search-preview-2025-03-11",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "web_search_options",
          "max_tokens",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000025",
          "completion": "0.00001",
          "image": "0.003613",
          "request": "0.035",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.05"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.035"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.03"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 167,
        "newest": 91,
        "throughputHighToLow": 38,
        "latencyLowToHigh": 294,
        "pricingLowToHigh": 314,
        "pricingHighToLow": 4
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o-search-preview-2025-03-11",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0.003613",
            "request": "0.035",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "web_search_options",
            "max_tokens",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 145.634,
          "latency": 4735
        }
      ]
    },
    {
      "slug": "perplexity/llama-3.1-sonar-small-128k-online",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-01T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Llama 3.1 Sonar 8B Online",
      "shortName": "Llama 3.1 Sonar 8B Online",
      "author": "perplexity",
      "description": "Llama 3.1 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is the online version of the [offline chat model](/models/perplexity/llama-3.1-sonar-small-128k-chat). It is focused on delivering helpful, up-to-date, and factual responses. #online",
      "modelVersionGroupId": "9e4cc81b-5f14-4987-9e40-74db1c86ecda",
      "contextLength": 127072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "perplexity/llama-3.1-sonar-small-128k-online",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "48b44b03-a839-42e9-863e-1b6c07aa42ae",
        "name": "Perplexity | perplexity/llama-3.1-sonar-small-128k-online",
        "contextLength": 127072,
        "model": {
          "slug": "perplexity/llama-3.1-sonar-small-128k-online",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-01T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Perplexity: Llama 3.1 Sonar 8B Online",
          "shortName": "Llama 3.1 Sonar 8B Online",
          "author": "perplexity",
          "description": "Llama 3.1 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is the online version of the [offline chat model](/models/perplexity/llama-3.1-sonar-small-128k-chat). It is focused on delivering helpful, up-to-date, and factual responses. #online",
          "modelVersionGroupId": "9e4cc81b-5f14-4987-9e40-74db1c86ecda",
          "contextLength": 127072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "perplexity/llama-3.1-sonar-small-128k-online",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "perplexity/llama-3.1-sonar-small-128k-online",
        "modelVariantPermaslug": "perplexity/llama-3.1-sonar-small-128k-online",
        "providerName": "Perplexity",
        "providerInfo": {
          "name": "Perplexity",
          "displayName": "Perplexity",
          "slug": "perplexity",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
            "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Perplexity",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.perplexity.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Perplexity.svg"
          }
        },
        "providerDisplayName": "Perplexity",
        "providerModelId": "llama-3.1-sonar-small-128k-online",
        "providerGroup": "Perplexity",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "frequency_penalty",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
          "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000002",
          "completion": "0.0000002",
          "image": "0",
          "request": "0.005",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 168,
        "newest": 227,
        "throughputHighToLow": 8,
        "latencyLowToHigh": 193,
        "pricingLowToHigh": 286,
        "pricingHighToLow": 32
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": [
        {
          "name": "Perplexity",
          "icon": "https://openrouter.ai/images/icons/Perplexity.svg",
          "slug": "perplexity",
          "quantization": "unknown",
          "context": 127072,
          "maxCompletionTokens": null,
          "providerModelId": "llama-3.1-sonar-small-128k-online",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0.005",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 240.215,
          "latency": 1293
        }
      ]
    },
    {
      "slug": "anthropic/claude-3-sonnet",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-05T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3 Sonnet (self-moderated)",
      "shortName": "Claude 3 Sonnet (self-moderated)",
      "author": "anthropic",
      "description": "Claude 3 Sonnet is an ideal balance of intelligence and speed for enterprise workloads. Maximum utility at a lower price, dependable, balanced for scaled deployments.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
      "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-sonnet",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "dc39604a-e702-4a0c-8bd8-0f2578f14a2d",
        "name": "Anthropic | anthropic/claude-3-sonnet:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3-sonnet",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-05T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3 Sonnet",
          "shortName": "Claude 3 Sonnet",
          "author": "anthropic",
          "description": "Claude 3 Sonnet is an ideal balance of intelligence and speed for enterprise workloads. Maximum utility at a lower price, dependable, balanced for scaled deployments.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
          "modelVersionGroupId": "30636d20-cda3-4a59-aa0c-1a5b6efba072",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-sonnet",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3-sonnet:beta",
        "modelVariantPermaslug": "anthropic/claude-3-sonnet:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-sonnet-20240229",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0.0048",
          "request": "0",
          "inputCacheRead": "0.0000003",
          "inputCacheWrite": "0.00000375",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 134,
        "newest": 281,
        "throughputHighToLow": 116,
        "latencyLowToHigh": 128,
        "pricingLowToHigh": 278,
        "pricingHighToLow": 50
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-sonnet-20240229",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 66.867,
          "latency": 756.5
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-sonnet@20240229",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0.0048",
            "request": "0",
            "inputCacheRead": "0.0000003",
            "inputCacheWrite": "0.00000375",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 68.078,
          "latency": 1041
        }
      ]
    },
    {
      "slug": "neversleep/llama-3.1-lumimaid-8b",
      "hfSlug": "NeverSleep/Lumimaid-v0.2-8B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-15T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "NeverSleep: Lumimaid v0.2 8B",
      "shortName": "Lumimaid v0.2 8B",
      "author": "neversleep",
      "description": "Lumimaid v0.2 8B is a finetune of [Llama 3.1 8B](/models/meta-llama/llama-3.1-8b-instruct) with a \"HUGE step up dataset wise\" compared to Lumimaid v0.1. Sloppy chats output were purged.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "neversleep/llama-3.1-lumimaid-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e36a24b0-90b7-495c-a993-0ff11c1e8a26",
        "name": "Mancer | neversleep/llama-3.1-lumimaid-8b",
        "contextLength": 32768,
        "model": {
          "slug": "neversleep/llama-3.1-lumimaid-8b",
          "hfSlug": "NeverSleep/Lumimaid-v0.2-8B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-15T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "NeverSleep: Lumimaid v0.2 8B",
          "shortName": "Lumimaid v0.2 8B",
          "author": "neversleep",
          "description": "Lumimaid v0.2 8B is a finetune of [Llama 3.1 8B](/models/meta-llama/llama-3.1-8b-instruct) with a \"HUGE step up dataset wise\" compared to Lumimaid v0.1. Sloppy chats output were purged.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "neversleep/llama-3.1-lumimaid-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "neversleep/llama-3.1-lumimaid-8b",
        "modelVariantPermaslug": "neversleep/llama-3.1-lumimaid-8b",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "lumi-8b-v2",
        "providerGroup": "Mancer",
        "quantization": "fp16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000009375",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 170,
        "newest": 206,
        "throughputHighToLow": 241,
        "latencyLowToHigh": 84,
        "pricingLowToHigh": 151,
        "pricingHighToLow": 165
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "fp16",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "lumi-8b-v2",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000009375",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.15,
          "outputCost": 0.94,
          "throughput": 31.744,
          "latency": 570
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "fp16",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "lumi-8b-v2",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.00000125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.2,
          "outputCost": 1.25,
          "throughput": 31.6855,
          "latency": 368.5
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "NeverSleep/Lumimaid-v0.2-8B",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 26.641,
          "latency": 1171.5
        }
      ]
    },
    {
      "slug": "mistralai/mistral-large-2407",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-19T01:06:55.27469+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral Large 2407",
      "shortName": "Mistral Large 2407",
      "author": "mistralai",
      "description": "This is Mistral AI's flagship model, Mistral Large 2 (version mistral-large-2407). It's a proprietary weights-available model and excels at reasoning, code, JSON, chat, and more. Read the launch announcement [here](https://mistral.ai/news/mistral-large-2407/).\n\nIt supports dozens of languages including French, German, Spanish, Italian, Portuguese, Arabic, Hindi, Russian, Chinese, Japanese, and Korean, along with 80+ coding languages including Python, Java, C, C++, JavaScript, and Bash. Its long context window allows precise information recall from large documents.\n",
      "modelVersionGroupId": "83129748-0564-4485-982a-d7a37a1ef3ec",
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-large-2407",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4a128170-b056-42d7-8462-a5cea647f9ad",
        "name": "Mistral | mistralai/mistral-large-2407",
        "contextLength": 131072,
        "model": {
          "slug": "mistralai/mistral-large-2407",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-19T01:06:55.27469+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral Large 2407",
          "shortName": "Mistral Large 2407",
          "author": "mistralai",
          "description": "This is Mistral AI's flagship model, Mistral Large 2 (version mistral-large-2407). It's a proprietary weights-available model and excels at reasoning, code, JSON, chat, and more. Read the launch announcement [here](https://mistral.ai/news/mistral-large-2407/).\n\nIt supports dozens of languages including French, German, Spanish, Italian, Portuguese, Arabic, Hindi, Russian, Chinese, Japanese, and Korean, along with 80+ coding languages including Python, Java, C, C++, JavaScript, and Bash. Its long context window allows precise information recall from large documents.\n",
          "modelVersionGroupId": "83129748-0564-4485-982a-d7a37a1ef3ec",
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-large-2407",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-large-2407",
        "modelVariantPermaslug": "mistralai/mistral-large-2407",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "mistral-large-2407",
        "providerGroup": "Mistral",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 171,
        "newest": 168,
        "throughputHighToLow": 207,
        "latencyLowToHigh": 67,
        "pricingLowToHigh": 244,
        "pricingHighToLow": 73
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-large-2407",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 2,
          "outputCost": 6,
          "throughput": 40.8395,
          "latency": 488
        }
      ]
    },
    {
      "slug": "google/gemma-2-27b-it",
      "hfSlug": "google/gemma-2-27b-it",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 2 27B",
      "shortName": "Gemma 2 27B",
      "author": "google",
      "description": "Gemma 2 27B by Google is an open model built from the same research and technology used to create the [Gemini models](/models?q=gemini).\n\nGemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning.\n\nSee the [launch announcement](https://blog.google/technology/developers/google-gemma-2/) for more details. Usage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms).",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemma-2-27b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2ddecefa-fddf-44bc-b8db-fa904f993eef",
        "name": "Nebius | google/gemma-2-27b-it",
        "contextLength": 8192,
        "model": {
          "slug": "google/gemma-2-27b-it",
          "hfSlug": "google/gemma-2-27b-it",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-07-13T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 2 27B",
          "shortName": "Gemma 2 27B",
          "author": "google",
          "description": "Gemma 2 27B by Google is an open model built from the same research and technology used to create the [Gemini models](/models?q=gemini).\n\nGemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning.\n\nSee the [launch announcement](https://blog.google/technology/developers/google-gemma-2/) for more details. Usage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms).",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemma-2-27b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-2-27b-it",
        "modelVariantPermaslug": "google/gemma-2-27b-it",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "google/gemma-2-27b-it",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 172,
        "newest": 238,
        "throughputHighToLow": 186,
        "latencyLowToHigh": 57,
        "pricingLowToHigh": 124,
        "pricingHighToLow": 195
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-2-27b-it",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 45.5635,
          "latency": 488
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 2048,
          "providerModelId": "google/gemma-2-27b-it",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 70.304,
          "latency": 497
        }
      ]
    },
    {
      "slug": "perplexity/sonar-pro",
      "hfSlug": "",
      "updatedAt": "2025-05-05T14:37:56.196383+00:00",
      "createdAt": "2025-03-07T01:53:43+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Sonar Pro",
      "shortName": "Sonar Pro",
      "author": "perplexity",
      "description": "Note: Sonar Pro pricing includes Perplexity search pricing. See [details here](https://docs.perplexity.ai/guides/pricing#detailed-pricing-breakdown-for-sonar-reasoning-pro-and-sonar-pro)\n\nFor enterprises seeking more advanced capabilities, the Sonar Pro API can handle in-depth, multi-step queries with added extensibility, like double the number of citations per search as Sonar on average. Plus, with a larger context window, it can handle longer and more nuanced searches and follow-up questions. ",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "perplexity/sonar-pro",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e19b1036-fab9-4f97-9579-8ea67959cc9b",
        "name": "Perplexity | perplexity/sonar-pro",
        "contextLength": 200000,
        "model": {
          "slug": "perplexity/sonar-pro",
          "hfSlug": "",
          "updatedAt": "2025-05-05T14:37:56.196383+00:00",
          "createdAt": "2025-03-07T01:53:43+00:00",
          "hfUpdatedAt": null,
          "name": "Perplexity: Sonar Pro",
          "shortName": "Sonar Pro",
          "author": "perplexity",
          "description": "Note: Sonar Pro pricing includes Perplexity search pricing. See [details here](https://docs.perplexity.ai/guides/pricing#detailed-pricing-breakdown-for-sonar-reasoning-pro-and-sonar-pro)\n\nFor enterprises seeking more advanced capabilities, the Sonar Pro API can handle in-depth, multi-step queries with added extensibility, like double the number of citations per search as Sonar on average. Plus, with a larger context window, it can handle longer and more nuanced searches and follow-up questions. ",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "perplexity/sonar-pro",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "perplexity/sonar-pro",
        "modelVariantPermaslug": "perplexity/sonar-pro",
        "providerName": "Perplexity",
        "providerInfo": {
          "name": "Perplexity",
          "displayName": "Perplexity",
          "slug": "perplexity",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
            "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Perplexity",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.perplexity.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Perplexity.svg"
          }
        },
        "providerDisplayName": "Perplexity",
        "providerModelId": "sonar-pro",
        "providerGroup": "Perplexity",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "web_search_options",
          "top_k",
          "frequency_penalty",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
          "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0",
          "request": "0",
          "webSearch": "0.005",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.014"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.01"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.006"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 173,
        "newest": 99,
        "throughputHighToLow": 150,
        "latencyLowToHigh": 277,
        "pricingLowToHigh": 268,
        "pricingHighToLow": 40
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": [
        {
          "name": "Perplexity",
          "icon": "https://openrouter.ai/images/icons/Perplexity.svg",
          "slug": "perplexity",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 8000,
          "providerModelId": "sonar-pro",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0",
            "request": "0",
            "webSearch": "0.005",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "web_search_options",
            "top_k",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 57.2625,
          "latency": 2619.5
        }
      ]
    },
    {
      "slug": "qwen/qwen3-8b",
      "hfSlug": "Qwen/Qwen3-8B",
      "updatedAt": "2025-05-12T00:35:52.624106+00:00",
      "createdAt": "2025-04-28T21:43:52.421936+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 8B (free)",
      "shortName": "Qwen3 8B (free)",
      "author": "qwen",
      "description": "Qwen3-8B is a dense 8.2B parameter causal language model from the Qwen3 series, designed for both reasoning-heavy tasks and efficient dialogue. It supports seamless switching between \"thinking\" mode for math, coding, and logical inference, and \"non-thinking\" mode for general conversation. The model is fine-tuned for instruction-following, agent integration, creative writing, and multilingual use across 100+ languages and dialects. It natively supports a 32K token context window and can extend to 131K tokens with YaRN scaling.",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-8b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "3ce04781-3def-489d-a591-a32f0d012971",
        "name": "Chutes | qwen/qwen3-8b-04-28:free",
        "contextLength": 40960,
        "model": {
          "slug": "qwen/qwen3-8b",
          "hfSlug": "Qwen/Qwen3-8B",
          "updatedAt": "2025-05-12T00:35:52.624106+00:00",
          "createdAt": "2025-04-28T21:43:52.421936+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 8B",
          "shortName": "Qwen3 8B",
          "author": "qwen",
          "description": "Qwen3-8B is a dense 8.2B parameter causal language model from the Qwen3 series, designed for both reasoning-heavy tasks and efficient dialogue. It supports seamless switching between \"thinking\" mode for math, coding, and logical inference, and \"non-thinking\" mode for general conversation. The model is fine-tuned for instruction-following, agent integration, creative writing, and multilingual use across 100+ languages and dialects. It natively supports a 32K token context window and can extend to 131K tokens with YaRN scaling.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-8b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-8b:free",
        "modelVariantPermaslug": "qwen/qwen3-8b-04-28:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/Qwen3-8B",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 40960,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 99,
        "newest": 24,
        "throughputHighToLow": 27,
        "latencyLowToHigh": 132,
        "pricingLowToHigh": 10,
        "pricingHighToLow": 229
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "qwen/qwen3-8b-fp8",
          "pricing": {
            "prompt": "0.000000035",
            "completion": "0.000000138",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.04,
          "outputCost": 0.14,
          "throughput": 90.228,
          "latency": 748
        }
      ]
    },
    {
      "slug": "amazon/nova-micro-v1",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-05T22:20:37.90344+00:00",
      "hfUpdatedAt": null,
      "name": "Amazon: Nova Micro 1.0",
      "shortName": "Nova Micro 1.0",
      "author": "amazon",
      "description": "Amazon Nova Micro 1.0 is a text-only model that delivers the lowest latency responses in the Amazon Nova family of models at a very low cost. With a context length of 128K tokens and optimized for speed and cost, Amazon Nova Micro excels at tasks such as text summarization, translation, content classification, interactive chat, and brainstorming. It has  simple mathematical reasoning and coding abilities.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Nova",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "amazon/nova-micro-v1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "474f0074-66f9-42f0-a866-81a2ffebb001",
        "name": "Amazon Bedrock | amazon/nova-micro-v1",
        "contextLength": 128000,
        "model": {
          "slug": "amazon/nova-micro-v1",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-05T22:20:37.90344+00:00",
          "hfUpdatedAt": null,
          "name": "Amazon: Nova Micro 1.0",
          "shortName": "Nova Micro 1.0",
          "author": "amazon",
          "description": "Amazon Nova Micro 1.0 is a text-only model that delivers the lowest latency responses in the Amazon Nova family of models at a very low cost. With a context length of 128K tokens and optimized for speed and cost, Amazon Nova Micro excels at tasks such as text summarization, translation, content classification, interactive chat, and brainstorming. It has  simple mathematical reasoning and coding abilities.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Nova",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "amazon/nova-micro-v1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "amazon/nova-micro-v1",
        "modelVariantPermaslug": "amazon/nova-micro-v1",
        "providerName": "Amazon Bedrock",
        "providerInfo": {
          "name": "Amazon Bedrock",
          "displayName": "Amazon Bedrock",
          "slug": "amazon-bedrock",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://aws.amazon.com/service-terms/",
            "privacyPolicyUrl": "https://aws.amazon.com/privacy",
            "dataPolicyUrl": "https://docs.aws.amazon.com/bedrock/latest/userguide/data-protection.html",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": true,
          "group": "Amazon Bedrock",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Bedrock.svg"
          }
        },
        "providerDisplayName": "Amazon Bedrock",
        "providerModelId": "us.amazon.nova-micro-v1:0",
        "providerGroup": "Amazon Bedrock",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 5120,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://aws.amazon.com/service-terms/",
          "privacyPolicyUrl": "https://aws.amazon.com/privacy",
          "dataPolicyUrl": "https://docs.aws.amazon.com/bedrock/latest/userguide/data-protection.html",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000000035",
          "completion": "0.00000014",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 175,
        "newest": 160,
        "throughputHighToLow": 6,
        "latencyLowToHigh": 50,
        "pricingLowToHigh": 90,
        "pricingHighToLow": 228
      },
      "authorIcon": "https://openrouter.ai/images/icons/Bedrock.svg",
      "providers": [
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 5120,
          "providerModelId": "us.amazon.nova-micro-v1:0",
          "pricing": {
            "prompt": "0.000000035",
            "completion": "0.00000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.04,
          "outputCost": 0.14,
          "throughput": 257.239,
          "latency": 414
        }
      ]
    },
    {
      "slug": "openai/o1-mini",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-12T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o1-mini",
      "shortName": "o1-mini",
      "author": "openai",
      "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/o1-mini",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e42e0d87-0bec-4adf-ac17-e5618f7b972e",
        "name": "OpenAI | openai/o1-mini",
        "contextLength": 128000,
        "model": {
          "slug": "openai/o1-mini",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-12T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o1-mini",
          "shortName": "o1-mini",
          "author": "openai",
          "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/o1-mini",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o1-mini",
        "modelVariantPermaslug": "openai/o1-mini",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o1-mini",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 65536,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "seed",
          "max_tokens"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000011",
          "completion": "0.0000044",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.00000055",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 176,
        "newest": 209,
        "throughputHighToLow": 317,
        "latencyLowToHigh": 289,
        "pricingLowToHigh": 233,
        "pricingHighToLow": 88
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 65536,
          "providerModelId": "o1-mini",
          "pricing": {
            "prompt": "0.0000011",
            "completion": "0.0000044",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000055",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "seed",
            "max_tokens"
          ],
          "inputCost": 1.1,
          "outputCost": 4.4,
          "throughput": 148.1655,
          "latency": 4672
        }
      ]
    },
    {
      "slug": "qwen/qwq-32b-preview",
      "hfSlug": "Qwen/QwQ-32B-Preview",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2024-11-28T00:42:21.381013+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: QwQ 32B Preview",
      "shortName": "QwQ 32B Preview",
      "author": "qwen",
      "description": "QwQ-32B-Preview is an experimental research model focused on AI reasoning capabilities developed by the Qwen Team. As a preview release, it demonstrates promising analytical abilities while having several important limitations:\n\n1. **Language Mixing and Code-Switching**: The model may mix languages or switch between them unexpectedly, affecting response clarity.\n2. **Recursive Reasoning Loops**: The model may enter circular reasoning patterns, leading to lengthy responses without a conclusive answer.\n3. **Safety and Ethical Considerations**: The model requires enhanced safety measures to ensure reliable and secure performance, and users should exercise caution when deploying it.\n4. **Performance and Benchmark Limitations**: The model excels in math and coding but has room for improvement in other areas, such as common sense reasoning and nuanced language understanding.\n\n",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwq-32b-preview",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "f7d63c65-9ad5-4f28-bb53-5fc9242efaea",
        "name": "Nebius | qwen/qwq-32b-preview",
        "contextLength": 32768,
        "model": {
          "slug": "qwen/qwq-32b-preview",
          "hfSlug": "Qwen/QwQ-32B-Preview",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2024-11-28T00:42:21.381013+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: QwQ 32B Preview",
          "shortName": "QwQ 32B Preview",
          "author": "qwen",
          "description": "QwQ-32B-Preview is an experimental research model focused on AI reasoning capabilities developed by the Qwen Team. As a preview release, it demonstrates promising analytical abilities while having several important limitations:\n\n1. **Language Mixing and Code-Switching**: The model may mix languages or switch between them unexpectedly, affecting response clarity.\n2. **Recursive Reasoning Loops**: The model may enter circular reasoning patterns, leading to lengthy responses without a conclusive answer.\n3. **Safety and Ethical Considerations**: The model requires enhanced safety measures to ensure reliable and secure performance, and users should exercise caution when deploying it.\n4. **Performance and Benchmark Limitations**: The model excels in math and coding but has room for improvement in other areas, such as common sense reasoning and nuanced language understanding.\n\n",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwq-32b-preview",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwq-32b-preview",
        "modelVariantPermaslug": "qwen/qwq-32b-preview",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "Qwen/QwQ-32B-Preview",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000009",
          "completion": "0.00000027",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 177,
        "newest": 162,
        "throughputHighToLow": 255,
        "latencyLowToHigh": 284,
        "pricingLowToHigh": 57,
        "pricingHighToLow": 200
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B-Preview",
          "pricing": {
            "prompt": "0.00000009",
            "completion": "0.00000027",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.09,
          "outputCost": 0.27,
          "throughput": 29.371,
          "latency": 1275.5
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B-Preview",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 24.9545,
          "latency": 21851.5
        }
      ]
    },
    {
      "slug": "perplexity/llama-3.1-sonar-large-128k-online",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-01T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Llama 3.1 Sonar 70B Online",
      "shortName": "Llama 3.1 Sonar 70B Online",
      "author": "perplexity",
      "description": "Llama 3.1 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is the online version of the [offline chat model](/models/perplexity/llama-3.1-sonar-large-128k-chat). It is focused on delivering helpful, up-to-date, and factual responses. #online",
      "modelVersionGroupId": "e0349fb1-b84a-4f4f-9023-e7f1c1e73b33",
      "contextLength": 127072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "perplexity/llama-3.1-sonar-large-128k-online",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "aaad39f2-2e0d-46a6-8078-928b6eebe5d3",
        "name": "Perplexity | perplexity/llama-3.1-sonar-large-128k-online",
        "contextLength": 127072,
        "model": {
          "slug": "perplexity/llama-3.1-sonar-large-128k-online",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-01T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Perplexity: Llama 3.1 Sonar 70B Online",
          "shortName": "Llama 3.1 Sonar 70B Online",
          "author": "perplexity",
          "description": "Llama 3.1 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is the online version of the [offline chat model](/models/perplexity/llama-3.1-sonar-large-128k-chat). It is focused on delivering helpful, up-to-date, and factual responses. #online",
          "modelVersionGroupId": "e0349fb1-b84a-4f4f-9023-e7f1c1e73b33",
          "contextLength": 127072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "perplexity/llama-3.1-sonar-large-128k-online",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "perplexity/llama-3.1-sonar-large-128k-online",
        "modelVariantPermaslug": "perplexity/llama-3.1-sonar-large-128k-online",
        "providerName": "Perplexity",
        "providerInfo": {
          "name": "Perplexity",
          "displayName": "Perplexity",
          "slug": "perplexity",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
            "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Perplexity",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.perplexity.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Perplexity.svg"
          }
        },
        "providerDisplayName": "Perplexity",
        "providerModelId": "llama-3.1-sonar-large-128k-online",
        "providerGroup": "Perplexity",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "frequency_penalty",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
          "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000001",
          "completion": "0.000001",
          "image": "0",
          "request": "0.005",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 178,
        "newest": 228,
        "throughputHighToLow": 97,
        "latencyLowToHigh": 218,
        "pricingLowToHigh": 288,
        "pricingHighToLow": 31
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": [
        {
          "name": "Perplexity",
          "icon": "https://openrouter.ai/images/icons/Perplexity.svg",
          "slug": "perplexity",
          "quantization": "unknown",
          "context": 127072,
          "maxCompletionTokens": null,
          "providerModelId": "llama-3.1-sonar-large-128k-online",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000001",
            "image": "0",
            "request": "0.005",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 1,
          "outputCost": 1,
          "throughput": 77.5415,
          "latency": 1730
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1-distill-qwen-32b",
      "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-29T23:53:50.865297+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1 Distill Qwen 32B (free)",
      "shortName": "R1 Distill Qwen 32B (free)",
      "author": "deepseek",
      "description": "DeepSeek R1 Distill Qwen 32B is a distilled large language model based on [Qwen 2.5 32B](https://huggingface.co/Qwen/Qwen2.5-32B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 72.6\n- MATH-500 pass@1: 94.3\n- CodeForces Rating: 1691\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 16000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-r1-distill-qwen-32b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "749d8a55-ab77-43a8-aa1a-4d0331c2e738",
        "name": "Nineteen | deepseek/deepseek-r1-distill-qwen-32b:free",
        "contextLength": 16000,
        "model": {
          "slug": "deepseek/deepseek-r1-distill-qwen-32b",
          "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-29T23:53:50.865297+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1 Distill Qwen 32B",
          "shortName": "R1 Distill Qwen 32B",
          "author": "deepseek",
          "description": "DeepSeek R1 Distill Qwen 32B is a distilled large language model based on [Qwen 2.5 32B](https://huggingface.co/Qwen/Qwen2.5-32B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 72.6\n- MATH-500 pass@1: 94.3\n- CodeForces Rating: 1691\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-r1-distill-qwen-32b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1-distill-qwen-32b:free",
        "modelVariantPermaslug": "deepseek/deepseek-r1-distill-qwen-32b:free",
        "providerName": "Nineteen",
        "providerInfo": {
          "name": "Nineteen",
          "displayName": "Nineteen",
          "slug": "nineteen",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://nineteen.ai/tos",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Nineteen",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nineteen.ai/&size=256"
          }
        },
        "providerDisplayName": "Nineteen",
        "providerModelId": "casperhansen/deepseek-r1-distill-qwen-32b-awq",
        "providerGroup": "Nineteen",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://nineteen.ai/tos",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 117,
        "newest": 133,
        "throughputHighToLow": 53,
        "latencyLowToHigh": 118,
        "pricingLowToHigh": 50,
        "pricingHighToLow": 192
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
          "pricing": {
            "prompt": "0.00000012",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.12,
          "outputCost": 0.18,
          "throughput": 45.471,
          "latency": 661
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 64000,
          "providerModelId": "deepseek/deepseek-r1-distill-qwen-32b",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 19.1495,
          "latency": 2299.5
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 80000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.00000488",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.5,
          "outputCost": 4.88,
          "throughput": 32.744,
          "latency": 864
        }
      ]
    },
    {
      "slug": "qwen/qwen2.5-vl-32b-instruct",
      "hfSlug": "Qwen/Qwen2.5-VL-32B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-24T18:10:38.542849+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen2.5 VL 32B Instruct (free)",
      "shortName": "Qwen2.5 VL 32B Instruct (free)",
      "author": "qwen",
      "description": "Qwen2.5-VL-32B is a multimodal vision-language model fine-tuned through reinforcement learning for enhanced mathematical reasoning, structured outputs, and visual problem-solving capabilities. It excels at visual analysis tasks, including object recognition, textual interpretation within images, and precise event localization in extended videos. Qwen2.5-VL-32B demonstrates state-of-the-art performance across multimodal benchmarks such as MMMU, MathVista, and VideoMME, while maintaining strong reasoning and clarity in text-based tasks like MMLU, mathematical problem-solving, and code generation.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen2.5-vl-32b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "dc909078-3013-470e-9410-258908dfab6a",
        "name": "Alibaba | qwen/qwen2.5-vl-32b-instruct:free",
        "contextLength": 8192,
        "model": {
          "slug": "qwen/qwen2.5-vl-32b-instruct",
          "hfSlug": "Qwen/Qwen2.5-VL-32B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-24T18:10:38.542849+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen2.5 VL 32B Instruct",
          "shortName": "Qwen2.5 VL 32B Instruct",
          "author": "qwen",
          "description": "Qwen2.5-VL-32B is a multimodal vision-language model fine-tuned through reinforcement learning for enhanced mathematical reasoning, structured outputs, and visual problem-solving capabilities. It excels at visual analysis tasks, including object recognition, textual interpretation within images, and precise event localization in extended videos. Qwen2.5-VL-32B demonstrates state-of-the-art performance across multimodal benchmarks such as MMMU, MathVista, and VideoMME, while maintaining strong reasoning and clarity in text-based tasks like MMLU, mathematical problem-solving, and code generation.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen2.5-vl-32b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen2.5-vl-32b-instruct:free",
        "modelVariantPermaslug": "qwen/qwen2.5-vl-32b-instruct:free",
        "providerName": "Alibaba",
        "providerInfo": {
          "name": "Alibaba",
          "displayName": "Alibaba",
          "slug": "alibaba",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
            "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "CN",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Alibaba",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.alibabacloud.com/&size=256"
          }
        },
        "providerDisplayName": "Alibaba",
        "providerModelId": "qwen2.5-vl-32b-instruct",
        "providerGroup": "Alibaba",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "seed",
          "response_format",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-product-terms-of-service-v-3-8-0",
          "privacyPolicyUrl": "https://www.alibabacloud.com/help/en/legal/latest/alibaba-cloud-international-website-privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 114,
        "newest": 73,
        "throughputHighToLow": 129,
        "latencyLowToHigh": 161,
        "pricingLowToHigh": 32,
        "pricingHighToLow": 103
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/qwen2p5-vl-32b-instruct",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 61.1,
          "latency": 950
        },
        {
          "name": "InoCloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inocloud.com/&size=256",
          "slug": "inoCloud",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": 128000,
          "providerModelId": "qwen/qwen2.5-vl-32b-instruct",
          "pricing": {
            "prompt": "0.0000011",
            "completion": "0.0000011",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 1.1,
          "outputCost": 1.1,
          "throughput": 26.459,
          "latency": 3078
        }
      ]
    },
    {
      "slug": "shisa-ai/shisa-v2-llama3.3-70b",
      "hfSlug": "shisa-ai/shisa-v2-llama3.3-70b",
      "updatedAt": "2025-04-15T22:08:27.703923+00:00",
      "createdAt": "2025-04-15T22:07:38.395118+00:00",
      "hfUpdatedAt": null,
      "name": "Shisa AI: Shisa V2 Llama 3.3 70B  (free)",
      "shortName": "Shisa V2 Llama 3.3 70B  (free)",
      "author": "shisa-ai",
      "description": "Shisa V2 Llama 3.3 70B is a bilingual Japanese-English chat model fine-tuned by Shisa.AI on Meta’s Llama-3.3-70B-Instruct base. It prioritizes Japanese language performance while retaining strong English capabilities. The model was optimized entirely through post-training, using a refined mix of supervised fine-tuning (SFT) and DPO datasets including regenerated ShareGPT-style data, translation tasks, roleplaying conversations, and instruction-following prompts. Unlike earlier Shisa releases, this version avoids tokenizer modifications or extended pretraining.\n\nShisa V2 70B achieves leading Japanese task performance across a wide range of custom and public benchmarks, including JA MT Bench, ELYZA 100, and Rakuda. It supports a 128K token context length and integrates smoothly with inference frameworks like vLLM and SGLang. While it inherits safety characteristics from its base model, no additional alignment was applied. The model is intended for high-performance bilingual chat, instruction following, and translation tasks across JA/EN.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "shisa-ai/shisa-v2-llama3.3-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "28fd88ec-30ab-402f-9c7b-652cc86ab0d6",
        "name": "Chutes | shisa-ai/shisa-v2-llama3.3-70b:free",
        "contextLength": 32768,
        "model": {
          "slug": "shisa-ai/shisa-v2-llama3.3-70b",
          "hfSlug": "shisa-ai/shisa-v2-llama3.3-70b",
          "updatedAt": "2025-04-15T22:08:27.703923+00:00",
          "createdAt": "2025-04-15T22:07:38.395118+00:00",
          "hfUpdatedAt": null,
          "name": "Shisa AI: Shisa V2 Llama 3.3 70B ",
          "shortName": "Shisa V2 Llama 3.3 70B ",
          "author": "shisa-ai",
          "description": "Shisa V2 Llama 3.3 70B is a bilingual Japanese-English chat model fine-tuned by Shisa.AI on Meta’s Llama-3.3-70B-Instruct base. It prioritizes Japanese language performance while retaining strong English capabilities. The model was optimized entirely through post-training, using a refined mix of supervised fine-tuning (SFT) and DPO datasets including regenerated ShareGPT-style data, translation tasks, roleplaying conversations, and instruction-following prompts. Unlike earlier Shisa releases, this version avoids tokenizer modifications or extended pretraining.\n\nShisa V2 70B achieves leading Japanese task performance across a wide range of custom and public benchmarks, including JA MT Bench, ELYZA 100, and Rakuda. It supports a 128K token context length and integrates smoothly with inference frameworks like vLLM and SGLang. While it inherits safety characteristics from its base model, no additional alignment was applied. The model is intended for high-performance bilingual chat, instruction following, and translation tasks across JA/EN.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "shisa-ai/shisa-v2-llama3.3-70b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "shisa-ai/shisa-v2-llama3.3-70b:free",
        "modelVariantPermaslug": "shisa-ai/shisa-v2-llama3.3-70b:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "shisa-ai/shisa-v2-llama3.3-70b",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 181,
        "newest": 46,
        "throughputHighToLow": 252,
        "latencyLowToHigh": 245,
        "pricingLowToHigh": 20,
        "pricingHighToLow": 268
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "meta-llama/llama-guard-4-12b",
      "hfSlug": "meta-llama/Llama-Guard-4-12B",
      "updatedAt": "2025-04-30T14:10:44.640461+00:00",
      "createdAt": "2025-04-30T01:06:33.531556+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama Guard 4 12B",
      "shortName": "Llama Guard 4 12B",
      "author": "meta-llama",
      "description": "Llama Guard 4 is a Llama 4 Scout-derived multimodal pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM—generating text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated.\n\nLlama Guard 4 was aligned to safeguard against the standardized MLCommons hazards taxonomy and designed to support multimodal Llama 4 capabilities. Specifically, it combines features from previous Llama Guard models, providing content moderation for English and multiple supported languages, along with enhanced capabilities to handle mixed text-and-image prompts, including multiple images. Additionally, Llama Guard 4 is integrated into the Llama Moderations API, extending robust safety classification to text and images.",
      "modelVersionGroupId": null,
      "contextLength": 163840,
      "inputModalities": [
        "image",
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-guard-4-12b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "850b84c3-42a7-4cec-99c0-b5582d0da66b",
        "name": "DeepInfra | meta-llama/llama-guard-4-12b",
        "contextLength": 163840,
        "model": {
          "slug": "meta-llama/llama-guard-4-12b",
          "hfSlug": "meta-llama/Llama-Guard-4-12B",
          "updatedAt": "2025-04-30T14:10:44.640461+00:00",
          "createdAt": "2025-04-30T01:06:33.531556+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama Guard 4 12B",
          "shortName": "Llama Guard 4 12B",
          "author": "meta-llama",
          "description": "Llama Guard 4 is a Llama 4 Scout-derived multimodal pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM—generating text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated.\n\nLlama Guard 4 was aligned to safeguard against the standardized MLCommons hazards taxonomy and designed to support multimodal Llama 4 capabilities. Specifically, it combines features from previous Llama Guard models, providing content moderation for English and multiple supported languages, along with enhanced capabilities to handle mixed text-and-image prompts, including multiple images. Additionally, Llama Guard 4 is integrated into the Llama Moderations API, extending robust safety classification to text and images.",
          "modelVersionGroupId": null,
          "contextLength": 163840,
          "inputModalities": [
            "image",
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-guard-4-12b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-guard-4-12b",
        "modelVariantPermaslug": "meta-llama/llama-guard-4-12b",
        "providerName": "DeepInfra",
        "providerInfo": {
          "name": "DeepInfra",
          "displayName": "DeepInfra",
          "slug": "deepinfra",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://deepinfra.com/privacy",
            "termsOfServiceUrl": "https://deepinfra.com/terms",
            "dataPolicyUrl": "https://deepinfra.com/docs/data",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "DeepInfra",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/DeepInfra.webp"
          }
        },
        "providerDisplayName": "DeepInfra",
        "providerModelId": "meta-llama/Llama-Guard-4-12B",
        "providerGroup": "DeepInfra",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://deepinfra.com/privacy",
          "termsOfServiceUrl": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000005",
          "completion": "0.00000005",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 182,
        "newest": 21,
        "throughputHighToLow": 89,
        "latencyLowToHigh": 63,
        "pricingLowToHigh": 96,
        "pricingHighToLow": 222
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-Guard-4-12B",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.05,
          "outputCost": 0.05,
          "throughput": 87.8985,
          "latency": 476
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 1048576,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-Guard-4-12B",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 1024,
          "providerModelId": "meta-llama/llama-guard-4-12b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 370.611,
          "latency": 757
        }
      ]
    },
    {
      "slug": "cohere/command-r-plus-08-2024",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-30T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Cohere: Command R+ (08-2024)",
      "shortName": "Command R+ (08-2024)",
      "author": "cohere",
      "description": "command-r-plus-08-2024 is an update of the [Command R+](/models/cohere/command-r-plus) with roughly 50% higher throughput and 25% lower latencies as compared to the previous Command R+ version, while keeping the hardware footprint the same.\n\nRead the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Cohere",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cohere/command-r-plus-08-2024",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cd63714a-d459-4806-bdf2-0dfea4f6614c",
        "name": "Cohere | cohere/command-r-plus-08-2024",
        "contextLength": 128000,
        "model": {
          "slug": "cohere/command-r-plus-08-2024",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-30T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Cohere: Command R+ (08-2024)",
          "shortName": "Command R+ (08-2024)",
          "author": "cohere",
          "description": "command-r-plus-08-2024 is an update of the [Command R+](/models/cohere/command-r-plus) with roughly 50% higher throughput and 25% lower latencies as compared to the previous Command R+ version, while keeping the hardware footprint the same.\n\nRead the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Cohere",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cohere/command-r-plus-08-2024",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cohere/command-r-plus-08-2024",
        "modelVariantPermaslug": "cohere/command-r-plus-08-2024",
        "providerName": "Cohere",
        "providerInfo": {
          "name": "Cohere",
          "displayName": "Cohere",
          "slug": "cohere",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://cohere.com/privacy",
            "termsOfServiceUrl": "https://cohere.com/terms-of-use",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cohere",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cohere.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Cohere.png"
          }
        },
        "providerDisplayName": "Cohere",
        "providerModelId": "command-r-plus-08-2024",
        "providerGroup": "Cohere",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://cohere.com/privacy",
          "termsOfServiceUrl": "https://cohere.com/terms-of-use",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000025",
          "completion": "0.00001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 183,
        "newest": 212,
        "throughputHighToLow": 209,
        "latencyLowToHigh": 46,
        "pricingLowToHigh": 263,
        "pricingHighToLow": 57
      },
      "authorIcon": "https://openrouter.ai/images/icons/Cohere.png",
      "providers": [
        {
          "name": "Cohere",
          "icon": "https://openrouter.ai/images/icons/Cohere.png",
          "slug": "cohere",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4000,
          "providerModelId": "command-r-plus-08-2024",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 40.1185,
          "latency": 420.5
        }
      ]
    },
    {
      "slug": "openai/gpt-4o-2024-05-13",
      "hfSlug": null,
      "updatedAt": "2025-04-23T22:07:30.08308+00:00",
      "createdAt": "2024-05-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4o (2024-05-13)",
      "shortName": "GPT-4o (2024-05-13)",
      "author": "openai",
      "description": "GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n#multimodal",
      "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4o-2024-05-13",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3d6584e7-a2bb-48d6-903d-24e3d90e7e55",
        "name": "OpenAI | openai/gpt-4o-2024-05-13",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4o-2024-05-13",
          "hfSlug": null,
          "updatedAt": "2025-04-23T22:07:30.08308+00:00",
          "createdAt": "2024-05-13T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4o (2024-05-13)",
          "shortName": "GPT-4o (2024-05-13)",
          "author": "openai",
          "description": "GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n#multimodal",
          "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4o-2024-05-13",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4o-2024-05-13",
        "modelVariantPermaslug": "openai/gpt-4o-2024-05-13",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4o-2024-05-13",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "web_search_options",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000005",
          "completion": "0.000015",
          "image": "0.007225",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.05"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.035"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.03"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 184,
        "newest": 261,
        "throughputHighToLow": 75,
        "latencyLowToHigh": 87,
        "pricingLowToHigh": 293,
        "pricingHighToLow": 29
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4o-2024-05-13",
          "pricing": {
            "prompt": "0.000005",
            "completion": "0.000015",
            "image": "0.007225",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 5,
          "outputCost": 15,
          "throughput": 91.995,
          "latency": 594
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4o",
          "pricing": {
            "prompt": "0.000005",
            "completion": "0.000015",
            "image": "0.007225",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 5,
          "outputCost": 15,
          "throughput": 146.892,
          "latency": 1532
        }
      ]
    },
    {
      "slug": "x-ai/grok-beta",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "xAI: Grok Beta",
      "shortName": "Grok Beta",
      "author": "x-ai",
      "description": "Grok Beta is xAI's experimental language model with state-of-the-art reasoning capabilities, best for complex and multi-step use cases.\n\nIt is the successor of [Grok 2](https://x.ai/blog/grok-2) with enhanced context length.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Grok",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "x-ai/grok-beta",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7f10aaf2-5317-4238-b4be-212fe355d24c",
        "name": "xAI | x-ai/grok-beta",
        "contextLength": 131072,
        "model": {
          "slug": "x-ai/grok-beta",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-20T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "xAI: Grok Beta",
          "shortName": "Grok Beta",
          "author": "x-ai",
          "description": "Grok Beta is xAI's experimental language model with state-of-the-art reasoning capabilities, best for complex and multi-step use cases.\n\nIt is the successor of [Grok 2](https://x.ai/blog/grok-2) with enhanced context length.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Grok",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "x-ai/grok-beta",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "x-ai/grok-beta",
        "modelVariantPermaslug": "x-ai/grok-beta",
        "providerName": "xAI",
        "providerInfo": {
          "name": "xAI",
          "displayName": "xAI",
          "slug": "xai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "xAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.x.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256"
          }
        },
        "providerDisplayName": "xAI",
        "providerModelId": "grok-beta",
        "providerGroup": "xAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000005",
          "completion": "0.000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 185,
        "newest": 185,
        "throughputHighToLow": 130,
        "latencyLowToHigh": 23,
        "pricingLowToHigh": 291,
        "pricingHighToLow": 27
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://x.ai/\\u0026size=256",
      "providers": [
        {
          "name": "xAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256",
          "slug": "xAi",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "grok-beta",
          "pricing": {
            "prompt": "0.000005",
            "completion": "0.000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 5,
          "outputCost": 15,
          "throughput": 59.998,
          "latency": 282
        }
      ]
    },
    {
      "slug": "google/gemma-3-4b-it",
      "hfSlug": "google/gemma-3-4b-it",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-13T22:38:30.653142+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 3 4B (free)",
      "shortName": "Gemma 3 4B (free)",
      "author": "google",
      "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling.",
      "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemma-3-4b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "1bbec5f0-58e0-4af2-b8ca-99c202b4ceca",
        "name": "Chutes | google/gemma-3-4b-it:free",
        "contextLength": 131072,
        "model": {
          "slug": "google/gemma-3-4b-it",
          "hfSlug": "google/gemma-3-4b-it",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-13T22:38:30.653142+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 3 4B",
          "shortName": "Gemma 3 4B",
          "author": "google",
          "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling.",
          "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemma-3-4b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-3-4b-it:free",
        "modelVariantPermaslug": "google/gemma-3-4b-it:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "unsloth/gemma-3-4b-it",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 60,
        "newest": 83,
        "throughputHighToLow": 70,
        "latencyLowToHigh": 26,
        "pricingLowToHigh": 38,
        "pricingHighToLow": 241
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-3-4b-it",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.02,
          "outputCost": 0.04,
          "throughput": 80.749,
          "latency": 300
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1-distill-qwen-14b",
      "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-29T23:39:00.13687+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1 Distill Qwen 14B",
      "shortName": "R1 Distill Qwen 14B",
      "author": "deepseek",
      "description": "DeepSeek R1 Distill Qwen 14B is a distilled large language model based on [Qwen 2.5 14B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 69.7\n- MATH-500 pass@1: 93.9\n- CodeForces Rating: 1481\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 64000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "deepseek/deepseek-r1-distill-qwen-14b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "a18c0e49-6efb-439a-9287-fb2f398f3c5a",
        "name": "Novita | deepseek/deepseek-r1-distill-qwen-14b",
        "contextLength": 64000,
        "model": {
          "slug": "deepseek/deepseek-r1-distill-qwen-14b",
          "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-29T23:39:00.13687+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1 Distill Qwen 14B",
          "shortName": "R1 Distill Qwen 14B",
          "author": "deepseek",
          "description": "DeepSeek R1 Distill Qwen 14B is a distilled large language model based on [Qwen 2.5 14B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 69.7\n- MATH-500 pass@1: 93.9\n- CodeForces Rating: 1481\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "deepseek/deepseek-r1-distill-qwen-14b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1-distill-qwen-14b",
        "modelVariantPermaslug": "deepseek/deepseek-r1-distill-qwen-14b",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "deepseek/deepseek-r1-distill-qwen-14b",
        "providerGroup": "Novita",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 64000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.00000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 187,
        "newest": 135,
        "throughputHighToLow": 124,
        "latencyLowToHigh": 192,
        "pricingLowToHigh": 51,
        "pricingHighToLow": 184
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 64000,
          "providerModelId": "deepseek/deepseek-r1-distill-qwen-14b",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.15,
          "outputCost": 0.15,
          "throughput": 45.768,
          "latency": 1328
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
          "pricing": {
            "prompt": "0.0000016",
            "completion": "0.0000016",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.6,
          "outputCost": 1.6,
          "throughput": 171.142,
          "latency": 360
        }
      ]
    },
    {
      "slug": "cognitivecomputations/dolphin-mixtral-8x22b",
      "hfSlug": "cognitivecomputations/dolphin-2.9.2-mixtral-8x22b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-08T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Dolphin 2.9.2 Mixtral 8x22B 🐬",
      "shortName": "Dolphin 2.9.2 Mixtral 8x22B 🐬",
      "author": "cognitivecomputations",
      "description": "Dolphin 2.9 is designed for instruction following, conversational, and coding. This model is a finetune of [Mixtral 8x22B Instruct](/models/mistralai/mixtral-8x22b-instruct). It features a 64k context length and was fine-tuned with a 16k sequence length using ChatML templates.\n\nThis model is a successor to [Dolphin Mixtral 8x7B](/models/cognitivecomputations/dolphin-mixtral-8x7b).\n\nThe model is uncensored and is stripped of alignment and bias. It requires an external alignment layer for ethical use. Users are cautioned to use this highly compliant model responsibly, as detailed in a blog post about uncensored models at [erichartford.com/uncensored-models](https://erichartford.com/uncensored-models).\n\n#moe #uncensored",
      "modelVersionGroupId": null,
      "contextLength": 16000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cognitivecomputations/dolphin-mixtral-8x22b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b2b95261-d791-438e-a33c-fdd706052cf3",
        "name": "Novita | cognitivecomputations/dolphin-mixtral-8x22b",
        "contextLength": 16000,
        "model": {
          "slug": "cognitivecomputations/dolphin-mixtral-8x22b",
          "hfSlug": "cognitivecomputations/dolphin-2.9.2-mixtral-8x22b",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-06-08T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Dolphin 2.9.2 Mixtral 8x22B 🐬",
          "shortName": "Dolphin 2.9.2 Mixtral 8x22B 🐬",
          "author": "cognitivecomputations",
          "description": "Dolphin 2.9 is designed for instruction following, conversational, and coding. This model is a finetune of [Mixtral 8x22B Instruct](/models/mistralai/mixtral-8x22b-instruct). It features a 64k context length and was fine-tuned with a 16k sequence length using ChatML templates.\n\nThis model is a successor to [Dolphin Mixtral 8x7B](/models/cognitivecomputations/dolphin-mixtral-8x7b).\n\nThe model is uncensored and is stripped of alignment and bias. It requires an external alignment layer for ethical use. Users are cautioned to use this highly compliant model responsibly, as detailed in a blog post about uncensored models at [erichartford.com/uncensored-models](https://erichartford.com/uncensored-models).\n\n#moe #uncensored",
          "modelVersionGroupId": null,
          "contextLength": 65536,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cognitivecomputations/dolphin-mixtral-8x22b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cognitivecomputations/dolphin-mixtral-8x22b",
        "modelVariantPermaslug": "cognitivecomputations/dolphin-mixtral-8x22b",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "cognitivecomputations/dolphin-mixtral-8x22b",
        "providerGroup": "Novita",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000009",
          "completion": "0.0000009",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 188,
        "newest": 247,
        "throughputHighToLow": 306,
        "latencyLowToHigh": 268,
        "pricingLowToHigh": 213,
        "pricingHighToLow": 104
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 16000,
          "maxCompletionTokens": 8192,
          "providerModelId": "cognitivecomputations/dolphin-mixtral-8x22b",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 11.476,
          "latency": 2448
        }
      ]
    },
    {
      "slug": "openai/gpt-4-1106-preview",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-06T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4 Turbo (older v1106)",
      "shortName": "GPT-4 Turbo (older v1106)",
      "author": "openai",
      "description": "The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.\n\nTraining data: up to April 2023.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4-1106-preview",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8744de26-f64f-41cf-bd0e-950a83d1a923",
        "name": "OpenAI | openai/gpt-4-1106-preview",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4-1106-preview",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-11-06T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4 Turbo (older v1106)",
          "shortName": "GPT-4 Turbo (older v1106)",
          "author": "openai",
          "description": "The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.\n\nTraining data: up to April 2023.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4-1106-preview",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4-1106-preview",
        "modelVariantPermaslug": "openai/gpt-4-1106-preview",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4-1106-preview",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00001",
          "completion": "0.00003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 189,
        "newest": 301,
        "throughputHighToLow": 222,
        "latencyLowToHigh": 105,
        "pricingLowToHigh": 304,
        "pricingHighToLow": 16
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4-1106-preview",
          "pricing": {
            "prompt": "0.00001",
            "completion": "0.00003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 10,
          "outputCost": 30,
          "throughput": 36.9935,
          "latency": 698
        }
      ]
    },
    {
      "slug": "cohere/command-a",
      "hfSlug": "CohereForAI/c4ai-command-a-03-2025",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-13T19:32:22.069645+00:00",
      "hfUpdatedAt": null,
      "name": "Cohere: Command A",
      "shortName": "Command A",
      "author": "cohere",
      "description": "Command A is an open-weights 111B parameter model with a 256k context window focused on delivering great performance across agentic, multilingual, and coding use cases.\nCompared to other leading proprietary and open-weights models Command A delivers maximum performance with minimum hardware costs, excelling on business-critical agentic and multilingual tasks.",
      "modelVersionGroupId": null,
      "contextLength": 256000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cohere/command-a-03-2025",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2e152629-dac1-41b0-8f4f-f8c449d2d504",
        "name": "Cohere | cohere/command-a-03-2025",
        "contextLength": 256000,
        "model": {
          "slug": "cohere/command-a",
          "hfSlug": "CohereForAI/c4ai-command-a-03-2025",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-13T19:32:22.069645+00:00",
          "hfUpdatedAt": null,
          "name": "Cohere: Command A",
          "shortName": "Command A",
          "author": "cohere",
          "description": "Command A is an open-weights 111B parameter model with a 256k context window focused on delivering great performance across agentic, multilingual, and coding use cases.\nCompared to other leading proprietary and open-weights models Command A delivers maximum performance with minimum hardware costs, excelling on business-critical agentic and multilingual tasks.",
          "modelVersionGroupId": null,
          "contextLength": 256000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cohere/command-a-03-2025",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cohere/command-a",
        "modelVariantPermaslug": "cohere/command-a-03-2025",
        "providerName": "Cohere",
        "providerInfo": {
          "name": "Cohere",
          "displayName": "Cohere",
          "slug": "cohere",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://cohere.com/privacy",
            "termsOfServiceUrl": "https://cohere.com/terms-of-use",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cohere",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cohere.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Cohere.png"
          }
        },
        "providerDisplayName": "Cohere",
        "providerModelId": "command-a-03-2025",
        "providerGroup": "Cohere",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://cohere.com/privacy",
          "termsOfServiceUrl": "https://cohere.com/terms-of-use",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000025",
          "completion": "0.00001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 190,
        "newest": 89,
        "throughputHighToLow": 82,
        "latencyLowToHigh": 21,
        "pricingLowToHigh": 259,
        "pricingHighToLow": 53
      },
      "authorIcon": "https://openrouter.ai/images/icons/Cohere.png",
      "providers": [
        {
          "name": "Cohere",
          "icon": "https://openrouter.ai/images/icons/Cohere.png",
          "slug": "cohere",
          "quantization": null,
          "context": 256000,
          "maxCompletionTokens": 8192,
          "providerModelId": "command-a-03-2025",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 92.287,
          "latency": 213
        }
      ]
    },
    {
      "slug": "openai/gpt-4",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-05-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4",
      "shortName": "GPT-4",
      "author": "openai",
      "description": "OpenAI's flagship model, GPT-4 is a large-scale multimodal language model capable of solving difficult problems with greater accuracy than previous models due to its broader general knowledge and advanced reasoning capabilities. Training data: up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 8191,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "355b1df4-06c8-4c36-a091-3d50477095fb",
        "name": "OpenAI | openai/gpt-4",
        "contextLength": 8191,
        "model": {
          "slug": "openai/gpt-4",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-05-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4",
          "shortName": "GPT-4",
          "author": "openai",
          "description": "OpenAI's flagship model, GPT-4 is a large-scale multimodal language model capable of solving difficult problems with greater accuracy than previous models due to its broader general knowledge and advanced reasoning capabilities. Training data: up to Sep 2021.",
          "modelVersionGroupId": null,
          "contextLength": 8191,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4",
        "modelVariantPermaslug": "openai/gpt-4",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00003",
          "completion": "0.00006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 191,
        "newest": 317,
        "throughputHighToLow": 260,
        "latencyLowToHigh": 113,
        "pricingLowToHigh": 312,
        "pricingHighToLow": 5
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 8191,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4",
          "pricing": {
            "prompt": "0.00003",
            "completion": "0.00006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 30,
          "outputCost": 60,
          "throughput": 24.4485,
          "latency": 714
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 8191,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4",
          "pricing": {
            "prompt": "0.00003",
            "completion": "0.00006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 30,
          "outputCost": 60,
          "throughput": 34.887,
          "latency": 7744.5
        }
      ]
    },
    {
      "slug": "mistralai/mistral-7b-instruct-v0.2",
      "hfSlug": "mistralai/Mistral-7B-Instruct-v0.2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral 7B Instruct v0.2",
      "shortName": "Mistral 7B Instruct v0.2",
      "author": "mistralai",
      "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\nAn improved version of [Mistral 7B Instruct](/modelsmistralai/mistral-7b-instruct-v0.1), with the following changes:\n\n- 32k context window (vs 8k context in v0.1)\n- Rope-theta = 1e6\n- No Sliding-Window Attention",
      "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-7b-instruct-v0.2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ae921682-8673-4287-b3bd-459304097932",
        "name": "Together | mistralai/mistral-7b-instruct-v0.2",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mistral-7b-instruct-v0.2",
          "hfSlug": "mistralai/Mistral-7B-Instruct-v0.2",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-12-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral 7B Instruct v0.2",
          "shortName": "Mistral 7B Instruct v0.2",
          "author": "mistralai",
          "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\nAn improved version of [Mistral 7B Instruct](/modelsmistralai/mistral-7b-instruct-v0.1), with the following changes:\n\n- 32k context window (vs 8k context in v0.1)\n- Rope-theta = 1e6\n- No Sliding-Window Attention",
          "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-7b-instruct-v0.2",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-7b-instruct-v0.2",
        "modelVariantPermaslug": "mistralai/mistral-7b-instruct-v0.2",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "mistralai/Mistral-7B-Instruct-v0.2",
        "providerGroup": "Together",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000002",
          "completion": "0.0000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 192,
        "newest": 291,
        "throughputHighToLow": 11,
        "latencyLowToHigh": 1,
        "pricingLowToHigh": 149,
        "pricingHighToLow": 173
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/Mistral-7B-Instruct-v0.2",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 217.765,
          "latency": 124
        }
      ]
    },
    {
      "slug": "google/gemma-2-9b-it",
      "hfSlug": "google/gemma-2-9b-it",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 2 9B (free)",
      "shortName": "Gemma 2 9B (free)",
      "author": "google",
      "description": "Gemma 2 9B by Google is an advanced, open-source language model that sets a new standard for efficiency and performance in its size class.\n\nDesigned for a wide variety of tasks, it empowers developers and researchers to build innovative applications, while maintaining accessibility, safety, and cost-effectiveness.\n\nSee the [launch announcement](https://blog.google/technology/developers/google-gemma-2/) for more details. Usage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms).",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemma-2-9b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c21a8adc-4c1d-4605-af09-eb65c192db01",
        "name": "Chutes | google/gemma-2-9b-it:free",
        "contextLength": 8192,
        "model": {
          "slug": "google/gemma-2-9b-it",
          "hfSlug": "google/gemma-2-9b-it",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-06-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 2 9B",
          "shortName": "Gemma 2 9B",
          "author": "google",
          "description": "Gemma 2 9B by Google is an advanced, open-source language model that sets a new standard for efficiency and performance in its size class.\n\nDesigned for a wide variety of tasks, it empowers developers and researchers to build innovative applications, while maintaining accessibility, safety, and cost-effectiveness.\n\nSee the [launch announcement](https://blog.google/technology/developers/google-gemma-2/) for more details. Usage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms).",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemma-2-9b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-2-9b-it:free",
        "modelVariantPermaslug": "google/gemma-2-9b-it:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "unsloth/gemma-2-9b-it",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 101,
        "newest": 240,
        "throughputHighToLow": 40,
        "latencyLowToHigh": 6,
        "pricingLowToHigh": 69,
        "pricingHighToLow": 239
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-2-9b-it",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.02,
          "outputCost": 0.06,
          "throughput": 142.1235,
          "latency": 182
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "google/gemma-2-9b-it",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.08,
          "outputCost": 0.08,
          "throughput": 31.9895,
          "latency": 662
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "gemma2-9b-it",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 848.4545,
          "latency": 330.5
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "google/gemma-2-9b-it",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 116.9945,
          "latency": 345
        }
      ]
    },
    {
      "slug": "perplexity/sonar-reasoning-pro",
      "hfSlug": "",
      "updatedAt": "2025-05-05T14:36:52.712881+00:00",
      "createdAt": "2025-03-07T02:08:28.125446+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Sonar Reasoning Pro",
      "shortName": "Sonar Reasoning Pro",
      "author": "perplexity",
      "description": "Note: Sonar Pro pricing includes Perplexity search pricing. See [details here](https://docs.perplexity.ai/guides/pricing#detailed-pricing-breakdown-for-sonar-reasoning-pro-and-sonar-pro)\n\nSonar Reasoning Pro is a premier reasoning model powered by DeepSeek R1 with Chain of Thought (CoT). Designed for advanced use cases, it supports in-depth, multi-step queries with a larger context window and can surface more citations per search, enabling more comprehensive and extensible responses.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "perplexity/sonar-reasoning-pro",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "0d28660e-435a-4853-a2c6-9d916df28fc7",
        "name": "Perplexity | perplexity/sonar-reasoning-pro",
        "contextLength": 128000,
        "model": {
          "slug": "perplexity/sonar-reasoning-pro",
          "hfSlug": "",
          "updatedAt": "2025-05-05T14:36:52.712881+00:00",
          "createdAt": "2025-03-07T02:08:28.125446+00:00",
          "hfUpdatedAt": null,
          "name": "Perplexity: Sonar Reasoning Pro",
          "shortName": "Sonar Reasoning Pro",
          "author": "perplexity",
          "description": "Note: Sonar Pro pricing includes Perplexity search pricing. See [details here](https://docs.perplexity.ai/guides/pricing#detailed-pricing-breakdown-for-sonar-reasoning-pro-and-sonar-pro)\n\nSonar Reasoning Pro is a premier reasoning model powered by DeepSeek R1 with Chain of Thought (CoT). Designed for advanced use cases, it supports in-depth, multi-step queries with a larger context window and can surface more citations per search, enabling more comprehensive and extensible responses.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "perplexity/sonar-reasoning-pro",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "perplexity/sonar-reasoning-pro",
        "modelVariantPermaslug": "perplexity/sonar-reasoning-pro",
        "providerName": "Perplexity",
        "providerInfo": {
          "name": "Perplexity",
          "displayName": "Perplexity",
          "slug": "perplexity",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
            "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Perplexity",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.perplexity.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Perplexity.svg"
          }
        },
        "providerDisplayName": "Perplexity",
        "providerModelId": "sonar-reasoning-pro",
        "providerGroup": "Perplexity",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "web_search_options",
          "top_k",
          "frequency_penalty",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
          "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000008",
          "image": "0",
          "request": "0",
          "webSearch": "0.005",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.014"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.01"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.006"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 194,
        "newest": 98,
        "throughputHighToLow": 157,
        "latencyLowToHigh": 261,
        "pricingLowToHigh": 249,
        "pricingHighToLow": 69
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": [
        {
          "name": "Perplexity",
          "icon": "https://openrouter.ai/images/icons/Perplexity.svg",
          "slug": "perplexity",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "sonar-reasoning-pro",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0.005",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "web_search_options",
            "top_k",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 2,
          "outputCost": 8,
          "throughput": 53.502,
          "latency": 2166
        }
      ]
    },
    {
      "slug": "cohere/command-r-plus",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-04T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Cohere: Command R+",
      "shortName": "Command R+",
      "author": "cohere",
      "description": "Command R+ is a new, 104B-parameter LLM from Cohere. It's useful for roleplay, general consumer usecases, and Retrieval Augmented Generation (RAG).\n\nIt offers multilingual support for ten key languages to facilitate global business operations. See benchmarks and the launch post [here](https://txt.cohere.com/command-r-plus-microsoft-azure/).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Cohere",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cohere/command-r-plus",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7bfb1bda-c33b-4f0f-b8c5-bb3216a31b6b",
        "name": "Cohere | cohere/command-r-plus",
        "contextLength": 128000,
        "model": {
          "slug": "cohere/command-r-plus",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-04-04T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Cohere: Command R+",
          "shortName": "Command R+",
          "author": "cohere",
          "description": "Command R+ is a new, 104B-parameter LLM from Cohere. It's useful for roleplay, general consumer usecases, and Retrieval Augmented Generation (RAG).\n\nIt offers multilingual support for ten key languages to facilitate global business operations. See benchmarks and the launch post [here](https://txt.cohere.com/command-r-plus-microsoft-azure/).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Cohere",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cohere/command-r-plus",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cohere/command-r-plus",
        "modelVariantPermaslug": "cohere/command-r-plus",
        "providerName": "Cohere",
        "providerInfo": {
          "name": "Cohere",
          "displayName": "Cohere",
          "slug": "cohere",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://cohere.com/privacy",
            "termsOfServiceUrl": "https://cohere.com/terms-of-use",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cohere",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cohere.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Cohere.png"
          }
        },
        "providerDisplayName": "Cohere",
        "providerModelId": "command-r-plus",
        "providerGroup": "Cohere",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://cohere.com/privacy",
          "termsOfServiceUrl": "https://cohere.com/terms-of-use",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 195,
        "newest": 272,
        "throughputHighToLow": 156,
        "latencyLowToHigh": 48,
        "pricingLowToHigh": 276,
        "pricingHighToLow": 48
      },
      "authorIcon": "https://openrouter.ai/images/icons/Cohere.png",
      "providers": [
        {
          "name": "Cohere",
          "icon": "https://openrouter.ai/images/icons/Cohere.png",
          "slug": "cohere",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4000,
          "providerModelId": "command-r-plus",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 56.734,
          "latency": 356.5
        }
      ]
    },
    {
      "slug": "mistralai/mistral-small",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral Small",
      "shortName": "Mistral Small",
      "author": "mistralai",
      "description": "With 22 billion parameters, Mistral Small v24.09 offers a convenient mid-point between (Mistral NeMo 12B)[/mistralai/mistral-nemo] and (Mistral Large 2)[/mistralai/mistral-large], providing a cost-effective solution that can be deployed across various platforms and environments. It has better reasoning, exhibits more capabilities, can produce and reason about code, and is multiligual, supporting English, French, German, Italian, and Spanish.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-small",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e9fb7fa9-5720-4fd1-ac88-06fba8fbca50",
        "name": "Mistral | mistralai/mistral-small",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mistral-small",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-01-10T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral Small",
          "shortName": "Mistral Small",
          "author": "mistralai",
          "description": "With 22 billion parameters, Mistral Small v24.09 offers a convenient mid-point between (Mistral NeMo 12B)[/mistralai/mistral-nemo] and (Mistral Large 2)[/mistralai/mistral-large], providing a cost-effective solution that can be deployed across various platforms and environments. It has better reasoning, exhibits more capabilities, can produce and reason about code, and is multiligual, supporting English, French, German, Italian, and Spanish.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-small",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-small",
        "modelVariantPermaslug": "mistralai/mistral-small",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "mistral-small-2409",
        "providerGroup": "Mistral",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000002",
          "completion": "0.0000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 196,
        "newest": 289,
        "throughputHighToLow": 68,
        "latencyLowToHigh": 36,
        "pricingLowToHigh": 155,
        "pricingHighToLow": 164
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-small-2409",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 109.463,
          "latency": 342
        }
      ]
    },
    {
      "slug": "infermatic/mn-inferor-12b",
      "hfSlug": "Infermatic/MN-12B-Inferor-v0.0",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-13T02:20:28.884947+00:00",
      "hfUpdatedAt": null,
      "name": "Infermatic: Mistral Nemo Inferor 12B",
      "shortName": "Mistral Nemo Inferor 12B",
      "author": "infermatic",
      "description": "Inferor 12B is a merge of top roleplay models, expert on immersive narratives and storytelling.\n\nThis model was merged using the [Model Stock](https://arxiv.org/abs/2403.19522) merge method using [anthracite-org/magnum-v4-12b](https://openrouter.ai/anthracite-org/magnum-v4-72b) as a base.\n",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "infermatic/mn-inferor-12b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cc0c2222-fb27-4c56-8ce6-1f6a6be16a93",
        "name": "Featherless | infermatic/mn-inferor-12b",
        "contextLength": 16384,
        "model": {
          "slug": "infermatic/mn-inferor-12b",
          "hfSlug": "Infermatic/MN-12B-Inferor-v0.0",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-13T02:20:28.884947+00:00",
          "hfUpdatedAt": null,
          "name": "Infermatic: Mistral Nemo Inferor 12B",
          "shortName": "Mistral Nemo Inferor 12B",
          "author": "infermatic",
          "description": "Inferor 12B is a merge of top roleplay models, expert on immersive narratives and storytelling.\n\nThis model was merged using the [Model Stock](https://arxiv.org/abs/2403.19522) merge method using [anthracite-org/magnum-v4-12b](https://openrouter.ai/anthracite-org/magnum-v4-72b) as a base.\n",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "infermatic/mn-inferor-12b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "infermatic/mn-inferor-12b",
        "modelVariantPermaslug": "infermatic/mn-inferor-12b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "Infermatic/MN-12B-Inferor-v0.0",
        "providerGroup": "Featherless",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 197,
        "newest": 171,
        "throughputHighToLow": 282,
        "latencyLowToHigh": 266,
        "pricingLowToHigh": 206,
        "pricingHighToLow": 110
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://infermatic.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": null,
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "Infermatic/MN-12B-Inferor-v0.0",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 18.725,
          "latency": 1937
        }
      ]
    },
    {
      "slug": "sao10k/l3-euryale-70b",
      "hfSlug": "Sao10K/L3-70B-Euryale-v2.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-18T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Sao10k: Llama 3 Euryale 70B v2.1",
      "shortName": "Llama 3 Euryale 70B v2.1",
      "author": "sao10k",
      "description": "Euryale 70B v2.1 is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k).\n\n- Better prompt adherence.\n- Better anatomy / spatial awareness.\n- Adapts much better to unique and custom formatting / reply formats.\n- Very creative, lots of unique swipes.\n- Is not restrictive during roleplays.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "sao10k/l3-euryale-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2ab67dc9-421b-408e-b61a-b4b86ea1df70",
        "name": "Novita | sao10k/l3-euryale-70b",
        "contextLength": 8192,
        "model": {
          "slug": "sao10k/l3-euryale-70b",
          "hfSlug": "Sao10K/L3-70B-Euryale-v2.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-06-18T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Sao10k: Llama 3 Euryale 70B v2.1",
          "shortName": "Llama 3 Euryale 70B v2.1",
          "author": "sao10k",
          "description": "Euryale 70B v2.1 is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k).\n\n- Better prompt adherence.\n- Better anatomy / spatial awareness.\n- Adapts much better to unique and custom formatting / reply formats.\n- Very creative, lots of unique swipes.\n- Is not restrictive during roleplays.",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "sao10k/l3-euryale-70b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "sao10k/l3-euryale-70b",
        "modelVariantPermaslug": "sao10k/l3-euryale-70b",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "sao10k/l3-70b-euryale-v2.1",
        "providerGroup": "Novita",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000148",
          "completion": "0.00000148",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 198,
        "newest": 246,
        "throughputHighToLow": 228,
        "latencyLowToHigh": 148,
        "pricingLowToHigh": 235,
        "pricingHighToLow": 83
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "sao10k/l3-70b-euryale-v2.1",
          "pricing": {
            "prompt": "0.00000148",
            "completion": "0.00000148",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 1.48,
          "outputCost": 1.48,
          "throughput": 34.968,
          "latency": 882
        }
      ]
    },
    {
      "slug": "inception/mercury-coder-small-beta",
      "hfSlug": "",
      "updatedAt": "2025-04-30T17:36:42.979824+00:00",
      "createdAt": "2025-04-30T17:24:40+00:00",
      "hfUpdatedAt": null,
      "name": "Inception: Mercury Coder Small Beta",
      "shortName": "Mercury Coder Small Beta",
      "author": "inception",
      "description": "Mercury Coder Small is the first diffusion large language model (dLLM). Applying a breakthrough discrete diffusion approach, the model runs 5-10x faster than even speed optimized models like Claude 3.5 Haiku and GPT-4o Mini while matching their performance. Mercury Coder Small's speed means that developers can stay in the flow while coding, enjoying rapid chat-based iteration and responsive code completion suggestions. On Copilot Arena, Mercury Coder ranks 1st in speed and ties for 2nd in quality. Read more in the [blog post here](https://www.inceptionlabs.ai/introducing-mercury).",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "inception/mercury-coder-small-beta",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "eb51fb37-11b0-42d1-924a-c25fa2375569",
        "name": "Inception | inception/mercury-coder-small-beta",
        "contextLength": 32000,
        "model": {
          "slug": "inception/mercury-coder-small-beta",
          "hfSlug": "",
          "updatedAt": "2025-04-30T17:36:42.979824+00:00",
          "createdAt": "2025-04-30T17:24:40+00:00",
          "hfUpdatedAt": null,
          "name": "Inception: Mercury Coder Small Beta",
          "shortName": "Mercury Coder Small Beta",
          "author": "inception",
          "description": "Mercury Coder Small is the first diffusion large language model (dLLM). Applying a breakthrough discrete diffusion approach, the model runs 5-10x faster than even speed optimized models like Claude 3.5 Haiku and GPT-4o Mini while matching their performance. Mercury Coder Small's speed means that developers can stay in the flow while coding, enjoying rapid chat-based iteration and responsive code completion suggestions. On Copilot Arena, Mercury Coder ranks 1st in speed and ties for 2nd in quality. Read more in the [blog post here](https://www.inceptionlabs.ai/introducing-mercury).",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "inception/mercury-coder-small-beta",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "inception/mercury-coder-small-beta",
        "modelVariantPermaslug": "inception/mercury-coder-small-beta",
        "providerName": "Inception",
        "providerInfo": {
          "name": "Inception",
          "displayName": "Inception",
          "slug": "inception",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.inceptionlabs.ai/terms",
            "privacyPolicyUrl": "https://www.inceptionlabs.ai/terms#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Inception",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.inceptionlabs.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Inception",
        "providerModelId": "mercury-coder-small",
        "providerGroup": "Inception",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "frequency_penalty",
          "presence_penalty",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.inceptionlabs.ai/terms",
          "privacyPolicyUrl": "https://www.inceptionlabs.ai/terms#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000025",
          "completion": "0.000001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 199,
        "newest": 14,
        "throughputHighToLow": 0,
        "latencyLowToHigh": 65,
        "pricingLowToHigh": 166,
        "pricingHighToLow": 151
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://www.inceptionlabs.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Inception",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.inceptionlabs.ai/&size=256",
          "slug": "inception",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "mercury-coder-small",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "frequency_penalty",
            "presence_penalty",
            "stop"
          ],
          "inputCost": 0.25,
          "outputCost": 1,
          "throughput": 693.381,
          "latency": 531
        }
      ]
    },
    {
      "slug": "cognitivecomputations/dolphin3.0-mistral-24b",
      "hfSlug": "cognitivecomputations/Dolphin3.0-Mistral-24B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-13T15:53:39.941479+00:00",
      "hfUpdatedAt": null,
      "name": "Dolphin3.0 Mistral 24B (free)",
      "shortName": "Dolphin3.0 Mistral 24B (free)",
      "author": "cognitivecomputations",
      "description": "Dolphin 3.0 is the next generation of the Dolphin series of instruct-tuned models.  Designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.\n\nDolphin aims to be a general purpose instruct model, similar to the models behind ChatGPT, Claude, Gemini. \n\nPart of the [Dolphin 3.0 Collection](https://huggingface.co/collections/cognitivecomputations/dolphin-30-677ab47f73d7ff66743979a3) Curated and trained by [Eric Hartford](https://huggingface.co/ehartford), [Ben Gitter](https://huggingface.co/bigstorm), [BlouseJury](https://huggingface.co/BlouseJury) and [Cognitive Computations](https://huggingface.co/cognitivecomputations)",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cognitivecomputations/dolphin3.0-mistral-24b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4c7841c6-0d75-49bc-be70-478c2ae4f12b",
        "name": "Chutes | cognitivecomputations/dolphin3.0-mistral-24b:free",
        "contextLength": 32768,
        "model": {
          "slug": "cognitivecomputations/dolphin3.0-mistral-24b",
          "hfSlug": "cognitivecomputations/Dolphin3.0-Mistral-24B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-13T15:53:39.941479+00:00",
          "hfUpdatedAt": null,
          "name": "Dolphin3.0 Mistral 24B",
          "shortName": "Dolphin3.0 Mistral 24B",
          "author": "cognitivecomputations",
          "description": "Dolphin 3.0 is the next generation of the Dolphin series of instruct-tuned models.  Designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.\n\nDolphin aims to be a general purpose instruct model, similar to the models behind ChatGPT, Claude, Gemini. \n\nPart of the [Dolphin 3.0 Collection](https://huggingface.co/collections/cognitivecomputations/dolphin-30-677ab47f73d7ff66743979a3) Curated and trained by [Eric Hartford](https://huggingface.co/ehartford), [Ben Gitter](https://huggingface.co/bigstorm), [BlouseJury](https://huggingface.co/BlouseJury) and [Cognitive Computations](https://huggingface.co/cognitivecomputations)",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cognitivecomputations/dolphin3.0-mistral-24b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cognitivecomputations/dolphin3.0-mistral-24b:free",
        "modelVariantPermaslug": "cognitivecomputations/dolphin3.0-mistral-24b:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "cognitivecomputations/Dolphin3.0-Mistral-24B",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 200,
        "newest": 114,
        "throughputHighToLow": 111,
        "latencyLowToHigh": 226,
        "pricingLowToHigh": 47,
        "pricingHighToLow": 295
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "perplexity/sonar-reasoning",
      "hfSlug": "",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-29T06:11:47.38089+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Sonar Reasoning",
      "shortName": "Sonar Reasoning",
      "author": "perplexity",
      "description": "Sonar Reasoning is a reasoning model provided by Perplexity based on [DeepSeek R1](/deepseek/deepseek-r1).\n\nIt allows developers to utilize long chain of thought with built-in web search. Sonar Reasoning is uncensored and hosted in US datacenters. ",
      "modelVersionGroupId": null,
      "contextLength": 127000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "perplexity/sonar-reasoning",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "dbca9058-f3e6-4487-9651-f2f4c9f44190",
        "name": "Perplexity | perplexity/sonar-reasoning",
        "contextLength": 127000,
        "model": {
          "slug": "perplexity/sonar-reasoning",
          "hfSlug": "",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-29T06:11:47.38089+00:00",
          "hfUpdatedAt": null,
          "name": "Perplexity: Sonar Reasoning",
          "shortName": "Sonar Reasoning",
          "author": "perplexity",
          "description": "Sonar Reasoning is a reasoning model provided by Perplexity based on [DeepSeek R1](/deepseek/deepseek-r1).\n\nIt allows developers to utilize long chain of thought with built-in web search. Sonar Reasoning is uncensored and hosted in US datacenters. ",
          "modelVersionGroupId": null,
          "contextLength": 127000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "perplexity/sonar-reasoning",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "perplexity/sonar-reasoning",
        "modelVariantPermaslug": "perplexity/sonar-reasoning",
        "providerName": "Perplexity",
        "providerInfo": {
          "name": "Perplexity",
          "displayName": "Perplexity",
          "slug": "perplexity",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
            "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Perplexity",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.perplexity.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Perplexity.svg"
          }
        },
        "providerDisplayName": "Perplexity",
        "providerModelId": "sonar-reasoning",
        "providerGroup": "Perplexity",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "web_search_options",
          "top_k",
          "frequency_penalty",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
          "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000001",
          "completion": "0.000005",
          "image": "0",
          "request": "0.005",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.012"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.008"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.005"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 201,
        "newest": 137,
        "throughputHighToLow": 90,
        "latencyLowToHigh": 242,
        "pricingLowToHigh": 289,
        "pricingHighToLow": 25
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": [
        {
          "name": "Perplexity",
          "icon": "https://openrouter.ai/images/icons/Perplexity.svg",
          "slug": "perplexity",
          "quantization": null,
          "context": 127000,
          "maxCompletionTokens": null,
          "providerModelId": "sonar-reasoning",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000005",
            "image": "0",
            "request": "0.005",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "web_search_options",
            "top_k",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 1,
          "outputCost": 5,
          "throughput": 88.2145,
          "latency": 1729.5
        }
      ]
    },
    {
      "slug": "anthropic/claude-3.5-haiku",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-04T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3.5 Haiku (self-moderated)",
      "shortName": "Claude 3.5 Haiku (self-moderated)",
      "author": "anthropic",
      "description": "Claude 3.5 Haiku features offers enhanced capabilities in speed, coding accuracy, and tool use. Engineered to excel in real-time applications, it delivers quick response times that are essential for dynamic tasks such as chat interactions and immediate coding suggestions.\n\nThis makes it highly suitable for environments that demand both speed and precision, such as software development, customer service bots, and data management systems.\n\nThis model is currently pointing to [Claude 3.5 Haiku (2024-10-22)](/anthropic/claude-3-5-haiku-20241022).",
      "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-5-haiku",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ced809d4-9715-4634-8b4d-ea0e09d6bb85",
        "name": "Anthropic | anthropic/claude-3-5-haiku:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3.5-haiku",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-04T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3.5 Haiku",
          "shortName": "Claude 3.5 Haiku",
          "author": "anthropic",
          "description": "Claude 3.5 Haiku features offers enhanced capabilities in speed, coding accuracy, and tool use. Engineered to excel in real-time applications, it delivers quick response times that are essential for dynamic tasks such as chat interactions and immediate coding suggestions.\n\nThis makes it highly suitable for environments that demand both speed and precision, such as software development, customer service bots, and data management systems.\n\nThis model is currently pointing to [Claude 3.5 Haiku (2024-10-22)](/anthropic/claude-3-5-haiku-20241022).",
          "modelVersionGroupId": "028ec497-a034-40fd-81fe-f51d0a0c640c",
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-5-haiku",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3.5-haiku:beta",
        "modelVariantPermaslug": "anthropic/claude-3-5-haiku:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-5-haiku-20241022",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.000004",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.00000008",
          "inputCacheWrite": "0.000001",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 47,
        "newest": 177,
        "throughputHighToLow": 153,
        "latencyLowToHigh": 187,
        "pricingLowToHigh": 219,
        "pricingHighToLow": 93
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-haiku-20241022",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 56.889,
          "latency": 1182
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "claude-3-5-haiku@20241022",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 59.854,
          "latency": 2483
        },
        {
          "name": "Amazon Bedrock",
          "icon": "https://openrouter.ai/images/icons/Bedrock.svg",
          "slug": "amazonBedrock",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 53.981,
          "latency": 1478
        },
        {
          "name": "Amazon Bedrock (US-WEST)",
          "icon": "",
          "slug": "amazonBedrock (usWest)",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 8192,
          "providerModelId": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000008",
            "inputCacheWrite": "0.000001",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.8,
          "outputCost": 4,
          "throughput": 55.934,
          "latency": 1301.5
        }
      ]
    },
    {
      "slug": "moonshotai/kimi-vl-a3b-thinking",
      "hfSlug": "moonshotai/Kimi-VL-A3B-Thinking",
      "updatedAt": "2025-04-10T17:10:17.814287+00:00",
      "createdAt": "2025-04-10T17:07:21.175402+00:00",
      "hfUpdatedAt": null,
      "name": "Moonshot AI: Kimi VL A3B Thinking (free)",
      "shortName": "Kimi VL A3B Thinking (free)",
      "author": "moonshotai",
      "description": "Kimi-VL is a lightweight Mixture-of-Experts vision-language model that activates only 2.8B parameters per step while delivering strong performance on multimodal reasoning and long-context tasks. The Kimi-VL-A3B-Thinking variant, fine-tuned with chain-of-thought and reinforcement learning, excels in math and visual reasoning benchmarks like MathVision, MMMU, and MathVista, rivaling much larger models such as Qwen2.5-VL-7B and Gemma-3-12B. It supports 128K context and high-resolution input via its MoonViT encoder.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "image",
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "moonshotai/kimi-vl-a3b-thinking",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ba332390-9210-4e73-a2c4-0fab667c7fb1",
        "name": "Chutes | moonshotai/kimi-vl-a3b-thinking:free",
        "contextLength": 131072,
        "model": {
          "slug": "moonshotai/kimi-vl-a3b-thinking",
          "hfSlug": "moonshotai/Kimi-VL-A3B-Thinking",
          "updatedAt": "2025-04-10T17:10:17.814287+00:00",
          "createdAt": "2025-04-10T17:07:21.175402+00:00",
          "hfUpdatedAt": null,
          "name": "Moonshot AI: Kimi VL A3B Thinking",
          "shortName": "Kimi VL A3B Thinking",
          "author": "moonshotai",
          "description": "Kimi-VL is a lightweight Mixture-of-Experts vision-language model that activates only 2.8B parameters per step while delivering strong performance on multimodal reasoning and long-context tasks. The Kimi-VL-A3B-Thinking variant, fine-tuned with chain-of-thought and reinforcement learning, excels in math and visual reasoning benchmarks like MathVision, MMMU, and MathVista, rivaling much larger models such as Qwen2.5-VL-7B and Gemma-3-12B. It supports 128K context and high-resolution input via its MoonViT encoder.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "image",
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "moonshotai/kimi-vl-a3b-thinking",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "moonshotai/kimi-vl-a3b-thinking:free",
        "modelVariantPermaslug": "moonshotai/kimi-vl-a3b-thinking:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "moonshotai/Kimi-VL-A3B-Thinking",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": 8,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 203,
        "newest": 55,
        "throughputHighToLow": 168,
        "latencyLowToHigh": 282,
        "pricingLowToHigh": 23,
        "pricingHighToLow": 271
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "google/learnlm-1.5-pro-experimental",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-21T19:15:51.117686+00:00",
      "hfUpdatedAt": null,
      "name": "Google: LearnLM 1.5 Pro Experimental (free)",
      "shortName": "LearnLM 1.5 Pro Experimental (free)",
      "author": "google",
      "description": "An experimental version of [Gemini 1.5 Pro](/google/gemini-pro-1.5) from Google.",
      "modelVersionGroupId": null,
      "contextLength": 32767,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/learnlm-1.5-pro-experimental",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "bf41a79d-a83a-4b05-afad-b69bcc66dddc",
        "name": "Google AI Studio | google/learnlm-1.5-pro-experimental:free",
        "contextLength": 32767,
        "model": {
          "slug": "google/learnlm-1.5-pro-experimental",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-21T19:15:51.117686+00:00",
          "hfUpdatedAt": null,
          "name": "Google: LearnLM 1.5 Pro Experimental",
          "shortName": "LearnLM 1.5 Pro Experimental",
          "author": "google",
          "description": "An experimental version of [Gemini 1.5 Pro](/google/gemini-pro-1.5) from Google.",
          "modelVersionGroupId": null,
          "contextLength": 40960,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/learnlm-1.5-pro-experimental",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/learnlm-1.5-pro-experimental:free",
        "modelVariantPermaslug": "google/learnlm-1.5-pro-experimental:free",
        "providerName": "Google AI Studio",
        "providerInfo": {
          "name": "Google AI Studio",
          "displayName": "Google AI Studio",
          "slug": "google-ai-studio",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://cloud.google.com/terms/",
            "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 55
            },
            "freeModels": {
              "training": true,
              "retainsPrompts": true,
              "retentionDays": 55
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Google AI Studio",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/GoogleAIStudio.svg"
          }
        },
        "providerDisplayName": "Google AI Studio",
        "providerModelId": "learnlm-1.5-pro-experimental",
        "providerGroup": "Google AI Studio",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": false,
        "maxPromptTokens": 32767,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://cloud.google.com/terms/",
          "privacyPolicyUrl": "https://cloud.google.com/terms/cloud-privacy-notice",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "freeModels": {
            "training": true,
            "retainsPrompts": true,
            "retentionDays": 55
          },
          "training": true,
          "retainsPrompts": true,
          "retentionDays": 55
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": 80,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 204,
        "newest": 164,
        "throughputHighToLow": 309,
        "latencyLowToHigh": 316,
        "pricingLowToHigh": 58,
        "pricingHighToLow": 306
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "deepseek/deepseek-r1-distill-qwen-1.5b",
      "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-31T12:54:27.964156+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1 Distill Qwen 1.5B",
      "shortName": "R1 Distill Qwen 1.5B",
      "author": "deepseek",
      "description": "DeepSeek R1 Distill Qwen 1.5B is a distilled large language model based on  [Qwen 2.5 Math 1.5B](https://huggingface.co/Qwen/Qwen2.5-Math-1.5B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It's a very small and efficient model which outperforms [GPT 4o 0513](/openai/gpt-4o-2024-05-13) on Math Benchmarks.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 28.9\n- AIME 2024 cons@64: 52.7\n- MATH-500 pass@1: 83.9\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-r1-distill-qwen-1.5b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "85bb5aae-0f60-4233-b275-d4e370685b3a",
        "name": "Together | deepseek/deepseek-r1-distill-qwen-1.5b",
        "contextLength": 131072,
        "model": {
          "slug": "deepseek/deepseek-r1-distill-qwen-1.5b",
          "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-31T12:54:27.964156+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1 Distill Qwen 1.5B",
          "shortName": "R1 Distill Qwen 1.5B",
          "author": "deepseek",
          "description": "DeepSeek R1 Distill Qwen 1.5B is a distilled large language model based on  [Qwen 2.5 Math 1.5B](https://huggingface.co/Qwen/Qwen2.5-Math-1.5B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It's a very small and efficient model which outperforms [GPT 4o 0513](/openai/gpt-4o-2024-05-13) on Math Benchmarks.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 28.9\n- AIME 2024 cons@64: 52.7\n- MATH-500 pass@1: 83.9\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-r1-distill-qwen-1.5b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1-distill-qwen-1.5b",
        "modelVariantPermaslug": "deepseek/deepseek-r1-distill-qwen-1.5b",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000018",
          "completion": "0.00000018",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 205,
        "newest": 130,
        "throughputHighToLow": 3,
        "latencyLowToHigh": 31,
        "pricingLowToHigh": 139,
        "pricingHighToLow": 181
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.18,
          "throughput": 334.425,
          "latency": 315
        }
      ]
    },
    {
      "slug": "anthropic/claude-3-opus",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-05T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude 3 Opus (self-moderated)",
      "shortName": "Claude 3 Opus (self-moderated)",
      "author": "anthropic",
      "description": "Claude 3 Opus is Anthropic's most powerful model for highly complex tasks. It boasts top-level performance, intelligence, fluency, and understanding.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-3-opus",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ee74a4e0-2863-4f51-99a5-997c31c48ae7",
        "name": "Anthropic | anthropic/claude-3-opus:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-3-opus",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-05T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude 3 Opus",
          "shortName": "Claude 3 Opus",
          "author": "anthropic",
          "description": "Claude 3 Opus is Anthropic's most powerful model for highly complex tasks. It boasts top-level performance, intelligence, fluency, and understanding.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)\n\n#multimodal",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-3-opus",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-3-opus:beta",
        "modelVariantPermaslug": "anthropic/claude-3-opus:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-3-opus-20240229",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000015",
          "completion": "0.000075",
          "image": "0.024",
          "request": "0",
          "inputCacheRead": "0.0000015",
          "inputCacheWrite": "0.00001875",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 135,
        "newest": 279,
        "throughputHighToLow": 247,
        "latencyLowToHigh": 232,
        "pricingLowToHigh": 309,
        "pricingHighToLow": 8
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-opus-20240229",
          "pricing": {
            "prompt": "0.000015",
            "completion": "0.000075",
            "image": "0.024",
            "request": "0",
            "inputCacheRead": "0.0000015",
            "inputCacheWrite": "0.00001875",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 15,
          "outputCost": 75,
          "throughput": 30.081,
          "latency": 1625
        },
        {
          "name": "Google Vertex",
          "icon": "https://openrouter.ai/images/icons/GoogleVertex.svg",
          "slug": "vertex",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-3-opus@20240229",
          "pricing": {
            "prompt": "0.000015",
            "completion": "0.000075",
            "image": "0.024",
            "request": "0",
            "inputCacheRead": "0.0000015",
            "inputCacheWrite": "0.00001875",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 15,
          "outputCost": 75,
          "throughput": 17.371,
          "latency": 3104
        }
      ]
    },
    {
      "slug": "mistralai/pixtral-large-2411",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-19T00:49:48.873161+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Pixtral Large 2411",
      "shortName": "Pixtral Large 2411",
      "author": "mistralai",
      "description": "Pixtral Large is a 124B parameter, open-weight, multimodal model built on top of [Mistral Large 2](/mistralai/mistral-large-2411). The model is able to understand documents, charts and natural images.\n\nThe model is available under the Mistral Research License (MRL) for research and educational use, and the Mistral Commercial License for experimentation, testing, and production for commercial purposes.\n\n",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/pixtral-large-2411",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "1a41639e-c1cf-422e-a871-27bc67f03928",
        "name": "Mistral | mistralai/pixtral-large-2411",
        "contextLength": 131072,
        "model": {
          "slug": "mistralai/pixtral-large-2411",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-19T00:49:48.873161+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Pixtral Large 2411",
          "shortName": "Pixtral Large 2411",
          "author": "mistralai",
          "description": "Pixtral Large is a 124B parameter, open-weight, multimodal model built on top of [Mistral Large 2](/mistralai/mistral-large-2411). The model is able to understand documents, charts and natural images.\n\nThe model is available under the Mistral Research License (MRL) for research and educational use, and the Mistral Commercial License for experimentation, testing, and production for commercial purposes.\n\n",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/pixtral-large-2411",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/pixtral-large-2411",
        "modelVariantPermaslug": "mistralai/pixtral-large-2411",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "pixtral-large-2411",
        "providerGroup": "Mistral",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000006",
          "image": "0.002888",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 207,
        "newest": 169,
        "throughputHighToLow": 227,
        "latencyLowToHigh": 237,
        "pricingLowToHigh": 245,
        "pricingHighToLow": 74
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "pixtral-large-2411",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000006",
            "image": "0.002888",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 2,
          "outputCost": 6,
          "throughput": 33.04,
          "latency": 1792
        }
      ]
    },
    {
      "slug": "qwen/qwen2.5-vl-3b-instruct",
      "hfSlug": "Qwen/Qwen2.5-VL-3B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-26T18:42:53.41832+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen2.5 VL 3B Instruct (free)",
      "shortName": "Qwen2.5 VL 3B Instruct (free)",
      "author": "qwen",
      "description": "Qwen2.5 VL 3B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2.5-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 64000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen2.5-vl-3b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "751df51c-753b-4849-b95a-bd5281cec4ff",
        "name": "Chutes | qwen/qwen2.5-vl-3b-instruct:free",
        "contextLength": 64000,
        "model": {
          "slug": "qwen/qwen2.5-vl-3b-instruct",
          "hfSlug": "Qwen/Qwen2.5-VL-3B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-26T18:42:53.41832+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen2.5 VL 3B Instruct",
          "shortName": "Qwen2.5 VL 3B Instruct",
          "author": "qwen",
          "description": "Qwen2.5 VL 3B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2.5-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
          "modelVersionGroupId": null,
          "contextLength": 64000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen2.5-vl-3b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen2.5-vl-3b-instruct:free",
        "modelVariantPermaslug": "qwen/qwen2.5-vl-3b-instruct:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/Qwen2.5-VL-3B-Instruct",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 208,
        "newest": 71,
        "throughputHighToLow": 63,
        "latencyLowToHigh": 267,
        "pricingLowToHigh": 30,
        "pricingHighToLow": 278
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "openai/gpt-4o-mini-search-preview",
      "hfSlug": "",
      "updatedAt": "2025-04-22T22:34:08.214467+00:00",
      "createdAt": "2025-03-12T22:22:02.718344+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4o-mini Search Preview",
      "shortName": "GPT-4o-mini Search Preview",
      "author": "openai",
      "description": "GPT-4o mini Search Preview is a specialized model for web search in Chat Completions. It is trained to understand and execute web search queries.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4o-mini-search-preview-2025-03-11",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "5154b382-e458-4539-bf6d-cbadfbaa0600",
        "name": "OpenAI | openai/gpt-4o-mini-search-preview-2025-03-11",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4o-mini-search-preview",
          "hfSlug": "",
          "updatedAt": "2025-04-22T22:34:08.214467+00:00",
          "createdAt": "2025-03-12T22:22:02.718344+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4o-mini Search Preview",
          "shortName": "GPT-4o-mini Search Preview",
          "author": "openai",
          "description": "GPT-4o mini Search Preview is a specialized model for web search in Chat Completions. It is trained to understand and execute web search queries.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4o-mini-search-preview-2025-03-11",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4o-mini-search-preview",
        "modelVariantPermaslug": "openai/gpt-4o-mini-search-preview-2025-03-11",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4o-mini-search-preview-2025-03-11",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "web_search_options",
          "max_tokens",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000006",
          "image": "0.000217",
          "request": "0.0275",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.03"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.0275"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.025"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 209,
        "newest": 90,
        "throughputHighToLow": 14,
        "latencyLowToHigh": 286,
        "pricingLowToHigh": 311,
        "pricingHighToLow": 7
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o-mini-search-preview-2025-03-11",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000006",
            "image": "0.000217",
            "request": "0.0275",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "web_search_options",
            "max_tokens",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.15,
          "outputCost": 0.6,
          "throughput": 188.349,
          "latency": 3344
        }
      ]
    },
    {
      "slug": "nothingiisreal/mn-celeste-12b",
      "hfSlug": "nothingiisreal/MN-12B-Celeste-V1.9",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral Nemo 12B Celeste",
      "shortName": "Mistral Nemo 12B Celeste",
      "author": "nothingiisreal",
      "description": "A specialized story writing and roleplaying model based on Mistral's NeMo 12B Instruct. Fine-tuned on curated datasets including Reddit Writing Prompts and Opus Instruct 25K.\n\nThis model excels at creative writing, offering improved NSFW capabilities, with smarter and more active narration. It demonstrates remarkable versatility in both SFW and NSFW scenarios, with strong Out of Character (OOC) steering capabilities, allowing fine-tuned control over narrative direction and character behavior.\n\nCheck out the model's [HuggingFace page](https://huggingface.co/nothingiisreal/MN-12B-Celeste-V1.9) for details on what parameters and prompts work best!",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nothingiisreal/mn-celeste-12b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "294ab81c-7834-4c4d-8309-302582d5c5b8",
        "name": "Featherless | nothingiisreal/mn-celeste-12b",
        "contextLength": 16384,
        "model": {
          "slug": "nothingiisreal/mn-celeste-12b",
          "hfSlug": "nothingiisreal/MN-12B-Celeste-V1.9",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-02T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral Nemo 12B Celeste",
          "shortName": "Mistral Nemo 12B Celeste",
          "author": "nothingiisreal",
          "description": "A specialized story writing and roleplaying model based on Mistral's NeMo 12B Instruct. Fine-tuned on curated datasets including Reddit Writing Prompts and Opus Instruct 25K.\n\nThis model excels at creative writing, offering improved NSFW capabilities, with smarter and more active narration. It demonstrates remarkable versatility in both SFW and NSFW scenarios, with strong Out of Character (OOC) steering capabilities, allowing fine-tuned control over narrative direction and character behavior.\n\nCheck out the model's [HuggingFace page](https://huggingface.co/nothingiisreal/MN-12B-Celeste-V1.9) for details on what parameters and prompts work best!",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nothingiisreal/mn-celeste-12b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nothingiisreal/mn-celeste-12b",
        "modelVariantPermaslug": "nothingiisreal/mn-celeste-12b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "nothingiisreal/MN-12B-Celeste-V1.9",
        "providerGroup": "Featherless",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 210,
        "newest": 226,
        "throughputHighToLow": 284,
        "latencyLowToHigh": 200,
        "pricingLowToHigh": 208,
        "pricingHighToLow": 112
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "nothingiisreal/MN-12B-Celeste-V1.9",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 17.565,
          "latency": 1434.5
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.1-8b-instruct",
      "hfSlug": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-23T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.1 8B Instruct (free)",
      "shortName": "Llama 3.1 8B Instruct (free)",
      "author": "meta-llama",
      "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 8B instruct-tuned version is fast and efficient.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "803c32ed-9861-4abf-b5da-7d9c9e6dcf04",
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.1-8b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b9e3354b-1533-4d33-9961-0ea9e6e0ff04",
        "name": "Crusoe | meta-llama/llama-3.1-8b-instruct:free",
        "contextLength": 131072,
        "model": {
          "slug": "meta-llama/llama-3.1-8b-instruct",
          "hfSlug": "meta-llama/Meta-Llama-3.1-8B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-07-23T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.1 8B Instruct",
          "shortName": "Llama 3.1 8B Instruct",
          "author": "meta-llama",
          "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 8B instruct-tuned version is fast and efficient.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": "803c32ed-9861-4abf-b5da-7d9c9e6dcf04",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.1-8b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.1-8b-instruct:free",
        "modelVariantPermaslug": "meta-llama/llama-3.1-8b-instruct:free",
        "providerName": "Crusoe",
        "providerInfo": {
          "name": "Crusoe",
          "displayName": "Crusoe",
          "slug": "crusoe",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://legal.crusoe.ai/open-router#cloud-privacy-policy",
            "termsOfServiceUrl": "https://legal.crusoe.ai/open-router#managed-inference-tos-open-router",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Crusoe",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://crusoe.ai/&size=256"
          }
        },
        "providerDisplayName": "Crusoe",
        "providerModelId": "meta-llama/Llama-3.1-8B-Instruct",
        "providerGroup": "Crusoe",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://legal.crusoe.ai/open-router#cloud-privacy-policy",
          "termsOfServiceUrl": "https://legal.crusoe.ai/open-router#managed-inference-tos-open-router",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 26,
        "newest": 229,
        "throughputHighToLow": 147,
        "latencyLowToHigh": 172,
        "pricingLowToHigh": 67,
        "pricingHighToLow": 242
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.1-8b-instruct/fp-16",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.02,
          "outputCost": 0.03,
          "throughput": 51.254,
          "latency": 1216
        },
        {
          "name": "DeepInfra (Turbo)",
          "icon": "",
          "slug": "deepInfra (turbo)",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.02,
          "outputCost": 0.03,
          "throughput": 101.8025,
          "latency": 250
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 8192,
          "providerModelId": "meta-llama/llama-3.1-8b-instruct",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.02,
          "outputCost": 0.05,
          "throughput": 78.6195,
          "latency": 720
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.02,
          "outputCost": 0.06,
          "throughput": 54.2545,
          "latency": 482
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.1-8b-instruct",
          "pricing": {
            "prompt": "0.000000025",
            "completion": "0.00000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.02,
          "outputCost": 0.04,
          "throughput": 162.054,
          "latency": 599
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.00000003",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "structured_outputs",
            "response_format",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.03,
          "outputCost": 0.05,
          "throughput": 52.068,
          "latency": 335
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": "fp8",
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.1-8b-instruct-fp8",
          "pricing": {
            "prompt": "0.000000045",
            "completion": "0.000000384",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.04,
          "outputCost": 0.38,
          "throughput": 23.518,
          "latency": 784
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama-3.1-8b-instant",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.05,
          "outputCost": 0.08,
          "throughput": 1509.833,
          "latency": 1465
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "llama3.1:8b",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.06,
          "outputCost": 0.1,
          "throughput": 115.271,
          "latency": 1593
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 268.7995,
          "latency": 981
        },
        {
          "name": "Cerebras",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cerebras.ai/&size=256",
          "slug": "cerebras",
          "quantization": "fp16",
          "context": 32000,
          "maxCompletionTokens": 32000,
          "providerModelId": "llama3.1-8b",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "response_format",
            "stop",
            "seed",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 3924.764,
          "latency": 187
        },
        {
          "name": "Friendli",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://friendli.ai/&size=256",
          "slug": "friendli",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 8000,
          "providerModelId": "meta-llama-3.1-8b-instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 282.548,
          "latency": 303
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.1,
          "outputCost": 0.2,
          "throughput": 878.542,
          "latency": 321.5
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": "fp8",
          "context": 131000,
          "maxCompletionTokens": 131000,
          "providerModelId": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.18,
          "outputCost": 0.18,
          "throughput": 62.505,
          "latency": 551
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.18,
          "throughput": 252.641,
          "latency": 313
        },
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": "unknown",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "accounts/fireworks/models/llama-v3p1-8b-instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 255.782,
          "latency": 361
        },
        {
          "name": "Avian.io",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://avian.io/&size=256",
          "slug": "avianIo",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "Meta-Llama-3.1-8B-Instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "response_format",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2
        }
      ]
    },
    {
      "slug": "arcee-ai/coder-large",
      "hfSlug": "",
      "updatedAt": "2025-05-05T21:48:22.361364+00:00",
      "createdAt": "2025-05-05T20:57:43.438481+00:00",
      "hfUpdatedAt": null,
      "name": "Arcee AI: Coder Large",
      "shortName": "Coder Large",
      "author": "arcee-ai",
      "description": "Coder‑Large is a 32 B‑parameter offspring of Qwen 2.5‑Instruct that has been further trained on permissively‑licensed GitHub, CodeSearchNet and synthetic bug‑fix corpora. It supports a 32k context window, enabling multi‑file refactoring or long diff review in a single call, and understands 30‑plus programming languages with special attention to TypeScript, Go and Terraform. Internal benchmarks show 5–8 pt gains over CodeLlama‑34 B‑Python on HumanEval and competitive BugFix scores thanks to a reinforcement pass that rewards compilable output. The model emits structured explanations alongside code blocks by default, making it suitable for educational tooling as well as production copilot scenarios. Cost‑wise, Together AI prices it well below proprietary incumbents, so teams can scale interactive coding without runaway spend. ",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "arcee-ai/coder-large",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "650746f1-a509-49e4-9660-3ecc91c025f5",
        "name": "Together | arcee-ai/coder-large",
        "contextLength": 32768,
        "model": {
          "slug": "arcee-ai/coder-large",
          "hfSlug": "",
          "updatedAt": "2025-05-05T21:48:22.361364+00:00",
          "createdAt": "2025-05-05T20:57:43.438481+00:00",
          "hfUpdatedAt": null,
          "name": "Arcee AI: Coder Large",
          "shortName": "Coder Large",
          "author": "arcee-ai",
          "description": "Coder‑Large is a 32 B‑parameter offspring of Qwen 2.5‑Instruct that has been further trained on permissively‑licensed GitHub, CodeSearchNet and synthetic bug‑fix corpora. It supports a 32k context window, enabling multi‑file refactoring or long diff review in a single call, and understands 30‑plus programming languages with special attention to TypeScript, Go and Terraform. Internal benchmarks show 5–8 pt gains over CodeLlama‑34 B‑Python on HumanEval and competitive BugFix scores thanks to a reinforcement pass that rewards compilable output. The model emits structured explanations alongside code blocks by default, making it suitable for educational tooling as well as production copilot scenarios. Cost‑wise, Together AI prices it well below proprietary incumbents, so teams can scale interactive coding without runaway spend. ",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "arcee-ai/coder-large",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "arcee-ai/coder-large",
        "modelVariantPermaslug": "arcee-ai/coder-large",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "arcee-ai/coder-large",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 212,
        "newest": 7,
        "throughputHighToLow": 81,
        "latencyLowToHigh": 22,
        "pricingLowToHigh": 182,
        "pricingHighToLow": 134
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://arcee.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "arcee-ai/coder-large",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.5,
          "outputCost": 0.8,
          "throughput": 93.633,
          "latency": 281
        }
      ]
    },
    {
      "slug": "thudm/glm-z1-32b",
      "hfSlug": "THUDM/GLM-Z1-32B-0414",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-04-17T21:09:08.005794+00:00",
      "hfUpdatedAt": null,
      "name": "THUDM: GLM Z1 32B",
      "shortName": "GLM Z1 32B",
      "author": "thudm",
      "description": "GLM-Z1-32B-0414 is an enhanced reasoning variant of GLM-4-32B, built for deep mathematical, logical, and code-oriented problem solving. It applies extended reinforcement learning—both task-specific and general pairwise preference-based—to improve performance on complex multi-step tasks. Compared to the base GLM-4-32B model, Z1 significantly boosts capabilities in structured reasoning and formal domains.\n\nThe model supports enforced “thinking” steps via prompt engineering and offers improved coherence for long-form outputs. It’s optimized for use in agentic workflows, and includes support for long context (via YaRN), JSON tool calling, and fine-grained sampling configuration for stable inference. Ideal for use cases requiring deliberate, multi-step reasoning or formal derivations.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thudm/glm-z1-32b-0414",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "f32bfaa2-38d1-4b3b-b5b7-568d2df68ca4",
        "name": "Novita | thudm/glm-z1-32b-0414",
        "contextLength": 32000,
        "model": {
          "slug": "thudm/glm-z1-32b",
          "hfSlug": "THUDM/GLM-Z1-32B-0414",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-04-17T21:09:08.005794+00:00",
          "hfUpdatedAt": null,
          "name": "THUDM: GLM Z1 32B",
          "shortName": "GLM Z1 32B",
          "author": "thudm",
          "description": "GLM-Z1-32B-0414 is an enhanced reasoning variant of GLM-4-32B, built for deep mathematical, logical, and code-oriented problem solving. It applies extended reinforcement learning—both task-specific and general pairwise preference-based—to improve performance on complex multi-step tasks. Compared to the base GLM-4-32B model, Z1 significantly boosts capabilities in structured reasoning and formal domains.\n\nThe model supports enforced “thinking” steps via prompt engineering and offers improved coherence for long-form outputs. It’s optimized for use in agentic workflows, and includes support for long context (via YaRN), JSON tool calling, and fine-grained sampling configuration for stable inference. Ideal for use cases requiring deliberate, multi-step reasoning or formal derivations.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thudm/glm-z1-32b-0414",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "thudm/glm-z1-32b",
        "modelVariantPermaslug": "thudm/glm-z1-32b-0414",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "thudm/glm-z1-32b-0414",
        "providerGroup": "Novita",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000024",
          "completion": "0.00000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 213,
        "newest": 37,
        "throughputHighToLow": 181,
        "latencyLowToHigh": 215,
        "pricingLowToHigh": 18,
        "pricingHighToLow": 161
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "thudm/glm-z1-32b-0414",
          "pricing": {
            "prompt": "0.00000024",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.24,
          "outputCost": 0.24,
          "throughput": 21.073,
          "latency": 1632
        }
      ]
    },
    {
      "slug": "cohere/command-r",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Cohere: Command R",
      "shortName": "Command R",
      "author": "cohere",
      "description": "Command-R is a 35B parameter model that performs conversational language tasks at a higher quality, more reliably, and with a longer context than previous models. It can be used for complex workflows like code generation, retrieval augmented generation (RAG), tool use, and agents.\n\nRead the launch post [here](https://txt.cohere.com/command-r/).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Cohere",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cohere/command-r",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "520aa031-d968-4fa1-9648-70c2d4a23a0a",
        "name": "Cohere | cohere/command-r",
        "contextLength": 128000,
        "model": {
          "slug": "cohere/command-r",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-14T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Cohere: Command R",
          "shortName": "Command R",
          "author": "cohere",
          "description": "Command-R is a 35B parameter model that performs conversational language tasks at a higher quality, more reliably, and with a longer context than previous models. It can be used for complex workflows like code generation, retrieval augmented generation (RAG), tool use, and agents.\n\nRead the launch post [here](https://txt.cohere.com/command-r/).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Cohere",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cohere/command-r",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cohere/command-r",
        "modelVariantPermaslug": "cohere/command-r",
        "providerName": "Cohere",
        "providerInfo": {
          "name": "Cohere",
          "displayName": "Cohere",
          "slug": "cohere",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://cohere.com/privacy",
            "termsOfServiceUrl": "https://cohere.com/terms-of-use",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cohere",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cohere.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Cohere.png"
          }
        },
        "providerDisplayName": "Cohere",
        "providerModelId": "command-r",
        "providerGroup": "Cohere",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://cohere.com/privacy",
          "termsOfServiceUrl": "https://cohere.com/terms-of-use",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 214,
        "newest": 276,
        "throughputHighToLow": 44,
        "latencyLowToHigh": 3,
        "pricingLowToHigh": 188,
        "pricingHighToLow": 127
      },
      "authorIcon": "https://openrouter.ai/images/icons/Cohere.png",
      "providers": [
        {
          "name": "Cohere",
          "icon": "https://openrouter.ai/images/icons/Cohere.png",
          "slug": "cohere",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4000,
          "providerModelId": "command-r",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 139.3455,
          "latency": 175
        }
      ]
    },
    {
      "slug": "thudm/glm-4-32b",
      "hfSlug": "THUDM/GLM-4-32B-0414",
      "updatedAt": "2025-04-17T21:06:30.647205+00:00",
      "createdAt": "2025-04-17T20:15:15.766619+00:00",
      "hfUpdatedAt": null,
      "name": "THUDM: GLM 4 32B",
      "shortName": "GLM 4 32B",
      "author": "thudm",
      "description": "GLM-4-32B-0414 is a 32B bilingual (Chinese-English) open-weight language model optimized for code generation, function calling, and agent-style tasks. Pretrained on 15T of high-quality and reasoning-heavy data, it was further refined using human preference alignment, rejection sampling, and reinforcement learning. The model excels in complex reasoning, artifact generation, and structured output tasks, achieving performance comparable to GPT-4o and DeepSeek-V3-0324 across several benchmarks.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thudm/glm-4-32b-0414",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "fa10cafb-307f-48a7-9b4a-3291cde14225",
        "name": "Novita | thudm/glm-4-32b-0414",
        "contextLength": 32000,
        "model": {
          "slug": "thudm/glm-4-32b",
          "hfSlug": "THUDM/GLM-4-32B-0414",
          "updatedAt": "2025-04-17T21:06:30.647205+00:00",
          "createdAt": "2025-04-17T20:15:15.766619+00:00",
          "hfUpdatedAt": null,
          "name": "THUDM: GLM 4 32B",
          "shortName": "GLM 4 32B",
          "author": "thudm",
          "description": "GLM-4-32B-0414 is a 32B bilingual (Chinese-English) open-weight language model optimized for code generation, function calling, and agent-style tasks. Pretrained on 15T of high-quality and reasoning-heavy data, it was further refined using human preference alignment, rejection sampling, and reinforcement learning. The model excels in complex reasoning, artifact generation, and structured output tasks, achieving performance comparable to GPT-4o and DeepSeek-V3-0324 across several benchmarks.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thudm/glm-4-32b-0414",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "thudm/glm-4-32b",
        "modelVariantPermaslug": "thudm/glm-4-32b-0414",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "thudm/glm-4-32b-0414",
        "providerGroup": "Novita",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000024",
          "completion": "0.00000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 128,
        "newest": 39,
        "throughputHighToLow": 192,
        "latencyLowToHigh": 112,
        "pricingLowToHigh": 19,
        "pricingHighToLow": 162
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "thudm/glm-4-32b-0414",
          "pricing": {
            "prompt": "0.00000024",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.24,
          "outputCost": 0.24,
          "throughput": 22.123,
          "latency": 1095
        }
      ]
    },
    {
      "slug": "anthracite-org/magnum-v4-72b",
      "hfSlug": "anthracite-org/magnum-v4-72b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Magnum v4 72B",
      "shortName": "Magnum v4 72B",
      "author": "anthracite-org",
      "description": "This is a series of models designed to replicate the prose quality of the Claude 3 models, specifically Sonnet(https://openrouter.ai/anthropic/claude-3.5-sonnet) and Opus(https://openrouter.ai/anthropic/claude-3-opus).\n\nThe model is fine-tuned on top of [Qwen2.5 72B](https://openrouter.ai/qwen/qwen-2.5-72b-instruct).",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthracite-org/magnum-v4-72b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "bdcb63ce-ae8d-449d-819b-4a229625421e",
        "name": "Mancer | anthracite-org/magnum-v4-72b",
        "contextLength": 16384,
        "model": {
          "slug": "anthracite-org/magnum-v4-72b",
          "hfSlug": "anthracite-org/magnum-v4-72b",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Magnum v4 72B",
          "shortName": "Magnum v4 72B",
          "author": "anthracite-org",
          "description": "This is a series of models designed to replicate the prose quality of the Claude 3 models, specifically Sonnet(https://openrouter.ai/anthropic/claude-3.5-sonnet) and Opus(https://openrouter.ai/anthropic/claude-3-opus).\n\nThe model is fine-tuned on top of [Qwen2.5 72B](https://openrouter.ai/qwen/qwen-2.5-72b-instruct).",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthracite-org/magnum-v4-72b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthracite-org/magnum-v4-72b",
        "modelVariantPermaslug": "anthracite-org/magnum-v4-72b",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "magnum-72b-v4",
        "providerGroup": "Mancer",
        "quantization": "fp6",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 1024,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.000001875",
          "completion": "0.00000225",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 216,
        "newest": 182,
        "throughputHighToLow": 290,
        "latencyLowToHigh": 80,
        "pricingLowToHigh": 239,
        "pricingHighToLow": 80
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "fp6",
          "context": 16384,
          "maxCompletionTokens": 1024,
          "providerModelId": "magnum-72b-v4",
          "pricing": {
            "prompt": "0.000001875",
            "completion": "0.00000225",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 1.88,
          "outputCost": 2.25,
          "throughput": 16.2965,
          "latency": 576.5
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "fp6",
          "context": 16384,
          "maxCompletionTokens": 1024,
          "providerModelId": "magnum-72b-v4",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 2.5,
          "outputCost": 3,
          "throughput": 16.323,
          "latency": 603
        },
        {
          "name": "Infermatic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256",
          "slug": "infermatic",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "anthracite-org-magnum-v4-72b-FP8-Dynamic",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 3,
          "outputCost": 3,
          "throughput": 17.825,
          "latency": 3167
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "anthracite-org/magnum-v4-72b",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 4,
          "outputCost": 6,
          "throughput": 13.755,
          "latency": 9663
        }
      ]
    },
    {
      "slug": "deepseek/deepseek-r1-distill-qwen-14b",
      "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-01-29T23:39:00.13687+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek: R1 Distill Qwen 14B (free)",
      "shortName": "R1 Distill Qwen 14B (free)",
      "author": "deepseek",
      "description": "DeepSeek R1 Distill Qwen 14B is a distilled large language model based on [Qwen 2.5 14B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 69.7\n- MATH-500 pass@1: 93.9\n- CodeForces Rating: 1481\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
      "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
      "contextLength": 64000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "deepseek/deepseek-r1-distill-qwen-14b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "d498727c-ad05-4d5c-997f-3abdf71ab15c",
        "name": "Chutes | deepseek/deepseek-r1-distill-qwen-14b:free",
        "contextLength": 64000,
        "model": {
          "slug": "deepseek/deepseek-r1-distill-qwen-14b",
          "hfSlug": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-01-29T23:39:00.13687+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek: R1 Distill Qwen 14B",
          "shortName": "R1 Distill Qwen 14B",
          "author": "deepseek",
          "description": "DeepSeek R1 Distill Qwen 14B is a distilled large language model based on [Qwen 2.5 14B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\n- AIME 2024 pass@1: 69.7\n- MATH-500 pass@1: 93.9\n- CodeForces Rating: 1481\n\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
          "modelVersionGroupId": "92d90d33-1fa7-4537-b283-b8199ac69987",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "deepseek/deepseek-r1-distill-qwen-14b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "deepseek/deepseek-r1-distill-qwen-14b:free",
        "modelVariantPermaslug": "deepseek/deepseek-r1-distill-qwen-14b:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 187,
        "newest": 135,
        "throughputHighToLow": 124,
        "latencyLowToHigh": 192,
        "pricingLowToHigh": 51,
        "pricingHighToLow": 184
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 64000,
          "maxCompletionTokens": 64000,
          "providerModelId": "deepseek/deepseek-r1-distill-qwen-14b",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.15,
          "outputCost": 0.15,
          "throughput": 45.768,
          "latency": 1328
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
          "pricing": {
            "prompt": "0.0000016",
            "completion": "0.0000016",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 1.6,
          "outputCost": 1.6,
          "throughput": 171.142,
          "latency": 360
        }
      ]
    },
    {
      "slug": "microsoft/phi-3-mini-128k-instruct",
      "hfSlug": "microsoft/Phi-3-mini-128k-instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-26T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: Phi-3 Mini 128K Instruct",
      "shortName": "Phi-3 Mini 128K Instruct",
      "author": "microsoft",
      "description": "Phi-3 Mini is a powerful 3.8B parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.\n\nAt time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. This model is static, trained on an offline dataset with an October 2023 cutoff date.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "phi3",
      "defaultSystem": null,
      "defaultStops": [
        "<|end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/phi-3-mini-128k-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b8da4002-63a2-416a-b5f5-b92d2be049dd",
        "name": "Azure | microsoft/phi-3-mini-128k-instruct",
        "contextLength": 128000,
        "model": {
          "slug": "microsoft/phi-3-mini-128k-instruct",
          "hfSlug": "microsoft/Phi-3-mini-128k-instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-26T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Microsoft: Phi-3 Mini 128K Instruct",
          "shortName": "Phi-3 Mini 128K Instruct",
          "author": "microsoft",
          "description": "Phi-3 Mini is a powerful 3.8B parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.\n\nAt time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. This model is static, trained on an offline dataset with an October 2023 cutoff date.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "phi3",
          "defaultSystem": null,
          "defaultStops": [
            "<|end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/phi-3-mini-128k-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "microsoft/phi-3-mini-128k-instruct",
        "modelVariantPermaslug": "microsoft/phi-3-mini-128k-instruct",
        "providerName": "Azure",
        "providerInfo": {
          "name": "Azure",
          "displayName": "Azure",
          "slug": "azure",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.microsoft.com/en-us/legal/terms-of-use?oneroute=true",
            "privacyPolicyUrl": "https://www.microsoft.com/en-us/privacy/privacystatement",
            "dataPolicyUrl": "https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?tabs=azure-portal",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Azure",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": "https://status.azure.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Azure.svg"
          }
        },
        "providerDisplayName": "Azure",
        "providerModelId": "phi3-mini-128k",
        "providerGroup": "Azure",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.microsoft.com/en-us/legal/terms-of-use?oneroute=true",
          "privacyPolicyUrl": "https://www.microsoft.com/en-us/privacy/privacystatement",
          "dataPolicyUrl": "https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?tabs=azure-portal",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 218,
        "newest": 253,
        "throughputHighToLow": 78,
        "latencyLowToHigh": 0,
        "pricingLowToHigh": 117,
        "pricingHighToLow": 205
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": [
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "phi3-mini-128k",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 85.059,
          "latency": 109
        }
      ]
    },
    {
      "slug": "openai/gpt-3.5-turbo-0125",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-05-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-3.5 Turbo 16k",
      "shortName": "GPT-3.5 Turbo 16k",
      "author": "openai",
      "description": "The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Training data: up to Sep 2021.\n\nThis version has a higher accuracy at responding in requested formats and a fix for a bug which caused a text encoding issue for non-English language function calls.",
      "modelVersionGroupId": null,
      "contextLength": 16385,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-3.5-turbo-0125",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9be0749c-ce48-4f4a-9e29-b74dbc29d7d6",
        "name": "OpenAI | openai/gpt-3.5-turbo-0125",
        "contextLength": 16385,
        "model": {
          "slug": "openai/gpt-3.5-turbo-0125",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-05-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-3.5 Turbo 16k",
          "shortName": "GPT-3.5 Turbo 16k",
          "author": "openai",
          "description": "The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Training data: up to Sep 2021.\n\nThis version has a higher accuracy at responding in requested formats and a fix for a bug which caused a text encoding issue for non-English language function calls.",
          "modelVersionGroupId": null,
          "contextLength": 16385,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-3.5-turbo-0125",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-3.5-turbo-0125",
        "modelVariantPermaslug": "openai/gpt-3.5-turbo-0125",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-3.5-turbo-0125",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 219,
        "newest": 316,
        "throughputHighToLow": 50,
        "latencyLowToHigh": 41,
        "pricingLowToHigh": 191,
        "pricingHighToLow": 130
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 16385,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-3.5-turbo-0125",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 130.7525,
          "latency": 396
        }
      ]
    },
    {
      "slug": "openai/gpt-3.5-turbo-1106",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-06T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-3.5 Turbo 16k (older v1106)",
      "shortName": "GPT-3.5 Turbo 16k (older v1106)",
      "author": "openai",
      "description": "An older GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Training data: up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 16385,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-3.5-turbo-1106",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "73b9d90a-d5a8-4bdd-9d59-93667d877629",
        "name": "OpenAI | openai/gpt-3.5-turbo-1106",
        "contextLength": 16385,
        "model": {
          "slug": "openai/gpt-3.5-turbo-1106",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-11-06T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-3.5 Turbo 16k (older v1106)",
          "shortName": "GPT-3.5 Turbo 16k (older v1106)",
          "author": "openai",
          "description": "An older GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Training data: up to Sep 2021.",
          "modelVersionGroupId": null,
          "contextLength": 16385,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-3.5-turbo-1106",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-3.5-turbo-1106",
        "modelVariantPermaslug": "openai/gpt-3.5-turbo-1106",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-3.5-turbo-1106",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000001",
          "completion": "0.000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 220,
        "newest": 300,
        "throughputHighToLow": 21,
        "latencyLowToHigh": 10,
        "pricingLowToHigh": 225,
        "pricingHighToLow": 99
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 16385,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-3.5-turbo-1106",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1,
          "outputCost": 2,
          "throughput": 175.9675,
          "latency": 217
        }
      ]
    },
    {
      "slug": "nousresearch/deephermes-3-llama-3-8b-preview",
      "hfSlug": "NousResearch/DeepHermes-3-Llama-3-8B-Preview",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-28T05:09:32.50188+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: DeepHermes 3 Llama 3 8B Preview (free)",
      "shortName": "DeepHermes 3 Llama 3 8B Preview (free)",
      "author": "nousresearch",
      "description": "DeepHermes 3 Preview is the latest version of our flagship Hermes series of LLMs by Nous Research, and one of the first models in the world to unify Reasoning (long chains of thought that improve answer accuracy) and normal LLM response modes into one model. We have also improved LLM annotation, judgement, and function calling.\n\nDeepHermes 3 Preview is one of the first LLM models to unify both \"intuitive\", traditional mode responses and long chain of thought reasoning responses into a single model, toggled by a system prompt.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/deephermes-3-llama-3-8b-preview",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "0e363cf8-2ac9-4f88-b85a-0020a1f60ce7",
        "name": "Chutes | nousresearch/deephermes-3-llama-3-8b-preview:free",
        "contextLength": 131072,
        "model": {
          "slug": "nousresearch/deephermes-3-llama-3-8b-preview",
          "hfSlug": "NousResearch/DeepHermes-3-Llama-3-8B-Preview",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-28T05:09:32.50188+00:00",
          "hfUpdatedAt": null,
          "name": "Nous: DeepHermes 3 Llama 3 8B Preview",
          "shortName": "DeepHermes 3 Llama 3 8B Preview",
          "author": "nousresearch",
          "description": "DeepHermes 3 Preview is the latest version of our flagship Hermes series of LLMs by Nous Research, and one of the first models in the world to unify Reasoning (long chains of thought that improve answer accuracy) and normal LLM response modes into one model. We have also improved LLM annotation, judgement, and function calling.\n\nDeepHermes 3 Preview is one of the first LLM models to unify both \"intuitive\", traditional mode responses and long chain of thought reasoning responses into a single model, toggled by a system prompt.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nousresearch/deephermes-3-llama-3-8b-preview",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nousresearch/deephermes-3-llama-3-8b-preview:free",
        "modelVariantPermaslug": "nousresearch/deephermes-3-llama-3-8b-preview:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "NousResearch/DeepHermes-3-Llama-3-8B-Preview",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 221,
        "newest": 105,
        "throughputHighToLow": 24,
        "latencyLowToHigh": 219,
        "pricingLowToHigh": 45,
        "pricingHighToLow": 293
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "deepseek/deepseek-coder",
      "hfSlug": "deepseek-ai/DeepSeek-Coder-V2-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek-Coder-V2",
      "shortName": "DeepSeek-Coder-V2",
      "author": "deepseek",
      "description": "DeepSeek-Coder-V2, an open-source Mixture-of-Experts (MoE) code language model. It is further pre-trained from an intermediate checkpoint of DeepSeek-V2 with additional 6 trillion tokens.\n\nThe original V1 model was trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese. It was pre-trained on project-level code corpus by employing a extra fill-in-the-blank task.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-coder",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "91fc52a2-a00f-4b45-b3a6-0d74a352bc07",
        "name": "Nebius | deepseek/deepseek-coder",
        "contextLength": 128000,
        "model": {
          "slug": "deepseek/deepseek-coder",
          "hfSlug": "deepseek-ai/DeepSeek-Coder-V2-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-14T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "DeepSeek-Coder-V2",
          "shortName": "DeepSeek-Coder-V2",
          "author": "deepseek",
          "description": "DeepSeek-Coder-V2, an open-source Mixture-of-Experts (MoE) code language model. It is further pre-trained from an intermediate checkpoint of DeepSeek-V2 with additional 6 trillion tokens.\n\nThe original V1 model was trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese. It was pre-trained on project-level code corpus by employing a extra fill-in-the-blank task.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "deepseek/deepseek-coder",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "deepseek/deepseek-coder",
        "modelVariantPermaslug": "deepseek/deepseek-coder",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000004",
          "completion": "0.00000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 222,
        "newest": 256,
        "throughputHighToLow": 55,
        "latencyLowToHigh": 15,
        "pricingLowToHigh": 92,
        "pricingHighToLow": 226
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.04,
          "outputCost": 0.12,
          "throughput": 123.569,
          "latency": 233
        }
      ]
    },
    {
      "slug": "perplexity/r1-1776",
      "hfSlug": "perplexity-ai/r1-1776",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-02-19T22:42:09.214134+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: R1 1776",
      "shortName": "R1 1776",
      "author": "perplexity",
      "description": "R1 1776 is a version of DeepSeek-R1 that has been post-trained to remove censorship constraints related to topics restricted by the Chinese government. The model retains its original reasoning capabilities while providing direct responses to a wider range of queries. R1 1776 is an offline chat model that does not use the perplexity search subsystem.\n\nThe model was tested on a multilingual dataset of over 1,000 examples covering sensitive topics to measure its likelihood of refusal or overly filtered responses. [Evaluation Results](https://cdn-uploads.huggingface.co/production/uploads/675c8332d01f593dc90817f5/GiN2VqC5hawUgAGJ6oHla.png) Its performance on math and reasoning benchmarks remains similar to the base R1 model. [Reasoning Performance](https://cdn-uploads.huggingface.co/production/uploads/675c8332d01f593dc90817f5/n4Z9Byqp2S7sKUvCvI40R.png)\n\nRead more on the [Blog Post](https://perplexity.ai/hub/blog/open-sourcing-r1-1776)",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "DeepSeek",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "perplexity/r1-1776",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "62190e52-ae3c-4b5b-913c-4a821a16de0b",
        "name": "Perplexity | perplexity/r1-1776",
        "contextLength": 128000,
        "model": {
          "slug": "perplexity/r1-1776",
          "hfSlug": "perplexity-ai/r1-1776",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-02-19T22:42:09.214134+00:00",
          "hfUpdatedAt": null,
          "name": "Perplexity: R1 1776",
          "shortName": "R1 1776",
          "author": "perplexity",
          "description": "R1 1776 is a version of DeepSeek-R1 that has been post-trained to remove censorship constraints related to topics restricted by the Chinese government. The model retains its original reasoning capabilities while providing direct responses to a wider range of queries. R1 1776 is an offline chat model that does not use the perplexity search subsystem.\n\nThe model was tested on a multilingual dataset of over 1,000 examples covering sensitive topics to measure its likelihood of refusal or overly filtered responses. [Evaluation Results](https://cdn-uploads.huggingface.co/production/uploads/675c8332d01f593dc90817f5/GiN2VqC5hawUgAGJ6oHla.png) Its performance on math and reasoning benchmarks remains similar to the base R1 model. [Reasoning Performance](https://cdn-uploads.huggingface.co/production/uploads/675c8332d01f593dc90817f5/n4Z9Byqp2S7sKUvCvI40R.png)\n\nRead more on the [Blog Post](https://perplexity.ai/hub/blog/open-sourcing-r1-1776)",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "DeepSeek",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "perplexity/r1-1776",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "perplexity/r1-1776",
        "modelVariantPermaslug": "perplexity/r1-1776",
        "providerName": "Perplexity",
        "providerInfo": {
          "name": "Perplexity",
          "displayName": "Perplexity",
          "slug": "perplexity",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
            "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Perplexity",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.perplexity.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Perplexity.svg"
          }
        },
        "providerDisplayName": "Perplexity",
        "providerModelId": "r1-1776",
        "providerGroup": "Perplexity",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "top_k",
          "frequency_penalty",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.perplexity.ai/hub/legal/perplexity-api-terms-of-service",
          "privacyPolicyUrl": "https://www.perplexity.ai/hub/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 223,
        "newest": 111,
        "throughputHighToLow": 121,
        "latencyLowToHigh": 164,
        "pricingLowToHigh": 251,
        "pricingHighToLow": 71
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": [
        {
          "name": "Perplexity",
          "icon": "https://openrouter.ai/images/icons/Perplexity.svg",
          "slug": "perplexity",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "r1-1776",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "top_k",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 2,
          "outputCost": 8,
          "throughput": 60.168,
          "latency": 1052
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 163840,
          "maxCompletionTokens": null,
          "providerModelId": "perplexity-ai/r1-1776",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 3,
          "outputCost": 7,
          "throughput": 69.044,
          "latency": 838
        }
      ]
    },
    {
      "slug": "open-r1/olympiccoder-32b",
      "hfSlug": "open-r1/OlympicCoder-32B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-03-15T22:20:28.942272+00:00",
      "hfUpdatedAt": null,
      "name": "OlympicCoder 32B (free)",
      "shortName": "OlympicCoder 32B (free)",
      "author": "open-r1",
      "description": "OlympicCoder-32B is a high-performing open-source model fine-tuned using the CodeForces-CoTs dataset, containing approximately 100,000 chain-of-thought programming samples. It excels at complex competitive programming benchmarks, such as IOI 2024 and Codeforces-style challenges, frequently surpassing state-of-the-art closed-source models. OlympicCoder-32B provides advanced reasoning, coherent multi-step problem-solving, and robust code generation capabilities, demonstrating significant potential for olympiad-level competitive programming applications.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "open-r1/olympiccoder-32b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "cf95d8ad-af21-42a1-9fa4-c68d7df33805",
        "name": "Chutes | open-r1/olympiccoder-32b:free",
        "contextLength": 32768,
        "model": {
          "slug": "open-r1/olympiccoder-32b",
          "hfSlug": "open-r1/OlympicCoder-32B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-03-15T22:20:28.942272+00:00",
          "hfUpdatedAt": null,
          "name": "OlympicCoder 32B",
          "shortName": "OlympicCoder 32B",
          "author": "open-r1",
          "description": "OlympicCoder-32B is a high-performing open-source model fine-tuned using the CodeForces-CoTs dataset, containing approximately 100,000 chain-of-thought programming samples. It excels at complex competitive programming benchmarks, such as IOI 2024 and Codeforces-style challenges, frequently surpassing state-of-the-art closed-source models. OlympicCoder-32B provides advanced reasoning, coherent multi-step problem-solving, and robust code generation capabilities, demonstrating significant potential for olympiad-level competitive programming applications.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "open-r1/olympiccoder-32b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "open-r1/olympiccoder-32b:free",
        "modelVariantPermaslug": "open-r1/olympiccoder-32b:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "open-r1/OlympicCoder-32B",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 224,
        "newest": 81,
        "throughputHighToLow": 143,
        "latencyLowToHigh": 275,
        "pricingLowToHigh": 36,
        "pricingHighToLow": 284
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "cohere/command-r-plus-04-2024",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Cohere: Command R+ (04-2024)",
      "shortName": "Command R+ (04-2024)",
      "author": "cohere",
      "description": "Command R+ is a new, 104B-parameter LLM from Cohere. It's useful for roleplay, general consumer usecases, and Retrieval Augmented Generation (RAG).\n\nIt offers multilingual support for ten key languages to facilitate global business operations. See benchmarks and the launch post [here](https://txt.cohere.com/command-r-plus-microsoft-azure/).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Cohere",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cohere/command-r-plus-04-2024",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "bc75924a-9b83-418a-a36d-d8d0b152ab93",
        "name": "Cohere | cohere/command-r-plus-04-2024",
        "contextLength": 128000,
        "model": {
          "slug": "cohere/command-r-plus-04-2024",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-04-02T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Cohere: Command R+ (04-2024)",
          "shortName": "Command R+ (04-2024)",
          "author": "cohere",
          "description": "Command R+ is a new, 104B-parameter LLM from Cohere. It's useful for roleplay, general consumer usecases, and Retrieval Augmented Generation (RAG).\n\nIt offers multilingual support for ten key languages to facilitate global business operations. See benchmarks and the launch post [here](https://txt.cohere.com/command-r-plus-microsoft-azure/).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Cohere",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cohere/command-r-plus-04-2024",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cohere/command-r-plus-04-2024",
        "modelVariantPermaslug": "cohere/command-r-plus-04-2024",
        "providerName": "Cohere",
        "providerInfo": {
          "name": "Cohere",
          "displayName": "Cohere",
          "slug": "cohere",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://cohere.com/privacy",
            "termsOfServiceUrl": "https://cohere.com/terms-of-use",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cohere",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cohere.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Cohere.png"
          }
        },
        "providerDisplayName": "Cohere",
        "providerModelId": "command-r-plus-04-2024",
        "providerGroup": "Cohere",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://cohere.com/privacy",
          "termsOfServiceUrl": "https://cohere.com/terms-of-use",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 225,
        "newest": 273,
        "throughputHighToLow": 151,
        "latencyLowToHigh": 35,
        "pricingLowToHigh": 277,
        "pricingHighToLow": 49
      },
      "authorIcon": "https://openrouter.ai/images/icons/Cohere.png",
      "providers": [
        {
          "name": "Cohere",
          "icon": "https://openrouter.ai/images/icons/Cohere.png",
          "slug": "cohere",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4000,
          "providerModelId": "command-r-plus-04-2024",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 3,
          "outputCost": 15,
          "throughput": 57.3725,
          "latency": 391
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.1-405b",
      "hfSlug": "meta-llama/llama-3.1-405B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.1 405B (base) (free)",
      "shortName": "Llama 3.1 405B (base) (free)",
      "author": "meta-llama",
      "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This is the base 405B pre-trained version.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "1fd9d06b-aa20-4c7d-a0b1-d3d9b5aae712",
      "contextLength": 64000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "none",
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.1-405b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "95fab27a-2e59-403e-9767-ed8a3447ba71",
        "name": "Chutes | meta-llama/llama-3.1-405b:free",
        "contextLength": 64000,
        "model": {
          "slug": "meta-llama/llama-3.1-405b",
          "hfSlug": "meta-llama/llama-3.1-405B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-02T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.1 405B (base)",
          "shortName": "Llama 3.1 405B (base)",
          "author": "meta-llama",
          "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This is the base 405B pre-trained version.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": "1fd9d06b-aa20-4c7d-a0b1-d3d9b5aae712",
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "none",
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.1-405b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.1-405b:free",
        "modelVariantPermaslug": "meta-llama/llama-3.1-405b:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "chutesai/Llama-3.1-405B-FP8",
        "providerGroup": "Chutes",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 110,
        "newest": 224,
        "throughputHighToLow": 270,
        "latencyLowToHigh": 292,
        "pricingLowToHigh": 66,
        "pricingHighToLow": 78
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-3.1-405B-FP8",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 2,
          "outputCost": 2
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "meta-llama/Meta-Llama-3.1-405B",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 4,
          "outputCost": 4,
          "throughput": 11.997,
          "latency": 1134.5
        }
      ]
    },
    {
      "slug": "qwen/qwen3-0.6b-04-28",
      "hfSlug": "Qwen/Qwen3-0.6B",
      "updatedAt": "2025-05-12T00:34:37.771851+00:00",
      "createdAt": "2025-04-30T20:05:26.503076+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 0.6B (free)",
      "shortName": "Qwen3 0.6B (free)",
      "author": "qwen",
      "description": "Qwen3-0.6B is a lightweight, 0.6 billion parameter language model in the Qwen3 series, offering support for both general-purpose dialogue and structured reasoning through a dual-mode (thinking/non-thinking) architecture. Despite its small size, it supports long contexts up to 32,768 tokens and provides multilingual, tool-use, and instruction-following capabilities.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-0.6b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "54c54d56-2d0d-4fa1-95ae-c74383a6e77e",
        "name": "Novita | qwen/qwen3-0.6b-04-28:free",
        "contextLength": 32000,
        "model": {
          "slug": "qwen/qwen3-0.6b-04-28",
          "hfSlug": "Qwen/Qwen3-0.6B",
          "updatedAt": "2025-05-12T00:34:37.771851+00:00",
          "createdAt": "2025-04-30T20:05:26.503076+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 0.6B",
          "shortName": "Qwen3 0.6B",
          "author": "qwen",
          "description": "Qwen3-0.6B is a lightweight, 0.6 billion parameter language model in the Qwen3 series, offering support for both general-purpose dialogue and structured reasoning through a dual-mode (thinking/non-thinking) architecture. Despite its small size, it supports long contexts up to 32,768 tokens and provides multilingual, tool-use, and instruction-following capabilities.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-0.6b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-0.6b-04-28:free",
        "modelVariantPermaslug": "qwen/qwen3-0.6b-04-28:free",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "qwen/qwen3-0.6b-fp8",
        "providerGroup": "Novita",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 227,
        "newest": 13,
        "throughputHighToLow": 182,
        "latencyLowToHigh": 108,
        "pricingLowToHigh": 3,
        "pricingHighToLow": 251
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "inflection/inflection-3-pi",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-11T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Inflection: Inflection 3 Pi",
      "shortName": "Inflection 3 Pi",
      "author": "inflection",
      "description": "Inflection 3 Pi powers Inflection's [Pi](https://pi.ai) chatbot, including backstory, emotional intelligence, productivity, and safety. It has access to recent news, and excels in scenarios like customer support and roleplay.\n\nPi has been trained to mirror your tone and style, if you use more emojis, so will Pi! Try experimenting with various prompts and conversation styles.",
      "modelVersionGroupId": null,
      "contextLength": 8000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "inflection/inflection-3-pi",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2dbf0c2a-b934-47dd-983d-0ad1d91a4838",
        "name": "Inflection | inflection/inflection-3-pi",
        "contextLength": 8000,
        "model": {
          "slug": "inflection/inflection-3-pi",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-11T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Inflection: Inflection 3 Pi",
          "shortName": "Inflection 3 Pi",
          "author": "inflection",
          "description": "Inflection 3 Pi powers Inflection's [Pi](https://pi.ai) chatbot, including backstory, emotional intelligence, productivity, and safety. It has access to recent news, and excels in scenarios like customer support and roleplay.\n\nPi has been trained to mirror your tone and style, if you use more emojis, so will Pi! Try experimenting with various prompts and conversation styles.",
          "modelVersionGroupId": null,
          "contextLength": 8000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "inflection/inflection-3-pi",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "inflection/inflection-3-pi",
        "modelVariantPermaslug": "inflection/inflection-3-pi",
        "providerName": "Inflection",
        "providerInfo": {
          "name": "Inflection",
          "displayName": "Inflection",
          "slug": "inflection",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://developers.inflection.ai/tos",
            "privacyPolicyUrl": "https://inflection.ai/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Inflection",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inflection.ai/&size=256"
          }
        },
        "providerDisplayName": "Inflection",
        "providerModelId": "inflection_3_pi",
        "providerGroup": "Inflection",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 1024,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://developers.inflection.ai/tos",
          "privacyPolicyUrl": "https://inflection.ai/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000025",
          "completion": "0.00001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 228,
        "newest": 192,
        "throughputHighToLow": 203,
        "latencyLowToHigh": 270,
        "pricingLowToHigh": 262,
        "pricingHighToLow": 56
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://inflection.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Inflection",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inflection.ai/&size=256",
          "slug": "inflection",
          "quantization": "unknown",
          "context": 8000,
          "maxCompletionTokens": 1024,
          "providerModelId": "inflection_3_pi",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 41.526,
          "latency": 2477
        }
      ]
    },
    {
      "slug": "arliai/qwq-32b-arliai-rpr-v1",
      "hfSlug": "ArliAI/QwQ-32B-ArliAI-RpR-v1",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-04-13T14:53:02.382429+00:00",
      "hfUpdatedAt": null,
      "name": "ArliAI: QwQ 32B RpR v1 (free)",
      "shortName": "QwQ 32B RpR v1 (free)",
      "author": "arliai",
      "description": "QwQ-32B-ArliAI-RpR-v1 is a 32B parameter model fine-tuned from Qwen/QwQ-32B using a curated creative writing and roleplay dataset originally developed for the RPMax series. It is designed to maintain coherence and reasoning across long multi-turn conversations by introducing explicit reasoning steps per dialogue turn, generated and refined using the base model itself.\n\nThe model was trained using RS-QLORA+ on 8K sequence lengths and supports up to 128K context windows (with practical performance around 32K). It is optimized for creative roleplay and dialogue generation, with an emphasis on minimizing cross-context repetition while preserving stylistic diversity.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "arliai/qwq-32b-arliai-rpr-v1",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "d6cbde45-bd1e-47b2-949e-61d0453fc229",
        "name": "Chutes | arliai/qwq-32b-arliai-rpr-v1:free",
        "contextLength": 32768,
        "model": {
          "slug": "arliai/qwq-32b-arliai-rpr-v1",
          "hfSlug": "ArliAI/QwQ-32B-ArliAI-RpR-v1",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-04-13T14:53:02.382429+00:00",
          "hfUpdatedAt": null,
          "name": "ArliAI: QwQ 32B RpR v1",
          "shortName": "QwQ 32B RpR v1",
          "author": "arliai",
          "description": "QwQ-32B-ArliAI-RpR-v1 is a 32B parameter model fine-tuned from Qwen/QwQ-32B using a curated creative writing and roleplay dataset originally developed for the RPMax series. It is designed to maintain coherence and reasoning across long multi-turn conversations by introducing explicit reasoning steps per dialogue turn, generated and refined using the base model itself.\n\nThe model was trained using RS-QLORA+ on 8K sequence lengths and supports up to 128K context windows (with practical performance around 32K). It is optimized for creative roleplay and dialogue generation, with an emphasis on minimizing cross-context repetition while preserving stylistic diversity.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "arliai/qwq-32b-arliai-rpr-v1",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "arliai/qwq-32b-arliai-rpr-v1:free",
        "modelVariantPermaslug": "arliai/qwq-32b-arliai-rpr-v1:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "ArliAI/QwQ-32B-ArliAI-RpR-v1",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 229,
        "newest": 53,
        "throughputHighToLow": 218,
        "latencyLowToHigh": 199,
        "pricingLowToHigh": 21,
        "pricingHighToLow": 269
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "mistralai/mistral-small-24b-instruct-2501",
      "hfSlug": "mistralai/Mistral-Small-24B-Instruct-2501",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-01-30T16:43:29.33592+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral Small 3 (free)",
      "shortName": "Mistral Small 3 (free)",
      "author": "mistralai",
      "description": "Mistral Small 3 is a 24B-parameter language model optimized for low-latency performance across common AI tasks. Released under the Apache 2.0 license, it features both pre-trained and instruction-tuned versions designed for efficient local deployment.\n\nThe model achieves 81% accuracy on the MMLU benchmark and performs competitively with larger models like Llama 3.3 70B and Qwen 32B, while operating at three times the speed on equivalent hardware. [Read the blog post about the model here.](https://mistral.ai/news/mistral-small-3/)",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-small-24b-instruct-2501",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "697b50b5-f19c-4b8b-b680-a0ca9b2e1f6a",
        "name": "Chutes | mistralai/mistral-small-24b-instruct-2501:free",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mistral-small-24b-instruct-2501",
          "hfSlug": "mistralai/Mistral-Small-24B-Instruct-2501",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-01-30T16:43:29.33592+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral Small 3",
          "shortName": "Mistral Small 3",
          "author": "mistralai",
          "description": "Mistral Small 3 is a 24B-parameter language model optimized for low-latency performance across common AI tasks. Released under the Apache 2.0 license, it features both pre-trained and instruction-tuned versions designed for efficient local deployment.\n\nThe model achieves 81% accuracy on the MMLU benchmark and performs competitively with larger models like Llama 3.3 70B and Qwen 32B, while operating at three times the speed on equivalent hardware. [Read the blog post about the model here.](https://mistral.ai/news/mistral-small-3/)",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-small-24b-instruct-2501",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-small-24b-instruct-2501:free",
        "modelVariantPermaslug": "mistralai/mistral-small-24b-instruct-2501:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "unsloth/Mistral-Small-24B-Instruct-2501",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 37,
        "newest": 131,
        "throughputHighToLow": 79,
        "latencyLowToHigh": 272,
        "pricingLowToHigh": 49,
        "pricingHighToLow": 216
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Enfer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256",
          "slug": "enfer",
          "quantization": null,
          "context": 28000,
          "maxCompletionTokens": 14000,
          "providerModelId": "mistralai/mistral-small-24b-instruct-2501",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logit_bias",
            "logprobs"
          ],
          "inputCost": 0.06,
          "outputCost": 0.12,
          "throughput": 29.9345,
          "latency": 6892
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral:small3",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000013",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.07,
          "outputCost": 0.13,
          "throughput": 38.234,
          "latency": 1662.5
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/Mistral-Small-24B-Instruct-2501",
          "pricing": {
            "prompt": "0.00000007",
            "completion": "0.00000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.07,
          "outputCost": 0.14,
          "throughput": 77.2675,
          "latency": 510
        },
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-small-2501",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 145.0315,
          "latency": 259
        },
        {
          "name": "Ubicloud",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.ubicloud.com/&size=256",
          "slug": "ubicloud",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "mistral-small-3",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "min_p",
            "seed",
            "response_format",
            "top_k"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 32.4045,
          "latency": 747
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "mistralai/Mistral-Small-24B-Instruct-2501",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 80.305,
          "latency": 654.5
        }
      ]
    },
    {
      "slug": "openai/o1-preview-2024-09-12",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-12T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o1-preview (2024-09-12)",
      "shortName": "o1-preview (2024-09-12)",
      "author": "openai",
      "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/o1-preview-2024-09-12",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "eb271416-aaeb-4958-bcdd-96c133f5cd7d",
        "name": "OpenAI | openai/o1-preview-2024-09-12",
        "contextLength": 128000,
        "model": {
          "slug": "openai/o1-preview-2024-09-12",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-12T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o1-preview (2024-09-12)",
          "shortName": "o1-preview (2024-09-12)",
          "author": "openai",
          "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/o1-preview-2024-09-12",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o1-preview-2024-09-12",
        "modelVariantPermaslug": "openai/o1-preview-2024-09-12",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o1-preview-2024-09-12",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "seed",
          "max_tokens"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000015",
          "completion": "0.00006",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.0000075",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 231,
        "newest": 208,
        "throughputHighToLow": 316,
        "latencyLowToHigh": 305,
        "pricingLowToHigh": 308,
        "pricingHighToLow": 12
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 32768,
          "providerModelId": "o1-preview-2024-09-12",
          "pricing": {
            "prompt": "0.000015",
            "completion": "0.00006",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.0000075",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "seed",
            "max_tokens"
          ],
          "inputCost": 15,
          "outputCost": 60,
          "throughput": 121.715,
          "latency": 7992
        }
      ]
    },
    {
      "slug": "meta-llama/llama-guard-3-8b",
      "hfSlug": "meta-llama/Llama-Guard-3-8B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-12T23:01:58.468577+00:00",
      "hfUpdatedAt": null,
      "name": "Llama Guard 3 8B",
      "shortName": "Llama Guard 3 8B",
      "author": "meta-llama",
      "description": "Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM – it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated.\n\nLlama Guard 3 was aligned to safeguard against the MLCommons standardized hazards taxonomy and designed to support Llama 3.1 capabilities. Specifically, it provides content moderation in 8 languages, and was optimized to support safety and security for search and code interpreter tool calls.\n",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "none",
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-guard-3-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b2fbbc15-67f2-4b72-94a0-112f1591f295",
        "name": "Nebius | meta-llama/llama-guard-3-8b",
        "contextLength": 131072,
        "model": {
          "slug": "meta-llama/llama-guard-3-8b",
          "hfSlug": "meta-llama/Llama-Guard-3-8B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-12T23:01:58.468577+00:00",
          "hfUpdatedAt": null,
          "name": "Llama Guard 3 8B",
          "shortName": "Llama Guard 3 8B",
          "author": "meta-llama",
          "description": "Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM – it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated.\n\nLlama Guard 3 was aligned to safeguard against the MLCommons standardized hazards taxonomy and designed to support Llama 3.1 capabilities. Specifically, it provides content moderation in 8 languages, and was optimized to support safety and security for search and code interpreter tool calls.\n",
          "modelVersionGroupId": null,
          "contextLength": 0,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "none",
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-guard-3-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-guard-3-8b",
        "modelVariantPermaslug": "meta-llama/llama-guard-3-8b",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "meta-llama/Llama-Guard-3-8B",
        "providerGroup": "Nebius",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000002",
          "completion": "0.00000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 232,
        "newest": 115,
        "throughputHighToLow": 287,
        "latencyLowToHigh": 16,
        "pricingLowToHigh": 79,
        "pricingHighToLow": 238
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-Guard-3-8B",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.02,
          "outputCost": 0.06,
          "throughput": 17.054,
          "latency": 242
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-Guard-3-8B",
          "pricing": {
            "prompt": "0.000000055",
            "completion": "0.000000055",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.06,
          "outputCost": 0.06,
          "throughput": 44.2035,
          "latency": 641.5
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Meta-Llama-Guard-3-8B",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 38.7615,
          "latency": 576
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": 8192,
          "providerModelId": "llama-guard-3-8b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": null,
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "Meta-Llama-Guard-3-8B",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 0,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-guard-3-8b",
          "pricing": {
            "prompt": "0.00000048",
            "completion": "0.00000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.48,
          "outputCost": 0.03
        }
      ]
    },
    {
      "slug": "qwen/qwen3-1.7b",
      "hfSlug": "Qwen/Qwen3-1.7B",
      "updatedAt": "2025-05-12T00:34:59.533129+00:00",
      "createdAt": "2025-04-30T16:43:08.565779+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen3 1.7B (free)",
      "shortName": "Qwen3 1.7B (free)",
      "author": "qwen",
      "description": "Qwen3-1.7B is a compact, 1.7 billion parameter dense language model from the Qwen3 series, featuring dual-mode operation for both efficient dialogue (non-thinking) and advanced reasoning (thinking). Despite its small size, it supports 32,768-token contexts and delivers strong multilingual, instruction-following, and agentic capabilities, including tool use and structured output.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen3",
      "instructType": "qwen3",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen3-1.7b-04-28",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "390a675c-72d2-4cfd-895e-63653fd3bf29",
        "name": "Novita | qwen/qwen3-1.7b-04-28:free",
        "contextLength": 32000,
        "model": {
          "slug": "qwen/qwen3-1.7b",
          "hfSlug": "Qwen/Qwen3-1.7B",
          "updatedAt": "2025-05-12T00:34:59.533129+00:00",
          "createdAt": "2025-04-30T16:43:08.565779+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen3 1.7B",
          "shortName": "Qwen3 1.7B",
          "author": "qwen",
          "description": "Qwen3-1.7B is a compact, 1.7 billion parameter dense language model from the Qwen3 series, featuring dual-mode operation for both efficient dialogue (non-thinking) and advanced reasoning (thinking). Despite its small size, it supports 32,768-token contexts and delivers strong multilingual, instruction-following, and agentic capabilities, including tool use and structured output.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen3",
          "instructType": "qwen3",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen3-1.7b-04-28",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwen3-1.7b:free",
        "modelVariantPermaslug": "qwen/qwen3-1.7b-04-28:free",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "qwen/qwen3-1.7b-fp8",
        "providerGroup": "Novita",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 233,
        "newest": 15,
        "throughputHighToLow": 175,
        "latencyLowToHigh": 123,
        "pricingLowToHigh": 4,
        "pricingHighToLow": 252
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "neversleep/noromaid-20b",
      "hfSlug": "NeverSleep/Noromaid-20b-v0.1.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-26T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Noromaid 20B",
      "shortName": "Noromaid 20B",
      "author": "neversleep",
      "description": "A collab between IkariDev and Undi. This merge is suitable for RP, ERP, and general knowledge.\n\n#merge #uncensored",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "neversleep/noromaid-20b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2a342807-616e-467d-ace8-10e1cc447a01",
        "name": "Mancer | neversleep/noromaid-20b",
        "contextLength": 8192,
        "model": {
          "slug": "neversleep/noromaid-20b",
          "hfSlug": "NeverSleep/Noromaid-20b-v0.1.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-11-26T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Noromaid 20B",
          "shortName": "Noromaid 20B",
          "author": "neversleep",
          "description": "A collab between IkariDev and Undi. This merge is suitable for RP, ERP, and general knowledge.\n\n#merge #uncensored",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "alpaca",
          "defaultSystem": null,
          "defaultStops": [
            "###",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "neversleep/noromaid-20b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "neversleep/noromaid-20b",
        "modelVariantPermaslug": "neversleep/noromaid-20b",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "noromaid",
        "providerGroup": "Mancer",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.0000009375",
          "completion": "0.0000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 234,
        "newest": 293,
        "throughputHighToLow": 271,
        "latencyLowToHigh": 170,
        "pricingLowToHigh": 216,
        "pricingHighToLow": 102
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 2048,
          "providerModelId": "noromaid",
          "pricing": {
            "prompt": "0.0000009375",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.94,
          "outputCost": 1.5,
          "throughput": 22.13,
          "latency": 1909
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 2048,
          "providerModelId": "noromaid",
          "pricing": {
            "prompt": "0.00000125",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 1.25,
          "outputCost": 2,
          "throughput": 21.8425,
          "latency": 2920.5
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.2-11b-vision-instruct",
      "hfSlug": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.2 11B Vision Instruct (free)",
      "shortName": "Llama 3.2 11B Vision Instruct (free)",
      "author": "meta-llama",
      "description": "Llama 3.2 11B Vision is a multimodal model with 11 billion parameters, designed to handle tasks combining visual and textual data. It excels in tasks such as image captioning and visual question answering, bridging the gap between language generation and visual reasoning. Pre-trained on a massive dataset of image-text pairs, it performs well in complex, high-accuracy image analysis.\n\nIts ability to integrate visual understanding with language processing makes it an ideal solution for industries requiring comprehensive visual-linguistic AI applications, such as content creation, AI-driven customer service, and research.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.2-11b-vision-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f7538554-912a-4cfe-a919-c5cfa3125617",
        "name": "Together | meta-llama/llama-3.2-11b-vision-instruct:free",
        "contextLength": 131072,
        "model": {
          "slug": "meta-llama/llama-3.2-11b-vision-instruct",
          "hfSlug": "meta-llama/Llama-3.2-11B-Vision-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.2 11B Vision Instruct",
          "shortName": "Llama 3.2 11B Vision Instruct",
          "author": "meta-llama",
          "description": "Llama 3.2 11B Vision is a multimodal model with 11 billion parameters, designed to handle tasks combining visual and textual data. It excels in tasks such as image captioning and visual question answering, bridging the gap between language generation and visual reasoning. Pre-trained on a massive dataset of image-text pairs, it performs well in complex, high-accuracy image analysis.\n\nIts ability to integrate visual understanding with language processing makes it an ideal solution for industries requiring comprehensive visual-linguistic AI applications, such as content creation, AI-driven customer service, and research.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.2-11b-vision-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.2-11b-vision-instruct:free",
        "modelVariantPermaslug": "meta-llama/llama-3.2-11b-vision-instruct:free",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "meta-llama/Llama-Vision-Free",
        "providerGroup": "Together",
        "quantization": "fp8",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 103,
        "newest": 202,
        "throughputHighToLow": 54,
        "latencyLowToHigh": 157,
        "pricingLowToHigh": 63,
        "pricingHighToLow": 223
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.2-11B-Vision-Instruct",
          "pricing": {
            "prompt": "0.000000049",
            "completion": "0.000000049",
            "image": "0.00007948",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.05,
          "outputCost": 0.05,
          "throughput": 13.236,
          "latency": 2793
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.2-11b-vision-instruct",
          "pricing": {
            "prompt": "0.000000049",
            "completion": "0.00000068",
            "image": "0.001281",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.05,
          "outputCost": 0.68,
          "throughput": 36.1495,
          "latency": 287
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.2-11b-vision-instruct",
          "pricing": {
            "prompt": "0.00000005",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.05,
          "outputCost": 0.05,
          "throughput": 119.6665,
          "latency": 249
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.2-11b-instruct/fp-16",
          "pricing": {
            "prompt": "0.000000055",
            "completion": "0.000000055",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.06,
          "outputCost": 0.06,
          "throughput": 35.308,
          "latency": 1398
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/llama-3.2-11b-vision-instruct",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.06,
          "outputCost": 0.06,
          "throughput": 60.662,
          "latency": 699
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000018",
            "image": "0.001156",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.18,
          "throughput": 140.8795,
          "latency": 407
        }
      ]
    },
    {
      "slug": "alpindale/goliath-120b",
      "hfSlug": "alpindale/goliath-120b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Goliath 120B",
      "shortName": "Goliath 120B",
      "author": "alpindale",
      "description": "A large LLM created by combining two fine-tuned Llama 70B models into one 120B model. Combines Xwin and Euryale.\n\nCredits to\n- [@chargoddard](https://huggingface.co/chargoddard) for developing the framework used to merge the model - [mergekit](https://github.com/cg123/mergekit).\n- [@Undi95](https://huggingface.co/Undi95) for helping with the merge ratios.\n\n#merge",
      "modelVersionGroupId": null,
      "contextLength": 6144,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "airoboros",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "alpindale/goliath-120b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "73654edf-bbfe-43bd-9c4c-13b858f00dc8",
        "name": "Mancer | alpindale/goliath-120b",
        "contextLength": 6144,
        "model": {
          "slug": "alpindale/goliath-120b",
          "hfSlug": "alpindale/goliath-120b",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-11-10T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Goliath 120B",
          "shortName": "Goliath 120B",
          "author": "alpindale",
          "description": "A large LLM created by combining two fine-tuned Llama 70B models into one 120B model. Combines Xwin and Euryale.\n\nCredits to\n- [@chargoddard](https://huggingface.co/chargoddard) for developing the framework used to merge the model - [mergekit](https://github.com/cg123/mergekit).\n- [@Undi95](https://huggingface.co/Undi95) for helping with the merge ratios.\n\n#merge",
          "modelVersionGroupId": null,
          "contextLength": 6144,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "airoboros",
          "defaultSystem": null,
          "defaultStops": [
            "USER:",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "alpindale/goliath-120b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "alpindale/goliath-120b",
        "modelVariantPermaslug": "alpindale/goliath-120b",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "goliath-120b",
        "providerGroup": "Mancer",
        "quantization": "int4",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 512,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.0000075",
          "completion": "0.000009375",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 236,
        "newest": 299,
        "throughputHighToLow": 286,
        "latencyLowToHigh": 258,
        "pricingLowToHigh": 295,
        "pricingHighToLow": 23
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "int4",
          "context": 6144,
          "maxCompletionTokens": 512,
          "providerModelId": "goliath-120b",
          "pricing": {
            "prompt": "0.0000075",
            "completion": "0.000009375",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 7.5,
          "outputCost": 9.38,
          "throughput": 17.0465,
          "latency": 2107.5
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "int4",
          "context": 6144,
          "maxCompletionTokens": 512,
          "providerModelId": "goliath-120b",
          "pricing": {
            "prompt": "0.00001",
            "completion": "0.0000125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 10,
          "outputCost": 12.5,
          "throughput": 20.064,
          "latency": 2041
        }
      ]
    },
    {
      "slug": "cognitivecomputations/dolphin3.0-r1-mistral-24b",
      "hfSlug": "cognitivecomputations/Dolphin3.0-R1-Mistral-24B",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-02-13T16:01:38.017763+00:00",
      "hfUpdatedAt": null,
      "name": "Dolphin3.0 R1 Mistral 24B (free)",
      "shortName": "Dolphin3.0 R1 Mistral 24B (free)",
      "author": "cognitivecomputations",
      "description": "Dolphin 3.0 R1 is the next generation of the Dolphin series of instruct-tuned models.  Designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.\n\nThe R1 version has been trained for 3 epochs to reason using 800k reasoning traces from the Dolphin-R1 dataset.\n\nDolphin aims to be a general purpose reasoning instruct model, similar to the models behind ChatGPT, Claude, Gemini.\n\nPart of the [Dolphin 3.0 Collection](https://huggingface.co/collections/cognitivecomputations/dolphin-30-677ab47f73d7ff66743979a3) Curated and trained by [Eric Hartford](https://huggingface.co/ehartford), [Ben Gitter](https://huggingface.co/bigstorm), [BlouseJury](https://huggingface.co/BlouseJury) and [Cognitive Computations](https://huggingface.co/cognitivecomputations)",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cognitivecomputations/dolphin3.0-r1-mistral-24b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "5ac910b5-4caf-40bc-a45c-f506089228b1",
        "name": "Chutes | cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
        "contextLength": 32768,
        "model": {
          "slug": "cognitivecomputations/dolphin3.0-r1-mistral-24b",
          "hfSlug": "cognitivecomputations/Dolphin3.0-R1-Mistral-24B",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-02-13T16:01:38.017763+00:00",
          "hfUpdatedAt": null,
          "name": "Dolphin3.0 R1 Mistral 24B",
          "shortName": "Dolphin3.0 R1 Mistral 24B",
          "author": "cognitivecomputations",
          "description": "Dolphin 3.0 R1 is the next generation of the Dolphin series of instruct-tuned models.  Designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.\n\nThe R1 version has been trained for 3 epochs to reason using 800k reasoning traces from the Dolphin-R1 dataset.\n\nDolphin aims to be a general purpose reasoning instruct model, similar to the models behind ChatGPT, Claude, Gemini.\n\nPart of the [Dolphin 3.0 Collection](https://huggingface.co/collections/cognitivecomputations/dolphin-30-677ab47f73d7ff66743979a3) Curated and trained by [Eric Hartford](https://huggingface.co/ehartford), [Ben Gitter](https://huggingface.co/bigstorm), [BlouseJury](https://huggingface.co/BlouseJury) and [Cognitive Computations](https://huggingface.co/cognitivecomputations)",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cognitivecomputations/dolphin3.0-r1-mistral-24b",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
        "modelVariantPermaslug": "cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "cognitivecomputations/Dolphin3.0-R1-Mistral-24B",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 237,
        "newest": 113,
        "throughputHighToLow": 112,
        "latencyLowToHigh": 249,
        "pricingLowToHigh": 46,
        "pricingHighToLow": 294
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "thudm/glm-z1-rumination-32b",
      "hfSlug": "THUDM/GLM-Z1-Rumination-32B-0414",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-04-25T17:18:15.30585+00:00",
      "hfUpdatedAt": null,
      "name": "THUDM: GLM Z1 Rumination 32B ",
      "shortName": "GLM Z1 Rumination 32B ",
      "author": "thudm",
      "description": "THUDM: GLM Z1 Rumination 32B is a 32B-parameter deep reasoning model from the GLM-4-Z1 series, optimized for complex, open-ended tasks requiring prolonged deliberation. It builds upon glm-4-32b-0414 with additional reinforcement learning phases and multi-stage alignment strategies, introducing “rumination” capabilities designed to emulate extended cognitive processing. This includes iterative reasoning, multi-hop analysis, and tool-augmented workflows such as search, retrieval, and citation-aware synthesis.\n\nThe model excels in research-style writing, comparative analysis, and intricate question answering. It supports function calling for search and navigation primitives (`search`, `click`, `open`, `finish`), enabling use in agent-style pipelines. Rumination behavior is governed by multi-turn loops with rule-based reward shaping and delayed decision mechanisms, benchmarked against Deep Research frameworks such as OpenAI’s internal alignment stacks. This variant is suitable for scenarios requiring depth over speed.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thudm/glm-z1-rumination-32b-0414",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "c61d1c8b-1e6d-4f60-97d8-893f51320223",
        "name": "Novita | thudm/glm-z1-rumination-32b-0414",
        "contextLength": 32000,
        "model": {
          "slug": "thudm/glm-z1-rumination-32b",
          "hfSlug": "THUDM/GLM-Z1-Rumination-32B-0414",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-04-25T17:18:15.30585+00:00",
          "hfUpdatedAt": null,
          "name": "THUDM: GLM Z1 Rumination 32B ",
          "shortName": "GLM Z1 Rumination 32B ",
          "author": "thudm",
          "description": "THUDM: GLM Z1 Rumination 32B is a 32B-parameter deep reasoning model from the GLM-4-Z1 series, optimized for complex, open-ended tasks requiring prolonged deliberation. It builds upon glm-4-32b-0414 with additional reinforcement learning phases and multi-stage alignment strategies, introducing “rumination” capabilities designed to emulate extended cognitive processing. This includes iterative reasoning, multi-hop analysis, and tool-augmented workflows such as search, retrieval, and citation-aware synthesis.\n\nThe model excels in research-style writing, comparative analysis, and intricate question answering. It supports function calling for search and navigation primitives (`search`, `click`, `open`, `finish`), enabling use in agent-style pipelines. Rumination behavior is governed by multi-turn loops with rule-based reward shaping and delayed decision mechanisms, benchmarked against Deep Research frameworks such as OpenAI’s internal alignment stacks. This variant is suitable for scenarios requiring depth over speed.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thudm/glm-z1-rumination-32b-0414",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "thudm/glm-z1-rumination-32b",
        "modelVariantPermaslug": "thudm/glm-z1-rumination-32b-0414",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "thudm/glm-z1-rumination-32b-0414",
        "providerGroup": "Novita",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000024",
          "completion": "0.00000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 238,
        "newest": 33,
        "throughputHighToLow": 263,
        "latencyLowToHigh": 239,
        "pricingLowToHigh": 156,
        "pricingHighToLow": 160
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "thudm/glm-z1-rumination-32b-0414",
          "pricing": {
            "prompt": "0.00000024",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.24,
          "outputCost": 0.24,
          "throughput": 20.503,
          "latency": 1572
        }
      ]
    },
    {
      "slug": "qwen/qwen-2.5-vl-7b-instruct",
      "hfSlug": "Qwen/Qwen2.5-VL-7B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen2.5-VL 7B Instruct (free)",
      "shortName": "Qwen2.5-VL 7B Instruct (free)",
      "author": "qwen",
      "description": "Qwen2.5 VL 7B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Understanding videos of 20min+: Qwen2.5-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2.5-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 64000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2-vl-7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4f1593d5-297e-433e-af46-3ebc8c84446a",
        "name": "Chutes | qwen/qwen-2-vl-7b-instruct:free",
        "contextLength": 64000,
        "model": {
          "slug": "qwen/qwen-2.5-vl-7b-instruct",
          "hfSlug": "Qwen/Qwen2.5-VL-7B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: Qwen2.5-VL 7B Instruct",
          "shortName": "Qwen2.5-VL 7B Instruct",
          "author": "qwen",
          "description": "Qwen2.5 VL 7B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Understanding videos of 20min+: Qwen2.5-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2.5-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwen-2-vl-7b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "qwen/qwen-2.5-vl-7b-instruct:free",
        "modelVariantPermaslug": "qwen/qwen-2-vl-7b-instruct:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/Qwen2.5-VL-7B-Instruct",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 64000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 115,
        "newest": 214,
        "throughputHighToLow": 80,
        "latencyLowToHigh": 153,
        "pricingLowToHigh": 65,
        "pricingHighToLow": 171
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/Qwen2.5-VL-7B-Instruct",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0.0001445",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 49.2875,
          "latency": 2055
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "bf16",
          "context": 128000,
          "maxCompletionTokens": 8192,
          "providerModelId": "qwen/qwen2.5-7b-instruct/bf-16",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 58.101,
          "latency": 3841
        },
        {
          "name": "kluster.ai",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256",
          "slug": "klusterAi",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "Qwen/Qwen2.5-VL-7B-Instruct",
          "pricing": {
            "prompt": "0.0000003",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "min_p",
            "seed"
          ],
          "inputCost": 0.3,
          "outputCost": 0.3,
          "throughput": 39.56,
          "latency": 2826
        }
      ]
    },
    {
      "slug": "microsoft/phi-4-reasoning",
      "hfSlug": "microsoft/Phi-4-reasoning",
      "updatedAt": "2025-05-01T20:20:23.543108+00:00",
      "createdAt": "2025-05-01T17:41:15.957157+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: Phi 4 Reasoning (free)",
      "shortName": "Phi 4 Reasoning (free)",
      "author": "microsoft",
      "description": "Phi-4-reasoning is a 14B parameter dense decoder-only transformer developed by Microsoft, fine-tuned from Phi-4 to enhance complex reasoning capabilities. It uses a combination of supervised fine-tuning on chain-of-thought traces and reinforcement learning, targeting math, science, and code reasoning tasks. With a 32k context window and high inference efficiency, it is optimized for structured responses in a two-part format: reasoning trace followed by a final solution.\n\nThe model achieves strong results on specialized benchmarks such as AIME, OmniMath, and LiveCodeBench, outperforming many larger models in structured reasoning tasks. It is released under the MIT license and intended for use in latency-constrained, English-only environments requiring reliable step-by-step logic. Recommended usage includes ChatML prompts and structured reasoning format for best results.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/phi-4-reasoning-04-30",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2cf5cbff-0bdf-44a4-bedb-722ca6e2d536",
        "name": "Chutes | microsoft/phi-4-reasoning-04-30:free",
        "contextLength": 32768,
        "model": {
          "slug": "microsoft/phi-4-reasoning",
          "hfSlug": "microsoft/Phi-4-reasoning",
          "updatedAt": "2025-05-01T20:20:23.543108+00:00",
          "createdAt": "2025-05-01T17:41:15.957157+00:00",
          "hfUpdatedAt": null,
          "name": "Microsoft: Phi 4 Reasoning",
          "shortName": "Phi 4 Reasoning",
          "author": "microsoft",
          "description": "Phi-4-reasoning is a 14B parameter dense decoder-only transformer developed by Microsoft, fine-tuned from Phi-4 to enhance complex reasoning capabilities. It uses a combination of supervised fine-tuning on chain-of-thought traces and reinforcement learning, targeting math, science, and code reasoning tasks. With a 32k context window and high inference efficiency, it is optimized for structured responses in a two-part format: reasoning trace followed by a final solution.\n\nThe model achieves strong results on specialized benchmarks such as AIME, OmniMath, and LiveCodeBench, outperforming many larger models in structured reasoning tasks. It is released under the MIT license and intended for use in latency-constrained, English-only environments requiring reliable step-by-step logic. Recommended usage includes ChatML prompts and structured reasoning format for best results.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/phi-4-reasoning-04-30",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "microsoft/phi-4-reasoning:free",
        "modelVariantPermaslug": "microsoft/phi-4-reasoning-04-30:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "microsoft/Phi-4-reasoning",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 240,
        "newest": 12,
        "throughputHighToLow": 32,
        "latencyLowToHigh": 173,
        "pricingLowToHigh": 2,
        "pricingHighToLow": 250
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": []
    },
    {
      "slug": "arcee-ai/arcee-blitz",
      "hfSlug": "arcee-ai/arcee-blitz",
      "updatedAt": "2025-05-05T20:32:10.090817+00:00",
      "createdAt": "2025-05-05T18:35:00.177097+00:00",
      "hfUpdatedAt": null,
      "name": "Arcee AI: Arcee Blitz",
      "shortName": "Arcee Blitz",
      "author": "arcee-ai",
      "description": "Arcee Blitz is a 24 B‑parameter dense model distilled from DeepSeek and built on Mistral architecture for \"everyday\" chat. The distillation‑plus‑refinement pipeline trims compute while keeping DeepSeek‑style reasoning, so Blitz punches above its weight on MMLU, GSM‑8K and BBH compared with other mid‑size open models. With a default 128 k context window and competitive throughput, it serves as a cost‑efficient workhorse for summarization, brainstorming and light code help. Internally, Arcee uses Blitz as the default writer in Conductor pipelines when the heavier Virtuoso line is not required. Users therefore get near‑70 B quality at ~⅓ the latency and price. ",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "arcee-ai/arcee-blitz",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b9e4eb0d-b61e-4d25-a26d-71178306bed3",
        "name": "Together | arcee-ai/arcee-blitz",
        "contextLength": 32768,
        "model": {
          "slug": "arcee-ai/arcee-blitz",
          "hfSlug": "arcee-ai/arcee-blitz",
          "updatedAt": "2025-05-05T20:32:10.090817+00:00",
          "createdAt": "2025-05-05T18:35:00.177097+00:00",
          "hfUpdatedAt": null,
          "name": "Arcee AI: Arcee Blitz",
          "shortName": "Arcee Blitz",
          "author": "arcee-ai",
          "description": "Arcee Blitz is a 24 B‑parameter dense model distilled from DeepSeek and built on Mistral architecture for \"everyday\" chat. The distillation‑plus‑refinement pipeline trims compute while keeping DeepSeek‑style reasoning, so Blitz punches above its weight on MMLU, GSM‑8K and BBH compared with other mid‑size open models. With a default 128 k context window and competitive throughput, it serves as a cost‑efficient workhorse for summarization, brainstorming and light code help. Internally, Arcee uses Blitz as the default writer in Conductor pipelines when the heavier Virtuoso line is not required. Users therefore get near‑70 B quality at ~⅓ the latency and price. ",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "arcee-ai/arcee-blitz",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "arcee-ai/arcee-blitz",
        "modelVariantPermaslug": "arcee-ai/arcee-blitz",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "arcee-ai/arcee-blitz",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000045",
          "completion": "0.00000075",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 241,
        "newest": 9,
        "throughputHighToLow": 85,
        "latencyLowToHigh": 75,
        "pricingLowToHigh": 177,
        "pricingHighToLow": 141
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://arcee.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "arcee-ai/arcee-blitz",
          "pricing": {
            "prompt": "0.00000045",
            "completion": "0.00000075",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.45,
          "outputCost": 0.75,
          "throughput": 88.758,
          "latency": 399.5
        }
      ]
    },
    {
      "slug": "eva-unit-01/eva-qwen-2.5-72b",
      "hfSlug": "EVA-UNIT-01/EVA-Qwen2.5-72B-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-21T17:36:46.956395+00:00",
      "hfUpdatedAt": null,
      "name": "EVA Qwen2.5 72B",
      "shortName": "EVA Qwen2.5 72B",
      "author": "eva-unit-01",
      "description": "EVA Qwen2.5 72B is a roleplay and storywriting specialist model. It's a full-parameter finetune of Qwen2.5-72B on mixture of synthetic and natural data.\n\nIt uses Celeste 70B 0.1 data mixture, greatly expanding it to improve versatility, creativity and \"flavor\" of the resulting model.",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "eva-unit-01/eva-qwen-2.5-72b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8b520449-b64b-4344-864d-5e0e8fe0d515",
        "name": "Featherless | eva-unit-01/eva-qwen-2.5-72b",
        "contextLength": 16384,
        "model": {
          "slug": "eva-unit-01/eva-qwen-2.5-72b",
          "hfSlug": "EVA-UNIT-01/EVA-Qwen2.5-72B-v0.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-21T17:36:46.956395+00:00",
          "hfUpdatedAt": null,
          "name": "EVA Qwen2.5 72B",
          "shortName": "EVA Qwen2.5 72B",
          "author": "eva-unit-01",
          "description": "EVA Qwen2.5 72B is a roleplay and storywriting specialist model. It's a full-parameter finetune of Qwen2.5-72B on mixture of synthetic and natural data.\n\nIt uses Celeste 70B 0.1 data mixture, greatly expanding it to improve versatility, creativity and \"flavor\" of the resulting model.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "eva-unit-01/eva-qwen-2.5-72b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "eva-unit-01/eva-qwen-2.5-72b",
        "modelVariantPermaslug": "eva-unit-01/eva-qwen-2.5-72b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "EVA-UNIT-01/EVA-Qwen2.5-72B-v0.2",
        "providerGroup": "Featherless",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000004",
          "completion": "0.000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 242,
        "newest": 165,
        "throughputHighToLow": 297,
        "latencyLowToHigh": 308,
        "pricingLowToHigh": 281,
        "pricingHighToLow": 36
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "EVA-UNIT-01/EVA-Qwen2.5-72B-v0.2",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 4,
          "outputCost": 6,
          "throughput": 13.788,
          "latency": 9402
        }
      ]
    },
    {
      "slug": "thudm/glm-z1-32b",
      "hfSlug": "THUDM/GLM-Z1-32B-0414",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-04-17T21:09:08.005794+00:00",
      "hfUpdatedAt": null,
      "name": "THUDM: GLM Z1 32B (free)",
      "shortName": "GLM Z1 32B (free)",
      "author": "thudm",
      "description": "GLM-Z1-32B-0414 is an enhanced reasoning variant of GLM-4-32B, built for deep mathematical, logical, and code-oriented problem solving. It applies extended reinforcement learning—both task-specific and general pairwise preference-based—to improve performance on complex multi-step tasks. Compared to the base GLM-4-32B model, Z1 significantly boosts capabilities in structured reasoning and formal domains.\n\nThe model supports enforced “thinking” steps via prompt engineering and offers improved coherence for long-form outputs. It’s optimized for use in agentic workflows, and includes support for long context (via YaRN), JSON tool calling, and fine-grained sampling configuration for stable inference. Ideal for use cases requiring deliberate, multi-step reasoning or formal derivations.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thudm/glm-z1-32b-0414",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "e22b972c-ea09-46e6-8028-89e654397b03",
        "name": "Chutes | thudm/glm-z1-32b-0414:free",
        "contextLength": 32768,
        "model": {
          "slug": "thudm/glm-z1-32b",
          "hfSlug": "THUDM/GLM-Z1-32B-0414",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-04-17T21:09:08.005794+00:00",
          "hfUpdatedAt": null,
          "name": "THUDM: GLM Z1 32B",
          "shortName": "GLM Z1 32B",
          "author": "thudm",
          "description": "GLM-Z1-32B-0414 is an enhanced reasoning variant of GLM-4-32B, built for deep mathematical, logical, and code-oriented problem solving. It applies extended reinforcement learning—both task-specific and general pairwise preference-based—to improve performance on complex multi-step tasks. Compared to the base GLM-4-32B model, Z1 significantly boosts capabilities in structured reasoning and formal domains.\n\nThe model supports enforced “thinking” steps via prompt engineering and offers improved coherence for long-form outputs. It’s optimized for use in agentic workflows, and includes support for long context (via YaRN), JSON tool calling, and fine-grained sampling configuration for stable inference. Ideal for use cases requiring deliberate, multi-step reasoning or formal derivations.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thudm/glm-z1-32b-0414",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "thudm/glm-z1-32b:free",
        "modelVariantPermaslug": "thudm/glm-z1-32b-0414:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "THUDM/GLM-Z1-32B-0414",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 213,
        "newest": 37,
        "throughputHighToLow": 181,
        "latencyLowToHigh": 215,
        "pricingLowToHigh": 18,
        "pricingHighToLow": 161
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": null,
          "context": 32000,
          "maxCompletionTokens": null,
          "providerModelId": "thudm/glm-z1-32b-0414",
          "pricing": {
            "prompt": "0.00000024",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.24,
          "outputCost": 0.24,
          "throughput": 21.073,
          "latency": 1632
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.2-3b-instruct",
      "hfSlug": "meta-llama/Llama-3.2-3B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.2 3B Instruct (free)",
      "shortName": "Llama 3.2 3B Instruct (free)",
      "author": "meta-llama",
      "description": "Llama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with the latest transformer architecture, it supports eight languages, including English, Spanish, and Hindi, and is adaptable for additional languages.\n\nTrained on 9 trillion tokens, the Llama 3.2 3B model excels in instruction-following, complex reasoning, and tool use. Its balanced performance makes it ideal for applications needing accuracy and efficiency in text generation across multilingual settings.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 20000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.2-3b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "25af6115-2bfe-4d4a-8c7a-71294a6d5f29",
        "name": "Nineteen | meta-llama/llama-3.2-3b-instruct:free",
        "contextLength": 20000,
        "model": {
          "slug": "meta-llama/llama-3.2-3b-instruct",
          "hfSlug": "meta-llama/Llama-3.2-3B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.2 3B Instruct",
          "shortName": "Llama 3.2 3B Instruct",
          "author": "meta-llama",
          "description": "Llama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with the latest transformer architecture, it supports eight languages, including English, Spanish, and Hindi, and is adaptable for additional languages.\n\nTrained on 9 trillion tokens, the Llama 3.2 3B model excels in instruction-following, complex reasoning, and tool use. Its balanced performance makes it ideal for applications needing accuracy and efficiency in text generation across multilingual settings.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.2-3b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.2-3b-instruct:free",
        "modelVariantPermaslug": "meta-llama/llama-3.2-3b-instruct:free",
        "providerName": "Nineteen",
        "providerInfo": {
          "name": "Nineteen",
          "displayName": "Nineteen",
          "slug": "nineteen",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://nineteen.ai/tos",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Nineteen",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nineteen.ai/&size=256"
          }
        },
        "providerDisplayName": "Nineteen",
        "providerModelId": "unsloth/Llama-3.2-3B-Instruct",
        "providerGroup": "Nineteen",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 20000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://nineteen.ai/tos",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 45,
        "newest": 197,
        "throughputHighToLow": 1,
        "latencyLowToHigh": 11,
        "pricingLowToHigh": 61,
        "pricingHighToLow": 245
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.2-3B-Instruct",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.01,
          "outputCost": 0.02,
          "throughput": 112.3055,
          "latency": 225
        },
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.2-3B-Instruct",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.01,
          "outputCost": 0.02,
          "throughput": 111.182,
          "latency": 245
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 131072,
          "providerModelId": "llama3.2-3b-instruct",
          "pricing": {
            "prompt": "0.000000015",
            "completion": "0.000000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.01,
          "outputCost": 0.02,
          "throughput": 305.3715,
          "latency": 693
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.2-3b-instruct/fp-16",
          "pricing": {
            "prompt": "0.00000002",
            "completion": "0.00000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.02,
          "outputCost": 0.02,
          "throughput": 85.271,
          "latency": 930
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/llama-3.2-3b-instruct",
          "pricing": {
            "prompt": "0.00000003",
            "completion": "0.00000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.03,
          "outputCost": 0.05,
          "throughput": 108.7615,
          "latency": 559
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.2-3b-instruct",
          "pricing": {
            "prompt": "0.000000051",
            "completion": "0.00000034",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.05,
          "outputCost": 0.34,
          "throughput": 157.798,
          "latency": 575
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
          "pricing": {
            "prompt": "0.00000006",
            "completion": "0.00000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.06,
          "outputCost": 0.06,
          "throughput": 163.087,
          "latency": 569.5
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "Meta-Llama-3.2-3B-Instruct",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000016",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.08,
          "outputCost": 0.16,
          "throughput": 3051.282,
          "latency": 653.5
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.2-3B-Instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.1,
          "outputCost": 0.1,
          "throughput": 113.793,
          "latency": 1108
        }
      ]
    },
    {
      "slug": "aion-labs/aion-rp-llama-3.1-8b",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-04T19:18:38.521648+00:00",
      "hfUpdatedAt": null,
      "name": "AionLabs: Aion-RP 1.0 (8B)",
      "shortName": "Aion-RP 1.0 (8B)",
      "author": "aion-labs",
      "description": "Aion-RP-Llama-3.1-8B ranks the highest in the character evaluation portion of the RPBench-Auto benchmark, a roleplaying-specific variant of Arena-Hard-Auto, where LLMs evaluate each other’s responses. It is a fine-tuned base model rather than an instruct model, designed to produce more natural and varied writing.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "aion-labs/aion-rp-llama-3.1-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "fd456f92-a506-4249-8527-988e9c1d84b3",
        "name": "AionLabs | aion-labs/aion-rp-llama-3.1-8b",
        "contextLength": 32768,
        "model": {
          "slug": "aion-labs/aion-rp-llama-3.1-8b",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-04T19:18:38.521648+00:00",
          "hfUpdatedAt": null,
          "name": "AionLabs: Aion-RP 1.0 (8B)",
          "shortName": "Aion-RP 1.0 (8B)",
          "author": "aion-labs",
          "description": "Aion-RP-Llama-3.1-8B ranks the highest in the character evaluation portion of the RPBench-Auto benchmark, a roleplaying-specific variant of Arena-Hard-Auto, where LLMs evaluate each other’s responses. It is a fine-tuned base model rather than an instruct model, designed to produce more natural and varied writing.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "aion-labs/aion-rp-llama-3.1-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "aion-labs/aion-rp-llama-3.1-8b",
        "modelVariantPermaslug": "aion-labs/aion-rp-llama-3.1-8b",
        "providerName": "AionLabs",
        "providerInfo": {
          "name": "AionLabs",
          "displayName": "AionLabs",
          "slug": "aion-labs",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.aionlabs.ai/terms/",
            "privacyPolicyUrl": "https://www.aionlabs.ai/privacy-policy/",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "AionLabs",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.aionlabs.ai/&size=256"
          }
        },
        "providerDisplayName": "AionLabs",
        "providerModelId": "aion-labs/aion-rp-llama-3.1-8b",
        "providerGroup": "AionLabs",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.aionlabs.ai/terms/",
          "privacyPolicyUrl": "https://www.aionlabs.ai/privacy-policy/",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000002",
          "completion": "0.0000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 245,
        "newest": 122,
        "throughputHighToLow": 197,
        "latencyLowToHigh": 207,
        "pricingLowToHigh": 146,
        "pricingHighToLow": 170
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://www.aionlabs.ai/\\u0026size=256",
      "providers": [
        {
          "name": "AionLabs",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.aionlabs.ai/&size=256",
          "slug": "aionLabs",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "aion-labs/aion-rp-llama-3.1-8b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 43.0425,
          "latency": 1423
        }
      ]
    },
    {
      "slug": "openai/o1-preview",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-12T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o1-preview",
      "shortName": "o1-preview",
      "author": "openai",
      "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/o1-preview",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "dde17d0c-3752-4967-84d5-a2b8d68a08d1",
        "name": "OpenAI | openai/o1-preview",
        "contextLength": 128000,
        "model": {
          "slug": "openai/o1-preview",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-12T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o1-preview",
          "shortName": "o1-preview",
          "author": "openai",
          "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/o1-preview",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o1-preview",
        "modelVariantPermaslug": "openai/o1-preview",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o1-preview",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "seed",
          "max_tokens"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000015",
          "completion": "0.00006",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.0000075",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 246,
        "newest": 207,
        "throughputHighToLow": 315,
        "latencyLowToHigh": 182,
        "pricingLowToHigh": 307,
        "pricingHighToLow": 11
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 32768,
          "providerModelId": "o1-preview",
          "pricing": {
            "prompt": "0.000015",
            "completion": "0.00006",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.0000075",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "seed",
            "max_tokens"
          ],
          "inputCost": 15,
          "outputCost": 60,
          "throughput": 109.215,
          "latency": 6129
        }
      ]
    },
    {
      "slug": "neversleep/llama-3.1-lumimaid-70b",
      "hfSlug": "NeverSleep/Lumimaid-v0.2-70B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "NeverSleep: Lumimaid v0.2 70B",
      "shortName": "Lumimaid v0.2 70B",
      "author": "neversleep",
      "description": "Lumimaid v0.2 70B is a finetune of [Llama 3.1 70B](/meta-llama/llama-3.1-70b-instruct) with a \"HUGE step up dataset wise\" compared to Lumimaid v0.1. Sloppy chats output were purged.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "neversleep/llama-3.1-lumimaid-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "038f8829-809b-4f91-a531-6a9881751186",
        "name": "Mancer | neversleep/llama-3.1-lumimaid-70b",
        "contextLength": 16384,
        "model": {
          "slug": "neversleep/llama-3.1-lumimaid-70b",
          "hfSlug": "NeverSleep/Lumimaid-v0.2-70B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "NeverSleep: Lumimaid v0.2 70B",
          "shortName": "Lumimaid v0.2 70B",
          "author": "neversleep",
          "description": "Lumimaid v0.2 70B is a finetune of [Llama 3.1 70B](/meta-llama/llama-3.1-70b-instruct) with a \"HUGE step up dataset wise\" compared to Lumimaid v0.1. Sloppy chats output were purged.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "neversleep/llama-3.1-lumimaid-70b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "neversleep/llama-3.1-lumimaid-70b",
        "modelVariantPermaslug": "neversleep/llama-3.1-lumimaid-70b",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "lumi-70b-v2",
        "providerGroup": "Mancer",
        "quantization": "fp16",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.000001875",
          "completion": "0.00000225",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 247,
        "newest": 181,
        "throughputHighToLow": 288,
        "latencyLowToHigh": 122,
        "pricingLowToHigh": 238,
        "pricingHighToLow": 79
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 2048,
          "providerModelId": "lumi-70b-v2",
          "pricing": {
            "prompt": "0.000001875",
            "completion": "0.00000225",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 1.88,
          "outputCost": 2.25,
          "throughput": 16.484,
          "latency": 727
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 2048,
          "providerModelId": "lumi-70b-v2",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 2.5,
          "outputCost": 3,
          "throughput": 16.399,
          "latency": 1076
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "NeverSleep/Lumimaid-v0.2-70B",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 4,
          "outputCost": 6,
          "throughput": 13.727,
          "latency": 8779
        }
      ]
    },
    {
      "slug": "mistralai/mistral-7b-instruct-v0.3",
      "hfSlug": "mistralai/Mistral-7B-Instruct-v0.3",
      "updatedAt": "2025-04-28T20:21:03.247395+00:00",
      "createdAt": "2024-05-27T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral 7B Instruct v0.3",
      "shortName": "Mistral 7B Instruct v0.3",
      "author": "mistralai",
      "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\nAn improved version of [Mistral 7B Instruct v0.2](/models/mistralai/mistral-7b-instruct-v0.2), with the following changes:\n\n- Extended vocabulary to 32768\n- Supports v3 Tokenizer\n- Supports function calling\n\nNOTE: Support for function calling depends on the provider.",
      "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-7b-instruct-v0.3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3b4d5f07-3c11-47c3-8a2b-97a5337d92fa",
        "name": "Enfer | mistralai/mistral-7b-instruct-v0.3",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mistral-7b-instruct-v0.3",
          "hfSlug": "mistralai/Mistral-7B-Instruct-v0.3",
          "updatedAt": "2025-04-28T20:21:03.247395+00:00",
          "createdAt": "2024-05-27T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral 7B Instruct v0.3",
          "shortName": "Mistral 7B Instruct v0.3",
          "author": "mistralai",
          "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\nAn improved version of [Mistral 7B Instruct v0.2](/models/mistralai/mistral-7b-instruct-v0.2), with the following changes:\n\n- Extended vocabulary to 32768\n- Supports v3 Tokenizer\n- Supports function calling\n\nNOTE: Support for function calling depends on the provider.",
          "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-7b-instruct-v0.3",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-7b-instruct-v0.3",
        "modelVariantPermaslug": "mistralai/mistral-7b-instruct-v0.3",
        "providerName": "Enfer",
        "providerInfo": {
          "name": "Enfer",
          "displayName": "Enfer",
          "slug": "enfer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://enfer.ai/privacy-policy",
            "privacyPolicyUrl": "https://enfer.ai/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Enfer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256"
          }
        },
        "providerDisplayName": "Enfer",
        "providerModelId": "mistralai/mistral-7b-instruct-v0-3",
        "providerGroup": "Enfer",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 16384,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "logit_bias",
          "logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://enfer.ai/privacy-policy",
          "privacyPolicyUrl": "https://enfer.ai/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000000028",
          "completion": "0.000000054",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 248,
        "newest": 252,
        "throughputHighToLow": 67,
        "latencyLowToHigh": 293,
        "pricingLowToHigh": 84,
        "pricingHighToLow": 235
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Enfer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://enfer.ai/&size=256",
          "slug": "enfer",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/mistral-7b-instruct-v0-3",
          "pricing": {
            "prompt": "0.000000028",
            "completion": "0.000000054",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logit_bias",
            "logprobs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.05,
          "throughput": 115.0915,
          "latency": 4562.5
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": 16384,
          "providerModelId": "mistralai/Mistral-7B-Instruct-v0.3",
          "pricing": {
            "prompt": "0.000000029",
            "completion": "0.000000055",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 111.213,
          "latency": 590
        },
        {
          "name": "NextBit",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nextbit256.com/&size=256",
          "slug": "nextBit",
          "quantization": "bf16",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral:7b",
          "pricing": {
            "prompt": "0.000000029",
            "completion": "0.000000058",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 62.988,
          "latency": 1872
        },
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistralai/mistral-7b-instruct",
          "pricing": {
            "prompt": "0.000000029",
            "completion": "0.000000059",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.03,
          "outputCost": 0.06,
          "throughput": 158.323,
          "latency": 1094
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": 4096,
          "providerModelId": "mistralai/Mistral-7B-Instruct-v0.3",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 215.931,
          "latency": 1034
        }
      ]
    },
    {
      "slug": "scb10x/llama3.1-typhoon2-70b-instruct",
      "hfSlug": "scb10x/llama3.1-typhoon2-70b-instruct",
      "updatedAt": "2025-03-28T21:15:16.004765+00:00",
      "createdAt": "2025-03-28T21:09:30.941107+00:00",
      "hfUpdatedAt": null,
      "name": "Typhoon2 70B Instruct",
      "shortName": "Typhoon2 70B Instruct",
      "author": "scb10x",
      "description": "Llama3.1-Typhoon2-70B-Instruct is a Thai-English instruction-tuned language model with 70 billion parameters, built on Llama 3.1. It demonstrates strong performance across general instruction-following, math, coding, and tool-use tasks, with state-of-the-art results in Thai-specific benchmarks such as IFEval, MT-Bench, and Thai-English code-switching.\n\nThe model excels in bilingual reasoning and function-calling scenarios, offering high accuracy across diverse domains. Comparative evaluations show consistent improvements over prior Thai LLMs and other Llama-based baselines. Full results and methodology are available in the [technical report.](https://arxiv.org/abs/2412.13702)",
      "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "scb10x/llama3.1-typhoon2-70b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "a7742414-57da-42fb-8657-08f317ace8f6",
        "name": "Together | scb10x/llama3.1-typhoon2-70b-instruct",
        "contextLength": 8192,
        "model": {
          "slug": "scb10x/llama3.1-typhoon2-70b-instruct",
          "hfSlug": "scb10x/llama3.1-typhoon2-70b-instruct",
          "updatedAt": "2025-03-28T21:15:16.004765+00:00",
          "createdAt": "2025-03-28T21:09:30.941107+00:00",
          "hfUpdatedAt": null,
          "name": "Typhoon2 70B Instruct",
          "shortName": "Typhoon2 70B Instruct",
          "author": "scb10x",
          "description": "Llama3.1-Typhoon2-70B-Instruct is a Thai-English instruction-tuned language model with 70 billion parameters, built on Llama 3.1. It demonstrates strong performance across general instruction-following, math, coding, and tool-use tasks, with state-of-the-art results in Thai-specific benchmarks such as IFEval, MT-Bench, and Thai-English code-switching.\n\nThe model excels in bilingual reasoning and function-calling scenarios, offering high accuracy across diverse domains. Comparative evaluations show consistent improvements over prior Thai LLMs and other Llama-based baselines. Full results and methodology are available in the [technical report.](https://arxiv.org/abs/2412.13702)",
          "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "scb10x/llama3.1-typhoon2-70b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "scb10x/llama3.1-typhoon2-70b-instruct",
        "modelVariantPermaslug": "scb10x/llama3.1-typhoon2-70b-instruct",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "scb10x/scb10x-llama3-1-typhoon2-70b-instruct",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000088",
          "completion": "0.00000088",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 249,
        "newest": 69,
        "throughputHighToLow": 224,
        "latencyLowToHigh": 146,
        "pricingLowToHigh": 211,
        "pricingHighToLow": 107
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "scb10x/scb10x-llama3-1-typhoon2-70b-instruct",
          "pricing": {
            "prompt": "0.00000088",
            "completion": "0.00000088",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.88,
          "outputCost": 0.88,
          "throughput": 36.394,
          "latency": 827
        }
      ]
    },
    {
      "slug": "sophosympatheia/midnight-rose-70b",
      "hfSlug": "sophosympatheia/Midnight-Rose-70B-v2.0.3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Midnight Rose 70B",
      "shortName": "Midnight Rose 70B",
      "author": "sophosympatheia",
      "description": "A merge with a complex family tree, this model was crafted for roleplaying and storytelling. Midnight Rose is a successor to Rogue Rose and Aurora Nights and improves upon them both. It wants to produce lengthy output by default and is the best creative writing merge produced so far by sophosympatheia.\n\nDescending from earlier versions of Midnight Rose and [Wizard Tulu Dolphin 70B](https://huggingface.co/sophosympatheia/Wizard-Tulu-Dolphin-70B-v1.0), it inherits the best qualities of each.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "airoboros",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "sophosympatheia/midnight-rose-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4696e1af-049d-4b3f-99f2-2dc374bfaf5f",
        "name": "Novita | sophosympatheia/midnight-rose-70b",
        "contextLength": 4096,
        "model": {
          "slug": "sophosympatheia/midnight-rose-70b",
          "hfSlug": "sophosympatheia/Midnight-Rose-70B-v2.0.3",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Midnight Rose 70B",
          "shortName": "Midnight Rose 70B",
          "author": "sophosympatheia",
          "description": "A merge with a complex family tree, this model was crafted for roleplaying and storytelling. Midnight Rose is a successor to Rogue Rose and Aurora Nights and improves upon them both. It wants to produce lengthy output by default and is the best creative writing merge produced so far by sophosympatheia.\n\nDescending from earlier versions of Midnight Rose and [Wizard Tulu Dolphin 70B](https://huggingface.co/sophosympatheia/Wizard-Tulu-Dolphin-70B-v1.0), it inherits the best qualities of each.",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "airoboros",
          "defaultSystem": null,
          "defaultStops": [
            "USER:",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "sophosympatheia/midnight-rose-70b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "sophosympatheia/midnight-rose-70b",
        "modelVariantPermaslug": "sophosympatheia/midnight-rose-70b",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "sophosympatheia/midnight-rose-70b",
        "providerGroup": "Novita",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 250,
        "newest": 274,
        "throughputHighToLow": 289,
        "latencyLowToHigh": 262,
        "pricingLowToHigh": 202,
        "pricingHighToLow": 118
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 4096,
          "maxCompletionTokens": null,
          "providerModelId": "sophosympatheia/midnight-rose-70b",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.8,
          "outputCost": 0.8,
          "throughput": 16.344,
          "latency": 2213
        }
      ]
    },
    {
      "slug": "mistralai/codestral-mamba",
      "hfSlug": "mistralai/mamba-codestral-7B-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-19T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Codestral Mamba",
      "shortName": "Codestral Mamba",
      "author": "mistralai",
      "description": "A 7.3B parameter Mamba-based model designed for code and reasoning tasks.\n\n- Linear time inference, allowing for theoretically infinite sequence lengths\n- 256k token context window\n- Optimized for quick responses, especially beneficial for code productivity\n- Performs comparably to state-of-the-art transformer models in code and reasoning tasks\n- Available under the Apache 2.0 license for free use, modification, and distribution",
      "modelVersionGroupId": null,
      "contextLength": 262144,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/codestral-mamba",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "52a1a2d3-8aee-4799-b93b-48cf71199b6c",
        "name": "Mistral | mistralai/codestral-mamba",
        "contextLength": 262144,
        "model": {
          "slug": "mistralai/codestral-mamba",
          "hfSlug": "mistralai/mamba-codestral-7B-v0.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-07-19T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Codestral Mamba",
          "shortName": "Codestral Mamba",
          "author": "mistralai",
          "description": "A 7.3B parameter Mamba-based model designed for code and reasoning tasks.\n\n- Linear time inference, allowing for theoretically infinite sequence lengths\n- 256k token context window\n- Optimized for quick responses, especially beneficial for code productivity\n- Performs comparably to state-of-the-art transformer models in code and reasoning tasks\n- Available under the Apache 2.0 license for free use, modification, and distribution",
          "modelVersionGroupId": null,
          "contextLength": 256000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/codestral-mamba",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/codestral-mamba",
        "modelVariantPermaslug": "mistralai/codestral-mamba",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "open-codestral-mamba",
        "providerGroup": "Mistral",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000025",
          "completion": "0.00000025",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 251,
        "newest": 233,
        "throughputHighToLow": 66,
        "latencyLowToHigh": 29,
        "pricingLowToHigh": 160,
        "pricingHighToLow": 157
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 262144,
          "maxCompletionTokens": null,
          "providerModelId": "open-codestral-mamba",
          "pricing": {
            "prompt": "0.00000025",
            "completion": "0.00000025",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "seed"
          ],
          "inputCost": 0.25,
          "outputCost": 0.25,
          "throughput": 109.497,
          "latency": 310
        }
      ]
    },
    {
      "slug": "mistralai/mistral-saba",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-17T14:40:39.116446+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Saba",
      "shortName": "Saba",
      "author": "mistralai",
      "description": "Mistral Saba is a 24B-parameter language model specifically designed for the Middle East and South Asia, delivering accurate and contextually relevant responses while maintaining efficient performance. Trained on curated regional datasets, it supports multiple Indian-origin languages—including Tamil and Malayalam—alongside Arabic. This makes it a versatile option for a range of regional and multilingual applications. Read more at the blog post [here](https://mistral.ai/en/news/mistral-saba)",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-saba-2502",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "c5a8bebe-8564-47ed-9d05-4151aa3c6e3a",
        "name": "Mistral | mistralai/mistral-saba-2502",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mistral-saba",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-17T14:40:39.116446+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Saba",
          "shortName": "Saba",
          "author": "mistralai",
          "description": "Mistral Saba is a 24B-parameter language model specifically designed for the Middle East and South Asia, delivering accurate and contextually relevant responses while maintaining efficient performance. Trained on curated regional datasets, it supports multiple Indian-origin languages—including Tamil and Malayalam—alongside Arabic. This makes it a versatile option for a range of regional and multilingual applications. Read more at the blog post [here](https://mistral.ai/en/news/mistral-saba)",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-saba-2502",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-saba",
        "modelVariantPermaslug": "mistralai/mistral-saba-2502",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "mistral-saba-latest",
        "providerGroup": "Mistral",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000002",
          "completion": "0.0000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 252,
        "newest": 112,
        "throughputHighToLow": 94,
        "latencyLowToHigh": 17,
        "pricingLowToHigh": 154,
        "pricingHighToLow": 163
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-saba-latest",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 0.2,
          "outputCost": 0.6,
          "throughput": 81.694,
          "latency": 248
        },
        {
          "name": "Groq",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256",
          "slug": "groq",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 32768,
          "providerModelId": "mistral-saba-24b",
          "pricing": {
            "prompt": "0.00000079",
            "completion": "0.00000079",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "top_logprobs",
            "logprobs",
            "logit_bias",
            "seed"
          ],
          "inputCost": 0.79,
          "outputCost": 0.79,
          "throughput": 425.554,
          "latency": 358
        }
      ]
    },
    {
      "slug": "openai/gpt-3.5-turbo-0613",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-3.5 Turbo (older v0613)",
      "shortName": "GPT-3.5 Turbo (older v0613)",
      "author": "openai",
      "description": "GPT-3.5 Turbo is OpenAI's fastest model. It can understand and generate natural language or code, and is optimized for chat and traditional completion tasks.\n\nTraining data up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 4095,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-3.5-turbo-0613",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f29e5bba-56f3-408a-a036-185e3dc20be3",
        "name": "Azure | openai/gpt-3.5-turbo-0613",
        "contextLength": 4095,
        "model": {
          "slug": "openai/gpt-3.5-turbo-0613",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-01-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-3.5 Turbo (older v0613)",
          "shortName": "GPT-3.5 Turbo (older v0613)",
          "author": "openai",
          "description": "GPT-3.5 Turbo is OpenAI's fastest model. It can understand and generate natural language or code, and is optimized for chat and traditional completion tasks.\n\nTraining data up to Sep 2021.",
          "modelVersionGroupId": null,
          "contextLength": 4095,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-3.5-turbo-0613",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-3.5-turbo-0613",
        "modelVariantPermaslug": "openai/gpt-3.5-turbo-0613",
        "providerName": "Azure",
        "providerInfo": {
          "name": "Azure",
          "displayName": "Azure",
          "slug": "azure",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.microsoft.com/en-us/legal/terms-of-use?oneroute=true",
            "privacyPolicyUrl": "https://www.microsoft.com/en-us/privacy/privacystatement",
            "dataPolicyUrl": "https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?tabs=azure-portal",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Azure",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": "https://status.azure.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Azure.svg"
          }
        },
        "providerDisplayName": "Azure",
        "providerModelId": "gpt-35-turbo",
        "providerGroup": "Azure",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.microsoft.com/en-us/legal/terms-of-use?oneroute=true",
          "privacyPolicyUrl": "https://www.microsoft.com/en-us/privacy/privacystatement",
          "dataPolicyUrl": "https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?tabs=azure-portal",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000001",
          "completion": "0.000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 253,
        "newest": 285,
        "throughputHighToLow": 22,
        "latencyLowToHigh": 156,
        "pricingLowToHigh": 224,
        "pricingHighToLow": 98
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 4095,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-35-turbo",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1,
          "outputCost": 2,
          "throughput": 159.411,
          "latency": 942
        }
      ]
    },
    {
      "slug": "bytedance-research/ui-tars-72b",
      "hfSlug": "bytedance-research/UI-TARS-72B-DPO",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-26T20:14:25.673407+00:00",
      "hfUpdatedAt": null,
      "name": "Bytedance: UI-TARS 72B  (free)",
      "shortName": "UI-TARS 72B  (free)",
      "author": "bytedance-research",
      "description": "UI-TARS 72B is an open-source multimodal AI model designed specifically for automating browser and desktop tasks through visual interaction and control. The model is built with a specialized vision architecture enabling accurate interpretation and manipulation of on-screen visual data. It supports automation tasks within web browsers as well as desktop applications, including Microsoft Office and VS Code.\n\nCore capabilities include intelligent screen detection, predictive action modeling, and efficient handling of repetitive interactions. UI-TARS employs supervised fine-tuning (SFT) tailored explicitly for computer control scenarios. It can be deployed locally or accessed via Hugging Face for demonstration purposes. Intended use cases encompass workflow automation, task scripting, and interactive desktop control applications.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "bytedance-research/ui-tars-72b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e480b8f8-44f2-42cb-bcec-5488d3341b07",
        "name": "Chutes | bytedance-research/ui-tars-72b:free",
        "contextLength": 32768,
        "model": {
          "slug": "bytedance-research/ui-tars-72b",
          "hfSlug": "bytedance-research/UI-TARS-72B-DPO",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-26T20:14:25.673407+00:00",
          "hfUpdatedAt": null,
          "name": "Bytedance: UI-TARS 72B ",
          "shortName": "UI-TARS 72B ",
          "author": "bytedance-research",
          "description": "UI-TARS 72B is an open-source multimodal AI model designed specifically for automating browser and desktop tasks through visual interaction and control. The model is built with a specialized vision architecture enabling accurate interpretation and manipulation of on-screen visual data. It supports automation tasks within web browsers as well as desktop applications, including Microsoft Office and VS Code.\n\nCore capabilities include intelligent screen detection, predictive action modeling, and efficient handling of repetitive interactions. UI-TARS employs supervised fine-tuning (SFT) tailored explicitly for computer control scenarios. It can be deployed locally or accessed via Hugging Face for demonstration purposes. Intended use cases encompass workflow automation, task scripting, and interactive desktop control applications.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "bytedance-research/ui-tars-72b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "bytedance-research/ui-tars-72b:free",
        "modelVariantPermaslug": "bytedance-research/ui-tars-72b:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "bytedance-research/UI-TARS-72B-DPO",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 254,
        "newest": 70,
        "throughputHighToLow": 285,
        "latencyLowToHigh": 296,
        "pricingLowToHigh": 29,
        "pricingHighToLow": 277
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "ai21/jamba-1.6-large",
      "hfSlug": "ai21labs/AI21-Jamba-Large-1.6",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-13T22:32:53+00:00",
      "hfUpdatedAt": null,
      "name": "AI21: Jamba 1.6 Large",
      "shortName": "Jamba 1.6 Large",
      "author": "ai21",
      "description": "AI21 Jamba Large 1.6 is a high-performance hybrid foundation model combining State Space Models (Mamba) with Transformer attention mechanisms. Developed by AI21, it excels in extremely long-context handling (256K tokens), demonstrates superior inference efficiency (up to 2.5x faster than comparable models), and supports structured JSON output and tool-use capabilities. It has 94 billion active parameters (398 billion total), optimized quantization support (ExpertsInt8), and multilingual proficiency in languages such as English, Spanish, French, Portuguese, Italian, Dutch, German, Arabic, and Hebrew.\n\nUsage of this model is subject to the [Jamba Open Model License](https://www.ai21.com/licenses/jamba-open-model-license).",
      "modelVersionGroupId": "cd1eb031-30bc-4e2e-aa06-3c20f986e5c7",
      "contextLength": 256000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "ai21/jamba-1.6-large",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f4dfbac5-0169-4bc8-9861-27dfef791169",
        "name": "AI21 | ai21/jamba-1.6-large",
        "contextLength": 256000,
        "model": {
          "slug": "ai21/jamba-1.6-large",
          "hfSlug": "ai21labs/AI21-Jamba-Large-1.6",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-13T22:32:53+00:00",
          "hfUpdatedAt": null,
          "name": "AI21: Jamba 1.6 Large",
          "shortName": "Jamba 1.6 Large",
          "author": "ai21",
          "description": "AI21 Jamba Large 1.6 is a high-performance hybrid foundation model combining State Space Models (Mamba) with Transformer attention mechanisms. Developed by AI21, it excels in extremely long-context handling (256K tokens), demonstrates superior inference efficiency (up to 2.5x faster than comparable models), and supports structured JSON output and tool-use capabilities. It has 94 billion active parameters (398 billion total), optimized quantization support (ExpertsInt8), and multilingual proficiency in languages such as English, Spanish, French, Portuguese, Italian, Dutch, German, Arabic, and Hebrew.\n\nUsage of this model is subject to the [Jamba Open Model License](https://www.ai21.com/licenses/jamba-open-model-license).",
          "modelVersionGroupId": "cd1eb031-30bc-4e2e-aa06-3c20f986e5c7",
          "contextLength": 256000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "ai21/jamba-1.6-large",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "ai21/jamba-1.6-large",
        "modelVariantPermaslug": "ai21/jamba-1.6-large",
        "providerName": "AI21",
        "providerInfo": {
          "name": "AI21",
          "displayName": "AI21",
          "slug": "ai21",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://www.ai21.com/privacy-policy/",
            "termsOfServiceUrl": "https://www.ai21.com/terms-of-service/",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "IL",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "AI21",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": "https://status.ai21.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://ai21.com/&size=256"
          }
        },
        "providerDisplayName": "AI21",
        "providerModelId": "jamba-large-1.6",
        "providerGroup": "AI21",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://www.ai21.com/privacy-policy/",
          "termsOfServiceUrl": "https://www.ai21.com/terms-of-service/",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000002",
          "completion": "0.000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 255,
        "newest": 85,
        "throughputHighToLow": 146,
        "latencyLowToHigh": 159,
        "pricingLowToHigh": 248,
        "pricingHighToLow": 68
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai21.com/\\u0026size=256",
      "providers": [
        {
          "name": "AI21",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://ai21.com/&size=256",
          "slug": "ai21",
          "quantization": "bf16",
          "context": 256000,
          "maxCompletionTokens": 4096,
          "providerModelId": "jamba-large-1.6",
          "pricing": {
            "prompt": "0.000002",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop"
          ],
          "inputCost": 2,
          "outputCost": 8,
          "throughput": 56.707,
          "latency": 969
        }
      ]
    },
    {
      "slug": "jondurbin/airoboros-l2-70b",
      "hfSlug": "jondurbin/airoboros-l2-70b-2.2.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-10-29T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Airoboros 70B",
      "shortName": "Airoboros 70B",
      "author": "jondurbin",
      "description": "A Llama 2 70B fine-tune using synthetic data (the Airoboros dataset).\n\nCurrently based on [jondurbin/airoboros-l2-70b](https://huggingface.co/jondurbin/airoboros-l2-70b-2.2.1), but might get updated in the future.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "airoboros",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "jondurbin/airoboros-l2-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "08737538-335d-4639-b6e9-cc34a8134e30",
        "name": "Novita | jondurbin/airoboros-l2-70b",
        "contextLength": 4096,
        "model": {
          "slug": "jondurbin/airoboros-l2-70b",
          "hfSlug": "jondurbin/airoboros-l2-70b-2.2.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-10-29T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Airoboros 70B",
          "shortName": "Airoboros 70B",
          "author": "jondurbin",
          "description": "A Llama 2 70B fine-tune using synthetic data (the Airoboros dataset).\n\nCurrently based on [jondurbin/airoboros-l2-70b](https://huggingface.co/jondurbin/airoboros-l2-70b-2.2.1), but might get updated in the future.",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "airoboros",
          "defaultSystem": null,
          "defaultStops": [
            "USER:",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "jondurbin/airoboros-l2-70b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "jondurbin/airoboros-l2-70b",
        "modelVariantPermaslug": "jondurbin/airoboros-l2-70b",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "jondurbin/airoboros-l2-70b",
        "providerGroup": "Novita",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000005",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 256,
        "newest": 302,
        "throughputHighToLow": 178,
        "latencyLowToHigh": 279,
        "pricingLowToHigh": 179,
        "pricingHighToLow": 140
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "NovitaAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "slug": "novitaAi",
          "quantization": "unknown",
          "context": 4096,
          "maxCompletionTokens": null,
          "providerModelId": "jondurbin/airoboros-l2-70b",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000005",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty",
            "logit_bias"
          ],
          "inputCost": 0.5,
          "outputCost": 0.5,
          "throughput": 46.637,
          "latency": 2908
        }
      ]
    },
    {
      "slug": "openai/gpt-3.5-turbo-instruct",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-09-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-3.5 Turbo Instruct",
      "shortName": "GPT-3.5 Turbo Instruct",
      "author": "openai",
      "description": "This model is a variant of GPT-3.5 Turbo tuned for instructional prompts and omitting chat-related optimizations. Training data: up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 4095,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-3.5-turbo-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "39594b4d-6c7e-4ccd-aeed-79f9b3ca5819",
        "name": "OpenAI | openai/gpt-3.5-turbo-instruct",
        "contextLength": 4095,
        "model": {
          "slug": "openai/gpt-3.5-turbo-instruct",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-09-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-3.5 Turbo Instruct",
          "shortName": "GPT-3.5 Turbo Instruct",
          "author": "openai",
          "description": "This model is a variant of GPT-3.5 Turbo tuned for instructional prompts and omitting chat-related optimizations. Training data: up to Sep 2021.",
          "modelVersionGroupId": null,
          "contextLength": 4095,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-3.5-turbo-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-3.5-turbo-instruct",
        "modelVariantPermaslug": "openai/gpt-3.5-turbo-instruct",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-3.5-turbo-instruct",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000015",
          "completion": "0.000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 257,
        "newest": 303,
        "throughputHighToLow": 39,
        "latencyLowToHigh": 100,
        "pricingLowToHigh": 236,
        "pricingHighToLow": 82
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 4095,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-3.5-turbo-instruct",
          "pricing": {
            "prompt": "0.0000015",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 1.5,
          "outputCost": 2,
          "throughput": 144.0315,
          "latency": 617.5
        }
      ]
    },
    {
      "slug": "openai/gpt-4-turbo-preview",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4 Turbo Preview",
      "shortName": "GPT-4 Turbo Preview",
      "author": "openai",
      "description": "The preview GPT-4 model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Training data: up to Dec 2023.\n\n**Note:** heavily rate limited by OpenAI while in preview.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4-turbo-preview",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "003933da-395a-48eb-86a3-0c4ec486d67f",
        "name": "OpenAI | openai/gpt-4-turbo-preview",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4-turbo-preview",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-01-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4 Turbo Preview",
          "shortName": "GPT-4 Turbo Preview",
          "author": "openai",
          "description": "The preview GPT-4 model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Training data: up to Dec 2023.\n\n**Note:** heavily rate limited by OpenAI while in preview.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4-turbo-preview",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4-turbo-preview",
        "modelVariantPermaslug": "openai/gpt-4-turbo-preview",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4-turbo-preview",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00001",
          "completion": "0.00003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 258,
        "newest": 286,
        "throughputHighToLow": 243,
        "latencyLowToHigh": 167,
        "pricingLowToHigh": 303,
        "pricingHighToLow": 15
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4-turbo-preview",
          "pricing": {
            "prompt": "0.00001",
            "completion": "0.00003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 10,
          "outputCost": 30,
          "throughput": 31.928,
          "latency": 1061
        }
      ]
    },
    {
      "slug": "google/gemma-3-1b-it",
      "hfSlug": "google/gemma-3-1b-it",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-14T14:45:56.842499+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 3 1B (free)",
      "shortName": "Gemma 3 1B (free)",
      "author": "google",
      "description": "Gemma 3 1B is the smallest of the new Gemma 3 family. It handles context windows up to 32k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Note: Gemma 3 1B is not multimodal. For the smallest multimodal Gemma 3 model, please see [Gemma 3 4B](google/gemma-3-4b-it)",
      "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
      "contextLength": 32768,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemma-3-1b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "19c49025-8f42-48eb-ae62-5b03cfb165ee",
        "name": "Chutes | google/gemma-3-1b-it:free",
        "contextLength": 32768,
        "model": {
          "slug": "google/gemma-3-1b-it",
          "hfSlug": "google/gemma-3-1b-it",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-14T14:45:56.842499+00:00",
          "hfUpdatedAt": null,
          "name": "Google: Gemma 3 1B",
          "shortName": "Gemma 3 1B",
          "author": "google",
          "description": "Gemma 3 1B is the smallest of the new Gemma 3 family. It handles context windows up to 32k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Note: Gemma 3 1B is not multimodal. For the smallest multimodal Gemma 3 model, please see [Gemma 3 4B](google/gemma-3-4b-it)",
          "modelVersionGroupId": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
          "contextLength": 32000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Gemini",
          "instructType": "gemma",
          "defaultSystem": null,
          "defaultStops": [
            "<start_of_turn>",
            "<end_of_turn>",
            "<eos>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "google/gemma-3-1b-it",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "google/gemma-3-1b-it:free",
        "modelVariantPermaslug": "google/gemma-3-1b-it:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "unsloth/gemma-3-1b-it",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 8192,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 259,
        "newest": 82,
        "throughputHighToLow": 9,
        "latencyLowToHigh": 149,
        "pricingLowToHigh": 37,
        "pricingHighToLow": 285
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "openai/o1-mini-2024-09-12",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-12T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o1-mini (2024-09-12)",
      "shortName": "o1-mini (2024-09-12)",
      "author": "openai",
      "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/o1-mini-2024-09-12",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "66ac30ec-dd07-4b8d-9dc0-5c7369bb2efe",
        "name": "OpenAI | openai/o1-mini-2024-09-12",
        "contextLength": 128000,
        "model": {
          "slug": "openai/o1-mini-2024-09-12",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-12T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o1-mini (2024-09-12)",
          "shortName": "o1-mini (2024-09-12)",
          "author": "openai",
          "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.\n\nThe o1 models are optimized for math, science, programming, and other STEM-related tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics, chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited.",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/o1-mini-2024-09-12",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o1-mini-2024-09-12",
        "modelVariantPermaslug": "openai/o1-mini-2024-09-12",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o1-mini-2024-09-12",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 65536,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "seed",
          "max_tokens"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000011",
          "completion": "0.0000044",
          "image": "0",
          "request": "0",
          "inputCacheRead": "0.00000055",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 260,
        "newest": 210,
        "throughputHighToLow": 318,
        "latencyLowToHigh": 298,
        "pricingLowToHigh": 234,
        "pricingHighToLow": 89
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 65536,
          "providerModelId": "o1-mini-2024-09-12",
          "pricing": {
            "prompt": "0.0000011",
            "completion": "0.0000044",
            "image": "0",
            "request": "0",
            "inputCacheRead": "0.00000055",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "seed",
            "max_tokens"
          ],
          "inputCost": 1.1,
          "outputCost": 4.4,
          "throughput": 107.572,
          "latency": 5659
        }
      ]
    },
    {
      "slug": "mistralai/mistral-medium",
      "hfSlug": null,
      "updatedAt": "2025-05-07T14:29:20.240884+00:00",
      "createdAt": "2024-01-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral Medium",
      "shortName": "Mistral Medium",
      "author": "mistralai",
      "description": "This is Mistral AI's closed-source, medium-sided model. It's powered by a closed-source prototype and excels at reasoning, code, JSON, chat, and more. In benchmarks, it compares with many of the flagship models of other companies.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-medium",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "27f1eb95-8d1a-471c-bfba-0713bf076753",
        "name": "Mistral | mistralai/mistral-medium",
        "contextLength": 32768,
        "model": {
          "slug": "mistralai/mistral-medium",
          "hfSlug": null,
          "updatedAt": "2025-05-07T14:29:20.240884+00:00",
          "createdAt": "2024-01-10T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral Medium",
          "shortName": "Mistral Medium",
          "author": "mistralai",
          "description": "This is Mistral AI's closed-source, medium-sided model. It's powered by a closed-source prototype and excels at reasoning, code, JSON, chat, and more. In benchmarks, it compares with many of the flagship models of other companies.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-medium",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-medium",
        "modelVariantPermaslug": "mistralai/mistral-medium",
        "providerName": "Mistral",
        "providerInfo": {
          "name": "Mistral",
          "displayName": "Mistral",
          "slug": "mistral",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "FR",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Mistral",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Mistral.png"
          }
        },
        "providerDisplayName": "Mistral",
        "providerModelId": "mistral-medium-2312",
        "providerGroup": "Mistral",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mistral.ai/terms/#terms-of-use",
          "privacyPolicyUrl": "https://mistral.ai/terms/#privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00000275",
          "completion": "0.0000081",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 261,
        "newest": 288,
        "throughputHighToLow": 177,
        "latencyLowToHigh": 62,
        "pricingLowToHigh": 266,
        "pricingHighToLow": 52
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Mistral",
          "icon": "https://openrouter.ai/images/icons/Mistral.png",
          "slug": "mistral",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "mistral-medium-2312",
          "pricing": {
            "prompt": "0.00000275",
            "completion": "0.0000081",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "response_format",
            "structured_outputs",
            "seed"
          ],
          "inputCost": 2.75,
          "outputCost": 8.1,
          "throughput": 46.852,
          "latency": 459
        }
      ]
    },
    {
      "slug": "rekaai/reka-flash-3",
      "hfSlug": "RekaAI/reka-flash-3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-12T20:53:33.296745+00:00",
      "hfUpdatedAt": null,
      "name": "Reka: Flash 3 (free)",
      "shortName": "Flash 3 (free)",
      "author": "rekaai",
      "description": "Reka Flash 3 is a general-purpose, instruction-tuned large language model with 21 billion parameters, developed by Reka. It excels at general chat, coding tasks, instruction-following, and function calling. Featuring a 32K context length and optimized through reinforcement learning (RLOO), it provides competitive performance comparable to proprietary models within a smaller parameter footprint. Ideal for low-latency, local, or on-device deployments, Reka Flash 3 is compact, supports efficient quantization (down to 11GB at 4-bit precision), and employs explicit reasoning tags (\"<reasoning>\") to indicate its internal thought process.\n\nReka Flash 3 is primarily an English model with limited multilingual understanding capabilities. The model weights are released under the Apache 2.0 license.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [
        "<sep>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "rekaai/reka-flash-3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4f75b624-7616-44ba-8152-fee614887754",
        "name": "Chutes | rekaai/reka-flash-3:free",
        "contextLength": 32768,
        "model": {
          "slug": "rekaai/reka-flash-3",
          "hfSlug": "RekaAI/reka-flash-3",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-12T20:53:33.296745+00:00",
          "hfUpdatedAt": null,
          "name": "Reka: Flash 3",
          "shortName": "Flash 3",
          "author": "rekaai",
          "description": "Reka Flash 3 is a general-purpose, instruction-tuned large language model with 21 billion parameters, developed by Reka. It excels at general chat, coding tasks, instruction-following, and function calling. Featuring a 32K context length and optimized through reinforcement learning (RLOO), it provides competitive performance comparable to proprietary models within a smaller parameter footprint. Ideal for low-latency, local, or on-device deployments, Reka Flash 3 is compact, supports efficient quantization (down to 11GB at 4-bit precision), and employs explicit reasoning tags (\"<reasoning>\") to indicate its internal thought process.\n\nReka Flash 3 is primarily an English model with limited multilingual understanding capabilities. The model weights are released under the Apache 2.0 license.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [
            "<sep>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "rekaai/reka-flash-3",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "rekaai/reka-flash-3:free",
        "modelVariantPermaslug": "rekaai/reka-flash-3:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "RekaAI/reka-flash-3",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 262,
        "newest": 92,
        "throughputHighToLow": 114,
        "latencyLowToHigh": 255,
        "pricingLowToHigh": 40,
        "pricingHighToLow": 288
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "mistralai/mistral-7b-instruct-v0.1",
      "hfSlug": "mistralai/Mistral-7B-Instruct-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-09-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mistral 7B Instruct v0.1",
      "shortName": "Mistral 7B Instruct v0.1",
      "author": "mistralai",
      "description": "A 7.3B parameter model that outperforms Llama 2 13B on all benchmarks, with optimizations for speed and context length.",
      "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
      "contextLength": 2824,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "mistral",
      "defaultSystem": null,
      "defaultStops": [
        "[INST]",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mistral-7b-instruct-v0.1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7f9cc99b-0c5c-4dc4-a662-07cebf628081",
        "name": "Cloudflare | mistralai/mistral-7b-instruct-v0.1",
        "contextLength": 2824,
        "model": {
          "slug": "mistralai/mistral-7b-instruct-v0.1",
          "hfSlug": "mistralai/Mistral-7B-Instruct-v0.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-09-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mistral: Mistral 7B Instruct v0.1",
          "shortName": "Mistral 7B Instruct v0.1",
          "author": "mistralai",
          "description": "A 7.3B parameter model that outperforms Llama 2 13B on all benchmarks, with optimizations for speed and context length.",
          "modelVersionGroupId": "1d07cc56-c54d-4587-b785-5093496397a4",
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "mistral",
          "defaultSystem": null,
          "defaultStops": [
            "[INST]",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mistralai/mistral-7b-instruct-v0.1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mistralai/mistral-7b-instruct-v0.1",
        "modelVariantPermaslug": "mistralai/mistral-7b-instruct-v0.1",
        "providerName": "Cloudflare",
        "providerInfo": {
          "name": "Cloudflare",
          "displayName": "Cloudflare",
          "slug": "cloudflare",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.cloudflare.com/service-specific-terms-developer-platform/#developer-platform-terms",
            "privacyPolicyUrl": "https://developers.cloudflare.com/workers-ai/privacy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cloudflare",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256"
          }
        },
        "providerDisplayName": "Cloudflare",
        "providerModelId": "@cf/mistral/mistral-7b-instruct-v0.1",
        "providerGroup": "Cloudflare",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "seed",
          "repetition_penalty",
          "frequency_penalty",
          "presence_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.cloudflare.com/service-specific-terms-developer-platform/#developer-platform-terms",
          "privacyPolicyUrl": "https://developers.cloudflare.com/workers-ai/privacy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000011",
          "completion": "0.00000019",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 263,
        "newest": 304,
        "throughputHighToLow": 295,
        "latencyLowToHigh": 152,
        "pricingLowToHigh": 121,
        "pricingHighToLow": 197
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": [
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": null,
          "context": 2824,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/mistral/mistral-7b-instruct-v0.1",
          "pricing": {
            "prompt": "0.00000011",
            "completion": "0.00000019",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.11,
          "outputCost": 0.19,
          "throughput": 15.911,
          "latency": 910
        },
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "mistralai/Mistral-7B-Instruct-v0.1",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 203.265,
          "latency": 304
        }
      ]
    },
    {
      "slug": "microsoft/phi-3-medium-128k-instruct",
      "hfSlug": "microsoft/Phi-3-medium-128k-instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-24T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: Phi-3 Medium 128K Instruct",
      "shortName": "Phi-3 Medium 128K Instruct",
      "author": "microsoft",
      "description": "Phi-3 128K Medium is a powerful 14-billion parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.\n\nAt time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. In the MMLU-Pro eval, the model even comes close to a Llama3 70B level of performance.\n\nFor 4k context length, try [Phi-3 Medium 4K](/models/microsoft/phi-3-medium-4k-instruct).",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "phi3",
      "defaultSystem": null,
      "defaultStops": [
        "<|end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/phi-3-medium-128k-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "1899ce7d-d477-442a-8528-50d8ec66df16",
        "name": "Nebius | microsoft/phi-3-medium-128k-instruct",
        "contextLength": 131072,
        "model": {
          "slug": "microsoft/phi-3-medium-128k-instruct",
          "hfSlug": "microsoft/Phi-3-medium-128k-instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-24T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Microsoft: Phi-3 Medium 128K Instruct",
          "shortName": "Phi-3 Medium 128K Instruct",
          "author": "microsoft",
          "description": "Phi-3 128K Medium is a powerful 14-billion parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.\n\nAt time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. In the MMLU-Pro eval, the model even comes close to a Llama3 70B level of performance.\n\nFor 4k context length, try [Phi-3 Medium 4K](/models/microsoft/phi-3-medium-4k-instruct).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "phi3",
          "defaultSystem": null,
          "defaultStops": [
            "<|end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "microsoft/phi-3-medium-128k-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "microsoft/phi-3-medium-128k-instruct",
        "modelVariantPermaslug": "microsoft/phi-3-medium-128k-instruct",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "microsoft/Phi-3-medium-128k-instruct",
        "providerGroup": "Nebius",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000001",
          "completion": "0.0000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 264,
        "newest": 254,
        "throughputHighToLow": 49,
        "latencyLowToHigh": 7,
        "pricingLowToHigh": 125,
        "pricingHighToLow": 196
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "microsoft/Phi-3-medium-128k-instruct",
          "pricing": {
            "prompt": "0.0000001",
            "completion": "0.0000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.1,
          "outputCost": 0.3,
          "throughput": 127.3485,
          "latency": 182.5
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": null,
          "providerModelId": "phi3-medium-128k",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p"
          ],
          "inputCost": 1,
          "outputCost": 1,
          "throughput": 57.342,
          "latency": 596
        }
      ]
    },
    {
      "slug": "arcee-ai/virtuoso-large",
      "hfSlug": "",
      "updatedAt": "2025-05-05T21:48:18.128183+00:00",
      "createdAt": "2025-05-05T21:01:25.294732+00:00",
      "hfUpdatedAt": null,
      "name": "Arcee AI: Virtuoso Large",
      "shortName": "Virtuoso Large",
      "author": "arcee-ai",
      "description": "Virtuoso‑Large is Arcee's top‑tier general‑purpose LLM at 72 B parameters, tuned to tackle cross‑domain reasoning, creative writing and enterprise QA. Unlike many 70 B peers, it retains the 128 k context inherited from Qwen 2.5, letting it ingest books, codebases or financial filings wholesale. Training blended DeepSeek R1 distillation, multi‑epoch supervised fine‑tuning and a final DPO/RLHF alignment stage, yielding strong performance on BIG‑Bench‑Hard, GSM‑8K and long‑context Needle‑In‑Haystack tests. Enterprises use Virtuoso‑Large as the \"fallback\" brain in Conductor pipelines when other SLMs flag low confidence. Despite its size, aggressive KV‑cache optimizations keep first‑token latency in the low‑second range on 8× H100 nodes, making it a practical production‑grade powerhouse.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "arcee-ai/virtuoso-large",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "6ea266fd-81e1-4ad2-ba62-2f09c5762435",
        "name": "Together | arcee-ai/virtuoso-large",
        "contextLength": 131072,
        "model": {
          "slug": "arcee-ai/virtuoso-large",
          "hfSlug": "",
          "updatedAt": "2025-05-05T21:48:18.128183+00:00",
          "createdAt": "2025-05-05T21:01:25.294732+00:00",
          "hfUpdatedAt": null,
          "name": "Arcee AI: Virtuoso Large",
          "shortName": "Virtuoso Large",
          "author": "arcee-ai",
          "description": "Virtuoso‑Large is Arcee's top‑tier general‑purpose LLM at 72 B parameters, tuned to tackle cross‑domain reasoning, creative writing and enterprise QA. Unlike many 70 B peers, it retains the 128 k context inherited from Qwen 2.5, letting it ingest books, codebases or financial filings wholesale. Training blended DeepSeek R1 distillation, multi‑epoch supervised fine‑tuning and a final DPO/RLHF alignment stage, yielding strong performance on BIG‑Bench‑Hard, GSM‑8K and long‑context Needle‑In‑Haystack tests. Enterprises use Virtuoso‑Large as the \"fallback\" brain in Conductor pipelines when other SLMs flag low confidence. Despite its size, aggressive KV‑cache optimizations keep first‑token latency in the low‑second range on 8× H100 nodes, making it a practical production‑grade powerhouse.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "arcee-ai/virtuoso-large",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "arcee-ai/virtuoso-large",
        "modelVariantPermaslug": "arcee-ai/virtuoso-large",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "arcee-ai/virtuoso-large",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 64000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000075",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 265,
        "newest": 6,
        "throughputHighToLow": 101,
        "latencyLowToHigh": 107,
        "pricingLowToHigh": 199,
        "pricingHighToLow": 119
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://arcee.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 64000,
          "providerModelId": "arcee-ai/virtuoso-large",
          "pricing": {
            "prompt": "0.00000075",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.75,
          "outputCost": 1.2,
          "throughput": 78.419,
          "latency": 687.5
        }
      ]
    },
    {
      "slug": "neversleep/llama-3-lumimaid-8b",
      "hfSlug": "NeverSleep/Llama-3-Lumimaid-8B-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-04T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "NeverSleep: Llama 3 Lumimaid 8B",
      "shortName": "Llama 3 Lumimaid 8B",
      "author": "neversleep",
      "description": "The NeverSleep team is back, with a Llama 3 8B finetune trained on their curated roleplay data. Striking a balance between eRP and RP, Lumimaid was designed to be serious, yet uncensored when necessary.\n\nTo enhance it's overall intelligence and chat capability, roughly 40% of the training data was not roleplay. This provides a breadth of knowledge to access, while still keeping roleplay as the primary strength.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 24576,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "neversleep/llama-3-lumimaid-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "2a3f32a8-a4f2-45b7-820d-ac1b4fb6dfa5",
        "name": "Mancer | neversleep/llama-3-lumimaid-8b",
        "contextLength": 24576,
        "model": {
          "slug": "neversleep/llama-3-lumimaid-8b",
          "hfSlug": "NeverSleep/Llama-3-Lumimaid-8B-v0.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-04T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "NeverSleep: Llama 3 Lumimaid 8B",
          "shortName": "Llama 3 Lumimaid 8B",
          "author": "neversleep",
          "description": "The NeverSleep team is back, with a Llama 3 8B finetune trained on their curated roleplay data. Striking a balance between eRP and RP, Lumimaid was designed to be serious, yet uncensored when necessary.\n\nTo enhance it's overall intelligence and chat capability, roughly 40% of the training data was not roleplay. This provides a breadth of knowledge to access, while still keeping roleplay as the primary strength.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 24576,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "neversleep/llama-3-lumimaid-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "neversleep/llama-3-lumimaid-8b",
        "modelVariantPermaslug": "neversleep/llama-3-lumimaid-8b",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "lumi-8b",
        "providerGroup": "Mancer",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.0000009375",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 80,
        "newest": 263,
        "throughputHighToLow": 144,
        "latencyLowToHigh": 95,
        "pricingLowToHigh": 152,
        "pricingHighToLow": 166
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "unknown",
          "context": 24576,
          "maxCompletionTokens": 2048,
          "providerModelId": "lumi-8b",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.0000009375",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.15,
          "outputCost": 0.94,
          "throughput": 57.9765,
          "latency": 641
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "unknown",
          "context": 24576,
          "maxCompletionTokens": 2048,
          "providerModelId": "lumi-8b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.00000125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.2,
          "outputCost": 1.25,
          "throughput": 60.202,
          "latency": 435
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 8192,
          "maxCompletionTokens": 4096,
          "providerModelId": "NeverSleep/Llama-3-Lumimaid-8B-v0.1",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 25.6735,
          "latency": 1299.5
        }
      ]
    },
    {
      "slug": "anthropic/claude-2.1",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude v2.1",
      "shortName": "Claude v2.1",
      "author": "anthropic",
      "description": "Claude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-2.1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7159a751-fb9d-4750-918b-a774fd71cfa3",
        "name": "Anthropic | anthropic/claude-2.1",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-2.1",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-11-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude v2.1",
          "shortName": "Claude v2.1",
          "author": "anthropic",
          "description": "Claude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-2.1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-2.1",
        "modelVariantPermaslug": "anthropic/claude-2.1",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-2.1",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000008",
          "completion": "0.000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 267,
        "newest": 294,
        "throughputHighToLow": 293,
        "latencyLowToHigh": 224,
        "pricingLowToHigh": 296,
        "pricingHighToLow": 17
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-2.1",
          "pricing": {
            "prompt": "0.000008",
            "completion": "0.000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 8,
          "outputCost": 24,
          "throughput": 16.038,
          "latency": 1531
        }
      ]
    },
    {
      "slug": "raifle/sorcererlm-8x22b",
      "hfSlug": "rAIfle/SorcererLM-8x22b-bf16",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-08T22:31:23.953049+00:00",
      "hfUpdatedAt": null,
      "name": "SorcererLM 8x22B",
      "shortName": "SorcererLM 8x22B",
      "author": "raifle",
      "description": "SorcererLM is an advanced RP and storytelling model, built as a Low-rank 16-bit LoRA fine-tuned on [WizardLM-2 8x22B](/microsoft/wizardlm-2-8x22b).\n\n- Advanced reasoning and emotional intelligence for engaging and immersive interactions\n- Vivid writing capabilities enriched with spatial and contextual awareness\n- Enhanced narrative depth, promoting creative and dynamic storytelling",
      "modelVersionGroupId": null,
      "contextLength": 16000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "vicuna",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "raifle/sorcererlm-8x22b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "65206957-c772-4743-93ff-45900a190ddd",
        "name": "Infermatic | raifle/sorcererlm-8x22b",
        "contextLength": 16000,
        "model": {
          "slug": "raifle/sorcererlm-8x22b",
          "hfSlug": "rAIfle/SorcererLM-8x22b-bf16",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-08T22:31:23.953049+00:00",
          "hfUpdatedAt": null,
          "name": "SorcererLM 8x22B",
          "shortName": "SorcererLM 8x22B",
          "author": "raifle",
          "description": "SorcererLM is an advanced RP and storytelling model, built as a Low-rank 16-bit LoRA fine-tuned on [WizardLM-2 8x22B](/microsoft/wizardlm-2-8x22b).\n\n- Advanced reasoning and emotional intelligence for engaging and immersive interactions\n- Vivid writing capabilities enriched with spatial and contextual awareness\n- Enhanced narrative depth, promoting creative and dynamic storytelling",
          "modelVersionGroupId": null,
          "contextLength": 16000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "vicuna",
          "defaultSystem": null,
          "defaultStops": [
            "USER:",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "raifle/sorcererlm-8x22b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "raifle/sorcererlm-8x22b",
        "modelVariantPermaslug": "raifle/sorcererlm-8x22b",
        "providerName": "Infermatic",
        "providerInfo": {
          "name": "Infermatic",
          "displayName": "Infermatic",
          "slug": "infermatic",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://infermatic.ai/privacy-policy/",
            "termsOfServiceUrl": "https://infermatic.ai/terms-and-conditions/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Infermatic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256"
          }
        },
        "providerDisplayName": "Infermatic",
        "providerModelId": "rAIfle-SorcererLM-8x22b-bf16",
        "providerGroup": "Infermatic",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://infermatic.ai/privacy-policy/",
          "termsOfServiceUrl": "https://infermatic.ai/terms-and-conditions/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000045",
          "completion": "0.0000045",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 268,
        "newest": 174,
        "throughputHighToLow": 160,
        "latencyLowToHigh": 141,
        "pricingLowToHigh": 285,
        "pricingHighToLow": 33
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Infermatic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256",
          "slug": "infermatic",
          "quantization": null,
          "context": 16000,
          "maxCompletionTokens": null,
          "providerModelId": "rAIfle-SorcererLM-8x22b-bf16",
          "pricing": {
            "prompt": "0.0000045",
            "completion": "0.0000045",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 4.5,
          "outputCost": 4.5,
          "throughput": 52.655,
          "latency": 799
        }
      ]
    },
    {
      "slug": "thudm/glm-4-9b",
      "hfSlug": "THUDM/GLM-4-9B-0414",
      "updatedAt": "2025-04-25T17:11:00.514702+00:00",
      "createdAt": "2025-04-25T17:10:23.758806+00:00",
      "hfUpdatedAt": null,
      "name": "THUDM: GLM 4 9B (free)",
      "shortName": "GLM 4 9B (free)",
      "author": "thudm",
      "description": "GLM-4-9B-0414 is a 9 billion parameter language model from the GLM-4 series developed by THUDM. Trained using the same reinforcement learning and alignment strategies as its larger 32B counterparts, GLM-4-9B-0414 achieves high performance relative to its size, making it suitable for resource-constrained deployments that still require robust language understanding and generation capabilities.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thudm/glm-4-9b-0414",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9998778a-6cd2-479c-8e48-cb349270eac6",
        "name": "Novita | thudm/glm-4-9b-0414:free",
        "contextLength": 32000,
        "model": {
          "slug": "thudm/glm-4-9b",
          "hfSlug": "THUDM/GLM-4-9B-0414",
          "updatedAt": "2025-04-25T17:11:00.514702+00:00",
          "createdAt": "2025-04-25T17:10:23.758806+00:00",
          "hfUpdatedAt": null,
          "name": "THUDM: GLM 4 9B",
          "shortName": "GLM 4 9B",
          "author": "thudm",
          "description": "GLM-4-9B-0414 is a 9 billion parameter language model from the GLM-4 series developed by THUDM. Trained using the same reinforcement learning and alignment strategies as its larger 32B counterparts, GLM-4-9B-0414 achieves high performance relative to its size, making it suitable for resource-constrained deployments that still require robust language understanding and generation capabilities.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thudm/glm-4-9b-0414",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "thudm/glm-4-9b:free",
        "modelVariantPermaslug": "thudm/glm-4-9b-0414:free",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "thudm/glm-4-9b-0414",
        "providerGroup": "Novita",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 269,
        "newest": 35,
        "throughputHighToLow": 193,
        "latencyLowToHigh": 191,
        "pricingLowToHigh": 16,
        "pricingHighToLow": 264
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "aion-labs/aion-1.0",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-04T19:32:37.000231+00:00",
      "hfUpdatedAt": null,
      "name": "AionLabs: Aion-1.0",
      "shortName": "Aion-1.0",
      "author": "aion-labs",
      "description": "Aion-1.0 is a multi-model system designed for high performance across various tasks, including reasoning and coding. It is built on DeepSeek-R1, augmented with additional models and techniques such as Tree of Thoughts (ToT) and Mixture of Experts (MoE). It is Aion Lab's most powerful reasoning model.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "aion-labs/aion-1.0",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "68716168-5661-4ed3-a841-caa166d7913e",
        "name": "AionLabs | aion-labs/aion-1.0",
        "contextLength": 131072,
        "model": {
          "slug": "aion-labs/aion-1.0",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-04T19:32:37.000231+00:00",
          "hfUpdatedAt": null,
          "name": "AionLabs: Aion-1.0",
          "shortName": "Aion-1.0",
          "author": "aion-labs",
          "description": "Aion-1.0 is a multi-model system designed for high performance across various tasks, including reasoning and coding. It is built on DeepSeek-R1, augmented with additional models and techniques such as Tree of Thoughts (ToT) and Mixture of Experts (MoE). It is Aion Lab's most powerful reasoning model.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "aion-labs/aion-1.0",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "aion-labs/aion-1.0",
        "modelVariantPermaslug": "aion-labs/aion-1.0",
        "providerName": "AionLabs",
        "providerInfo": {
          "name": "AionLabs",
          "displayName": "AionLabs",
          "slug": "aion-labs",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.aionlabs.ai/terms/",
            "privacyPolicyUrl": "https://www.aionlabs.ai/privacy-policy/",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "AionLabs",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.aionlabs.ai/&size=256"
          }
        },
        "providerDisplayName": "AionLabs",
        "providerModelId": "aion-labs/aion-1.0",
        "providerGroup": "AionLabs",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.aionlabs.ai/terms/",
          "privacyPolicyUrl": "https://www.aionlabs.ai/privacy-policy/",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.000004",
          "completion": "0.000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 270,
        "newest": 120,
        "throughputHighToLow": 191,
        "latencyLowToHigh": 213,
        "pricingLowToHigh": 284,
        "pricingHighToLow": 34
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://www.aionlabs.ai/\\u0026size=256",
      "providers": [
        {
          "name": "AionLabs",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.aionlabs.ai/&size=256",
          "slug": "aionLabs",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "aion-labs/aion-1.0",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning"
          ],
          "inputCost": 4,
          "outputCost": 8,
          "throughput": 44.135,
          "latency": 1462
        }
      ]
    },
    {
      "slug": "aetherwiing/mn-starcannon-12b",
      "hfSlug": "aetherwiing/MN-12B-Starcannon-v2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Aetherwiing: Starcannon 12B",
      "shortName": "Starcannon 12B",
      "author": "aetherwiing",
      "description": "Starcannon 12B v2 is a creative roleplay and story writing model, based on Mistral Nemo, using [nothingiisreal/mn-celeste-12b](/nothingiisreal/mn-celeste-12b) as a base, with [intervitens/mini-magnum-12b-v1.1](https://huggingface.co/intervitens/mini-magnum-12b-v1.1) merged in using the [TIES](https://arxiv.org/abs/2306.01708) method.\n\nAlthough more similar to Magnum overall, the model remains very creative, with a pleasant writing style. It is recommended for people wanting more variety than Magnum, and yet more verbose prose than Celeste.",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "aetherwiing/mn-starcannon-12b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "1d498993-f126-4279-8bd7-66c2cfc88423",
        "name": "Featherless | aetherwiing/mn-starcannon-12b",
        "contextLength": 16384,
        "model": {
          "slug": "aetherwiing/mn-starcannon-12b",
          "hfSlug": "aetherwiing/MN-12B-Starcannon-v2",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-08-13T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Aetherwiing: Starcannon 12B",
          "shortName": "Starcannon 12B",
          "author": "aetherwiing",
          "description": "Starcannon 12B v2 is a creative roleplay and story writing model, based on Mistral Nemo, using [nothingiisreal/mn-celeste-12b](/nothingiisreal/mn-celeste-12b) as a base, with [intervitens/mini-magnum-12b-v1.1](https://huggingface.co/intervitens/mini-magnum-12b-v1.1) merged in using the [TIES](https://arxiv.org/abs/2306.01708) method.\n\nAlthough more similar to Magnum overall, the model remains very creative, with a pleasant writing style. It is recommended for people wanting more variety than Magnum, and yet more verbose prose than Celeste.",
          "modelVersionGroupId": null,
          "contextLength": 12000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "aetherwiing/mn-starcannon-12b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "aetherwiing/mn-starcannon-12b",
        "modelVariantPermaslug": "aetherwiing/mn-starcannon-12b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "AuriAetherwiing/MN-12B-Starcannon-v2",
        "providerGroup": "Featherless",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 271,
        "newest": 222,
        "throughputHighToLow": 281,
        "latencyLowToHigh": 285,
        "pricingLowToHigh": 207,
        "pricingHighToLow": 111
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "AuriAetherwiing/MN-12B-Starcannon-v2",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 19.113,
          "latency": 3387.5
        }
      ]
    },
    {
      "slug": "thudm/glm-z1-9b",
      "hfSlug": "thudm/glm-z1-9b-0414",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-04-25T17:12:20.695158+00:00",
      "hfUpdatedAt": null,
      "name": "THUDM: GLM Z1 9B (free)",
      "shortName": "GLM Z1 9B (free)",
      "author": "thudm",
      "description": "GLM-Z1-9B-0414 is a 9B-parameter language model developed by THUDM as part of the GLM-4 family. It incorporates techniques originally applied to larger GLM-Z1 models, including extended reinforcement learning, pairwise ranking alignment, and training on reasoning-intensive tasks such as mathematics, code, and logic. Despite its smaller size, it demonstrates strong performance on general-purpose reasoning tasks and outperforms many open-source models in its weight class.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "thudm/glm-z1-9b-0414",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "8ad6c714-038b-432e-8719-d2cb7feb7187",
        "name": "Novita | thudm/glm-z1-9b-0414:free",
        "contextLength": 32000,
        "model": {
          "slug": "thudm/glm-z1-9b",
          "hfSlug": "thudm/glm-z1-9b-0414",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2025-04-25T17:12:20.695158+00:00",
          "hfUpdatedAt": null,
          "name": "THUDM: GLM Z1 9B",
          "shortName": "GLM Z1 9B",
          "author": "thudm",
          "description": "GLM-Z1-9B-0414 is a 9B-parameter language model developed by THUDM as part of the GLM-4 family. It incorporates techniques originally applied to larger GLM-Z1 models, including extended reinforcement learning, pairwise ranking alignment, and training on reasoning-intensive tasks such as mathematics, code, and logic. Despite its smaller size, it demonstrates strong performance on general-purpose reasoning tasks and outperforms many open-source models in its weight class.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "thudm/glm-z1-9b-0414",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "thudm/glm-z1-9b:free",
        "modelVariantPermaslug": "thudm/glm-z1-9b-0414:free",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "thudm/glm-z1-9b-0414",
        "providerGroup": "Novita",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 272,
        "newest": 34,
        "throughputHighToLow": 184,
        "latencyLowToHigh": 177,
        "pricingLowToHigh": 15,
        "pricingHighToLow": 263
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "liquid/lfm-40b",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-30T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Liquid: LFM 40B MoE",
      "shortName": "LFM 40B MoE",
      "author": "liquid",
      "description": "Liquid's 40.3B Mixture of Experts (MoE) model. Liquid Foundation Models (LFMs) are large neural networks built with computational units rooted in dynamic systems.\n\nLFMs are general-purpose AI models that can be used to model any kind of sequential data, including video, audio, text, time series, and signals.\n\nSee the [launch announcement](https://www.liquid.ai/liquid-foundation-models) for benchmarks and more info.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "liquid/lfm-40b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7901899b-4845-4089-979d-34a1ef065875",
        "name": "Liquid | liquid/lfm-40b",
        "contextLength": 32768,
        "model": {
          "slug": "liquid/lfm-40b",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-30T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Liquid: LFM 40B MoE",
          "shortName": "LFM 40B MoE",
          "author": "liquid",
          "description": "Liquid's 40.3B Mixture of Experts (MoE) model. Liquid Foundation Models (LFMs) are large neural networks built with computational units rooted in dynamic systems.\n\nLFMs are general-purpose AI models that can be used to model any kind of sequential data, including video, audio, text, time series, and signals.\n\nSee the [launch announcement](https://www.liquid.ai/liquid-foundation-models) for benchmarks and more info.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "liquid/lfm-40b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "liquid/lfm-40b",
        "modelVariantPermaslug": "liquid/lfm-40b",
        "providerName": "Liquid",
        "providerInfo": {
          "name": "Liquid",
          "displayName": "Liquid",
          "slug": "liquid",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.liquid.ai/terms-conditions",
            "privacyPolicyUrl": "https://www.liquid.ai/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Liquid",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.liquid.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Liquid",
        "providerModelId": "lfm-40b",
        "providerGroup": "Liquid",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.liquid.ai/terms-conditions",
          "privacyPolicyUrl": "https://www.liquid.ai/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.00000015",
          "completion": "0.00000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 273,
        "newest": 196,
        "throughputHighToLow": 18,
        "latencyLowToHigh": 71,
        "pricingLowToHigh": 134,
        "pricingHighToLow": 185
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://www.liquid.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Liquid",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.liquid.ai/&size=256",
          "slug": "liquid",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "lfm-40b",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.15,
          "outputCost": 0.15,
          "throughput": 184.404,
          "latency": 507
        },
        {
          "name": "Lambda",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256",
          "slug": "lambda",
          "quantization": "bf16",
          "context": 65536,
          "maxCompletionTokens": 65536,
          "providerModelId": "lfm-40b",
          "pricing": {
            "prompt": "0.00000015",
            "completion": "0.00000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 0.15,
          "outputCost": 0.15,
          "throughput": 182.46,
          "latency": 269
        }
      ]
    },
    {
      "slug": "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
      "hfSlug": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 2 Mixtral 8x7B DPO",
      "shortName": "Hermes 2 Mixtral 8x7B DPO",
      "author": "nousresearch",
      "description": "Nous Hermes 2 Mixtral 8x7B DPO is the new flagship Nous Research model trained over the [Mixtral 8x7B MoE LLM](/models/mistralai/mixtral-8x7b).\n\nThe model was trained on over 1,000,000 entries of primarily [GPT-4](/models/openai/gpt-4) generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.\n\n#moe",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "5ec74ebb-b872-4d66-a93a-3d2696ecc664",
        "name": "Together | nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
        "contextLength": 32768,
        "model": {
          "slug": "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
          "hfSlug": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-01-16T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Nous: Hermes 2 Mixtral 8x7B DPO",
          "shortName": "Hermes 2 Mixtral 8x7B DPO",
          "author": "nousresearch",
          "description": "Nous Hermes 2 Mixtral 8x7B DPO is the new flagship Nous Research model trained over the [Mixtral 8x7B MoE LLM](/models/mistralai/mixtral-8x7b).\n\nThe model was trained on over 1,000,000 entries of primarily [GPT-4](/models/openai/gpt-4) generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.\n\n#moe",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
        "modelVariantPermaslug": "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
        "providerGroup": "Together",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 2048,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000006",
          "completion": "0.0000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 274,
        "newest": 287,
        "throughputHighToLow": 59,
        "latencyLowToHigh": 86,
        "pricingLowToHigh": 192,
        "pricingHighToLow": 126
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 32768,
          "maxCompletionTokens": 2048,
          "providerModelId": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
          "pricing": {
            "prompt": "0.0000006",
            "completion": "0.0000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.6,
          "outputCost": 0.6,
          "throughput": 121.876,
          "latency": 591
        }
      ]
    },
    {
      "slug": "opengvlab/internvl3-2b",
      "hfSlug": "OpenGVLab/InternVL3-2B",
      "updatedAt": "2025-04-30T13:55:48.070004+00:00",
      "createdAt": "2025-04-30T13:30:07.912688+00:00",
      "hfUpdatedAt": null,
      "name": "OpenGVLab: InternVL3 2B (free)",
      "shortName": "InternVL3 2B (free)",
      "author": "opengvlab",
      "description": "The 2b version of the InternVL3 series, for an even higher inference speed and very reasonable performance. An advanced multimodal large language model (MLLM) series that demonstrates superior overall performance. Compared to InternVL 2.5, InternVL3 exhibits superior multimodal perception and reasoning capabilities, while further extending its multimodal capabilities to encompass tool usage, GUI agents, industrial image analysis, 3D vision perception, and more.",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "image",
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "opengvlab/internvl3-2b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "ec1cddcf-1619-457b-9008-bbadc41eb2bb",
        "name": "Nineteen | opengvlab/internvl3-2b:free",
        "contextLength": 32000,
        "model": {
          "slug": "opengvlab/internvl3-2b",
          "hfSlug": "OpenGVLab/InternVL3-2B",
          "updatedAt": "2025-04-30T13:55:48.070004+00:00",
          "createdAt": "2025-04-30T13:30:07.912688+00:00",
          "hfUpdatedAt": null,
          "name": "OpenGVLab: InternVL3 2B",
          "shortName": "InternVL3 2B",
          "author": "opengvlab",
          "description": "The 2b version of the InternVL3 series, for an even higher inference speed and very reasonable performance. An advanced multimodal large language model (MLLM) series that demonstrates superior overall performance. Compared to InternVL 2.5, InternVL3 exhibits superior multimodal perception and reasoning capabilities, while further extending its multimodal capabilities to encompass tool usage, GUI agents, industrial image analysis, 3D vision perception, and more.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "image",
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "opengvlab/internvl3-2b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "opengvlab/internvl3-2b:free",
        "modelVariantPermaslug": "opengvlab/internvl3-2b:free",
        "providerName": "Nineteen",
        "providerInfo": {
          "name": "Nineteen",
          "displayName": "Nineteen",
          "slug": "nineteen",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://nineteen.ai/tos",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Nineteen",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://nineteen.ai/&size=256"
          }
        },
        "providerDisplayName": "Nineteen",
        "providerModelId": "OpenGVLab/InternVL3-2B",
        "providerGroup": "Nineteen",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://nineteen.ai/tos",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 275,
        "newest": 18,
        "throughputHighToLow": 2,
        "latencyLowToHigh": 109,
        "pricingLowToHigh": 7,
        "pricingHighToLow": 255
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "openai/gpt-4o",
      "hfSlug": null,
      "updatedAt": "2025-04-23T22:07:26.226912+00:00",
      "createdAt": "2024-05-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4o (extended)",
      "shortName": "GPT-4o (extended)",
      "author": "openai",
      "description": "GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n#multimodal",
      "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image",
        "file"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4o",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3f4c883a-bd8b-4e01-ac1b-25cc9a17dd61",
        "name": "OpenAI | openai/gpt-4o:extended",
        "contextLength": 128000,
        "model": {
          "slug": "openai/gpt-4o",
          "hfSlug": null,
          "updatedAt": "2025-04-23T22:07:26.226912+00:00",
          "createdAt": "2024-05-13T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4o",
          "shortName": "GPT-4o",
          "author": "openai",
          "description": "GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.\n\nFor benchmarking against other models, it was briefly called [\"im-also-a-good-gpt2-chatbot\"](https://twitter.com/LiamFedus/status/1790064963966370209)\n\n#multimodal",
          "modelVersionGroupId": "76e36b33-358e-477a-be24-09f954fcea74",
          "contextLength": 128000,
          "inputModalities": [
            "text",
            "image",
            "file"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4o",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4o:extended",
        "modelVariantPermaslug": "openai/gpt-4o:extended",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4o-64k-output-alpha",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "extended",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 64000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "web_search_options",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000006",
          "completion": "0.000018",
          "image": "0.007225",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [
          {
            "type": "search-threshold",
            "threshold": "high",
            "request": "0.05"
          },
          {
            "type": "search-threshold",
            "threshold": "medium",
            "request": "0.035"
          },
          {
            "type": "search-threshold",
            "threshold": "low",
            "request": "0.03"
          }
        ],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 35,
        "newest": 258,
        "throughputHighToLow": 43,
        "latencyLowToHigh": 110,
        "pricingLowToHigh": 265,
        "pricingHighToLow": 24
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0.003613",
            "request": "0",
            "inputCacheRead": "0.00000125",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 49.275,
          "latency": 674
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 16384,
          "providerModelId": "gpt-4o",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0.003613",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "web_search_options",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 111.027,
          "latency": 2187
        }
      ]
    },
    {
      "slug": "qwen/qwq-32b-preview",
      "hfSlug": "Qwen/QwQ-32B-Preview",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2024-11-28T00:42:21.381013+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: QwQ 32B Preview (free)",
      "shortName": "QwQ 32B Preview (free)",
      "author": "qwen",
      "description": "QwQ-32B-Preview is an experimental research model focused on AI reasoning capabilities developed by the Qwen Team. As a preview release, it demonstrates promising analytical abilities while having several important limitations:\n\n1. **Language Mixing and Code-Switching**: The model may mix languages or switch between them unexpectedly, affecting response clarity.\n2. **Recursive Reasoning Loops**: The model may enter circular reasoning patterns, leading to lengthy responses without a conclusive answer.\n3. **Safety and Ethical Considerations**: The model requires enhanced safety measures to ensure reliable and secure performance, and users should exercise caution when deploying it.\n4. **Performance and Benchmark Limitations**: The model excels in math and coding but has room for improvement in other areas, such as common sense reasoning and nuanced language understanding.\n\n",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwq-32b-preview",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": {
        "id": "accf2340-5259-48e3-a2f2-54f384667459",
        "name": "Chutes | qwen/qwq-32b-preview:free",
        "contextLength": 16384,
        "model": {
          "slug": "qwen/qwq-32b-preview",
          "hfSlug": "Qwen/QwQ-32B-Preview",
          "updatedAt": "2025-05-02T21:14:16.355933+00:00",
          "createdAt": "2024-11-28T00:42:21.381013+00:00",
          "hfUpdatedAt": null,
          "name": "Qwen: QwQ 32B Preview",
          "shortName": "QwQ 32B Preview",
          "author": "qwen",
          "description": "QwQ-32B-Preview is an experimental research model focused on AI reasoning capabilities developed by the Qwen Team. As a preview release, it demonstrates promising analytical abilities while having several important limitations:\n\n1. **Language Mixing and Code-Switching**: The model may mix languages or switch between them unexpectedly, affecting response clarity.\n2. **Recursive Reasoning Loops**: The model may enter circular reasoning patterns, leading to lengthy responses without a conclusive answer.\n3. **Safety and Ethical Considerations**: The model requires enhanced safety measures to ensure reliable and secure performance, and users should exercise caution when deploying it.\n4. **Performance and Benchmark Limitations**: The model excels in math and coding but has room for improvement in other areas, such as common sense reasoning and nuanced language understanding.\n\n",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "deepseek-r1",
          "defaultSystem": null,
          "defaultStops": [
            "<｜User｜>",
            "<｜end▁of▁sentence｜>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "qwen/qwq-32b-preview",
          "reasoningConfig": {
            "startToken": "<think>",
            "endToken": "</think>"
          },
          "features": {
            "reasoningConfig": {
              "startToken": "<think>",
              "endToken": "</think>"
            }
          }
        },
        "modelVariantSlug": "qwen/qwq-32b-preview:free",
        "modelVariantPermaslug": "qwen/qwq-32b-preview:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "Qwen/QwQ-32B-Preview",
        "providerGroup": "Chutes",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 177,
        "newest": 162,
        "throughputHighToLow": 255,
        "latencyLowToHigh": 284,
        "pricingLowToHigh": 57,
        "pricingHighToLow": 200
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B-Preview",
          "pricing": {
            "prompt": "0.00000009",
            "completion": "0.00000027",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.09,
          "outputCost": 0.27,
          "throughput": 29.371,
          "latency": 1275.5
        },
        {
          "name": "Hyperbolic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hyperbolic.xyz/&size=256",
          "slug": "hyperbolic",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "Qwen/QwQ-32B-Preview",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "logprobs",
            "top_logprobs",
            "seed",
            "logit_bias",
            "top_k",
            "min_p",
            "repetition_penalty"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 24.9545,
          "latency": 21851.5
        }
      ]
    },
    {
      "slug": "01-ai/yi-large",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "01.AI: Yi Large",
      "shortName": "Yi Large",
      "author": "01-ai",
      "description": "The Yi Large model was designed by 01.AI with the following usecases in mind: knowledge search, data classification, human-like chat bots, and customer service.\n\nIt stands out for its multilingual proficiency, particularly in Spanish, Chinese, Japanese, German, and French.\n\nCheck out the [launch announcement](https://01-ai.github.io/blog/01.ai-yi-large-llm-launch) to learn more.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "01-ai/yi-large",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "5880ca91-521e-4755-b316-1d887d67d582",
        "name": "Fireworks | 01-ai/yi-large",
        "contextLength": 32768,
        "model": {
          "slug": "01-ai/yi-large",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-06-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "01.AI: Yi Large",
          "shortName": "Yi Large",
          "author": "01-ai",
          "description": "The Yi Large model was designed by 01.AI with the following usecases in mind: knowledge search, data classification, human-like chat bots, and customer service.\n\nIt stands out for its multilingual proficiency, particularly in Spanish, Chinese, Japanese, German, and French.\n\nCheck out the [launch announcement](https://01-ai.github.io/blog/01.ai-yi-large-llm-launch) to learn more.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Yi",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "01-ai/yi-large",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "01-ai/yi-large",
        "modelVariantPermaslug": "01-ai/yi-large",
        "providerName": "Fireworks",
        "providerInfo": {
          "name": "Fireworks",
          "displayName": "Fireworks",
          "slug": "fireworks",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://fireworks.ai/terms-of-service",
            "privacyPolicyUrl": "https://fireworks.ai/privacy-policy",
            "dataPolicyUrl": "https://docs.fireworks.ai/guides/security_compliance/data_handling",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Fireworks",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.fireworks.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Fireworks.png"
          }
        },
        "providerDisplayName": "Fireworks",
        "providerModelId": "accounts/yi-01-ai/models/yi-large",
        "providerGroup": "Fireworks",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "response_format",
          "structured_outputs",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://fireworks.ai/terms-of-service",
          "privacyPolicyUrl": "https://fireworks.ai/privacy-policy",
          "dataPolicyUrl": "https://docs.fireworks.ai/guides/security_compliance/data_handling",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 278,
        "newest": 242,
        "throughputHighToLow": 105,
        "latencyLowToHigh": 94,
        "pricingLowToHigh": 257,
        "pricingHighToLow": 62
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Fireworks",
          "icon": "https://openrouter.ai/images/icons/Fireworks.png",
          "slug": "fireworks",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": 4096,
          "providerModelId": "accounts/yi-01-ai/models/yi-large",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "response_format",
            "structured_outputs",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 3,
          "outputCost": 3,
          "throughput": 76.003,
          "latency": 636
        }
      ]
    },
    {
      "slug": "pygmalionai/mythalion-13b",
      "hfSlug": "PygmalionAI/mythalion-13b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-09-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Pygmalion: Mythalion 13B",
      "shortName": "Mythalion 13B",
      "author": "pygmalionai",
      "description": "A blend of the new Pygmalion-13b and MythoMax. #merge",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "pygmalionai/mythalion-13b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "81260a05-530c-42d2-b654-2e149377cbfd",
        "name": "Mancer | pygmalionai/mythalion-13b",
        "contextLength": 8192,
        "model": {
          "slug": "pygmalionai/mythalion-13b",
          "hfSlug": "PygmalionAI/mythalion-13b",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-09-02T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Pygmalion: Mythalion 13B",
          "shortName": "Mythalion 13B",
          "author": "pygmalionai",
          "description": "A blend of the new Pygmalion-13b and MythoMax. #merge",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "alpaca",
          "defaultSystem": null,
          "defaultStops": [
            "###",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "pygmalionai/mythalion-13b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "pygmalionai/mythalion-13b",
        "modelVariantPermaslug": "pygmalionai/mythalion-13b",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "mythalion",
        "providerGroup": "Mancer",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 1024,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.0000005625",
          "completion": "0.000001125",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 279,
        "newest": 305,
        "throughputHighToLow": 266,
        "latencyLowToHigh": 158,
        "pricingLowToHigh": 193,
        "pricingHighToLow": 125
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 1024,
          "providerModelId": "mythalion",
          "pricing": {
            "prompt": "0.0000005625",
            "completion": "0.000001125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 0.56,
          "outputCost": 1.13,
          "throughput": 23.286,
          "latency": 923.5
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "PygmalionAI/mythalion-13b",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 16.258,
          "latency": 1468
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": 1024,
          "providerModelId": "mythalion",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 1,
          "outputCost": 1.5,
          "throughput": 22.156,
          "latency": 664
        }
      ]
    },
    {
      "slug": "neversleep/llama-3-lumimaid-70b",
      "hfSlug": "NeverSleep/Llama-3-Lumimaid-70B-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "NeverSleep: Llama 3 Lumimaid 70B",
      "shortName": "Llama 3 Lumimaid 70B",
      "author": "neversleep",
      "description": "The NeverSleep team is back, with a Llama 3 70B finetune trained on their curated roleplay data. Striking a balance between eRP and RP, Lumimaid was designed to be serious, yet uncensored when necessary.\n\nTo enhance it's overall intelligence and chat capability, roughly 40% of the training data was not roleplay. This provides a breadth of knowledge to access, while still keeping roleplay as the primary strength.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "neversleep/llama-3-lumimaid-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9dec8b8b-2d23-49bf-ba8f-1116b6195c03",
        "name": "Featherless | neversleep/llama-3-lumimaid-70b",
        "contextLength": 8192,
        "model": {
          "slug": "neversleep/llama-3-lumimaid-70b",
          "hfSlug": "NeverSleep/Llama-3-Lumimaid-70B-v0.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-16T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "NeverSleep: Llama 3 Lumimaid 70B",
          "shortName": "Llama 3 Lumimaid 70B",
          "author": "neversleep",
          "description": "The NeverSleep team is back, with a Llama 3 70B finetune trained on their curated roleplay data. Striking a balance between eRP and RP, Lumimaid was designed to be serious, yet uncensored when necessary.\n\nTo enhance it's overall intelligence and chat capability, roughly 40% of the training data was not roleplay. This provides a breadth of knowledge to access, while still keeping roleplay as the primary strength.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "neversleep/llama-3-lumimaid-70b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "neversleep/llama-3-lumimaid-70b",
        "modelVariantPermaslug": "neversleep/llama-3-lumimaid-70b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "NeverSleep/Llama-3-Lumimaid-70B-v0.1",
        "providerGroup": "Featherless",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000004",
          "completion": "0.000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 280,
        "newest": 255,
        "throughputHighToLow": 299,
        "latencyLowToHigh": 206,
        "pricingLowToHigh": 283,
        "pricingHighToLow": 38
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 8192,
          "maxCompletionTokens": 4096,
          "providerModelId": "NeverSleep/Llama-3-Lumimaid-70B-v0.1",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 4,
          "outputCost": 6,
          "throughput": 13.7785,
          "latency": 1395
        }
      ]
    },
    {
      "slug": "featherless/qwerky-72b",
      "hfSlug": "featherless-ai/Qwerky-72B",
      "updatedAt": "2025-04-05T20:00:55.640298+00:00",
      "createdAt": "2025-03-20T14:39:57.009814+00:00",
      "hfUpdatedAt": null,
      "name": "Qwerky 72B (free)",
      "shortName": "Qwerky 72B (free)",
      "author": "featherless",
      "description": "Qwerky-72B is a linear-attention RWKV variant of the Qwen 2.5 72B model, optimized to significantly reduce computational cost at scale. Leveraging linear attention, it achieves substantial inference speedups (>1000x) while retaining competitive accuracy on common benchmarks like ARC, HellaSwag, Lambada, and MMLU. It inherits knowledge and language support from Qwen 2.5, supporting approximately 30 languages, making it suitable for efficient inference in large-context applications.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "featherless/qwerky-72b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7c2131ab-09f3-4e51-b253-fa28b790e034",
        "name": "Featherless | featherless/qwerky-72b:free",
        "contextLength": 32768,
        "model": {
          "slug": "featherless/qwerky-72b",
          "hfSlug": "featherless-ai/Qwerky-72B",
          "updatedAt": "2025-04-05T20:00:55.640298+00:00",
          "createdAt": "2025-03-20T14:39:57.009814+00:00",
          "hfUpdatedAt": null,
          "name": "Qwerky 72B",
          "shortName": "Qwerky 72B",
          "author": "featherless",
          "description": "Qwerky-72B is a linear-attention RWKV variant of the Qwen 2.5 72B model, optimized to significantly reduce computational cost at scale. Leveraging linear attention, it achieves substantial inference speedups (>1000x) while retaining competitive accuracy on common benchmarks like ARC, HellaSwag, Lambada, and MMLU. It inherits knowledge and language support from Qwen 2.5, supporting approximately 30 languages, making it suitable for efficient inference in large-context applications.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "featherless/qwerky-72b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "featherless/qwerky-72b:free",
        "modelVariantPermaslug": "featherless/qwerky-72b:free",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "featherless-ai/Qwerky-72B",
        "providerGroup": "Featherless",
        "quantization": null,
        "variant": "free",
        "isFree": true,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 281,
        "newest": 77,
        "throughputHighToLow": 280,
        "latencyLowToHigh": 269,
        "pricingLowToHigh": 34,
        "pricingHighToLow": 282
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://featherless.ai/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "anthropic/claude-2",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude v2",
      "shortName": "Claude v2",
      "author": "anthropic",
      "description": "Claude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "258ddc79-e520-4e68-8069-ea6771698c5a",
        "name": "Anthropic | anthropic/claude-2",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-2",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-11-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude v2",
          "shortName": "Claude v2",
          "author": "anthropic",
          "description": "Claude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-2",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-2",
        "modelVariantPermaslug": "anthropic/claude-2",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-2.1",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000008",
          "completion": "0.000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 282,
        "newest": 296,
        "throughputHighToLow": 291,
        "latencyLowToHigh": 202,
        "pricingLowToHigh": 298,
        "pricingHighToLow": 19
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-2.1",
          "pricing": {
            "prompt": "0.000008",
            "completion": "0.000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 8,
          "outputCost": 24,
          "throughput": 16.037,
          "latency": 1566
        }
      ]
    },
    {
      "slug": "openai/gpt-3.5-turbo-16k",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-08-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-3.5 Turbo 16k",
      "shortName": "GPT-3.5 Turbo 16k",
      "author": "openai",
      "description": "This model offers four times the context length of gpt-3.5-turbo, allowing it to support approximately 20 pages of text in a single request at a higher cost. Training data: up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 16385,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-3.5-turbo-16k",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "eb1a93d0-a295-4afb-86d3-e2d10538c12d",
        "name": "OpenAI | openai/gpt-3.5-turbo-16k",
        "contextLength": 16385,
        "model": {
          "slug": "openai/gpt-3.5-turbo-16k",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-08-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-3.5 Turbo 16k",
          "shortName": "GPT-3.5 Turbo 16k",
          "author": "openai",
          "description": "This model offers four times the context length of gpt-3.5-turbo, allowing it to support approximately 20 pages of text in a single request at a higher cost. Training data: up to Sep 2021.",
          "modelVersionGroupId": null,
          "contextLength": 16385,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-3.5-turbo-16k",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-3.5-turbo-16k",
        "modelVariantPermaslug": "openai/gpt-3.5-turbo-16k",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-3.5-turbo-16k",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000004",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 283,
        "newest": 306,
        "throughputHighToLow": 42,
        "latencyLowToHigh": 72,
        "pricingLowToHigh": 258,
        "pricingHighToLow": 60
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 16385,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-3.5-turbo-16k",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 3,
          "outputCost": 4,
          "throughput": 140.9345,
          "latency": 511
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 16385,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-35-turbo-16k",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 3,
          "outputCost": 4,
          "throughput": 149.102,
          "latency": 1347
        }
      ]
    },
    {
      "slug": "x-ai/grok-vision-beta",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-19T00:37:04.585936+00:00",
      "hfUpdatedAt": null,
      "name": "xAI: Grok Vision Beta",
      "shortName": "Grok Vision Beta",
      "author": "x-ai",
      "description": "Grok Vision Beta is xAI's experimental language model with vision capability.\n\n",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Grok",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "x-ai/grok-vision-beta",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "641fa158-ffaa-45e0-a7cd-8d51bef6213b",
        "name": "xAI | x-ai/grok-vision-beta",
        "contextLength": 8192,
        "model": {
          "slug": "x-ai/grok-vision-beta",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-19T00:37:04.585936+00:00",
          "hfUpdatedAt": null,
          "name": "xAI: Grok Vision Beta",
          "shortName": "Grok Vision Beta",
          "author": "x-ai",
          "description": "Grok Vision Beta is xAI's experimental language model with vision capability.\n\n",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Grok",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "x-ai/grok-vision-beta",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "x-ai/grok-vision-beta",
        "modelVariantPermaslug": "x-ai/grok-vision-beta",
        "providerName": "xAI",
        "providerInfo": {
          "name": "xAI",
          "displayName": "xAI",
          "slug": "xai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "xAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.x.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256"
          }
        },
        "providerDisplayName": "xAI",
        "providerModelId": "grok-vision-beta",
        "providerGroup": "xAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://x.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://x.ai/legal/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000005",
          "completion": "0.000015",
          "image": "0.009",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 284,
        "newest": 170,
        "throughputHighToLow": 125,
        "latencyLowToHigh": 64,
        "pricingLowToHigh": 290,
        "pricingHighToLow": 26
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://x.ai/\\u0026size=256",
      "providers": [
        {
          "name": "xAI",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://x.ai/&size=256",
          "slug": "xAi",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "grok-vision-beta",
          "pricing": {
            "prompt": "0.000005",
            "completion": "0.000015",
            "image": "0.009",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 5,
          "outputCost": 15,
          "throughput": 62.485,
          "latency": 486
        }
      ]
    },
    {
      "slug": "meta-llama/llama-3.2-1b-instruct",
      "hfSlug": "meta-llama/Llama-3.2-1B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3.2 1B Instruct (free)",
      "shortName": "Llama 3.2 1B Instruct (free)",
      "author": "meta-llama",
      "description": "Llama 3.2 1B is a 1-billion-parameter language model focused on efficiently performing natural language tasks, such as summarization, dialogue, and multilingual text analysis. Its smaller size allows it to operate efficiently in low-resource environments while maintaining strong task performance.\n\nSupporting eight core languages and fine-tunable for more, Llama 1.3B is ideal for businesses or developers seeking lightweight yet powerful AI solutions that can operate in diverse multilingual settings without the high computational demand of larger models.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 131000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3.2-1b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "f9134b27-e5e2-4f19-b241-d85cd5a38433",
        "name": "Novita | meta-llama/llama-3.2-1b-instruct:free",
        "contextLength": 131000,
        "model": {
          "slug": "meta-llama/llama-3.2-1b-instruct",
          "hfSlug": "meta-llama/Llama-3.2-1B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 3.2 1B Instruct",
          "shortName": "Llama 3.2 1B Instruct",
          "author": "meta-llama",
          "description": "Llama 3.2 1B is a 1-billion-parameter language model focused on efficiently performing natural language tasks, such as summarization, dialogue, and multilingual text analysis. Its smaller size allows it to operate efficiently in low-resource environments while maintaining strong task performance.\n\nSupporting eight core languages and fine-tunable for more, Llama 1.3B is ideal for businesses or developers seeking lightweight yet powerful AI solutions that can operate in diverse multilingual settings without the high computational demand of larger models.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-3.2-1b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-3.2-1b-instruct:free",
        "modelVariantPermaslug": "meta-llama/llama-3.2-1b-instruct:free",
        "providerName": "Novita",
        "providerInfo": {
          "name": "Novita",
          "displayName": "NovitaAI",
          "slug": "novita",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
            "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Novita",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.novita.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "NovitaAI",
        "providerModelId": "meta-llama/llama-3.2-1b-instruct",
        "providerGroup": "Novita",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyUrl": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 39,
        "newest": 199,
        "throughputHighToLow": 4,
        "latencyLowToHigh": 91,
        "pricingLowToHigh": 62,
        "pricingHighToLow": 247
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": "fp8",
          "context": 131072,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/Llama-3.2-1B-Instruct",
          "pricing": {
            "prompt": "0.000000005",
            "completion": "0.00000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.01,
          "outputCost": 0.01,
          "throughput": 31.5455,
          "latency": 583
        },
        {
          "name": "DeepInfra",
          "icon": "https://openrouter.ai/images/icons/DeepInfra.webp",
          "slug": "deepInfra",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/Llama-3.2-1B-Instruct",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "response_format",
            "top_k",
            "seed",
            "min_p"
          ],
          "inputCost": 0.01,
          "outputCost": 0.01,
          "throughput": 144.546,
          "latency": 649
        },
        {
          "name": "inference.net",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inference.net/&size=256",
          "slug": "inferenceNet",
          "quantization": "fp16",
          "context": 16384,
          "maxCompletionTokens": 16384,
          "providerModelId": "meta-llama/llama-3.2-1b-instruct/fp-16",
          "pricing": {
            "prompt": "0.00000001",
            "completion": "0.00000001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "min_p",
            "logit_bias",
            "top_logprobs"
          ],
          "inputCost": 0.01,
          "outputCost": 0.01,
          "throughput": 143.192,
          "latency": 1023
        },
        {
          "name": "Cloudflare",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cloudflare.com/&size=256",
          "slug": "cloudflare",
          "quantization": "unknown",
          "context": 60000,
          "maxCompletionTokens": null,
          "providerModelId": "@cf/meta/llama-3.2-1b-instruct",
          "pricing": {
            "prompt": "0.000000027",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "seed",
            "repetition_penalty",
            "frequency_penalty",
            "presence_penalty"
          ],
          "inputCost": 0.03,
          "outputCost": 0.2,
          "throughput": 277.904,
          "latency": 789
        },
        {
          "name": "SambaNova",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://sambanova.ai/&size=256",
          "slug": "sambaNova",
          "quantization": "bf16",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "Meta-Llama-3.2-1B-Instruct",
          "pricing": {
            "prompt": "0.00000004",
            "completion": "0.00000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 0.04,
          "outputCost": 0.08,
          "throughput": 4054.054,
          "latency": 827
        }
      ]
    },
    {
      "slug": "moonshotai/moonlight-16b-a3b-instruct",
      "hfSlug": "moonshotai/Moonlight-16B-A3B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-28T05:16:41.979606+00:00",
      "hfUpdatedAt": null,
      "name": "Moonshot AI: Moonlight 16B A3B Instruct (free)",
      "shortName": "Moonlight 16B A3B Instruct (free)",
      "author": "moonshotai",
      "description": "Moonlight-16B-A3B-Instruct is a 16B-parameter Mixture-of-Experts (MoE) language model developed by Moonshot AI. It is optimized for instruction-following tasks with 3B activated parameters per inference. The model advances the Pareto frontier in performance per FLOP across English, coding, math, and Chinese benchmarks. It outperforms comparable models like Llama3-3B and Deepseek-v2-Lite while maintaining efficient deployment capabilities through Hugging Face integration and compatibility with popular inference engines like vLLM12.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "moonshotai/moonlight-16b-a3b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "1d289d23-b3d0-43c3-b7f4-f169b7a1af3d",
        "name": "Chutes | moonshotai/moonlight-16b-a3b-instruct:free",
        "contextLength": 8192,
        "model": {
          "slug": "moonshotai/moonlight-16b-a3b-instruct",
          "hfSlug": "moonshotai/Moonlight-16B-A3B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-28T05:16:41.979606+00:00",
          "hfUpdatedAt": null,
          "name": "Moonshot AI: Moonlight 16B A3B Instruct",
          "shortName": "Moonlight 16B A3B Instruct",
          "author": "moonshotai",
          "description": "Moonlight-16B-A3B-Instruct is a 16B-parameter Mixture-of-Experts (MoE) language model developed by Moonshot AI. It is optimized for instruction-following tasks with 3B activated parameters per inference. The model advances the Pareto frontier in performance per FLOP across English, coding, math, and Chinese benchmarks. It outperforms comparable models like Llama3-3B and Deepseek-v2-Lite while maintaining efficient deployment capabilities through Hugging Face integration and compatibility with popular inference engines like vLLM12.",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "moonshotai/moonlight-16b-a3b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "moonshotai/moonlight-16b-a3b-instruct:free",
        "modelVariantPermaslug": "moonshotai/moonlight-16b-a3b-instruct:free",
        "providerName": "Chutes",
        "providerInfo": {
          "name": "Chutes",
          "displayName": "Chutes",
          "slug": "chutes",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://chutes.ai/tos",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Chutes",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
          }
        },
        "providerDisplayName": "Chutes",
        "providerModelId": "moonshotai/Moonlight-16B-A3B-Instruct",
        "providerGroup": "Chutes",
        "quantization": "bf16",
        "variant": "free",
        "isFree": true,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://chutes.ai/tos",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0",
          "completion": "0",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 286,
        "newest": 104,
        "throughputHighToLow": 210,
        "latencyLowToHigh": 198,
        "pricingLowToHigh": 44,
        "pricingHighToLow": 292
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "arcee-ai/caller-large",
      "hfSlug": "",
      "updatedAt": "2025-05-05T23:32:30.837689+00:00",
      "createdAt": "2025-05-05T23:31:09.181141+00:00",
      "hfUpdatedAt": null,
      "name": "Arcee AI: Caller Large",
      "shortName": "Caller Large",
      "author": "arcee-ai",
      "description": "Caller Large is Arcee's specialist \"function‑calling\" SLM built to orchestrate external tools and APIs. Instead of maximizing next‑token accuracy, training focuses on structured JSON outputs, parameter extraction and multi‑step tool chains, making Caller a natural choice for retrieval‑augmented generation, robotic process automation or data‑pull chatbots. It incorporates a routing head that decides when (and how) to invoke a tool versus answering directly, reducing hallucinated calls. The model is already the backbone of Arcee Conductor's auto‑tool mode, where it parses user intent, emits clean function signatures and hands control back once the tool response is ready. Developers thus gain an OpenAI‑style function‑calling UX without handing requests to a frontier‑scale model. ",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "arcee-ai/caller-large",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "587c1cf8-5f90-42f7-9657-4d83c51a1bfb",
        "name": "Together | arcee-ai/caller-large",
        "contextLength": 32768,
        "model": {
          "slug": "arcee-ai/caller-large",
          "hfSlug": "",
          "updatedAt": "2025-05-05T23:32:30.837689+00:00",
          "createdAt": "2025-05-05T23:31:09.181141+00:00",
          "hfUpdatedAt": null,
          "name": "Arcee AI: Caller Large",
          "shortName": "Caller Large",
          "author": "arcee-ai",
          "description": "Caller Large is Arcee's specialist \"function‑calling\" SLM built to orchestrate external tools and APIs. Instead of maximizing next‑token accuracy, training focuses on structured JSON outputs, parameter extraction and multi‑step tool chains, making Caller a natural choice for retrieval‑augmented generation, robotic process automation or data‑pull chatbots. It incorporates a routing head that decides when (and how) to invoke a tool versus answering directly, reducing hallucinated calls. The model is already the backbone of Arcee Conductor's auto‑tool mode, where it parses user intent, emits clean function signatures and hands control back once the tool response is ready. Developers thus gain an OpenAI‑style function‑calling UX without handing requests to a frontier‑scale model. ",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "arcee-ai/caller-large",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "arcee-ai/caller-large",
        "modelVariantPermaslug": "arcee-ai/caller-large",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "arcee-ai/caller",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000055",
          "completion": "0.00000085",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 287,
        "newest": 3,
        "throughputHighToLow": 88,
        "latencyLowToHigh": 52,
        "pricingLowToHigh": 186,
        "pricingHighToLow": 132
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://arcee.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "arcee-ai/caller",
          "pricing": {
            "prompt": "0.00000055",
            "completion": "0.00000085",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.55,
          "outputCost": 0.85,
          "throughput": 86.658,
          "latency": 468.5
        }
      ]
    },
    {
      "slug": "aion-labs/aion-1.0-mini",
      "hfSlug": "FuseAI/FuseO1-DeepSeekR1-QwQ-SkyT1-32B-Preview",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-04T19:25:07.903671+00:00",
      "hfUpdatedAt": null,
      "name": "AionLabs: Aion-1.0-Mini",
      "shortName": "Aion-1.0-Mini",
      "author": "aion-labs",
      "description": "Aion-1.0-Mini 32B parameter model is a distilled version of the DeepSeek-R1 model, designed for strong performance in reasoning domains such as mathematics, coding, and logic. It is a modified variant of a FuseAI model that outperforms R1-Distill-Qwen-32B and R1-Distill-Llama-70B, with benchmark results available on its [Hugging Face page](https://huggingface.co/FuseAI/FuseO1-DeepSeekR1-QwQ-SkyT1-32B-Preview), independently replicated for verification.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "aion-labs/aion-1.0-mini",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "83eeb9eb-edea-49f5-abad-3f245f46420f",
        "name": "AionLabs | aion-labs/aion-1.0-mini",
        "contextLength": 131072,
        "model": {
          "slug": "aion-labs/aion-1.0-mini",
          "hfSlug": "FuseAI/FuseO1-DeepSeekR1-QwQ-SkyT1-32B-Preview",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-02-04T19:25:07.903671+00:00",
          "hfUpdatedAt": null,
          "name": "AionLabs: Aion-1.0-Mini",
          "shortName": "Aion-1.0-Mini",
          "author": "aion-labs",
          "description": "Aion-1.0-Mini 32B parameter model is a distilled version of the DeepSeek-R1 model, designed for strong performance in reasoning domains such as mathematics, coding, and logic. It is a modified variant of a FuseAI model that outperforms R1-Distill-Qwen-32B and R1-Distill-Llama-70B, with benchmark results available on its [Hugging Face page](https://huggingface.co/FuseAI/FuseO1-DeepSeekR1-QwQ-SkyT1-32B-Preview), independently replicated for verification.",
          "modelVersionGroupId": null,
          "contextLength": 16384,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "aion-labs/aion-1.0-mini",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "aion-labs/aion-1.0-mini",
        "modelVariantPermaslug": "aion-labs/aion-1.0-mini",
        "providerName": "AionLabs",
        "providerInfo": {
          "name": "AionLabs",
          "displayName": "AionLabs",
          "slug": "aion-labs",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.aionlabs.ai/terms/",
            "privacyPolicyUrl": "https://www.aionlabs.ai/privacy-policy/",
            "paidModels": {
              "training": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "AionLabs",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.aionlabs.ai/&size=256"
          }
        },
        "providerDisplayName": "AionLabs",
        "providerModelId": "aion-labs/aion-1.0-mini",
        "providerGroup": "AionLabs",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.aionlabs.ai/terms/",
          "privacyPolicyUrl": "https://www.aionlabs.ai/privacy-policy/",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000007",
          "completion": "0.0000014",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 288,
        "newest": 121,
        "throughputHighToLow": 93,
        "latencyLowToHigh": 309,
        "pricingLowToHigh": 198,
        "pricingHighToLow": 120
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://www.aionlabs.ai/\\u0026size=256",
      "providers": [
        {
          "name": "AionLabs",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.aionlabs.ai/&size=256",
          "slug": "aionLabs",
          "quantization": "bf16",
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "aion-labs/aion-1.0-mini",
          "pricing": {
            "prompt": "0.0000007",
            "completion": "0.0000014",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning"
          ],
          "inputCost": 0.7,
          "outputCost": 1.4,
          "throughput": 82.181,
          "latency": 9085.5
        }
      ]
    },
    {
      "slug": "openai/gpt-4-32k",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-08-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4 32k",
      "shortName": "GPT-4 32k",
      "author": "openai",
      "description": "GPT-4-32k is an extended version of GPT-4, with the same capabilities but quadrupled context length, allowing for processing up to 40 pages of text in a single pass. This is particularly beneficial for handling longer content like interacting with PDFs without an external vector database. Training data: up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 32767,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4-32k",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "806209b6-a8c5-4a81-a5d7-057a6678d809",
        "name": "OpenAI | openai/gpt-4-32k",
        "contextLength": 32767,
        "model": {
          "slug": "openai/gpt-4-32k",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-08-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4 32k",
          "shortName": "GPT-4 32k",
          "author": "openai",
          "description": "GPT-4-32k is an extended version of GPT-4, with the same capabilities but quadrupled context length, allowing for processing up to 40 pages of text in a single pass. This is particularly beneficial for handling longer content like interacting with PDFs without an external vector database. Training data: up to Sep 2021.",
          "modelVersionGroupId": null,
          "contextLength": 32767,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4-32k",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4-32k",
        "modelVariantPermaslug": "openai/gpt-4-32k",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4-32k",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00006",
          "completion": "0.00012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 289,
        "newest": 307,
        "throughputHighToLow": 234,
        "latencyLowToHigh": 231,
        "pricingLowToHigh": 315,
        "pricingHighToLow": 2
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 32767,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4-32k",
          "pricing": {
            "prompt": "0.00006",
            "completion": "0.00012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 60,
          "outputCost": 120,
          "throughput": 32.5215,
          "latency": 1556.5
        },
        {
          "name": "Azure",
          "icon": "https://openrouter.ai/images/icons/Azure.svg",
          "slug": "azure",
          "quantization": "unknown",
          "context": 32767,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4-32k",
          "pricing": {
            "prompt": "0.00006",
            "completion": "0.00012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 60,
          "outputCost": 120,
          "throughput": 267.708,
          "latency": 9512
        }
      ]
    },
    {
      "slug": "anthropic/claude-2.1",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude v2.1 (self-moderated)",
      "shortName": "Claude v2.1 (self-moderated)",
      "author": "anthropic",
      "description": "Claude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-2.1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7159a751-fb9d-4750-918b-a774fd71cfa3",
        "name": "Anthropic | anthropic/claude-2.1:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-2.1",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-11-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude v2.1",
          "shortName": "Claude v2.1",
          "author": "anthropic",
          "description": "Claude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-2.1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-2.1:beta",
        "modelVariantPermaslug": "anthropic/claude-2.1:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-2.1",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000008",
          "completion": "0.000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 267,
        "newest": 294,
        "throughputHighToLow": 293,
        "latencyLowToHigh": 224,
        "pricingLowToHigh": 296,
        "pricingHighToLow": 17
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-2.1",
          "pricing": {
            "prompt": "0.000008",
            "completion": "0.000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 8,
          "outputCost": 24,
          "throughput": 16.038,
          "latency": 1531
        }
      ]
    },
    {
      "slug": "cohere/command-r-03-2024",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-02T01:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Cohere: Command R (03-2024)",
      "shortName": "Command R (03-2024)",
      "author": "cohere",
      "description": "Command-R is a 35B parameter model that performs conversational language tasks at a higher quality, more reliably, and with a longer context than previous models. It can be used for complex workflows like code generation, retrieval augmented generation (RAG), tool use, and agents.\n\nRead the launch post [here](https://txt.cohere.com/command-r/).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Cohere",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cohere/command-r-03-2024",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "718ce55c-0d8b-4c0e-af62-2a2f695b90f2",
        "name": "Cohere | cohere/command-r-03-2024",
        "contextLength": 128000,
        "model": {
          "slug": "cohere/command-r-03-2024",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-02T01:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Cohere: Command R (03-2024)",
          "shortName": "Command R (03-2024)",
          "author": "cohere",
          "description": "Command-R is a 35B parameter model that performs conversational language tasks at a higher quality, more reliably, and with a longer context than previous models. It can be used for complex workflows like code generation, retrieval augmented generation (RAG), tool use, and agents.\n\nRead the launch post [here](https://txt.cohere.com/command-r/).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
          "modelVersionGroupId": null,
          "contextLength": 128000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Cohere",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cohere/command-r-03-2024",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cohere/command-r-03-2024",
        "modelVariantPermaslug": "cohere/command-r-03-2024",
        "providerName": "Cohere",
        "providerInfo": {
          "name": "Cohere",
          "displayName": "Cohere",
          "slug": "cohere",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://cohere.com/privacy",
            "termsOfServiceUrl": "https://cohere.com/terms-of-use",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cohere",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cohere.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Cohere.png"
          }
        },
        "providerDisplayName": "Cohere",
        "providerModelId": "command-r-03-2024",
        "providerGroup": "Cohere",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://cohere.com/privacy",
          "termsOfServiceUrl": "https://cohere.com/terms-of-use",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000015",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 291,
        "newest": 283,
        "throughputHighToLow": 45,
        "latencyLowToHigh": 30,
        "pricingLowToHigh": 189,
        "pricingHighToLow": 128
      },
      "authorIcon": "https://openrouter.ai/images/icons/Cohere.png",
      "providers": [
        {
          "name": "Cohere",
          "icon": "https://openrouter.ai/images/icons/Cohere.png",
          "slug": "cohere",
          "quantization": "unknown",
          "context": 128000,
          "maxCompletionTokens": 4000,
          "providerModelId": "command-r-03-2024",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 0.5,
          "outputCost": 1.5,
          "throughput": 139.198,
          "latency": 324
        }
      ]
    },
    {
      "slug": "sao10k/fimbulvetr-11b-v2",
      "hfSlug": "Sao10K/Fimbulvetr-11B-v2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-21T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Fimbulvetr 11B v2",
      "shortName": "Fimbulvetr 11B v2",
      "author": "sao10k",
      "description": "Creative writing model, routed with permission. It's fast, it keeps the conversation going, and it stays in character.\n\nIf you submit a raw prompt, you can use Alpaca or Vicuna formats.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "sao10k/fimbulvetr-11b-v2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "6ed93451-df6d-4ced-adec-318c0b5e713d",
        "name": "Featherless | sao10k/fimbulvetr-11b-v2",
        "contextLength": 4096,
        "model": {
          "slug": "sao10k/fimbulvetr-11b-v2",
          "hfSlug": "Sao10K/Fimbulvetr-11B-v2",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-04-21T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Fimbulvetr 11B v2",
          "shortName": "Fimbulvetr 11B v2",
          "author": "sao10k",
          "description": "Creative writing model, routed with permission. It's fast, it keeps the conversation going, and it stays in character.\n\nIf you submit a raw prompt, you can use Alpaca or Vicuna formats.",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "alpaca",
          "defaultSystem": null,
          "defaultStops": [
            "###",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "sao10k/fimbulvetr-11b-v2",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "sao10k/fimbulvetr-11b-v2",
        "modelVariantPermaslug": "sao10k/fimbulvetr-11b-v2",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "Sao10K/Fimbulvetr-11B-v2",
        "providerGroup": "Featherless",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 292,
        "newest": 265,
        "throughputHighToLow": 265,
        "latencyLowToHigh": 144,
        "pricingLowToHigh": 209,
        "pricingHighToLow": 113
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "Sao10K/Fimbulvetr-11B-v2",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 23.3245,
          "latency": 878.5
        }
      ]
    },
    {
      "slug": "undi95/toppy-m-7b",
      "hfSlug": "Undi95/Toppy-M-7B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Toppy M 7B",
      "shortName": "Toppy M 7B",
      "author": "undi95",
      "description": "A wild 7B parameter model that merges several models using the new task_arithmetic merge method from mergekit.\nList of merged models:\n- NousResearch/Nous-Capybara-7B-V1.9\n- [HuggingFaceH4/zephyr-7b-beta](/models/huggingfaceh4/zephyr-7b-beta)\n- lemonilia/AshhLimaRP-Mistral-7B\n- Vulkane/120-Days-of-Sodom-LoRA-Mistral-7b\n- Undi95/Mistral-pippa-sharegpt-7b-qlora\n\n#merge #uncensored",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "undi95/toppy-m-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "d2b3973b-76cb-43ef-affa-1ca7e1b25ea2",
        "name": "Featherless | undi95/toppy-m-7b",
        "contextLength": 4096,
        "model": {
          "slug": "undi95/toppy-m-7b",
          "hfSlug": "Undi95/Toppy-M-7B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-11-10T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Toppy M 7B",
          "shortName": "Toppy M 7B",
          "author": "undi95",
          "description": "A wild 7B parameter model that merges several models using the new task_arithmetic merge method from mergekit.\nList of merged models:\n- NousResearch/Nous-Capybara-7B-V1.9\n- [HuggingFaceH4/zephyr-7b-beta](/models/huggingfaceh4/zephyr-7b-beta)\n- lemonilia/AshhLimaRP-Mistral-7B\n- Vulkane/120-Days-of-Sodom-LoRA-Mistral-7b\n- Undi95/Mistral-pippa-sharegpt-7b-qlora\n\n#merge #uncensored",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Mistral",
          "instructType": "alpaca",
          "defaultSystem": null,
          "defaultStops": [
            "###",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "undi95/toppy-m-7b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "undi95/toppy-m-7b",
        "modelVariantPermaslug": "undi95/toppy-m-7b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "Undi95/Toppy-M-7B",
        "providerGroup": "Featherless",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": false,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 293,
        "newest": 298,
        "throughputHighToLow": 267,
        "latencyLowToHigh": 186,
        "pricingLowToHigh": 210,
        "pricingHighToLow": 114
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": null,
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "Undi95/Toppy-M-7B",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 23.1,
          "latency": 1231
        }
      ]
    },
    {
      "slug": "ai21/jamba-1.6-mini",
      "hfSlug": "ai21labs/AI21-Jamba-Mini-1.6",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-13T22:32:51+00:00",
      "hfUpdatedAt": null,
      "name": "AI21: Jamba Mini 1.6",
      "shortName": "Jamba Mini 1.6",
      "author": "ai21",
      "description": "AI21 Jamba Mini 1.6 is a hybrid foundation model combining State Space Models (Mamba) with Transformer attention mechanisms. With 12 billion active parameters (52 billion total), this model excels in extremely long-context tasks (up to 256K tokens) and achieves superior inference efficiency, outperforming comparable open models on tasks such as retrieval-augmented generation (RAG) and grounded question answering. Jamba Mini 1.6 supports multilingual tasks across English, Spanish, French, Portuguese, Italian, Dutch, German, Arabic, and Hebrew, along with structured JSON output and tool-use capabilities.\n\nUsage of this model is subject to the [Jamba Open Model License](https://www.ai21.com/licenses/jamba-open-model-license).",
      "modelVersionGroupId": "cd1eb031-30bc-4e2e-aa06-3c20f986e5c7",
      "contextLength": 256000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "ai21/jamba-1.6-mini",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "8c1760f3-6c79-4ba7-9d89-6d5168b075d8",
        "name": "AI21 | ai21/jamba-1.6-mini",
        "contextLength": 256000,
        "model": {
          "slug": "ai21/jamba-1.6-mini",
          "hfSlug": "ai21labs/AI21-Jamba-Mini-1.6",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-13T22:32:51+00:00",
          "hfUpdatedAt": null,
          "name": "AI21: Jamba Mini 1.6",
          "shortName": "Jamba Mini 1.6",
          "author": "ai21",
          "description": "AI21 Jamba Mini 1.6 is a hybrid foundation model combining State Space Models (Mamba) with Transformer attention mechanisms. With 12 billion active parameters (52 billion total), this model excels in extremely long-context tasks (up to 256K tokens) and achieves superior inference efficiency, outperforming comparable open models on tasks such as retrieval-augmented generation (RAG) and grounded question answering. Jamba Mini 1.6 supports multilingual tasks across English, Spanish, French, Portuguese, Italian, Dutch, German, Arabic, and Hebrew, along with structured JSON output and tool-use capabilities.\n\nUsage of this model is subject to the [Jamba Open Model License](https://www.ai21.com/licenses/jamba-open-model-license).",
          "modelVersionGroupId": "cd1eb031-30bc-4e2e-aa06-3c20f986e5c7",
          "contextLength": 256000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "ai21/jamba-1.6-mini",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "ai21/jamba-1.6-mini",
        "modelVariantPermaslug": "ai21/jamba-1.6-mini",
        "providerName": "AI21",
        "providerInfo": {
          "name": "AI21",
          "displayName": "AI21",
          "slug": "ai21",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://www.ai21.com/privacy-policy/",
            "termsOfServiceUrl": "https://www.ai21.com/terms-of-service/",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "IL",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "AI21",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": "https://status.ai21.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://ai21.com/&size=256"
          }
        },
        "providerDisplayName": "AI21",
        "providerModelId": "jamba-mini-1.6",
        "providerGroup": "AI21",
        "quantization": "bf16",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://www.ai21.com/privacy-policy/",
          "termsOfServiceUrl": "https://www.ai21.com/terms-of-service/",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000002",
          "completion": "0.0000004",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 294,
        "newest": 86,
        "throughputHighToLow": 12,
        "latencyLowToHigh": 73,
        "pricingLowToHigh": 150,
        "pricingHighToLow": 168
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai21.com/\\u0026size=256",
      "providers": [
        {
          "name": "AI21",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://ai21.com/&size=256",
          "slug": "ai21",
          "quantization": "bf16",
          "context": 256000,
          "maxCompletionTokens": 4096,
          "providerModelId": "jamba-mini-1.6",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000004",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop"
          ],
          "inputCost": 0.2,
          "outputCost": 0.4,
          "throughput": 208.3575,
          "latency": 503
        }
      ]
    },
    {
      "slug": "openai/o1-pro",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-19T22:26:51.610039+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: o1-pro",
      "shortName": "o1-pro",
      "author": "openai",
      "description": "The o1 series of models are trained with reinforcement learning to think before they answer and perform complex reasoning. The o1-pro model uses more compute to think harder and provide consistently better answers.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/o1-pro",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "046ae30d-fe99-44b4-b020-21127e4342c7",
        "name": "OpenAI | openai/o1-pro",
        "contextLength": 200000,
        "model": {
          "slug": "openai/o1-pro",
          "hfSlug": "",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2025-03-19T22:26:51.610039+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: o1-pro",
          "shortName": "o1-pro",
          "author": "openai",
          "description": "The o1 series of models are trained with reinforcement learning to think before they answer and perform complex reasoning. The o1-pro model uses more compute to think harder and provide consistently better answers.",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text",
            "image"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/o1-pro",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/o1-pro",
        "modelVariantPermaslug": "openai/o1-pro",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "o1-pro",
        "providerGroup": "OpenAI",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 100000,
        "maxPromptImages": 1,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "reasoning",
          "include_reasoning",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00015",
          "completion": "0.0006",
          "image": "0.21675",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": true,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 295,
        "newest": 78,
        "throughputHighToLow": 305,
        "latencyLowToHigh": 314,
        "pricingLowToHigh": 318,
        "pricingHighToLow": 0
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": null,
          "context": 200000,
          "maxCompletionTokens": 100000,
          "providerModelId": "o1-pro",
          "pricing": {
            "prompt": "0.00015",
            "completion": "0.0006",
            "image": "0.21675",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "reasoning",
            "include_reasoning",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format"
          ],
          "inputCost": 150,
          "outputCost": 600,
          "throughput": 12.56,
          "latency": 156692
        }
      ]
    },
    {
      "slug": "anthracite-org/magnum-v2-72b",
      "hfSlug": "anthracite-org/magnum-v2-72b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-30T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Magnum v2 72B",
      "shortName": "Magnum v2 72B",
      "author": "anthracite-org",
      "description": "From the maker of [Goliath](https://openrouter.ai/models/alpindale/goliath-120b), Magnum 72B is the seventh in a family of models designed to achieve the prose quality of the Claude 3 models, notably Opus & Sonnet.\n\nThe model is based on [Qwen2 72B](https://openrouter.ai/models/qwen/qwen-2-72b-instruct) and trained with 55 million tokens of highly curated roleplay (RP) data.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthracite-org/magnum-v2-72b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "740509db-9804-483c-9004-65a3884d7be7",
        "name": "Infermatic | anthracite-org/magnum-v2-72b",
        "contextLength": 32768,
        "model": {
          "slug": "anthracite-org/magnum-v2-72b",
          "hfSlug": "anthracite-org/magnum-v2-72b",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-09-30T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Magnum v2 72B",
          "shortName": "Magnum v2 72B",
          "author": "anthracite-org",
          "description": "From the maker of [Goliath](https://openrouter.ai/models/alpindale/goliath-120b), Magnum 72B is the seventh in a family of models designed to achieve the prose quality of the Claude 3 models, notably Opus & Sonnet.\n\nThe model is based on [Qwen2 72B](https://openrouter.ai/models/qwen/qwen-2-72b-instruct) and trained with 55 million tokens of highly curated roleplay (RP) data.",
          "modelVersionGroupId": null,
          "contextLength": 32768,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthracite-org/magnum-v2-72b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthracite-org/magnum-v2-72b",
        "modelVariantPermaslug": "anthracite-org/magnum-v2-72b",
        "providerName": "Infermatic",
        "providerInfo": {
          "name": "Infermatic",
          "displayName": "Infermatic",
          "slug": "infermatic",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://infermatic.ai/privacy-policy/",
            "termsOfServiceUrl": "https://infermatic.ai/terms-and-conditions/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Infermatic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256"
          }
        },
        "providerDisplayName": "Infermatic",
        "providerModelId": "anthracite-org-magnum-v2-72b-FP8-Dynamic",
        "providerGroup": "Infermatic",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://infermatic.ai/privacy-policy/",
          "termsOfServiceUrl": "https://infermatic.ai/terms-and-conditions/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000003",
          "completion": "0.000003",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 296,
        "newest": 195,
        "throughputHighToLow": 198,
        "latencyLowToHigh": 171,
        "pricingLowToHigh": 256,
        "pricingHighToLow": 61
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Infermatic",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://infermatic.ai/&size=256",
          "slug": "infermatic",
          "quantization": "fp8",
          "context": 32768,
          "maxCompletionTokens": null,
          "providerModelId": "anthracite-org-magnum-v2-72b-FP8-Dynamic",
          "pricing": {
            "prompt": "0.000003",
            "completion": "0.000003",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 3,
          "outputCost": 3,
          "throughput": 42.945,
          "latency": 1065.5
        },
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "anthracite-org/magnum-v2-72b",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 4,
          "outputCost": 6,
          "throughput": 13.779,
          "latency": 1985
        }
      ]
    },
    {
      "slug": "meta-llama/llama-2-70b-chat",
      "hfSlug": "meta-llama/Llama-2-70b-chat-hf",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-06-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 2 70B Chat",
      "shortName": "Llama 2 70B Chat",
      "author": "meta-llama",
      "description": "The flagship, 70 billion parameter language model from Meta, fine tuned for chat completions. Llama 2 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align to human preferences for helpfulness and safety.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "llama2",
      "defaultSystem": null,
      "defaultStops": [
        "</s>",
        "[INST]"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-2-70b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "08b4e0b7-69ca-4c23-8500-ff49a5175285",
        "name": "Together | meta-llama/llama-2-70b-chat",
        "contextLength": 4096,
        "model": {
          "slug": "meta-llama/llama-2-70b-chat",
          "hfSlug": "meta-llama/Llama-2-70b-chat-hf",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-06-20T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: Llama 2 70B Chat",
          "shortName": "Llama 2 70B Chat",
          "author": "meta-llama",
          "description": "The flagship, 70 billion parameter language model from Meta, fine tuned for chat completions. Llama 2 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align to human preferences for helpfulness and safety.",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "llama2",
          "defaultSystem": null,
          "defaultStops": [
            "</s>",
            "[INST]"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-2-70b-chat",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-2-70b-chat",
        "modelVariantPermaslug": "meta-llama/llama-2-70b-chat",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "meta-llama-llama-2-70b-hf",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000009",
          "completion": "0.0000009",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 297,
        "newest": 314,
        "throughputHighToLow": 183,
        "latencyLowToHigh": 82,
        "pricingLowToHigh": 215,
        "pricingHighToLow": 106
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 4096,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama-llama-2-70b-hf",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000009",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.9,
          "outputCost": 0.9,
          "throughput": 46.022,
          "latency": 560
        }
      ]
    },
    {
      "slug": "all-hands/openhands-lm-32b-v0.1",
      "hfSlug": "all-hands/openhands-lm-32b-v0.1",
      "updatedAt": "2025-04-02T17:07:18.295736+00:00",
      "createdAt": "2025-04-02T16:56:53.893822+00:00",
      "hfUpdatedAt": null,
      "name": "OpenHands LM 32B V0.1",
      "shortName": "OpenHands LM 32B V0.1",
      "author": "all-hands",
      "description": "OpenHands LM v0.1 is a 32B open-source coding model fine-tuned from Qwen2.5-Coder-32B-Instruct using reinforcement learning techniques outlined in SWE-Gym. It is optimized for autonomous software development agents and achieves strong performance on SWE-Bench Verified, with a 37.2% resolve rate. The model supports a 128K token context window, making it well-suited for long-horizon code reasoning and large codebase tasks.\n\nOpenHands LM is designed for local deployment and runs on consumer-grade GPUs such as a single 3090. It enables fully offline agent workflows without dependency on proprietary APIs. This release is intended as a research preview, and future updates aim to improve generalizability, reduce repetition, and offer smaller variants.",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "all-hands/openhands-lm-32b-v0.1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3b9c711a-07e8-43d3-a0d7-f387dff982c7",
        "name": "Featherless | all-hands/openhands-lm-32b-v0.1",
        "contextLength": 16384,
        "model": {
          "slug": "all-hands/openhands-lm-32b-v0.1",
          "hfSlug": "all-hands/openhands-lm-32b-v0.1",
          "updatedAt": "2025-04-02T17:07:18.295736+00:00",
          "createdAt": "2025-04-02T16:56:53.893822+00:00",
          "hfUpdatedAt": null,
          "name": "OpenHands LM 32B V0.1",
          "shortName": "OpenHands LM 32B V0.1",
          "author": "all-hands",
          "description": "OpenHands LM v0.1 is a 32B open-source coding model fine-tuned from Qwen2.5-Coder-32B-Instruct using reinforcement learning techniques outlined in SWE-Gym. It is optimized for autonomous software development agents and achieves strong performance on SWE-Bench Verified, with a 37.2% resolve rate. The model supports a 128K token context window, making it well-suited for long-horizon code reasoning and large codebase tasks.\n\nOpenHands LM is designed for local deployment and runs on consumer-grade GPUs such as a single 3090. It enables fully offline agent workflows without dependency on proprietary APIs. This release is intended as a research preview, and future updates aim to improve generalizability, reduce repetition, and offer smaller variants.",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "all-hands/openhands-lm-32b-v0.1",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "all-hands/openhands-lm-32b-v0.1",
        "modelVariantPermaslug": "all-hands/openhands-lm-32b-v0.1",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "all-hands/openhands-lm-32b-v0.1",
        "providerGroup": "Featherless",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000026",
          "completion": "0.0000034",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 298,
        "newest": 65,
        "throughputHighToLow": 303,
        "latencyLowToHigh": 248,
        "pricingLowToHigh": 252,
        "pricingHighToLow": 65
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": null,
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "all-hands/openhands-lm-32b-v0.1",
          "pricing": {
            "prompt": "0.0000026",
            "completion": "0.0000034",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 2.6,
          "outputCost": 3.4,
          "throughput": 13.103,
          "latency": 1865.5
        }
      ]
    },
    {
      "slug": "anthropic/claude-2.0",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude v2.0",
      "shortName": "Claude v2.0",
      "author": "anthropic",
      "description": "Anthropic's flagship model. Superior performance on tasks that require complex reasoning. Supports hundreds of pages of text.",
      "modelVersionGroupId": null,
      "contextLength": 100000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-2.0",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "5a724bb2-64a0-4e69-a04c-bbe4e5d2e391",
        "name": "Anthropic | anthropic/claude-2.0",
        "contextLength": 100000,
        "model": {
          "slug": "anthropic/claude-2.0",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-07-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude v2.0",
          "shortName": "Claude v2.0",
          "author": "anthropic",
          "description": "Anthropic's flagship model. Superior performance on tasks that require complex reasoning. Supports hundreds of pages of text.",
          "modelVersionGroupId": null,
          "contextLength": 100000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-2.0",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-2.0",
        "modelVariantPermaslug": "anthropic/claude-2.0",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-2.0",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000008",
          "completion": "0.000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 299,
        "newest": 310,
        "throughputHighToLow": 250,
        "latencyLowToHigh": 194,
        "pricingLowToHigh": 300,
        "pricingHighToLow": 21
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 100000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-2.0",
          "pricing": {
            "prompt": "0.000008",
            "completion": "0.000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 8,
          "outputCost": 24,
          "throughput": 30.145,
          "latency": 1285
        }
      ]
    },
    {
      "slug": "mancer/weaver",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-08-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mancer: Weaver (alpha)",
      "shortName": "Weaver (alpha)",
      "author": "mancer",
      "description": "An attempt to recreate Claude-style verbosity, but don't expect the same level of coherence or memory. Meant for use in roleplay/narrative situations.",
      "modelVersionGroupId": null,
      "contextLength": 8000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mancer/weaver",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cafb0c7d-4cff-445c-b6d5-446f46dd13cf",
        "name": "Mancer | mancer/weaver",
        "contextLength": 8000,
        "model": {
          "slug": "mancer/weaver",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-08-02T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Mancer: Weaver (alpha)",
          "shortName": "Weaver (alpha)",
          "author": "mancer",
          "description": "An attempt to recreate Claude-style verbosity, but don't expect the same level of coherence or memory. Meant for use in roleplay/narrative situations.",
          "modelVersionGroupId": null,
          "contextLength": 8000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama2",
          "instructType": "alpaca",
          "defaultSystem": null,
          "defaultStops": [
            "###",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "mancer/weaver",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "mancer/weaver",
        "modelVariantPermaslug": "mancer/weaver",
        "providerName": "Mancer",
        "providerInfo": {
          "name": "Mancer",
          "displayName": "Mancer",
          "slug": "mancer",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://mancer.tech/terms",
            "privacyPolicyUrl": "https://mancer.tech/privacy",
            "paidModels": {
              "training": true,
              "retainsPrompts": true
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Mancer",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256"
          }
        },
        "providerDisplayName": "Mancer",
        "providerModelId": "weaver-alpha",
        "providerGroup": "Mancer",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 1000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed",
          "top_a"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://mancer.tech/terms",
          "privacyPolicyUrl": "https://mancer.tech/privacy",
          "paidModels": {
            "training": true,
            "retainsPrompts": true
          },
          "training": true,
          "retainsPrompts": true
        },
        "pricing": {
          "prompt": "0.000001125",
          "completion": "0.000001125",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0.25
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 300,
        "newest": 309,
        "throughputHighToLow": 195,
        "latencyLowToHigh": 115,
        "pricingLowToHigh": 227,
        "pricingHighToLow": 91
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://mancer.tech/\\u0026size=256",
      "providers": [
        {
          "name": "Mancer",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer",
          "quantization": "unknown",
          "context": 8000,
          "maxCompletionTokens": 1000,
          "providerModelId": "weaver-alpha",
          "pricing": {
            "prompt": "0.000001125",
            "completion": "0.000001125",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0.25
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 1.13,
          "outputCost": 1.13,
          "throughput": 43.774,
          "latency": 733
        },
        {
          "name": "Mancer (private)",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://mancer.tech/&size=256",
          "slug": "mancer (private)",
          "quantization": "unknown",
          "context": 8000,
          "maxCompletionTokens": 1000,
          "providerModelId": "weaver-alpha",
          "pricing": {
            "prompt": "0.0000015",
            "completion": "0.0000015",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "logit_bias",
            "top_k",
            "min_p",
            "seed",
            "top_a"
          ],
          "inputCost": 1.5,
          "outputCost": 1.5,
          "throughput": 44.091,
          "latency": 540
        }
      ]
    },
    {
      "slug": "eva-unit-01/eva-llama-3.33-70b",
      "hfSlug": "EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-16T19:28:23.771236+00:00",
      "hfUpdatedAt": null,
      "name": "EVA Llama 3.33 70B",
      "shortName": "EVA Llama 3.33 70B",
      "author": "eva-unit-01",
      "description": "EVA Llama 3.33 70b is a roleplay and storywriting specialist model. It is a full-parameter finetune of [Llama-3.3-70B-Instruct](https://openrouter.ai/meta-llama/llama-3.3-70b-instruct) on mixture of synthetic and natural data.\n\nIt uses Celeste 70B 0.1 data mixture, greatly expanding it to improve versatility, creativity and \"flavor\" of the resulting model\n\nThis model was built with Llama by Meta.\n",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "eva-unit-01/eva-llama-3.33-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cc5c89d5-5596-48b0-af30-45b1fef9d8c5",
        "name": "Featherless | eva-unit-01/eva-llama-3.33-70b",
        "contextLength": 16384,
        "model": {
          "slug": "eva-unit-01/eva-llama-3.33-70b",
          "hfSlug": "EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-12-16T19:28:23.771236+00:00",
          "hfUpdatedAt": null,
          "name": "EVA Llama 3.33 70B",
          "shortName": "EVA Llama 3.33 70B",
          "author": "eva-unit-01",
          "description": "EVA Llama 3.33 70b is a roleplay and storywriting specialist model. It is a full-parameter finetune of [Llama-3.3-70B-Instruct](https://openrouter.ai/meta-llama/llama-3.3-70b-instruct) on mixture of synthetic and natural data.\n\nIt uses Celeste 70B 0.1 data mixture, greatly expanding it to improve versatility, creativity and \"flavor\" of the resulting model\n\nThis model was built with Llama by Meta.\n",
          "modelVersionGroupId": null,
          "contextLength": 16384,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "eva-unit-01/eva-llama-3.33-70b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "eva-unit-01/eva-llama-3.33-70b",
        "modelVariantPermaslug": "eva-unit-01/eva-llama-3.33-70b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.0",
        "providerGroup": "Featherless",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000004",
          "completion": "0.000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 301,
        "newest": 152,
        "throughputHighToLow": 296,
        "latencyLowToHigh": 310,
        "pricingLowToHigh": 280,
        "pricingHighToLow": 35
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.0",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 4,
          "outputCost": 6,
          "throughput": 13.858,
          "latency": 13849
        }
      ]
    },
    {
      "slug": "arcee-ai/maestro-reasoning",
      "hfSlug": "",
      "updatedAt": "2025-05-05T21:48:13.389346+00:00",
      "createdAt": "2025-05-05T21:41:09.235957+00:00",
      "hfUpdatedAt": null,
      "name": "Arcee AI: Maestro Reasoning",
      "shortName": "Maestro Reasoning",
      "author": "arcee-ai",
      "description": "Maestro Reasoning is Arcee's flagship analysis model: a 32 B‑parameter derivative of Qwen 2.5‑32 B tuned with DPO and chain‑of‑thought RL for step‑by‑step logic. Compared to the earlier 7 B preview, the production 32 B release widens the context window to 128 k tokens and doubles pass‑rate on MATH and GSM‑8K, while also lifting code completion accuracy. Its instruction style encourages structured \"thought → answer\" traces that can be parsed or hidden according to user preference. That transparency pairs well with audit‑focused industries like finance or healthcare where seeing the reasoning path matters. In Arcee Conductor, Maestro is automatically selected for complex, multi‑constraint queries that smaller SLMs bounce. ",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "arcee-ai/maestro-reasoning",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "0edd5142-34f6-431d-828b-14c16e184eb0",
        "name": "Together | arcee-ai/maestro-reasoning",
        "contextLength": 131072,
        "model": {
          "slug": "arcee-ai/maestro-reasoning",
          "hfSlug": "",
          "updatedAt": "2025-05-05T21:48:13.389346+00:00",
          "createdAt": "2025-05-05T21:41:09.235957+00:00",
          "hfUpdatedAt": null,
          "name": "Arcee AI: Maestro Reasoning",
          "shortName": "Maestro Reasoning",
          "author": "arcee-ai",
          "description": "Maestro Reasoning is Arcee's flagship analysis model: a 32 B‑parameter derivative of Qwen 2.5‑32 B tuned with DPO and chain‑of‑thought RL for step‑by‑step logic. Compared to the earlier 7 B preview, the production 32 B release widens the context window to 128 k tokens and doubles pass‑rate on MATH and GSM‑8K, while also lifting code completion accuracy. Its instruction style encourages structured \"thought → answer\" traces that can be parsed or hidden according to user preference. That transparency pairs well with audit‑focused industries like finance or healthcare where seeing the reasoning path matters. In Arcee Conductor, Maestro is automatically selected for complex, multi‑constraint queries that smaller SLMs bounce. ",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "arcee-ai/maestro-reasoning",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "arcee-ai/maestro-reasoning",
        "modelVariantPermaslug": "arcee-ai/maestro-reasoning",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "arcee-ai/maestro-reasoning",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000009",
          "completion": "0.0000033",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 302,
        "newest": 5,
        "throughputHighToLow": 65,
        "latencyLowToHigh": 70,
        "pricingLowToHigh": 226,
        "pricingHighToLow": 92
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://arcee.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32000,
          "providerModelId": "arcee-ai/maestro-reasoning",
          "pricing": {
            "prompt": "0.0000009",
            "completion": "0.0000033",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.9,
          "outputCost": 3.3,
          "throughput": 113.949,
          "latency": 499.5
        }
      ]
    },
    {
      "slug": "arcee-ai/virtuoso-medium-v2",
      "hfSlug": "arcee-ai/Virtuoso-Medium-v2",
      "updatedAt": "2025-05-05T21:48:27.917466+00:00",
      "createdAt": "2025-05-05T20:53:54.621827+00:00",
      "hfUpdatedAt": null,
      "name": "Arcee AI: Virtuoso Medium V2",
      "shortName": "Virtuoso Medium V2",
      "author": "arcee-ai",
      "description": "Virtuoso‑Medium‑v2 is a 32 B model distilled from DeepSeek‑v3 logits and merged back onto a Qwen 2.5 backbone, yielding a sharper, more factual successor to the original Virtuoso Medium. The team harvested ~1.1 B logit tokens and applied \"fusion‑merging\" plus DPO alignment, which pushed scores past Arcee‑Nova 2024 and many 40 B‑plus peers on MMLU‑Pro, MATH and HumanEval. With a 128 k context and aggressive quantization options (from BF16 down to 4‑bit GGUF), it balances capability with deployability on single‑GPU nodes. Typical use cases include enterprise chat assistants, technical writing aids and medium‑complexity code drafting where Virtuoso‑Large would be overkill. ",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "arcee-ai/virtuoso-medium-v2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "b3494a2a-b7d6-4055-a379-d77711c85c7b",
        "name": "Together | arcee-ai/virtuoso-medium-v2",
        "contextLength": 131072,
        "model": {
          "slug": "arcee-ai/virtuoso-medium-v2",
          "hfSlug": "arcee-ai/Virtuoso-Medium-v2",
          "updatedAt": "2025-05-05T21:48:27.917466+00:00",
          "createdAt": "2025-05-05T20:53:54.621827+00:00",
          "hfUpdatedAt": null,
          "name": "Arcee AI: Virtuoso Medium V2",
          "shortName": "Virtuoso Medium V2",
          "author": "arcee-ai",
          "description": "Virtuoso‑Medium‑v2 is a 32 B model distilled from DeepSeek‑v3 logits and merged back onto a Qwen 2.5 backbone, yielding a sharper, more factual successor to the original Virtuoso Medium. The team harvested ~1.1 B logit tokens and applied \"fusion‑merging\" plus DPO alignment, which pushed scores past Arcee‑Nova 2024 and many 40 B‑plus peers on MMLU‑Pro, MATH and HumanEval. With a 128 k context and aggressive quantization options (from BF16 down to 4‑bit GGUF), it balances capability with deployability on single‑GPU nodes. Typical use cases include enterprise chat assistants, technical writing aids and medium‑complexity code drafting where Virtuoso‑Large would be overkill. ",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "arcee-ai/virtuoso-medium-v2",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "arcee-ai/virtuoso-medium-v2",
        "modelVariantPermaslug": "arcee-ai/virtuoso-medium-v2",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "arcee-ai/virtuoso-medium-v2",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 32768,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000008",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 303,
        "newest": 8,
        "throughputHighToLow": 142,
        "latencyLowToHigh": 99,
        "pricingLowToHigh": 183,
        "pricingHighToLow": 135
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://arcee.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 32768,
          "providerModelId": "arcee-ai/virtuoso-medium-v2",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000008",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.5,
          "outputCost": 0.8,
          "throughput": 58.564,
          "latency": 641
        }
      ]
    },
    {
      "slug": "alpindale/magnum-72b",
      "hfSlug": "alpindale/magnum-72b-v1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-11T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Magnum 72B",
      "shortName": "Magnum 72B",
      "author": "alpindale",
      "description": "From the maker of [Goliath](https://openrouter.ai/models/alpindale/goliath-120b), Magnum 72B is the first in a new family of models designed to achieve the prose quality of the Claude 3 models, notably Opus & Sonnet.\n\nThe model is based on [Qwen2 72B](https://openrouter.ai/models/qwen/qwen-2-72b-instruct) and trained with 55 million tokens of highly curated roleplay (RP) data.",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "alpindale/magnum-72b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3a1f8d4e-f9ef-44ae-a9a2-9a58bb03e7dc",
        "name": "Featherless | alpindale/magnum-72b",
        "contextLength": 16384,
        "model": {
          "slug": "alpindale/magnum-72b",
          "hfSlug": "alpindale/magnum-72b-v1",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-07-11T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Magnum 72B",
          "shortName": "Magnum 72B",
          "author": "alpindale",
          "description": "From the maker of [Goliath](https://openrouter.ai/models/alpindale/goliath-120b), Magnum 72B is the first in a new family of models designed to achieve the prose quality of the Claude 3 models, notably Opus & Sonnet.\n\nThe model is based on [Qwen2 72B](https://openrouter.ai/models/qwen/qwen-2-72b-instruct) and trained with 55 million tokens of highly curated roleplay (RP) data.",
          "modelVersionGroupId": null,
          "contextLength": 16384,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "alpindale/magnum-72b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "alpindale/magnum-72b",
        "modelVariantPermaslug": "alpindale/magnum-72b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "anthracite-org/magnum-v1-72b",
        "providerGroup": "Featherless",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.000004",
          "completion": "0.000006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 304,
        "newest": 239,
        "throughputHighToLow": 300,
        "latencyLowToHigh": 307,
        "pricingLowToHigh": 282,
        "pricingHighToLow": 37
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "anthracite-org/magnum-v1-72b",
          "pricing": {
            "prompt": "0.000004",
            "completion": "0.000006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 4,
          "outputCost": 6,
          "throughput": 13.742,
          "latency": 9719
        }
      ]
    },
    {
      "slug": "anthropic/claude-2.0",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude v2.0 (self-moderated)",
      "shortName": "Claude v2.0 (self-moderated)",
      "author": "anthropic",
      "description": "Anthropic's flagship model. Superior performance on tasks that require complex reasoning. Supports hundreds of pages of text.",
      "modelVersionGroupId": null,
      "contextLength": 100000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-2.0",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "5a724bb2-64a0-4e69-a04c-bbe4e5d2e391",
        "name": "Anthropic | anthropic/claude-2.0:beta",
        "contextLength": 100000,
        "model": {
          "slug": "anthropic/claude-2.0",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-07-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude v2.0",
          "shortName": "Claude v2.0",
          "author": "anthropic",
          "description": "Anthropic's flagship model. Superior performance on tasks that require complex reasoning. Supports hundreds of pages of text.",
          "modelVersionGroupId": null,
          "contextLength": 100000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-2.0",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-2.0:beta",
        "modelVariantPermaslug": "anthropic/claude-2.0:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-2.0",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000008",
          "completion": "0.000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 299,
        "newest": 310,
        "throughputHighToLow": 250,
        "latencyLowToHigh": 194,
        "pricingLowToHigh": 300,
        "pricingHighToLow": 21
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 100000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-2.0",
          "pricing": {
            "prompt": "0.000008",
            "completion": "0.000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 8,
          "outputCost": 24,
          "throughput": 30.145,
          "latency": 1285
        }
      ]
    },
    {
      "slug": "allenai/olmo-7b-instruct",
      "hfSlug": "allenai/OLMo-7B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OLMo 7B Instruct",
      "shortName": "OLMo 7B Instruct",
      "author": "allenai",
      "description": "OLMo 7B Instruct by the Allen Institute for AI is a model finetuned for question answering. It demonstrates **notable performance** across multiple benchmarks including TruthfulQA and ToxiGen.\n\n**Open Source**: The model, its code, checkpoints, logs are released under the [Apache 2.0 license](https://choosealicense.com/licenses/apache-2.0).\n\n- [Core repo (training, inference, fine-tuning etc.)](https://github.com/allenai/OLMo)\n- [Evaluation code](https://github.com/allenai/OLMo-Eval)\n- [Further fine-tuning code](https://github.com/allenai/open-instruct)\n- [Paper](https://arxiv.org/abs/2402.00838)\n- [Technical blog post](https://blog.allenai.org/olmo-open-language-model-87ccfc95f580)\n- [W&B Logs](https://wandb.ai/ai2-llm/OLMo-7B/reports/OLMo-7B--Vmlldzo2NzQyMzk5)",
      "modelVersionGroupId": null,
      "contextLength": 2048,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "zephyr",
      "defaultSystem": null,
      "defaultStops": [
        "<|user|>\n",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "allenai/olmo-7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "e4f30272-1ce4-40ad-92a9-065c7f7dad69",
        "name": "Nebius | allenai/olmo-7b-instruct",
        "contextLength": 2048,
        "model": {
          "slug": "allenai/olmo-7b-instruct",
          "hfSlug": "allenai/OLMo-7B-Instruct",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-10T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OLMo 7B Instruct",
          "shortName": "OLMo 7B Instruct",
          "author": "allenai",
          "description": "OLMo 7B Instruct by the Allen Institute for AI is a model finetuned for question answering. It demonstrates **notable performance** across multiple benchmarks including TruthfulQA and ToxiGen.\n\n**Open Source**: The model, its code, checkpoints, logs are released under the [Apache 2.0 license](https://choosealicense.com/licenses/apache-2.0).\n\n- [Core repo (training, inference, fine-tuning etc.)](https://github.com/allenai/OLMo)\n- [Evaluation code](https://github.com/allenai/OLMo-Eval)\n- [Further fine-tuning code](https://github.com/allenai/open-instruct)\n- [Paper](https://arxiv.org/abs/2402.00838)\n- [Technical blog post](https://blog.allenai.org/olmo-open-language-model-87ccfc95f580)\n- [W&B Logs](https://wandb.ai/ai2-llm/OLMo-7B/reports/OLMo-7B--Vmlldzo2NzQyMzk5)",
          "modelVersionGroupId": null,
          "contextLength": 2048,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "zephyr",
          "defaultSystem": null,
          "defaultStops": [
            "<|user|>\n",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "allenai/olmo-7b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "allenai/olmo-7b-instruct",
        "modelVariantPermaslug": "allenai/olmo-7b-instruct",
        "providerName": "Nebius",
        "providerInfo": {
          "name": "Nebius",
          "displayName": "Nebius AI Studio",
          "slug": "nebius",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
            "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "DE",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Nebius",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
            "invertRequired": true
          }
        },
        "providerDisplayName": "Nebius AI Studio",
        "providerModelId": "allenai/OLMo-7B-Instruct-hf",
        "providerGroup": "Nebius",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "logit_bias",
          "logprobs",
          "top_logprobs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://docs.nebius.com/legal/studio/terms-of-use/",
          "privacyPolicyUrl": "https://docs.nebius.com/legal/studio/privacy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000008",
          "completion": "0.00000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 306,
        "newest": 262,
        "throughputHighToLow": 166,
        "latencyLowToHigh": 13,
        "pricingLowToHigh": 108,
        "pricingHighToLow": 209
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://allenai.org/\\u0026size=256",
      "providers": [
        {
          "name": "Nebius AI Studio",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://docs.nebius.com/&size=256",
          "slug": "nebiusAiStudio",
          "quantization": null,
          "context": 2048,
          "maxCompletionTokens": null,
          "providerModelId": "allenai/OLMo-7B-Instruct-hf",
          "pricing": {
            "prompt": "0.00000008",
            "completion": "0.00000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "logit_bias",
            "logprobs",
            "top_logprobs"
          ],
          "inputCost": 0.08,
          "outputCost": 0.24,
          "throughput": 50.721,
          "latency": 239
        }
      ]
    },
    {
      "slug": "arcee-ai/spotlight",
      "hfSlug": "",
      "updatedAt": "2025-05-05T21:47:17.011692+00:00",
      "createdAt": "2025-05-05T21:45:52.249082+00:00",
      "hfUpdatedAt": null,
      "name": "Arcee AI: Spotlight",
      "shortName": "Spotlight",
      "author": "arcee-ai",
      "description": "Spotlight is a 7‑billion‑parameter vision‑language model derived from Qwen 2.5‑VL and fine‑tuned by Arcee AI for tight image‑text grounding tasks. It offers a 32 k‑token context window, enabling rich multimodal conversations that combine lengthy documents with one or more images. Training emphasized fast inference on consumer GPUs while retaining strong captioning, visual‐question‑answering, and diagram‑analysis accuracy. As a result, Spotlight slots neatly into agent workflows where screenshots, charts or UI mock‑ups need to be interpreted on the fly. Early benchmarks show it matching or out‑scoring larger VLMs such as LLaVA‑1.6 13 B on popular VQA and POPE alignment tests. ",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "image",
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "arcee-ai/spotlight",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "a9b3fe6f-e21f-4f3c-9ea7-f70d856939d6",
        "name": "Together | arcee-ai/spotlight",
        "contextLength": 131072,
        "model": {
          "slug": "arcee-ai/spotlight",
          "hfSlug": "",
          "updatedAt": "2025-05-05T21:47:17.011692+00:00",
          "createdAt": "2025-05-05T21:45:52.249082+00:00",
          "hfUpdatedAt": null,
          "name": "Arcee AI: Spotlight",
          "shortName": "Spotlight",
          "author": "arcee-ai",
          "description": "Spotlight is a 7‑billion‑parameter vision‑language model derived from Qwen 2.5‑VL and fine‑tuned by Arcee AI for tight image‑text grounding tasks. It offers a 32 k‑token context window, enabling rich multimodal conversations that combine lengthy documents with one or more images. Training emphasized fast inference on consumer GPUs while retaining strong captioning, visual‐question‑answering, and diagram‑analysis accuracy. As a result, Spotlight slots neatly into agent workflows where screenshots, charts or UI mock‑ups need to be interpreted on the fly. Early benchmarks show it matching or out‑scoring larger VLMs such as LLaVA‑1.6 13 B on popular VQA and POPE alignment tests. ",
          "modelVersionGroupId": null,
          "contextLength": 131072,
          "inputModalities": [
            "image",
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "arcee-ai/spotlight",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "arcee-ai/spotlight",
        "modelVariantPermaslug": "arcee-ai/spotlight",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "arcee_ai/arcee-spotlight",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 65537,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000018",
          "completion": "0.00000018",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 307,
        "newest": 4,
        "throughputHighToLow": 23,
        "latencyLowToHigh": 56,
        "pricingLowToHigh": 137,
        "pricingHighToLow": 179
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://arcee.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 131072,
          "maxCompletionTokens": 65537,
          "providerModelId": "arcee_ai/arcee-spotlight",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.18,
          "throughput": 190.058,
          "latency": 268
        }
      ]
    },
    {
      "slug": "openai/gpt-4-0314",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-05-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4 (older v0314)",
      "shortName": "GPT-4 (older v0314)",
      "author": "openai",
      "description": "GPT-4-0314 is the first version of GPT-4 released, with a context length of 8,192 tokens, and was supported until June 14. Training data: up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 8191,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4-0314",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "69206fec-9f6f-4338-9919-5ed90134c376",
        "name": "OpenAI | openai/gpt-4-0314",
        "contextLength": 8191,
        "model": {
          "slug": "openai/gpt-4-0314",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-05-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4 (older v0314)",
          "shortName": "GPT-4 (older v0314)",
          "author": "openai",
          "description": "GPT-4-0314 is the first version of GPT-4 released, with a context length of 8,192 tokens, and was supported until June 14. Training data: up to Sep 2021.",
          "modelVersionGroupId": null,
          "contextLength": 8191,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4-0314",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4-0314",
        "modelVariantPermaslug": "openai/gpt-4-0314",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4-0314",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00003",
          "completion": "0.00006",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 308,
        "newest": 318,
        "throughputHighToLow": 187,
        "latencyLowToHigh": 145,
        "pricingLowToHigh": 313,
        "pricingHighToLow": 6
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 8191,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4-0314",
          "pricing": {
            "prompt": "0.00003",
            "completion": "0.00006",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 30,
          "outputCost": 60,
          "throughput": 42.422,
          "latency": 946
        }
      ]
    },
    {
      "slug": "cohere/command",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Cohere: Command",
      "shortName": "Command",
      "author": "cohere",
      "description": "Command is an instruction-following conversational model that performs language tasks with high quality, more reliably and with a longer context than our base generative models.\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Cohere",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cohere/command",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "73e8a047-c823-454e-ab82-ceea5d165747",
        "name": "Cohere | cohere/command",
        "contextLength": 4096,
        "model": {
          "slug": "cohere/command",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-03-14T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Cohere: Command",
          "shortName": "Command",
          "author": "cohere",
          "description": "Command is an instruction-following conversational model that performs language tasks with high quality, more reliably and with a longer context than our base generative models.\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Cohere",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "cohere/command",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "cohere/command",
        "modelVariantPermaslug": "cohere/command",
        "providerName": "Cohere",
        "providerInfo": {
          "name": "Cohere",
          "displayName": "Cohere",
          "slug": "cohere",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://cohere.com/privacy",
            "termsOfServiceUrl": "https://cohere.com/terms-of-use",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Cohere",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.cohere.ai/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Cohere.png"
          }
        },
        "providerDisplayName": "Cohere",
        "providerModelId": "command",
        "providerGroup": "Cohere",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4000,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "seed",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://cohere.com/privacy",
          "termsOfServiceUrl": "https://cohere.com/terms-of-use",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000001",
          "completion": "0.000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 309,
        "newest": 275,
        "throughputHighToLow": 253,
        "latencyLowToHigh": 147,
        "pricingLowToHigh": 223,
        "pricingHighToLow": 97
      },
      "authorIcon": "https://openrouter.ai/images/icons/Cohere.png",
      "providers": [
        {
          "name": "Cohere",
          "icon": "https://openrouter.ai/images/icons/Cohere.png",
          "slug": "cohere",
          "quantization": "unknown",
          "context": 4096,
          "maxCompletionTokens": 4000,
          "providerModelId": "command",
          "pricing": {
            "prompt": "0.000001",
            "completion": "0.000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "seed",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 1,
          "outputCost": 2,
          "throughput": 25.501,
          "latency": 870.5
        }
      ]
    },
    {
      "slug": "eleutherai/llemma_7b",
      "hfSlug": "EleutherAI/llemma_7b",
      "updatedAt": "2025-05-02T04:24:19.618314+00:00",
      "createdAt": "2025-04-14T15:07:05.530993+00:00",
      "hfUpdatedAt": null,
      "name": "EleutherAI: Llemma 7b",
      "shortName": "Llemma 7b",
      "author": "eleutherai",
      "description": "Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens. Llemma models are particularly strong at chain-of-thought mathematical reasoning and using computational tools for mathematics, such as Python and formal theorem provers.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "code-llama",
      "defaultSystem": null,
      "defaultStops": [
        "Source: assistant",
        "<step>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "eleutherai/llemma_7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "eb965d1b-6176-49cd-a4ea-c8bae8bb8f1d",
        "name": "Featherless | eleutherai/llemma_7b",
        "contextLength": 4096,
        "model": {
          "slug": "eleutherai/llemma_7b",
          "hfSlug": "EleutherAI/llemma_7b",
          "updatedAt": "2025-05-02T04:24:19.618314+00:00",
          "createdAt": "2025-04-14T15:07:05.530993+00:00",
          "hfUpdatedAt": null,
          "name": "EleutherAI: Llemma 7b",
          "shortName": "Llemma 7b",
          "author": "eleutherai",
          "description": "Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens. Llemma models are particularly strong at chain-of-thought mathematical reasoning and using computational tools for mathematics, such as Python and formal theorem provers.",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "code-llama",
          "defaultSystem": null,
          "defaultStops": [
            "Source: assistant",
            "<step>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "eleutherai/llemma_7b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "eleutherai/llemma_7b",
        "modelVariantPermaslug": "eleutherai/llemma_7b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "EleutherAI/llemma_7b",
        "providerGroup": "Featherless",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 310,
        "newest": 51,
        "throughputHighToLow": 273,
        "latencyLowToHigh": 230,
        "pricingLowToHigh": 204,
        "pricingHighToLow": 108
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": null,
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "EleutherAI/llemma_7b",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 21.085,
          "latency": 1593.5
        }
      ]
    },
    {
      "slug": "meta-llama/llama-guard-2-8b",
      "hfSlug": "meta-llama/Meta-Llama-Guard-2-8B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: LlamaGuard 2 8B",
      "shortName": "LlamaGuard 2 8B",
      "author": "meta-llama",
      "description": "This safeguard model has 8B parameters and is based on the Llama 3 family. Just like is predecessor, [LlamaGuard 1](https://huggingface.co/meta-llama/LlamaGuard-7b), it can do both prompt and response classification.\n\nLlamaGuard 2 acts as a normal LLM would, generating text that indicates whether the given input/output is safe/unsafe. If deemed unsafe, it will also share the content categories violated.\n\nFor best results, please use raw prompt input or the `/completions` endpoint, instead of the chat API.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "none",
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-guard-2-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4f39d8b1-b1e1-4158-ab45-8a3de7674c7b",
        "name": "Together | meta-llama/llama-guard-2-8b",
        "contextLength": 8192,
        "model": {
          "slug": "meta-llama/llama-guard-2-8b",
          "hfSlug": "meta-llama/Meta-Llama-Guard-2-8B",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-05-13T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Meta: LlamaGuard 2 8B",
          "shortName": "LlamaGuard 2 8B",
          "author": "meta-llama",
          "description": "This safeguard model has 8B parameters and is based on the Llama 3 family. Just like is predecessor, [LlamaGuard 1](https://huggingface.co/meta-llama/LlamaGuard-7b), it can do both prompt and response classification.\n\nLlamaGuard 2 acts as a normal LLM would, generating text that indicates whether the given input/output is safe/unsafe. If deemed unsafe, it will also share the content categories violated.\n\nFor best results, please use raw prompt input or the `/completions` endpoint, instead of the chat API.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "none",
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "meta-llama/llama-guard-2-8b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "meta-llama/llama-guard-2-8b",
        "modelVariantPermaslug": "meta-llama/llama-guard-2-8b",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "meta-llama/LlamaGuard-2-8b",
        "providerGroup": "Together",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000002",
          "completion": "0.0000002",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 311,
        "newest": 260,
        "throughputHighToLow": 109,
        "latencyLowToHigh": 178,
        "pricingLowToHigh": 148,
        "pricingHighToLow": 172
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": "unknown",
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "meta-llama/LlamaGuard-2-8b",
          "pricing": {
            "prompt": "0.0000002",
            "completion": "0.0000002",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.2,
          "outputCost": 0.2,
          "throughput": 74.433,
          "latency": 895
        }
      ]
    },
    {
      "slug": "eva-unit-01/eva-qwen-2.5-32b",
      "hfSlug": "EVA-UNIT-01/EVA-Qwen2.5-32B-v0.2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-08T22:27:27.726229+00:00",
      "hfUpdatedAt": null,
      "name": "EVA Qwen2.5 32B",
      "shortName": "EVA Qwen2.5 32B",
      "author": "eva-unit-01",
      "description": "EVA Qwen2.5 32B is a roleplaying/storywriting specialist model. It's a full-parameter finetune of Qwen2.5-32B on mixture of synthetic and natural data.\n\nIt uses Celeste 70B 0.1 data mixture, greatly expanding it to improve versatility, creativity and \"flavor\" of the resulting model.",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "eva-unit-01/eva-qwen-2.5-32b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "3d087ccd-9e09-47cd-9f1f-8822ef9156e0",
        "name": "Featherless | eva-unit-01/eva-qwen-2.5-32b",
        "contextLength": 16384,
        "model": {
          "slug": "eva-unit-01/eva-qwen-2.5-32b",
          "hfSlug": "EVA-UNIT-01/EVA-Qwen2.5-32B-v0.2",
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-11-08T22:27:27.726229+00:00",
          "hfUpdatedAt": null,
          "name": "EVA Qwen2.5 32B",
          "shortName": "EVA Qwen2.5 32B",
          "author": "eva-unit-01",
          "description": "EVA Qwen2.5 32B is a roleplaying/storywriting specialist model. It's a full-parameter finetune of Qwen2.5-32B on mixture of synthetic and natural data.\n\nIt uses Celeste 70B 0.1 data mixture, greatly expanding it to improve versatility, creativity and \"flavor\" of the resulting model.",
          "modelVersionGroupId": null,
          "contextLength": 32000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Qwen",
          "instructType": "chatml",
          "defaultSystem": null,
          "defaultStops": [
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "eva-unit-01/eva-qwen-2.5-32b",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "eva-unit-01/eva-qwen-2.5-32b",
        "modelVariantPermaslug": "eva-unit-01/eva-qwen-2.5-32b",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "EVA-UNIT-01/EVA-Qwen2.5-32B-v0.2",
        "providerGroup": "Featherless",
        "quantization": "fp8",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000026",
          "completion": "0.0000034",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 312,
        "newest": 175,
        "throughputHighToLow": 298,
        "latencyLowToHigh": 216,
        "pricingLowToHigh": 253,
        "pricingHighToLow": 66
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": "fp8",
          "context": 16384,
          "maxCompletionTokens": 4096,
          "providerModelId": "EVA-UNIT-01/EVA-Qwen2.5-32B-v0.2",
          "pricing": {
            "prompt": "0.0000026",
            "completion": "0.0000034",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 2.6,
          "outputCost": 3.4,
          "throughput": 13.748,
          "latency": 1588.5
        }
      ]
    },
    {
      "slug": "scb10x/llama3.1-typhoon2-8b-instruct",
      "hfSlug": "scb10x/llama3.1-typhoon2-8b-instruct",
      "updatedAt": "2025-03-28T21:16:32.49476+00:00",
      "createdAt": "2025-03-28T21:15:11.257967+00:00",
      "hfUpdatedAt": null,
      "name": "Typhoon2 8B Instruct",
      "shortName": "Typhoon2 8B Instruct",
      "author": "scb10x",
      "description": "Llama3.1-Typhoon2-8B-Instruct is a Thai-English instruction-tuned model with 8 billion parameters, built on Llama 3.1. It significantly improves over its base model in Thai reasoning, instruction-following, and function-calling tasks, while maintaining competitive English performance. The model is optimized for bilingual interaction and performs well on Thai-English code-switching, MT-Bench, IFEval, and tool-use benchmarks.\n\nDespite its smaller size, it demonstrates strong generalization across math, coding, and multilingual benchmarks, outperforming comparable 8B models across most Thai-specific tasks. Full benchmark results and methodology are available in the [technical report.](https://arxiv.org/abs/2412.13702)",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "scb10x/llama3.1-typhoon2-8b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "cd687004-e160-49f4-b6a1-0f6ab950f046",
        "name": "Together | scb10x/llama3.1-typhoon2-8b-instruct",
        "contextLength": 8192,
        "model": {
          "slug": "scb10x/llama3.1-typhoon2-8b-instruct",
          "hfSlug": "scb10x/llama3.1-typhoon2-8b-instruct",
          "updatedAt": "2025-03-28T21:16:32.49476+00:00",
          "createdAt": "2025-03-28T21:15:11.257967+00:00",
          "hfUpdatedAt": null,
          "name": "Typhoon2 8B Instruct",
          "shortName": "Typhoon2 8B Instruct",
          "author": "scb10x",
          "description": "Llama3.1-Typhoon2-8B-Instruct is a Thai-English instruction-tuned model with 8 billion parameters, built on Llama 3.1. It significantly improves over its base model in Thai reasoning, instruction-following, and function-calling tasks, while maintaining competitive English performance. The model is optimized for bilingual interaction and performs well on Thai-English code-switching, MT-Bench, IFEval, and tool-use benchmarks.\n\nDespite its smaller size, it demonstrates strong generalization across math, coding, and multilingual benchmarks, outperforming comparable 8B models across most Thai-specific tasks. Full benchmark results and methodology are available in the [technical report.](https://arxiv.org/abs/2412.13702)",
          "modelVersionGroupId": null,
          "contextLength": 8192,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Llama3",
          "instructType": "llama3",
          "defaultSystem": null,
          "defaultStops": [
            "<|eot_id|>",
            "<|end_of_text|>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "scb10x/llama3.1-typhoon2-8b-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "scb10x/llama3.1-typhoon2-8b-instruct",
        "modelVariantPermaslug": "scb10x/llama3.1-typhoon2-8b-instruct",
        "providerName": "Together",
        "providerInfo": {
          "name": "Together",
          "displayName": "Together",
          "slug": "together",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
            "privacyPolicyUrl": "https://www.together.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": false,
          "group": "Together",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
          }
        },
        "providerDisplayName": "Together",
        "providerModelId": "scb10x/scb10x-llama3-1-typhoon2-8b-instruct",
        "providerGroup": "Together",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": null,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.together.ai/terms-of-service",
          "privacyPolicyUrl": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.00000018",
          "completion": "0.00000018",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 313,
        "newest": 68,
        "throughputHighToLow": 106,
        "latencyLowToHigh": 77,
        "pricingLowToHigh": 138,
        "pricingHighToLow": 180
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Together",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256",
          "slug": "together",
          "quantization": null,
          "context": 8192,
          "maxCompletionTokens": null,
          "providerModelId": "scb10x/scb10x-llama3-1-typhoon2-8b-instruct",
          "pricing": {
            "prompt": "0.00000018",
            "completion": "0.00000018",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "repetition_penalty",
            "logit_bias",
            "min_p",
            "response_format"
          ],
          "inputCost": 0.18,
          "outputCost": 0.18,
          "throughput": 71.164,
          "latency": 617
        }
      ]
    },
    {
      "slug": "alfredpros/codellama-7b-instruct-solidity",
      "hfSlug": "AlfredPros/CodeLlama-7b-Instruct-Solidity",
      "updatedAt": "2025-05-02T04:22:52.685612+00:00",
      "createdAt": "2025-04-14T14:44:34.216191+00:00",
      "hfUpdatedAt": null,
      "name": "AlfredPros: CodeLLaMa 7B Instruct Solidity",
      "shortName": "CodeLLaMa 7B Instruct Solidity",
      "author": "alfredpros",
      "description": "A finetuned 7 billion parameters Code LLaMA - Instruct model to generate Solidity smart contract using 4-bit QLoRA finetuning provided by PEFT library.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": "",
      "permaslug": "alfredpros/codellama-7b-instruct-solidity",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "7b1e72cd-c414-4ed4-b277-2edaddbf97a0",
        "name": "Featherless | alfredpros/codellama-7b-instruct-solidity",
        "contextLength": 4096,
        "model": {
          "slug": "alfredpros/codellama-7b-instruct-solidity",
          "hfSlug": "AlfredPros/CodeLlama-7b-Instruct-Solidity",
          "updatedAt": "2025-05-02T04:22:52.685612+00:00",
          "createdAt": "2025-04-14T14:44:34.216191+00:00",
          "hfUpdatedAt": null,
          "name": "AlfredPros: CodeLLaMa 7B Instruct Solidity",
          "shortName": "CodeLLaMa 7B Instruct Solidity",
          "author": "alfredpros",
          "description": "A finetuned 7 billion parameters Code LLaMA - Instruct model to generate Solidity smart contract using 4-bit QLoRA finetuning provided by PEFT library.",
          "modelVersionGroupId": null,
          "contextLength": 4096,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": "alpaca",
          "defaultSystem": null,
          "defaultStops": [
            "###",
            "</s>"
          ],
          "hidden": false,
          "router": null,
          "warningMessage": "",
          "permaslug": "alfredpros/codellama-7b-instruct-solidity",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "alfredpros/codellama-7b-instruct-solidity",
        "modelVariantPermaslug": "alfredpros/codellama-7b-instruct-solidity",
        "providerName": "Featherless",
        "providerInfo": {
          "name": "Featherless",
          "displayName": "Featherless",
          "slug": "featherless",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://featherless.ai/terms",
            "privacyPolicyUrl": "https://featherless.ai/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": false
            }
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Featherless",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256"
          }
        },
        "providerDisplayName": "Featherless",
        "providerModelId": "AlfredPros/CodeLlama-7b-Instruct-Solidity",
        "providerGroup": "Featherless",
        "quantization": null,
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "min_p",
          "seed"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://featherless.ai/terms",
          "privacyPolicyUrl": "https://featherless.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          },
          "training": false,
          "retainsPrompts": false
        },
        "pricing": {
          "prompt": "0.0000008",
          "completion": "0.0000012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportedParameters": {},
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 314,
        "newest": 52,
        "throughputHighToLow": 277,
        "latencyLowToHigh": 228,
        "pricingLowToHigh": 205,
        "pricingHighToLow": 109
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": [
        {
          "name": "Featherless",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://featherless.ai/&size=256",
          "slug": "featherless",
          "quantization": null,
          "context": 4096,
          "maxCompletionTokens": 4096,
          "providerModelId": "AlfredPros/CodeLlama-7b-Instruct-Solidity",
          "pricing": {
            "prompt": "0.0000008",
            "completion": "0.0000012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "repetition_penalty",
            "top_k",
            "min_p",
            "seed"
          ],
          "inputCost": 0.8,
          "outputCost": 1.2,
          "throughput": 21.112,
          "latency": 1526.5
        }
      ]
    },
    {
      "slug": "inflection/inflection-3-productivity",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-11T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Inflection: Inflection 3 Productivity",
      "shortName": "Inflection 3 Productivity",
      "author": "inflection",
      "description": "Inflection 3 Productivity is optimized for following instructions. It is better for tasks requiring JSON output or precise adherence to provided guidelines. It has access to recent news.\n\nFor emotional intelligence similar to Pi, see [Inflect 3 Pi](/inflection/inflection-3-pi)\n\nSee [Inflection's announcement](https://inflection.ai/blog/enterprise) for more details.",
      "modelVersionGroupId": null,
      "contextLength": 8000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "inflection/inflection-3-productivity",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "32d4977a-e055-4d2b-a351-5fc09039e363",
        "name": "Inflection | inflection/inflection-3-productivity",
        "contextLength": 8000,
        "model": {
          "slug": "inflection/inflection-3-productivity",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-10-11T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Inflection: Inflection 3 Productivity",
          "shortName": "Inflection 3 Productivity",
          "author": "inflection",
          "description": "Inflection 3 Productivity is optimized for following instructions. It is better for tasks requiring JSON output or precise adherence to provided guidelines. It has access to recent news.\n\nFor emotional intelligence similar to Pi, see [Inflect 3 Pi](/inflection/inflection-3-pi)\n\nSee [Inflection's announcement](https://inflection.ai/blog/enterprise) for more details.",
          "modelVersionGroupId": null,
          "contextLength": 8000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "inflection/inflection-3-productivity",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "inflection/inflection-3-productivity",
        "modelVariantPermaslug": "inflection/inflection-3-productivity",
        "providerName": "Inflection",
        "providerInfo": {
          "name": "Inflection",
          "displayName": "Inflection",
          "slug": "inflection",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://developers.inflection.ai/tos",
            "privacyPolicyUrl": "https://inflection.ai/privacy-policy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            }
          },
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "Inflection",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": null,
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inflection.ai/&size=256"
          }
        },
        "providerDisplayName": "Inflection",
        "providerModelId": "inflection_3_productivity",
        "providerGroup": "Inflection",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 1024,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://developers.inflection.ai/tos",
          "privacyPolicyUrl": "https://inflection.ai/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.0000025",
          "completion": "0.00001",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 315,
        "newest": 191,
        "throughputHighToLow": 190,
        "latencyLowToHigh": 278,
        "pricingLowToHigh": 261,
        "pricingHighToLow": 55
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://inflection.ai/\\u0026size=256",
      "providers": [
        {
          "name": "Inflection",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://inflection.ai/&size=256",
          "slug": "inflection",
          "quantization": "unknown",
          "context": 8000,
          "maxCompletionTokens": 1024,
          "providerModelId": "inflection_3_productivity",
          "pricing": {
            "prompt": "0.0000025",
            "completion": "0.00001",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop"
          ],
          "inputCost": 2.5,
          "outputCost": 10,
          "throughput": 45.045,
          "latency": 2822
        }
      ]
    },
    {
      "slug": "openai/gpt-4-32k-0314",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-08-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4 32k (older v0314)",
      "shortName": "GPT-4 32k (older v0314)",
      "author": "openai",
      "description": "GPT-4-32k is an extended version of GPT-4, with the same capabilities but quadrupled context length, allowing for processing up to 40 pages of text in a single pass. This is particularly beneficial for handling longer content like interacting with PDFs without an external vector database. Training data: up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 32767,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4-32k-0314",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "9a55e9d7-3bc9-4498-8547-f8ae149a261b",
        "name": "OpenAI | openai/gpt-4-32k-0314",
        "contextLength": 32767,
        "model": {
          "slug": "openai/gpt-4-32k-0314",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-08-28T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "OpenAI: GPT-4 32k (older v0314)",
          "shortName": "GPT-4 32k (older v0314)",
          "author": "openai",
          "description": "GPT-4-32k is an extended version of GPT-4, with the same capabilities but quadrupled context length, allowing for processing up to 40 pages of text in a single pass. This is particularly beneficial for handling longer content like interacting with PDFs without an external vector database. Training data: up to Sep 2021.",
          "modelVersionGroupId": null,
          "contextLength": 32767,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "GPT",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "openai/gpt-4-32k-0314",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "openai/gpt-4-32k-0314",
        "modelVariantPermaslug": "openai/gpt-4-32k-0314",
        "providerName": "OpenAI",
        "providerInfo": {
          "name": "OpenAI",
          "displayName": "OpenAI",
          "slug": "openai",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
            "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
            "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "OpenAI",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.openai.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/OpenAI.svg",
            "invertRequired": true
          }
        },
        "providerDisplayName": "OpenAI",
        "providerModelId": "gpt-4-32k-0314",
        "providerGroup": "OpenAI",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "isByok": false,
        "moderationRequired": true,
        "dataPolicy": {
          "termsOfServiceUrl": "https://openai.com/policies/row-terms-of-use/",
          "privacyPolicyUrl": "https://openai.com/policies/privacy-policy/",
          "dataPolicyUrl": "https://platform.openai.com/docs/guides/your-data",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.00006",
          "completion": "0.00012",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": true,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 316,
        "newest": 308,
        "throughputHighToLow": 242,
        "latencyLowToHigh": 174,
        "pricingLowToHigh": 316,
        "pricingHighToLow": 3
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": [
        {
          "name": "OpenAI",
          "icon": "https://openrouter.ai/images/icons/OpenAI.svg",
          "slug": "openAi",
          "quantization": "unknown",
          "context": 32767,
          "maxCompletionTokens": 4096,
          "providerModelId": "gpt-4-32k-0314",
          "pricing": {
            "prompt": "0.00006",
            "completion": "0.00012",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "tools",
            "tool_choice",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "logit_bias",
            "logprobs",
            "top_logprobs",
            "response_format",
            "structured_outputs"
          ],
          "inputCost": 60,
          "outputCost": 120,
          "throughput": 31.436,
          "latency": 1077
        }
      ]
    },
    {
      "slug": "anthropic/claude-2",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude v2 (self-moderated)",
      "shortName": "Claude v2 (self-moderated)",
      "author": "anthropic",
      "description": "Claude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "258ddc79-e520-4e68-8069-ea6771698c5a",
        "name": "Anthropic | anthropic/claude-2:beta",
        "contextLength": 200000,
        "model": {
          "slug": "anthropic/claude-2",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2023-11-22T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "Anthropic: Claude v2",
          "shortName": "Claude v2",
          "author": "anthropic",
          "description": "Claude 2 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and a new beta feature: tool use.",
          "modelVersionGroupId": null,
          "contextLength": 200000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Claude",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "anthropic/claude-2",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "anthropic/claude-2:beta",
        "modelVariantPermaslug": "anthropic/claude-2:beta",
        "providerName": "Anthropic",
        "providerInfo": {
          "name": "Anthropic",
          "displayName": "Anthropic",
          "slug": "anthropic",
          "baseUrl": "url",
          "dataPolicy": {
            "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
            "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
            "paidModels": {
              "training": false,
              "retainsPrompts": true,
              "retentionDays": 30
            },
            "requiresUserIds": true
          },
          "headquarters": "US",
          "hasChatCompletions": true,
          "hasCompletions": true,
          "isAbortable": true,
          "moderationRequired": true,
          "group": "Anthropic",
          "editors": [],
          "owners": [],
          "isMultipartSupported": true,
          "statusPageUrl": "https://status.anthropic.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "/images/icons/Anthropic.svg"
          }
        },
        "providerDisplayName": "Anthropic",
        "providerModelId": "claude-2.1",
        "providerGroup": "Anthropic",
        "quantization": "unknown",
        "variant": "beta",
        "isFree": false,
        "canAbort": true,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "termsOfServiceUrl": "https://www.anthropic.com/legal/commercial-terms",
          "privacyPolicyUrl": "https://www.anthropic.com/legal/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true,
            "retentionDays": 30
          },
          "requiresUserIds": true,
          "training": false,
          "retainsPrompts": true,
          "retentionDays": 30
        },
        "pricing": {
          "prompt": "0.000008",
          "completion": "0.000024",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": true,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": true,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 282,
        "newest": 296,
        "throughputHighToLow": 291,
        "latencyLowToHigh": 202,
        "pricingLowToHigh": 298,
        "pricingHighToLow": 19
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": [
        {
          "name": "Anthropic",
          "icon": "https://openrouter.ai/images/icons/Anthropic.svg",
          "slug": "anthropic",
          "quantization": "unknown",
          "context": 200000,
          "maxCompletionTokens": 4096,
          "providerModelId": "claude-2.1",
          "pricing": {
            "prompt": "0.000008",
            "completion": "0.000024",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "top_k",
            "stop"
          ],
          "inputCost": 8,
          "outputCost": 24,
          "throughput": 16.037,
          "latency": 1566
        }
      ]
    },
    {
      "slug": "ai21/jamba-instruct",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "AI21: Jamba Instruct",
      "shortName": "Jamba Instruct",
      "author": "ai21",
      "description": "The Jamba-Instruct model, introduced by AI21 Labs, is an instruction-tuned variant of their hybrid SSM-Transformer Jamba model, specifically optimized for enterprise applications.\n\n- 256K Context Window: It can process extensive information, equivalent to a 400-page novel, which is beneficial for tasks involving large documents such as financial reports or legal documents\n- Safety and Accuracy: Jamba-Instruct is designed with enhanced safety features to ensure secure deployment in enterprise environments, reducing the risk and cost of implementation\n\nRead their [announcement](https://www.ai21.com/blog/announcing-jamba) to learn more.\n\nJamba has a knowledge cutoff of February 2024.",
      "modelVersionGroupId": null,
      "contextLength": 256000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "ai21/jamba-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": {
        "id": "4bdfe9f1-ba9f-4da1-ae1f-904bc6a7cd84",
        "name": "AI21 | ai21/jamba-instruct",
        "contextLength": 256000,
        "model": {
          "slug": "ai21/jamba-instruct",
          "hfSlug": null,
          "updatedAt": "2025-03-28T03:20:30.853469+00:00",
          "createdAt": "2024-06-25T00:00:00+00:00",
          "hfUpdatedAt": null,
          "name": "AI21: Jamba Instruct",
          "shortName": "Jamba Instruct",
          "author": "ai21",
          "description": "The Jamba-Instruct model, introduced by AI21 Labs, is an instruction-tuned variant of their hybrid SSM-Transformer Jamba model, specifically optimized for enterprise applications.\n\n- 256K Context Window: It can process extensive information, equivalent to a 400-page novel, which is beneficial for tasks involving large documents such as financial reports or legal documents\n- Safety and Accuracy: Jamba-Instruct is designed with enhanced safety features to ensure secure deployment in enterprise environments, reducing the risk and cost of implementation\n\nRead their [announcement](https://www.ai21.com/blog/announcing-jamba) to learn more.\n\nJamba has a knowledge cutoff of February 2024.",
          "modelVersionGroupId": null,
          "contextLength": 256000,
          "inputModalities": [
            "text"
          ],
          "outputModalities": [
            "text"
          ],
          "hasTextOutput": true,
          "group": "Other",
          "instructType": null,
          "defaultSystem": null,
          "defaultStops": [],
          "hidden": false,
          "router": null,
          "warningMessage": null,
          "permaslug": "ai21/jamba-instruct",
          "reasoningConfig": null,
          "features": {}
        },
        "modelVariantSlug": "ai21/jamba-instruct",
        "modelVariantPermaslug": "ai21/jamba-instruct",
        "providerName": "AI21",
        "providerInfo": {
          "name": "AI21",
          "displayName": "AI21",
          "slug": "ai21",
          "baseUrl": "url",
          "dataPolicy": {
            "privacyPolicyUrl": "https://www.ai21.com/privacy-policy/",
            "termsOfServiceUrl": "https://www.ai21.com/terms-of-service/",
            "paidModels": {
              "training": false
            }
          },
          "headquarters": "IL",
          "hasChatCompletions": true,
          "hasCompletions": false,
          "isAbortable": false,
          "moderationRequired": false,
          "group": "AI21",
          "editors": [],
          "owners": [],
          "isMultipartSupported": false,
          "statusPageUrl": "https://status.ai21.com/",
          "byokEnabled": true,
          "isPrimaryProvider": true,
          "icon": {
            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://ai21.com/&size=256"
          }
        },
        "providerDisplayName": "AI21",
        "providerModelId": "jamba-instruct",
        "providerGroup": "AI21",
        "quantization": "unknown",
        "variant": "standard",
        "isFree": false,
        "canAbort": false,
        "maxPromptTokens": null,
        "maxCompletionTokens": 4096,
        "maxPromptImages": null,
        "maxTokensPerImage": null,
        "supportedParameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop"
        ],
        "isByok": false,
        "moderationRequired": false,
        "dataPolicy": {
          "privacyPolicyUrl": "https://www.ai21.com/privacy-policy/",
          "termsOfServiceUrl": "https://www.ai21.com/terms-of-service/",
          "paidModels": {
            "training": false
          },
          "training": false
        },
        "pricing": {
          "prompt": "0.0000005",
          "completion": "0.0000007",
          "image": "0",
          "request": "0",
          "webSearch": "0",
          "internalReasoning": "0",
          "discount": 0
        },
        "variablePricings": [],
        "isHidden": false,
        "isDeranked": false,
        "isDisabled": false,
        "supportsToolParameters": false,
        "supportsReasoning": false,
        "supportsMultipart": false,
        "limitRpm": null,
        "limitRpd": null,
        "hasCompletions": false,
        "hasChatCompletions": true,
        "features": {
          "supportsDocumentUrl": null
        },
        "providerRegion": null
      },
      "sorting": {
        "topWeekly": 318,
        "newest": 243,
        "throughputHighToLow": 311,
        "latencyLowToHigh": 318,
        "pricingLowToHigh": 181,
        "pricingHighToLow": 137
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai21.com/\\u0026size=256",
      "providers": [
        {
          "name": "AI21",
          "icon": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://ai21.com/&size=256",
          "slug": "ai21",
          "quantization": "unknown",
          "context": 256000,
          "maxCompletionTokens": 4096,
          "providerModelId": "jamba-instruct",
          "pricing": {
            "prompt": "0.0000005",
            "completion": "0.0000007",
            "image": "0",
            "request": "0",
            "webSearch": "0",
            "internalReasoning": "0",
            "discount": 0
          },
          "supportedParameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop"
          ],
          "inputCost": 0.5,
          "outputCost": 0.7
        }
      ]
    },
    {
      "slug": "openrouter/optimus-alpha",
      "hfSlug": "",
      "updatedAt": "2025-04-10T19:05:05.295462+00:00",
      "createdAt": "2025-04-10T13:30:19+00:00",
      "hfUpdatedAt": null,
      "name": "Optimus Alpha",
      "shortName": "Optimus Alpha",
      "author": "openrouter",
      "description": "This is a cloaked model provided to the community to gather feedback. It's geared toward real world use cases, including programming.\n\n**Note:** All prompts and completions for this model are logged by the provider and may be used to improve the model.",
      "modelVersionGroupId": null,
      "contextLength": 1000000,
      "inputModalities": [
        "image",
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openrouter/optimus-alpha",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 319,
        "newest": 319,
        "throughputHighToLow": 319,
        "latencyLowToHigh": 319,
        "pricingLowToHigh": 319,
        "pricingHighToLow": 319
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://openrouter.ai/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "nvidia/llama-3.1-nemotron-nano-8b-v1",
      "hfSlug": "nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
      "updatedAt": "2025-04-08T14:53:32.88218+00:00",
      "createdAt": "2025-04-08T14:51:13.861184+00:00",
      "hfUpdatedAt": null,
      "name": "NVIDIA: Llama 3.1 Nemotron Nano 8B v1",
      "shortName": "Llama 3.1 Nemotron Nano 8B v1",
      "author": "nvidia",
      "description": "Llama-3.1-Nemotron-Nano-8B-v1 is a compact large language model (LLM) derived from Meta's Llama-3.1-8B-Instruct, specifically optimized for reasoning tasks, conversational interactions, retrieval-augmented generation (RAG), and tool-calling applications. It balances accuracy and efficiency, fitting comfortably onto a single consumer-grade RTX GPU for local deployment. The model supports extended context lengths of up to 128K tokens.\n\nNote: you must include `detailed thinking on` in the system prompt to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations) for more.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nvidia/llama-3.1-nemotron-nano-8b-v1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 320,
        "newest": 320,
        "throughputHighToLow": 320,
        "latencyLowToHigh": 320,
        "pricingLowToHigh": 320,
        "pricingHighToLow": 320
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nvidia.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "tokyotech-llm/llama-3.1-swallow-8b-instruct-v0.3",
      "hfSlug": "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3",
      "updatedAt": "2025-04-07T00:46:18.321729+00:00",
      "createdAt": "2025-04-07T00:45:42.283161+00:00",
      "hfUpdatedAt": null,
      "name": "Swallow: Llama 3.1 Swallow 8B Instruct V0.3",
      "shortName": "Llama 3.1 Swallow 8B Instruct V0.3",
      "author": "tokyotech-llm",
      "description": "Llama 3.1 Swallow 8B is a large language model that was built by continual pre-training on the Meta Llama 3.1 8B. Llama 3.1 Swallow enhanced the Japanese language capabilities of the original Llama 3.1 while retaining the English language capabilities. \nSwallow used approximately 200 billion tokens that were sampled from a large Japanese web corpus (Swallow Corpus Version 2), Japanese and English Wikipedia articles, and mathematical and coding contents, etc (see the Training Datasets section of the base model) for continual pre-training. The instruction-tuned models (Instruct) were built by supervised fine-tuning (SFT) on the synthetic data specially built for Japanese.\n",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "tokyotech-llm/llama-3.1-swallow-8b-instruct-v0.3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 321,
        "newest": 321,
        "throughputHighToLow": 321,
        "latencyLowToHigh": 321,
        "pricingLowToHigh": 321,
        "pricingHighToLow": 321
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "openrouter/quasar-alpha",
      "hfSlug": "",
      "updatedAt": "2025-04-10T19:05:56.821658+00:00",
      "createdAt": "2025-04-02T20:46:49.278785+00:00",
      "hfUpdatedAt": null,
      "name": "Quasar Alpha",
      "shortName": "Quasar Alpha",
      "author": "openrouter",
      "description": "This is a cloaked model provided to the community to gather feedback. It’s a powerful, all-purpose model supporting long-context tasks, including code generation.\n\n**Note:** All prompts and completions for this model are logged by the provider  and may be used to improve the model.",
      "modelVersionGroupId": null,
      "contextLength": 1000000,
      "inputModalities": [
        "image",
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openrouter/quasar-alpha",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 322,
        "newest": 322,
        "throughputHighToLow": 322,
        "latencyLowToHigh": 322,
        "pricingLowToHigh": 322,
        "pricingHighToLow": 322
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://openrouter.ai/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "allenai/molmo-7b-d",
      "hfSlug": "allenai/Molmo-7B-D-0924",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-26T21:07:27.910928+00:00",
      "hfUpdatedAt": null,
      "name": "AllenAI: Molmo 7B D",
      "shortName": "Molmo 7B D",
      "author": "allenai",
      "description": "Molmo is a family of open vision-language models developed by the Allen Institute for AI. Molmo models are trained on PixMo, a dataset of 1 million, highly-curated image-text pairs. It has state-of-the-art performance among multimodal models with a similar size while being fully open-source. You can find all models in the Molmo family [here](https://huggingface.co/collections/allenai/molmo-66f379e6fe3b8ef090a8ca19). Learn more about the Molmo family [in the announcement blog post](https://molmo.allenai.org/blog) or the [paper](https://huggingface.co/papers/2409.17146).\n\nMolmo 7B-D is based on [Qwen2-7B](https://huggingface.co/Qwen/Qwen2-7B) and uses [OpenAI CLIP](https://huggingface.co/openai/clip-vit-large-patch14-336) as vision backbone. It performs comfortably between GPT-4V and GPT-4o on both academic benchmarks and human evaluation.\n\nThis checkpoint is a preview of the Molmo release. All artifacts used in creating Molmo (PixMo dataset, training code, evaluations, intermediate checkpoints) will be made available at a later date, furthering our commitment to open-source AI development and reproducibility.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "allenai/molmo-7b-d-0924",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 323,
        "newest": 323,
        "throughputHighToLow": 323,
        "latencyLowToHigh": 323,
        "pricingLowToHigh": 323,
        "pricingHighToLow": 323
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://allenai.org/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "steelskull/l3.3-electra-r1-70b",
      "hfSlug": "Steelskull/L3.3-Electra-R1-70b",
      "updatedAt": "2025-05-02T21:14:16.355933+00:00",
      "createdAt": "2025-03-15T19:40:11.589736+00:00",
      "hfUpdatedAt": null,
      "name": "SteelSkull: L3.3 Electra R1 70B",
      "shortName": "L3.3 Electra R1 70B",
      "author": "steelskull",
      "description": "L3.3-Electra-R1-70 is the newest release of the Unnamed series. Built on a DeepSeek R1 Distill base, Electra-R1 integrates various models together to provide an intelligent and coherent model capable of providing deep character insights. Through proper prompting, the model demonstrates advanced reasoning capabilities and unprompted exploration of character inner thoughts and motivations. Read more about the model and [prompting here](https://huggingface.co/Steelskull/L3.3-Electra-R1-70b)",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "deepseek-r1",
      "defaultSystem": null,
      "defaultStops": [
        "<｜User｜>",
        "<｜end▁of▁sentence｜>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "steelskull/l3.3-electra-r1-70b",
      "reasoningConfig": {
        "startToken": "<think>",
        "endToken": "</think>"
      },
      "features": {
        "reasoningConfig": {
          "startToken": "<think>",
          "endToken": "</think>"
        }
      },
      "endpoint": null,
      "sorting": {
        "topWeekly": 324,
        "newest": 324,
        "throughputHighToLow": 324,
        "latencyLowToHigh": 324,
        "pricingLowToHigh": 324,
        "pricingHighToLow": 324
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "allenai/olmo-2-0325-32b-instruct",
      "hfSlug": "allenai/OLMo-2-0325-32B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-14T21:42:36.35362+00:00",
      "hfUpdatedAt": null,
      "name": "AllenAI: Olmo 2 32B Instruct",
      "shortName": "Olmo 2 32B Instruct",
      "author": "allenai",
      "description": "OLMo-2 32B Instruct is a supervised instruction-finetuned variant of the OLMo-2 32B March 2025 base model. It excels in complex reasoning and instruction-following tasks across diverse benchmarks such as GSM8K, MATH, IFEval, and general NLP evaluation. Developed by AI2, OLMo-2 32B is part of an open, research-oriented initiative, trained primarily on English-language datasets to advance the understanding and development of open-source language models.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "allenai/olmo-2-0325-32b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 325,
        "newest": 325,
        "throughputHighToLow": 325,
        "latencyLowToHigh": 325,
        "pricingLowToHigh": 325,
        "pricingHighToLow": 325
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://allenai.org/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "latitudegames/wayfarer-large-70b-llama-3.3",
      "hfSlug": "LatitudeGames/Wayfarer-Large-70B-Llama-3.3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-10T20:01:25.311759+00:00",
      "hfUpdatedAt": null,
      "name": "LatitudeGames: Wayfarer Large 70B Llama 3.3",
      "shortName": "Wayfarer Large 70B Llama 3.3",
      "author": "latitudegames",
      "description": "Wayfarer Large 70B is a roleplay and text-adventure model fine-tuned from Meta’s Llama-3.3-70B-Instruct. Specifically optimized for narrative-driven, challenging scenarios, it introduces realistic stakes, conflicts, and consequences often avoided by standard RLHF-aligned models. Trained using a curated blend of adventure, roleplay, and instructive fiction datasets, Wayfarer emphasizes tense storytelling, authentic player failure scenarios, and robust narrative immersion, making it uniquely suited for interactive fiction and gaming experiences.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "latitudegames/wayfarer-large-70b-llama-3.3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 326,
        "newest": 326,
        "throughputHighToLow": 326,
        "latencyLowToHigh": 326,
        "pricingLowToHigh": 326,
        "pricingHighToLow": 326
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "qwen/qwen2.5-32b-instruct",
      "hfSlug": "Qwen/Qwen2.5-32B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-03-03T22:59:04.755619+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen: Qwen2.5 32B Instruct",
      "shortName": "Qwen2.5 32B Instruct",
      "author": "qwen",
      "description": "Qwen2.5 32B Instruct is the instruction-tuned variant of the latest Qwen large language model series. It provides enhanced instruction-following capabilities, improved proficiency in coding and mathematical reasoning, and robust handling of structured data and outputs such as JSON. It supports long-context processing up to 128K tokens and multilingual tasks across 29+ languages. The model has 32.5 billion parameters, 64 layers, and utilizes an advanced transformer architecture with RoPE, SwiGLU, RMSNorm, and Attention QKV bias.\n\nFor more details, please refer to the [Qwen2.5 Blog](https://qwenlm.github.io/blog/qwen2.5/) .",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen2.5-32b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 327,
        "newest": 327,
        "throughputHighToLow": 327,
        "latencyLowToHigh": 327,
        "pricingLowToHigh": 327,
        "pricingHighToLow": 327
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "allenai/llama-3.1-tulu-3-405b",
      "hfSlug": "allenai/Llama-3.1-Tulu-3-405B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-02-08T22:23:41.550447+00:00",
      "hfUpdatedAt": null,
      "name": "Llama 3.1 Tulu 3 405B",
      "shortName": "Llama 3.1 Tulu 3 405B",
      "author": "allenai",
      "description": "Tülu 3 405B is the largest model in the Tülu 3 family, applying fully open post-training recipes at a 405B parameter scale. Built on the Llama 3.1 405B base, it leverages Reinforcement Learning with Verifiable Rewards (RLVR) to enhance instruction following, MATH, GSM8K, and IFEval performance. As part of Tülu 3’s fully open-source approach, it offers state-of-the-art capabilities while surpassing prior open-weight models like Llama 3.1 405B Instruct and Nous Hermes 3 405B on multiple benchmarks. To read more, [click here.](https://allenai.org/blog/tulu-3-405B)",
      "modelVersionGroupId": null,
      "contextLength": 0,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "allenai/llama-3.1-tulu-3-405b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 328,
        "newest": 328,
        "throughputHighToLow": 328,
        "latencyLowToHigh": 328,
        "pricingLowToHigh": 328,
        "pricingHighToLow": 328
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://allenai.org/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "sao10k/l3.1-70b-hanami-x1",
      "hfSlug": "Sao10K/L3.1-70B-Hanami-x1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2025-01-08T02:20:54.222148+00:00",
      "hfUpdatedAt": null,
      "name": "Sao10K: Llama 3.1 70B Hanami x1",
      "shortName": "Llama 3.1 70B Hanami x1",
      "author": "sao10k",
      "description": "This is [Sao10K](/sao10k)'s experiment over [Euryale v2.2](/sao10k/l3.1-euryale-70b).",
      "modelVersionGroupId": null,
      "contextLength": 16000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "sao10k/l3.1-70b-hanami-x1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 329,
        "newest": 329,
        "throughputHighToLow": 329,
        "latencyLowToHigh": 329,
        "pricingLowToHigh": 329,
        "pricingHighToLow": 329
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "inflatebot/mn-mag-mell-r1",
      "hfSlug": "inflatebot/MN-12B-Mag-Mell-R1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-12-18T15:23:59.252033+00:00",
      "hfUpdatedAt": null,
      "name": "Inflatebot: Mag Mell R1 12B",
      "shortName": "Mag Mell R1 12B",
      "author": "inflatebot",
      "description": "Mag Mell is a merge of pre-trained language models created using mergekit, based on [Mistral Nemo](/mistralai/mistral-nemo). It is a great roleplay and storytelling model which combines the best parts of many other models to be a general purpose solution for many usecases.\n\nIntended to be a general purpose \"Best of Nemo\" model for any fictional, creative use case. \n\nMag Mell is composed of 3 intermediate parts:\n- Hero (RP, trope coverage)\n- Monk (Intelligence, groundedness)\n- Deity (Prose, flair)",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "inflatebot/mn-mag-mell-r1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 330,
        "newest": 330,
        "throughputHighToLow": 330,
        "latencyLowToHigh": 330,
        "pricingLowToHigh": 330,
        "pricingHighToLow": 330
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "google/gemini-exp-1121",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-21T19:18:45.23737+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini Experimental 1121",
      "shortName": "Gemini Experimental 1121",
      "author": "google",
      "description": "Experimental release (November 21st, 2024) of Gemini.",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-exp-1121",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 331,
        "newest": 331,
        "throughputHighToLow": 331,
        "latencyLowToHigh": 331,
        "pricingLowToHigh": 331,
        "pricingHighToLow": 331
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "google/gemini-exp-1114",
      "hfSlug": "",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-11-15T23:52:20.203831+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini Experimental 1114",
      "shortName": "Gemini Experimental 1114",
      "author": "google",
      "description": "Gemini 11-14 (2024) experimental model features \"quality\" improvements.",
      "modelVersionGroupId": null,
      "contextLength": 40960,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-exp-1114",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 332,
        "newest": 332,
        "throughputHighToLow": 332,
        "latencyLowToHigh": 332,
        "pricingLowToHigh": 332,
        "pricingHighToLow": 332
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "x-ai/grok-2-mini",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-12T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "xAI: Grok 2 mini",
      "shortName": "Grok 2 mini",
      "author": "x-ai",
      "description": "Grok 2 Mini is xAI's fast, lightweight language model that offers a balance between speed and answer quality.\n\nTo use the stronger model, see [Grok Beta](/x-ai/grok-beta).\n\nFor more information, see the [launch announcement](https://x.ai/blog/grok-2).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Grok",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "x-ai/grok-2-mini",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 333,
        "newest": 333,
        "throughputHighToLow": 333,
        "latencyLowToHigh": 333,
        "pricingLowToHigh": 333,
        "pricingHighToLow": 333
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://x.ai/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "x-ai/grok-2",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-10-12T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "xAI: Grok 2",
      "shortName": "Grok 2",
      "author": "x-ai",
      "description": "Grok 2 is xAI's frontier language model with state-of-the-art reasoning capabilities, best for complex and multi-step use cases.\n\nTo use a faster version, see [Grok 2 Mini](/x-ai/grok-2-mini).\n\nFor more information, see the [launch announcement](https://x.ai/blog/grok-2).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Grok",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "x-ai/grok-2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 334,
        "newest": 334,
        "throughputHighToLow": 334,
        "latencyLowToHigh": 334,
        "pricingLowToHigh": 334,
        "pricingHighToLow": 334
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://x.ai/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "eva-unit-01/eva-qwen-2.5-14b",
      "hfSlug": "EVA-UNIT-01/EVA-Qwen2.5-14B-v0.0",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-30T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "EVA Qwen2.5 14B",
      "shortName": "EVA Qwen2.5 14B",
      "author": "eva-unit-01",
      "description": "A model specializing in RP and creative writing, this model is based on Qwen2.5-14B, fine-tuned with a mixture of synthetic and natural data.\n\nIt is trained on 1.5M tokens of role-play data, and fine-tuned on 1.5M tokens of synthetic data.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "eva-unit-01/eva-qwen-2.5-14b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 335,
        "newest": 335,
        "throughputHighToLow": 335,
        "latencyLowToHigh": 335,
        "pricingLowToHigh": 335,
        "pricingHighToLow": 335
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "mattshumer/reflection-70b",
      "hfSlug": "mattshumer/Reflection-70B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-09-06T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Reflection 70B",
      "shortName": "Reflection 70B",
      "author": "mattshumer",
      "description": "Reflection Llama-3.1 70B is trained with a new technique called Reflection-Tuning that teaches a LLM to detect mistakes in its reasoning and correct course.\n\nThe model was trained on synthetic data.",
      "modelVersionGroupId": null,
      "contextLength": 131072,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mattshumer/reflection-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 336,
        "newest": 336,
        "throughputHighToLow": 336,
        "latencyLowToHigh": 336,
        "pricingLowToHigh": 336,
        "pricingHighToLow": 336
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "google/gemini-flash-1.5-exp",
      "hfSlug": null,
      "updatedAt": "2025-04-04T21:52:16.674964+00:00",
      "createdAt": "2024-08-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 1.5 Flash Experimental",
      "shortName": "Gemini 1.5 Flash Experimental",
      "author": "google",
      "description": "Gemini 1.5 Flash Experimental is an experimental version of the [Gemini 1.5 Flash](/models/google/gemini-flash-1.5) model.\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n#multimodal\n\nNote: This model is experimental and not suited for production use-cases. It may be removed or redirected to another model in the future.",
      "modelVersionGroupId": "86ec374b-de4b-4920-a960-94f25078e303",
      "contextLength": 1000000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-flash-1.5-exp",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 337,
        "newest": 337,
        "throughputHighToLow": 337,
        "latencyLowToHigh": 337,
        "pricingLowToHigh": 337,
        "pricingHighToLow": 337
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "lynn/soliloquy-v3",
      "hfSlug": "openlynn/Soliloquy-7B-v3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-24T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Lynn: Llama 3 Soliloquy 7B v3 32K",
      "shortName": "Llama 3 Soliloquy 7B v3 32K",
      "author": "lynn",
      "description": "Soliloquy v3 is a highly capable roleplaying model designed for immersive, dynamic experiences. Trained on over 2 billion tokens of roleplaying data, Soliloquy v3 boasts a vast knowledge base and rich literary expression, supporting up to 32k context length. It outperforms existing models of comparable size, delivering enhanced roleplaying capabilities.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "lynn/soliloquy-v3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 338,
        "newest": 338,
        "throughputHighToLow": 338,
        "latencyLowToHigh": 338,
        "pricingLowToHigh": 338,
        "pricingHighToLow": 338
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://api.lynn.app/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "01-ai/yi-1.5-34b-chat",
      "hfSlug": "01-ai/Yi-1.5-34B-Chat",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-23T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Yi 1.5 34B Chat",
      "shortName": "Yi 1.5 34B Chat",
      "author": "01-ai",
      "description": "The Yi series models are large language models trained from scratch by developers at [01.AI](https://01.ai/). This is a predecessor to the Yi 34B model. It is continuously pre-trained on Yi with a high-quality corpus of 500B tokens and fine-tuned on 3M diverse fine-tuning samples..",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "01-ai/yi-1.5-34b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 339,
        "newest": 339,
        "throughputHighToLow": 339,
        "latencyLowToHigh": 340,
        "pricingLowToHigh": 339,
        "pricingHighToLow": 339
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "ai21/jamba-1-5-mini",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-23T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "AI21: Jamba 1.5 Mini",
      "shortName": "Jamba 1.5 Mini",
      "author": "ai21",
      "description": "Jamba 1.5 Mini is the world's first production-grade Mamba-based model, combining SSM and Transformer architectures for a 256K context window and high efficiency.\n\nIt works with 9 languages and can handle various writing and analysis tasks as well as or better than similar small models.\n\nThis model uses less computer memory and works faster with longer texts than previous designs.\n\nRead their [announcement](https://www.ai21.com/blog/announcing-jamba-model-family) to learn more.",
      "modelVersionGroupId": null,
      "contextLength": 256000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "ai21/jamba-1-5-mini",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 340,
        "newest": 340,
        "throughputHighToLow": 340,
        "latencyLowToHigh": 341,
        "pricingLowToHigh": 340,
        "pricingHighToLow": 340
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai21.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "ai21/jamba-1-5-large",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-23T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "AI21: Jamba 1.5 Large",
      "shortName": "Jamba 1.5 Large",
      "author": "ai21",
      "description": "Jamba 1.5 Large is part of AI21's new family of open models, offering superior speed, efficiency, and quality.\n\nIt features a 256K effective context window, the longest among open models, enabling improved performance on tasks like document summarization and analysis.\n\nBuilt on a novel SSM-Transformer architecture, it outperforms larger models like Llama 3.1 70B on benchmarks while maintaining resource efficiency.\n\nRead their [announcement](https://www.ai21.com/blog/announcing-jamba-model-family) to learn more.",
      "modelVersionGroupId": null,
      "contextLength": 256000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "ai21/jamba-1-5-large",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 341,
        "newest": 341,
        "throughputHighToLow": 341,
        "latencyLowToHigh": 339,
        "pricingLowToHigh": 341,
        "pricingHighToLow": 341
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai21.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "01-ai/yi-large-turbo",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "01.AI: Yi Large Turbo",
      "shortName": "Yi Large Turbo",
      "author": "01-ai",
      "description": "The Yi Large Turbo model is a High Performance and Cost-Effectiveness model offering powerful capabilities at a competitive price.\n\nIt's ideal for a wide range of scenarios, including complex inference and high-quality text generation.\n\nCheck out the [launch announcement](https://01-ai.github.io/blog/01.ai-yi-large-llm-launch) to learn more.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "01-ai/yi-large-turbo",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 342,
        "newest": 342,
        "throughputHighToLow": 342,
        "latencyLowToHigh": 343,
        "pricingLowToHigh": 342,
        "pricingHighToLow": 342
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "01-ai/yi-large-fc",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "01.AI: Yi Large FC",
      "shortName": "Yi Large FC",
      "author": "01-ai",
      "description": "The Yi Large Function Calling (FC) is a specialized model with capability of tool use. The model can decide whether to call the tool based on the tool definition passed in by the user, and the calling method will be generate in the specified format.\n\nIt's applicable to various production scenarios that require building agents or workflows.",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "01-ai/yi-large-fc",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 343,
        "newest": 343,
        "throughputHighToLow": 343,
        "latencyLowToHigh": 342,
        "pricingLowToHigh": 343,
        "pricingHighToLow": 343
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "01-ai/yi-vision",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-08-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "01.AI: Yi Vision",
      "shortName": "Yi Vision",
      "author": "01-ai",
      "description": "The Yi Vision is a complex visual task models provide high-performance understanding and analysis capabilities based on multiple images.\n\nIt's ideal for scenarios that require analysis and interpretation of images and charts, such as image question answering, chart understanding, OCR, visual reasoning, education, research report understanding, or multilingual document reading.",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "01-ai/yi-vision",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 344,
        "newest": 344,
        "throughputHighToLow": 344,
        "latencyLowToHigh": 344,
        "pricingLowToHigh": 344,
        "pricingHighToLow": 344
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "google/gemini-pro-1.5-exp",
      "hfSlug": null,
      "updatedAt": "2025-04-04T21:52:38.837881+00:00",
      "createdAt": "2024-08-01T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemini 1.5 Pro Experimental",
      "shortName": "Gemini 1.5 Pro Experimental",
      "author": "google",
      "description": "Gemini 1.5 Pro Experimental is a bleeding-edge version of the [Gemini 1.5 Pro](/models/google/gemini-pro-1.5) model. Because it's currently experimental, it will be **heavily rate-limited** by Google.\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n#multimodal",
      "modelVersionGroupId": null,
      "contextLength": 1000000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemini-pro-1.5-exp",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 345,
        "newest": 345,
        "throughputHighToLow": 345,
        "latencyLowToHigh": 345,
        "pricingLowToHigh": 345,
        "pricingHighToLow": 345
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "cognitivecomputations/dolphin-llama-3-70b",
      "hfSlug": "cognitivecomputations/dolphin-2.9.1-llama-3-70b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-19T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Dolphin Llama 3 70B 🐬",
      "shortName": "Dolphin Llama 3 70B 🐬",
      "author": "cognitivecomputations",
      "description": "Dolphin 2.9 is designed for instruction following, conversational, and coding. This model is a fine-tune of [Llama 3 70B](/models/meta-llama/llama-3-70b-instruct). It demonstrates improvements in instruction, conversation, coding, and function calling abilities, when compared to the original.\n\nUncensored and is stripped of alignment and bias, it requires an external alignment layer for ethical use. Users are cautioned to use this highly compliant model responsibly, as detailed in a blog post about uncensored models at [erichartford.com/uncensored-models](https://erichartford.com/uncensored-models).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cognitivecomputations/dolphin-llama-3-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 346,
        "newest": 346,
        "throughputHighToLow": 346,
        "latencyLowToHigh": 346,
        "pricingLowToHigh": 346,
        "pricingHighToLow": 346
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "qwen/qwen-2-7b-instruct",
      "hfSlug": "Qwen/Qwen2-7B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen 2 7B Instruct",
      "shortName": "Qwen 2 7B Instruct",
      "author": "qwen",
      "description": "Qwen2 7B is a transformer-based model that excels in language understanding, multilingual capabilities, coding, mathematics, and reasoning.\n\nIt features SwiGLU activation, attention QKV bias, and group query attention. It is pretrained on extensive data with supervised finetuning and direct preference optimization.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2/) and [GitHub repo](https://github.com/QwenLM/Qwen2).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-2-7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 347,
        "newest": 347,
        "throughputHighToLow": 347,
        "latencyLowToHigh": 347,
        "pricingLowToHigh": 347,
        "pricingHighToLow": 347
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "nousresearch/hermes-2-theta-llama-3-8b",
      "hfSlug": "NousResearch/Hermes-2-Theta-Llama-3-8B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-07-11T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 2 Theta 8B",
      "shortName": "Hermes 2 Theta 8B",
      "author": "nousresearch",
      "description": "An experimental merge model based on Llama 3, exhibiting a very distinctive style of writing. It combines the the best of [Meta's Llama 3 8B](https://openrouter.ai/models/meta-llama/llama-3-8b-instruct) and Nous Research's [Hermes 2 Pro](https://openrouter.ai/models/nousresearch/hermes-2-pro-llama-3-8b).\n\nHermes-2 Θ (theta) was specifically designed with a few capabilities in mind: executing function calls, generating JSON output, and most remarkably, demonstrating metacognitive abilities (contemplating the nature of thought and recognizing the diversity of cognitive processes among individuals).",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/hermes-2-theta-llama-3-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 348,
        "newest": 348,
        "throughputHighToLow": 348,
        "latencyLowToHigh": 348,
        "pricingLowToHigh": 348,
        "pricingHighToLow": 348
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "sao10k/l3-stheno-8b",
      "hfSlug": "Sao10K/L3-8B-Stheno-v3.3-32K",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-27T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Sao10K: Llama 3 Stheno 8B v3.3 32K",
      "shortName": "Llama 3 Stheno 8B v3.3 32K",
      "author": "sao10k",
      "description": "Stheno 8B 32K is a creative writing/roleplay model from [Sao10k](https://ko-fi.com/sao10k). It was trained at 8K context, then expanded to 32K context.\n\nCompared to older Stheno version, this model is trained on:\n- 2x the amount of creative writing samples\n- Cleaned up roleplaying samples\n- Fewer low quality samples",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "sao10k/l3-stheno-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 349,
        "newest": 349,
        "throughputHighToLow": 349,
        "latencyLowToHigh": 349,
        "pricingLowToHigh": 349,
        "pricingHighToLow": 349
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "nvidia/nemotron-4-340b-instruct",
      "hfSlug": "nvidia/Nemotron-4-340B-Instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-23T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "NVIDIA: Nemotron-4 340B Instruct",
      "shortName": "Nemotron-4 340B Instruct",
      "author": "nvidia",
      "description": "Nemotron-4-340B-Instruct is an English-language chat model optimized for synthetic data generation. This large language model (LLM) is a fine-tuned version of Nemotron-4-340B-Base, designed for single and multi-turn chat use-cases with a 4,096 token context length.\n\nThe base model was pre-trained on 9 trillion tokens from diverse English texts, 50+ natural languages, and 40+ coding languages. The instruct model underwent additional alignment steps:\n\n1. Supervised Fine-tuning (SFT)\n2. Direct Preference Optimization (DPO)\n3. Reward-aware Preference Optimization (RPO)\n\nThe alignment process used approximately 20K human-annotated samples, while 98% of the data for fine-tuning was synthetically generated. Detailed information about the synthetic data generation pipeline is available in the [technical report](https://arxiv.org/html/2406.11704v1).",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "nemotron",
      "defaultSystem": null,
      "defaultStops": [
        "<|endoftext|>",
        "<extra_id_1>",
        "\u0011",
        "<extra_id_1>User"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nvidia/nemotron-4-340b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 350,
        "newest": 350,
        "throughputHighToLow": 350,
        "latencyLowToHigh": 350,
        "pricingLowToHigh": 350,
        "pricingHighToLow": 350
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nvidia.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "microsoft/phi-3-medium-4k-instruct",
      "hfSlug": "microsoft/Phi-3-medium-4k-instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-15T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Microsoft: Phi-3 Medium 4K Instruct",
      "shortName": "Phi-3 Medium 4K Instruct",
      "author": "microsoft",
      "description": "Phi-3 4K Medium is a powerful 14-billion parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.\n\nAt time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. In the MMLU-Pro eval, the model even comes close to a Llama3 70B level of performance.\n\nFor 128k context length, try [Phi-3 Medium 128K](/models/microsoft/phi-3-medium-128k-instruct).",
      "modelVersionGroupId": null,
      "contextLength": 4000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "phi3",
      "defaultSystem": null,
      "defaultStops": [
        "<|end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/phi-3-medium-4k-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 351,
        "newest": 351,
        "throughputHighToLow": 351,
        "latencyLowToHigh": 351,
        "pricingLowToHigh": 351,
        "pricingHighToLow": 351
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": []
    },
    {
      "slug": "bigcode/starcoder2-15b-instruct",
      "hfSlug": "bigcode/starcoder2-15b-instruct-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "StarCoder2 15B Instruct",
      "shortName": "StarCoder2 15B Instruct",
      "author": "bigcode",
      "description": "StarCoder2 15B Instruct excels in coding-related tasks, primarily in Python. It is the first self-aligned open-source LLM developed by BigCode. This model was fine-tuned without any human annotations or distilled data from proprietary LLMs.\n\nThe base model uses [Grouped Query Attention](https://arxiv.org/abs/2305.13245) and was trained using the [Fill-in-the-Middle objective](https://arxiv.org/abs/2207.14255) objective on 4+ trillion tokens.",
      "modelVersionGroupId": null,
      "contextLength": 16384,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "bigcode/starcoder2-15b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 352,
        "newest": 352,
        "throughputHighToLow": 352,
        "latencyLowToHigh": 352,
        "pricingLowToHigh": 352,
        "pricingHighToLow": 352
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "openchat/openchat-8b",
      "hfSlug": "openchat/openchat-3.6-8b-20240522",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-06-01T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenChat 3.6 8B",
      "shortName": "OpenChat 3.6 8B",
      "author": "openchat",
      "description": "OpenChat 8B is a library of open-source language models, fine-tuned with \"C-RLFT (Conditioned Reinforcement Learning Fine-Tuning)\" - a strategy inspired by offline reinforcement learning. It has been trained on mixed-quality data without preference labels.\n\nIt outperforms many similarly sized models including [Llama 3 8B Instruct](/models/meta-llama/llama-3-8b-instruct) and various fine-tuned models. It excels in general conversation, coding assistance, and mathematical reasoning.\n\n- For OpenChat fine-tuned on Mistral 7B, check out [OpenChat 7B](/models/openchat/openchat-7b).\n- For OpenChat fine-tuned on Llama 8B, check out [OpenChat 8B](/models/openchat/openchat-8b).\n\n#open-source",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "openchat",
      "defaultSystem": null,
      "defaultStops": [
        "<|end_of_turn|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openchat/openchat-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 353,
        "newest": 353,
        "throughputHighToLow": 353,
        "latencyLowToHigh": 353,
        "pricingLowToHigh": 353,
        "pricingHighToLow": 353
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "perplexity/llama-3-sonar-large-32k-online",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Llama3 Sonar 70B Online",
      "shortName": "Llama3 Sonar 70B Online",
      "author": "perplexity",
      "description": "Llama3 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is the online version of the [offline chat model](/models/perplexity/llama-3-sonar-large-32k-chat). It is focused on delivering helpful, up-to-date, and factual responses. #online",
      "modelVersionGroupId": "e0349fb1-b84a-4f4f-9023-e7f1c1e73b33",
      "contextLength": 28000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "perplexity/llama-3-sonar-large-32k-online",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 354,
        "newest": 354,
        "throughputHighToLow": 354,
        "latencyLowToHigh": 355,
        "pricingLowToHigh": 354,
        "pricingHighToLow": 354
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": []
    },
    {
      "slug": "deepseek/deepseek-chat-v2.5",
      "hfSlug": "deepseek-ai/DeepSeek-V2.5",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "DeepSeek V2.5",
      "shortName": "DeepSeek V2.5",
      "author": "deepseek",
      "description": "DeepSeek-V2.5 is an upgraded version that combines DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct. The new model integrates the general and coding abilities of the two previous versions. For model details, please visit [DeepSeek-V2 page](https://github.com/deepseek-ai/DeepSeek-V2) for more information.",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "deepseek/deepseek-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 355,
        "newest": 355,
        "throughputHighToLow": 355,
        "latencyLowToHigh": 358,
        "pricingLowToHigh": 355,
        "pricingHighToLow": 355
      },
      "authorIcon": "https://openrouter.ai/images/icons/DeepSeek.png",
      "providers": []
    },
    {
      "slug": "perplexity/llama-3-sonar-small-32k-chat",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Llama3 Sonar 8B",
      "shortName": "Llama3 Sonar 8B",
      "author": "perplexity",
      "description": "Llama3 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is a normal offline LLM, but the [online version](/models/perplexity/llama-3-sonar-small-32k-online) of this model has Internet access.",
      "modelVersionGroupId": "9e4cc81b-5f14-4987-9e40-74db1c86ecda",
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "perplexity/llama-3-sonar-small-32k-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 356,
        "newest": 356,
        "throughputHighToLow": 356,
        "latencyLowToHigh": 354,
        "pricingLowToHigh": 356,
        "pricingHighToLow": 356
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": []
    },
    {
      "slug": "perplexity/llama-3-sonar-small-32k-online",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Llama3 Sonar 8B Online",
      "shortName": "Llama3 Sonar 8B Online",
      "author": "perplexity",
      "description": "Llama3 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is the online version of the [offline chat model](/models/perplexity/llama-3-sonar-small-32k-chat). It is focused on delivering helpful, up-to-date, and factual responses. #online",
      "modelVersionGroupId": "9e4cc81b-5f14-4987-9e40-74db1c86ecda",
      "contextLength": 28000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "perplexity/llama-3-sonar-small-32k-online",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 357,
        "newest": 357,
        "throughputHighToLow": 357,
        "latencyLowToHigh": 356,
        "pricingLowToHigh": 357,
        "pricingHighToLow": 357
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": []
    },
    {
      "slug": "perplexity/llama-3-sonar-large-32k-chat",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-14T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Perplexity: Llama3 Sonar 70B",
      "shortName": "Llama3 Sonar 70B",
      "author": "perplexity",
      "description": "Llama3 Sonar is Perplexity's latest model family. It surpasses their earlier Sonar models in cost-efficiency, speed, and performance.\n\nThis is a normal offline LLM, but the [online version](/models/perplexity/llama-3-sonar-large-32k-online) of this model has Internet access.",
      "modelVersionGroupId": "e0349fb1-b84a-4f4f-9023-e7f1c1e73b33",
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "perplexity/llama-3-sonar-large-32k-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 358,
        "newest": 358,
        "throughputHighToLow": 358,
        "latencyLowToHigh": 357,
        "pricingLowToHigh": 358,
        "pricingHighToLow": 358
      },
      "authorIcon": "https://openrouter.ai/images/icons/Perplexity.svg",
      "providers": []
    },
    {
      "slug": "meta-llama/llama-3-8b",
      "hfSlug": "meta-llama/Meta-Llama-3-8b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3 8B (Base)",
      "shortName": "Llama 3 8B (Base)",
      "author": "meta-llama",
      "description": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This is the base 8B pre-trained version.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "803c32ed-9861-4abf-b5da-7d9c9e6dcf04",
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3-8b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 359,
        "newest": 359,
        "throughputHighToLow": 359,
        "latencyLowToHigh": 360,
        "pricingLowToHigh": 359,
        "pricingHighToLow": 359
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "meta-llama/llama-3-70b",
      "hfSlug": "meta-llama/Meta-Llama-3-70b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 3 70B (Base)",
      "shortName": "Llama 3 70B (Base)",
      "author": "meta-llama",
      "description": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This is the base 70B pre-trained version.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": "397604e2-45fa-454e-a85d-9921f5138747",
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-3-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 360,
        "newest": 360,
        "throughputHighToLow": 360,
        "latencyLowToHigh": 359,
        "pricingLowToHigh": 360,
        "pricingHighToLow": 360
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "liuhaotian/llava-yi-34b",
      "hfSlug": "liuhaotian/llava-v1.6-34b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-11T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "LLaVA v1.6 34B",
      "shortName": "LLaVA v1.6 34B",
      "author": "liuhaotian",
      "description": "LLaVA Yi 34B is an open-source model trained by fine-tuning LLM on multimodal instruction-following data. It is an auto-regressive language model, based on the transformer architecture. Base LLM: [NousResearch/Nous-Hermes-2-Yi-34B](/models/nousresearch/nous-hermes-yi-34b)\n\nIt was trained in December 2023.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "liuhaotian/llava-yi-34b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 361,
        "newest": 361,
        "throughputHighToLow": 361,
        "latencyLowToHigh": 361,
        "pricingLowToHigh": 361,
        "pricingHighToLow": 361
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "qwen/qwen-110b-chat",
      "hfSlug": "Qwen/Qwen1.5-110B-Chat",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen 1.5 110B Chat",
      "shortName": "Qwen 1.5 110B Chat",
      "author": "qwen",
      "description": "Qwen1.5 110B is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen, the improvements include:\n\n- Significant performance improvement in human preference for chat models\n- Multilingual support of both base and chat models\n- Stable support of 32K context length for models of all sizes\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen1.5/) and [GitHub repo](https://github.com/QwenLM/Qwen1.5).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-110b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 362,
        "newest": 362,
        "throughputHighToLow": 362,
        "latencyLowToHigh": 363,
        "pricingLowToHigh": 362,
        "pricingHighToLow": 362
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "qwen/qwen-72b-chat",
      "hfSlug": "Qwen/Qwen1.5-72B-Chat",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen 1.5 72B Chat",
      "shortName": "Qwen 1.5 72B Chat",
      "author": "qwen",
      "description": "Qwen1.5 72B is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen, the improvements include:\n\n- Significant performance improvement in human preference for chat models\n- Multilingual support of both base and chat models\n- Stable support of 32K context length for models of all sizes\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen1.5/) and [GitHub repo](https://github.com/QwenLM/Qwen1.5).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-72b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 363,
        "newest": 363,
        "throughputHighToLow": 363,
        "latencyLowToHigh": 366,
        "pricingLowToHigh": 363,
        "pricingHighToLow": 363
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "qwen/qwen-32b-chat",
      "hfSlug": "Qwen/Qwen1.5-32B-Chat",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen 1.5 32B Chat",
      "shortName": "Qwen 1.5 32B Chat",
      "author": "qwen",
      "description": "Qwen1.5 32B is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen, the improvements include:\n\n- Significant performance improvement in human preference for chat models\n- Multilingual support of both base and chat models\n- Stable support of 32K context length for models of all sizes\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen1.5/) and [GitHub repo](https://github.com/QwenLM/Qwen1.5).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-32b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 364,
        "newest": 364,
        "throughputHighToLow": 364,
        "latencyLowToHigh": 367,
        "pricingLowToHigh": 364,
        "pricingHighToLow": 364
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "qwen/qwen-14b-chat",
      "hfSlug": "Qwen/Qwen1.5-14B-Chat",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen 1.5 14B Chat",
      "shortName": "Qwen 1.5 14B Chat",
      "author": "qwen",
      "description": "Qwen1.5 14B is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen, the improvements include:\n\n- Significant performance improvement in human preference for chat models\n- Multilingual support of both base and chat models\n- Stable support of 32K context length for models of all sizes\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen1.5/) and [GitHub repo](https://github.com/QwenLM/Qwen1.5).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-14b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 365,
        "newest": 365,
        "throughputHighToLow": 365,
        "latencyLowToHigh": 364,
        "pricingLowToHigh": 365,
        "pricingHighToLow": 365
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "qwen/qwen-7b-chat",
      "hfSlug": "Qwen/Qwen1.5-7B-Chat",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen 1.5 7B Chat",
      "shortName": "Qwen 1.5 7B Chat",
      "author": "qwen",
      "description": "Qwen1.5 7B is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen, the improvements include:\n\n- Significant performance improvement in human preference for chat models\n- Multilingual support of both base and chat models\n- Stable support of 32K context length for models of all sizes\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen1.5/) and [GitHub repo](https://github.com/QwenLM/Qwen1.5).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-7b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 366,
        "newest": 366,
        "throughputHighToLow": 366,
        "latencyLowToHigh": 365,
        "pricingLowToHigh": 366,
        "pricingHighToLow": 366
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "qwen/qwen-4b-chat",
      "hfSlug": "Qwen/Qwen1.5-4B-Chat",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-05-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Qwen 1.5 4B Chat",
      "shortName": "Qwen 1.5 4B Chat",
      "author": "qwen",
      "description": "Qwen1.5 4B is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen, the improvements include:\n\n- Significant performance improvement in human preference for chat models\n- Multilingual support of both base and chat models\n- Stable support of 32K context length for models of all sizes\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen1.5/) and [GitHub repo](https://github.com/QwenLM/Qwen1.5).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Qwen",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "qwen/qwen-4b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 367,
        "newest": 367,
        "throughputHighToLow": 367,
        "latencyLowToHigh": 362,
        "pricingLowToHigh": 367,
        "pricingHighToLow": 367
      },
      "authorIcon": "https://openrouter.ai/images/icons/Qwen.png",
      "providers": []
    },
    {
      "slug": "snowflake/snowflake-arctic-instruct",
      "hfSlug": "Snowflake/snowflake-arctic-instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-30T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Snowflake: Arctic Instruct",
      "shortName": "Arctic Instruct",
      "author": "snowflake",
      "description": "Arctic is a dense-MoE Hybrid transformer architecture pre-trained from scratch by the Snowflake AI Research Team. Arctic combines a 10B dense transformer model with a residual 128x3.66B MoE MLP resulting in 480B total and 17B active parameters chosen using a top-2 gating.\n\nTo read more about this model's release, [click here](https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/).",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "snowflake/snowflake-arctic-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 368,
        "newest": 368,
        "throughputHighToLow": 368,
        "latencyLowToHigh": 368,
        "pricingLowToHigh": 368,
        "pricingHighToLow": 368
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "fireworks/firellava-13b",
      "hfSlug": "fireworks-ai/FireLLaVA-13b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-26T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Fireworks: FireLLaVA 13B",
      "shortName": "FireLLaVA 13B",
      "author": "fireworks",
      "description": "A blazing fast vision-language model, FireLLaVA quickly understands both text and images. It achieves impressive chat skills in tests, and was designed to mimic multimodal GPT-4.\n\nThe first commercially permissive open source LLaVA model, trained entirely on open source LLM generated instruction following data.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "vicuna",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "fireworks/firellava-13b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 369,
        "newest": 369,
        "throughputHighToLow": 369,
        "latencyLowToHigh": 369,
        "pricingLowToHigh": 369,
        "pricingHighToLow": 369
      },
      "authorIcon": "https://openrouter.ai/images/icons/Fireworks.png",
      "providers": []
    },
    {
      "slug": "lynn/soliloquy-l3",
      "hfSlug": "openlynn/Llama-3-Soliloquy-8B-v2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Lynn: Llama 3 Soliloquy 8B v2",
      "shortName": "Llama 3 Soliloquy 8B v2",
      "author": "lynn",
      "description": "Soliloquy-L3 v2 is a fast, highly capable roleplaying model designed for immersive, dynamic experiences. Trained on over 250 million tokens of roleplaying data, Soliloquy-L3 has a vast knowledge base, rich literary expression, and support for up to 24k context length. It outperforms existing ~13B models, delivering enhanced roleplaying capabilities.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
      "modelVersionGroupId": null,
      "contextLength": 24576,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama3",
      "instructType": "llama3",
      "defaultSystem": null,
      "defaultStops": [
        "<|eot_id|>",
        "<|end_of_text|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "lynn/soliloquy-l3",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 370,
        "newest": 370,
        "throughputHighToLow": 370,
        "latencyLowToHigh": 370,
        "pricingLowToHigh": 370,
        "pricingHighToLow": 370
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://api.lynn.app/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "microsoft/wizardlm-2-7b",
      "hfSlug": "microsoft/WizardLM-2-7B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "WizardLM-2 7B",
      "shortName": "WizardLM-2 7B",
      "author": "microsoft",
      "description": "WizardLM-2 7B is the smaller variant of Microsoft AI's latest Wizard model. It is the fastest and achieves comparable performance with existing 10x larger opensource leading models\n\nIt is a finetune of [Mistral 7B Instruct](/models/mistralai/mistral-7b-instruct), using the same technique as [WizardLM-2 8x22B](/models/microsoft/wizardlm-2-8x22b).\n\nTo read more about the model release, [click here](https://wizardlm.github.io/WizardLM2/).\n\n#moe",
      "modelVersionGroupId": null,
      "contextLength": 32000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "vicuna",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "microsoft/wizardlm-2-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 371,
        "newest": 371,
        "throughputHighToLow": 371,
        "latencyLowToHigh": 371,
        "pricingLowToHigh": 371,
        "pricingHighToLow": 371
      },
      "authorIcon": "https://openrouter.ai/images/icons/Microsoft.svg",
      "providers": []
    },
    {
      "slug": "huggingfaceh4/zephyr-orpo-141b-a35b",
      "hfSlug": "HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-12T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Zephyr 141B-A35B",
      "shortName": "Zephyr 141B-A35B",
      "author": "huggingfaceh4",
      "description": "Zephyr 141B-A35B is A Mixture of Experts (MoE) model with 141B total parameters and 35B active parameters. Fine-tuned on a mix of publicly available, synthetic datasets.\n\nIt is an instruct finetune of [Mixtral 8x22B](/models/mistralai/mixtral-8x22b).\n\n#moe",
      "modelVersionGroupId": null,
      "contextLength": 65536,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "zephyr",
      "defaultSystem": null,
      "defaultStops": [
        "<|user|>\n",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "huggingfaceh4/zephyr-orpo-141b-a35b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 372,
        "newest": 372,
        "throughputHighToLow": 372,
        "latencyLowToHigh": 372,
        "pricingLowToHigh": 372,
        "pricingHighToLow": 372
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "mistralai/mixtral-8x22b",
      "hfSlug": "mistralai/Mixtral-8x22B-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-04-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral: Mixtral 8x22B (base)",
      "shortName": "Mixtral 8x22B (base)",
      "author": "mistralai",
      "description": "Mixtral 8x22B is a large-scale language model from Mistral AI. It consists of 8 experts, each 22 billion parameters, with each token using 2 experts at a time.\n\nIt was released via [X](https://twitter.com/MistralAI/status/1777869263778291896).\n\n#moe",
      "modelVersionGroupId": null,
      "contextLength": 65536,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "mistralai/mixtral-8x22b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 373,
        "newest": 373,
        "throughputHighToLow": 373,
        "latencyLowToHigh": 373,
        "pricingLowToHigh": 373,
        "pricingHighToLow": 373
      },
      "authorIcon": "https://openrouter.ai/images/icons/Mistral.png",
      "providers": []
    },
    {
      "slug": "databricks/dbrx-instruct",
      "hfSlug": "databricks/dbrx-instruct",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-03-29T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Databricks: DBRX 132B Instruct",
      "shortName": "DBRX 132B Instruct",
      "author": "databricks",
      "description": "DBRX is a new open source large language model developed by Databricks. At 132B, it outperforms existing open source LLMs like Llama 2 70B and [Mixtral-8x7b](/models/mistralai/mixtral-8x7b) on standard industry benchmarks for language understanding, programming, math, and logic.\n\nIt uses a fine-grained mixture-of-experts (MoE) architecture. 36B parameters are active on any input. It was pre-trained on 12T tokens of text and code data. Compared to other open MoE models like Mixtral-8x7B and Grok-1, DBRX is fine-grained, meaning it uses a larger number of smaller experts.\n\nSee the launch announcement and benchmark results [here](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm).\n\n#moe",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Other",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "databricks/dbrx-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 374,
        "newest": 374,
        "throughputHighToLow": 374,
        "latencyLowToHigh": 374,
        "pricingLowToHigh": 374,
        "pricingHighToLow": 374
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://databricks.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "google/gemma-7b-it",
      "hfSlug": "google/gemma-1.1-7b-it",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-02-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: Gemma 7B",
      "shortName": "Gemma 7B",
      "author": "google",
      "description": "Gemma by Google is an advanced, open-source language model family, leveraging the latest in decoder-only, text-to-text technology. It offers English language capabilities across text generation tasks like question answering, summarization, and reasoning. The Gemma 7B variant is comparable in performance to leading open source models.\n\nUsage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms).",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Gemini",
      "instructType": "gemma",
      "defaultSystem": null,
      "defaultStops": [
        "<start_of_turn>",
        "<end_of_turn>",
        "<eos>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/gemma-7b-it",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 375,
        "newest": 375,
        "throughputHighToLow": 375,
        "latencyLowToHigh": 375,
        "pricingLowToHigh": 375,
        "pricingHighToLow": 375
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "nousresearch/nous-hermes-2-mistral-7b-dpo",
      "hfSlug": "NousResearch/Nous-Hermes-2-Mistral-7B-DPO",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-02-21T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 2 Mistral 7B DPO",
      "shortName": "Hermes 2 Mistral 7B DPO",
      "author": "nousresearch",
      "description": "This is the flagship 7B Hermes model, a Direct Preference Optimization (DPO) of [Teknium/OpenHermes-2.5-Mistral-7B](/models/teknium/openhermes-2.5-mistral-7b). It shows improvement across the board on all benchmarks tested - AGIEval, BigBench Reasoning, GPT4All, and TruthfulQA.\n\nThe model prior to DPO was trained on 1,000,000 instructions/chats of GPT-4 quality or better, primarily synthetic data as well as other high quality datasets.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/nous-hermes-2-mistral-7b-dpo",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 376,
        "newest": 376,
        "throughputHighToLow": 376,
        "latencyLowToHigh": 376,
        "pricingLowToHigh": 376,
        "pricingHighToLow": 376
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "meta-llama/codellama-70b-instruct",
      "hfSlug": "meta-llama/CodeLlama-70b-Instruct-hf",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-30T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: CodeLlama 70B Instruct",
      "shortName": "CodeLlama 70B Instruct",
      "author": "meta-llama",
      "description": "Code Llama is a family of large language models for code. This one is based on [Llama 2 70B](/models/meta-llama/llama-2-70b-chat) and provides zero-shot instruction-following ability for programming tasks.",
      "modelVersionGroupId": null,
      "contextLength": 2048,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "code-llama",
      "defaultSystem": null,
      "defaultStops": [
        "Source: assistant",
        "<step>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/codellama-70b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 377,
        "newest": 377,
        "throughputHighToLow": 377,
        "latencyLowToHigh": 377,
        "pricingLowToHigh": 377,
        "pricingHighToLow": 377
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "recursal/eagle-7b",
      "hfSlug": "RWKV/v5-Eagle",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-29T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "RWKV v5: Eagle 7B",
      "shortName": "Eagle 7B",
      "author": "recursal",
      "description": "Eagle 7B is trained on 1.1 Trillion Tokens across 100+ world languages (70% English, 15% multilang, 15% code).\n\n- Built on the [RWKV-v5](/models?q=rwkv) architecture (a linear transformer with 10-100x+ lower inference cost)\n- Ranks as the world's greenest 7B model (per token)\n- Outperforms all 7B class models in multi-lingual benchmarks\n- Approaches Falcon (1.5T), LLaMA2 (2T), Mistral (>2T?) level of performance in English evals\n- Trade blows with MPT-7B (1T) in English evals\n- All while being an [\"Attention-Free Transformer\"](https://www.isattentionallyouneed.com/)\n\nEagle 7B models are provided for free, by [Recursal.AI](https://recursal.ai), for the beta period till end of March 2024\n\nFind out more [here](https://blog.rwkv.com/p/eagle-7b-soaring-past-transformers)\n\n[rnn](/models?q=rwkv)",
      "modelVersionGroupId": null,
      "contextLength": 10000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "RWKV",
      "instructType": "rwkv",
      "defaultSystem": null,
      "defaultStops": [
        "\nUser:",
        "\n\nUser:"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "recursal/eagle-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 378,
        "newest": 378,
        "throughputHighToLow": 378,
        "latencyLowToHigh": 378,
        "pricingLowToHigh": 378,
        "pricingHighToLow": 378
      },
      "authorIcon": "https://openrouter.ai/images/icons/Recursal.jpg",
      "providers": []
    },
    {
      "slug": "01-ai/yi-34b-200k",
      "hfSlug": "01-ai/Yi-34B-200K",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Yi 34B 200K",
      "shortName": "Yi 34B 200K",
      "author": "01-ai",
      "description": "The Yi series models are large language models trained from scratch by developers at [01.AI](https://01.ai/). This version was trained on a large context length, allowing ~200k words (1000 paragraphs) of combined input and output.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": "none",
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "01-ai/yi-34b-200k",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 379,
        "newest": 379,
        "throughputHighToLow": 379,
        "latencyLowToHigh": 379,
        "pricingLowToHigh": 379,
        "pricingHighToLow": 379
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "nousresearch/nous-hermes-2-mixtral-8x7b-sft",
      "hfSlug": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 2 Mixtral 8x7B SFT",
      "shortName": "Hermes 2 Mixtral 8x7B SFT",
      "author": "nousresearch",
      "description": "Nous Hermes 2 Mixtral 8x7B SFT is the supervised finetune only version of [the Nous Research model](/models/nousresearch/nous-hermes-2-mixtral-8x7b-dpo) trained over the [Mixtral 8x7B MoE LLM](/models/mistralai/mixtral-8x7b).\n\nThe model was trained on over 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.\n\n#moe",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/nous-hermes-2-mixtral-8x7b-sft",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 380,
        "newest": 380,
        "throughputHighToLow": 380,
        "latencyLowToHigh": 380,
        "pricingLowToHigh": 380,
        "pricingHighToLow": 380
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "austism/chronos-hermes-13b",
      "hfSlug": "Austism/chronos-hermes-13b-v2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-05T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Chronos Hermes 13B v2",
      "shortName": "Chronos Hermes 13B v2",
      "author": "austism",
      "description": "A 75/25 merge of [Chronos 13b v2](https://huggingface.co/elinas/chronos-13b-v2) and [Nous Hermes Llama2 13b](/models/nousresearch/nous-hermes-llama2-13b). This offers the imaginative writing style of Chronos while retaining coherency. Outputs are long and use exceptional prose. #merge",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "austism/chronos-hermes-13b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 381,
        "newest": 381,
        "throughputHighToLow": 381,
        "latencyLowToHigh": 381,
        "pricingLowToHigh": 381,
        "pricingHighToLow": 381
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "jondurbin/bagel-34b",
      "hfSlug": "jondurbin/bagel-34b-v0.2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-05T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Bagel 34B v0.2",
      "shortName": "Bagel 34B v0.2",
      "author": "jondurbin",
      "description": "An experimental fine-tune of [Yi 34b 200k](/models/01-ai/yi-34b-200k) using [bagel](https://github.com/jondurbin/bagel). This is the version of the fine-tune before direct preference optimization (DPO) has been applied. DPO performs better on benchmarks, but this version is likely better for creative writing, roleplay, etc.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "jondurbin/bagel-34b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 382,
        "newest": 382,
        "throughputHighToLow": 382,
        "latencyLowToHigh": 382,
        "pricingLowToHigh": 382,
        "pricingHighToLow": 382
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "nousresearch/nous-hermes-yi-34b",
      "hfSlug": "NousResearch/Nous-Hermes-2-Yi-34B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 2 Yi 34B",
      "shortName": "Hermes 2 Yi 34B",
      "author": "nousresearch",
      "description": "Nous Hermes 2 Yi 34B was trained on 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape.\n\nNous-Hermes 2 on Yi 34B outperforms all Nous-Hermes & Open-Hermes models of the past, achieving new heights in all benchmarks for a Nous Research LLM as well as surpassing many popular finetunes.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/nous-hermes-yi-34b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 383,
        "newest": 383,
        "throughputHighToLow": 383,
        "latencyLowToHigh": 384,
        "pricingLowToHigh": 383,
        "pricingHighToLow": 383
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "neversleep/noromaid-mixtral-8x7b-instruct",
      "hfSlug": "NeverSleep/Noromaid-v0.1-mixtral-8x7b-Instruct-v3",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2024-01-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Noromaid Mixtral 8x7B Instruct",
      "shortName": "Noromaid Mixtral 8x7B Instruct",
      "author": "neversleep",
      "description": "This model was trained for 8h(v1) + 8h(v2) + 12h(v3) on customized modified datasets, focusing on RP, uncensoring, and a modified version of the Alpaca prompting (that was already used in LimaRP), which should be at the same conversational level as ChatLM or Llama2-Chat without adding any additional special tokens.",
      "modelVersionGroupId": null,
      "contextLength": 8000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "alpaca-modif",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": "Due to low usage, this model is deprecated and will be removed from the API on July 22, 2024.",
      "permaslug": "neversleep/noromaid-mixtral-8x7b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 384,
        "newest": 384,
        "throughputHighToLow": 384,
        "latencyLowToHigh": 383,
        "pricingLowToHigh": 384,
        "pricingHighToLow": 384
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "cognitivecomputations/dolphin-mixtral-8x7b",
      "hfSlug": "cognitivecomputations/dolphin-2.6-mixtral-8x7b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-21T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Dolphin 2.6 Mixtral 8x7B 🐬",
      "shortName": "Dolphin 2.6 Mixtral 8x7B 🐬",
      "author": "cognitivecomputations",
      "description": "This is a 16k context fine-tune of [Mixtral-8x7b](/models/mistralai/mixtral-8x7b). It excels in coding tasks due to extensive training with coding data and is known for its obedience, although it lacks DPO tuning.\n\nThe model is uncensored and is stripped of alignment and bias. It requires an external alignment layer for ethical use. Users are cautioned to use this highly compliant model responsibly, as detailed in a blog post about uncensored models at [erichartford.com/uncensored-models](https://erichartford.com/uncensored-models).\n\n#moe #uncensored",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "cognitivecomputations/dolphin-mixtral-8x7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 385,
        "newest": 385,
        "throughputHighToLow": 385,
        "latencyLowToHigh": 385,
        "pricingLowToHigh": 385,
        "pricingHighToLow": 385
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "recursal/rwkv-5-3b-ai-town",
      "hfSlug": "recursal/rwkv-5-3b-ai-town",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "RWKV v5 3B AI Town",
      "shortName": "RWKV v5 3B AI Town",
      "author": "recursal",
      "description": "This is an [RWKV 3B model](/models/rwkv/rwkv-5-world-3b) finetuned specifically for the [AI Town](https://github.com/a16z-infra/ai-town) project.\n\n[RWKV](https://wiki.rwkv.com) is an RNN (recurrent neural network) with transformer-level performance. It aims to combine the best of RNNs and transformers - great performance, fast inference, low VRAM, fast training, \"infinite\" context length, and free sentence embedding.\n\nRWKV 3B models are provided for free, by Recursal.AI, for the beta period. More details [here](https://substack.recursal.ai/p/public-rwkv-3b-model-via-openrouter).\n\n#rnn",
      "modelVersionGroupId": null,
      "contextLength": 10000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "RWKV",
      "instructType": "rwkv",
      "defaultSystem": null,
      "defaultStops": [
        "\nUser:",
        "\n\nUser:"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "recursal/rwkv-5-3b-ai-town",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 386,
        "newest": 386,
        "throughputHighToLow": 386,
        "latencyLowToHigh": 386,
        "pricingLowToHigh": 386,
        "pricingHighToLow": 386
      },
      "authorIcon": "https://openrouter.ai/images/icons/Recursal.jpg",
      "providers": []
    },
    {
      "slug": "rwkv/rwkv-5-world-3b",
      "hfSlug": "RWKV/rwkv-5-world-3b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-10T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "RWKV v5 World 3B",
      "shortName": "RWKV v5 World 3B",
      "author": "rwkv",
      "description": "[RWKV](https://wiki.rwkv.com) is an RNN (recurrent neural network) with transformer-level performance. It aims to combine the best of RNNs and transformers - great performance, fast inference, low VRAM, fast training, \"infinite\" context length, and free sentence embedding.\n\nRWKV-5 is trained on 100+ world languages (70% English, 15% multilang, 15% code).\n\nRWKV 3B models are provided for free, by Recursal.AI, for the beta period. More details [here](https://substack.recursal.ai/p/public-rwkv-3b-model-via-openrouter).\n\n#rnn",
      "modelVersionGroupId": null,
      "contextLength": 10000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "RWKV",
      "instructType": "rwkv",
      "defaultSystem": null,
      "defaultStops": [
        "\nUser:",
        "\n\nUser:"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "rwkv/rwkv-5-world-3b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 387,
        "newest": 387,
        "throughputHighToLow": 387,
        "latencyLowToHigh": 387,
        "pricingLowToHigh": 387,
        "pricingHighToLow": 387
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "togethercomputer/stripedhyena-nous-7b",
      "hfSlug": "togethercomputer/StripedHyena-Nous-7B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "StripedHyena Nous 7B",
      "shortName": "StripedHyena Nous 7B",
      "author": "togethercomputer",
      "description": "This is the chat model variant of the [StripedHyena series](/models?q=stripedhyena) developed by Together in collaboration with Nous Research.\n\nStripedHyena uses a new architecture that competes with traditional Transformers, particularly in long-context data processing. It combines attention mechanisms with gated convolutions for improved speed, efficiency, and scaling. This model marks a significant advancement in AI architecture for sequence modeling tasks.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "togethercomputer/stripedhyena-nous-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 388,
        "newest": 388,
        "throughputHighToLow": 388,
        "latencyLowToHigh": 388,
        "pricingLowToHigh": 388,
        "pricingHighToLow": 388
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "togethercomputer/stripedhyena-hessian-7b",
      "hfSlug": "togethercomputer/StripedHyena-Hessian-7B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-09T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "StripedHyena Hessian 7B (base)",
      "shortName": "StripedHyena Hessian 7B (base)",
      "author": "togethercomputer",
      "description": "This is the base model variant of the [StripedHyena series](/models?q=stripedhyena), developed by Together.\n\nStripedHyena uses a new architecture that competes with traditional Transformers, particularly in long-context data processing. It combines attention mechanisms with gated convolutions for improved speed, efficiency, and scaling. This model marks an advancement in AI architecture for sequence modeling tasks.",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "none",
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "togethercomputer/stripedhyena-hessian-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 389,
        "newest": 389,
        "throughputHighToLow": 389,
        "latencyLowToHigh": 389,
        "pricingLowToHigh": 389,
        "pricingHighToLow": 389
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "koboldai/psyfighter-13b-2",
      "hfSlug": "KoboldAI/LLaMA2-13B-Psyfighter2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-08T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Psyfighter v2 13B",
      "shortName": "Psyfighter v2 13B",
      "author": "koboldai",
      "description": "The v2 of [Psyfighter](/models/jebcarter/psyfighter-13b) - a merged model created by the KoboldAI community members Jeb Carter and TwistedShadows, made possible thanks to the KoboldAI merge request service.\n\nThe intent was to add medical data to supplement the model's fictional ability with more details on anatomy and mental states. This model should not be used for medical advice or therapy because of its high likelihood of pulling in fictional data.\n\nIt's a merge between:\n\n- [KoboldAI/LLaMA2-13B-Tiefighter](https://huggingface.co/KoboldAI/LLaMA2-13B-Tiefighter)\n- [Doctor-Shotgun/cat-v1.0-13b](https://huggingface.co/Doctor-Shotgun/cat-v1.0-13b)\n- [Doctor-Shotgun/llama-2-13b-chat-limarp-v2-merged](https://huggingface.co/Doctor-Shotgun/llama-2-13b-chat-limarp-v2-merged).\n\n#merge",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "koboldai/psyfighter-13b-2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 390,
        "newest": 390,
        "throughputHighToLow": 390,
        "latencyLowToHigh": 390,
        "pricingLowToHigh": 390,
        "pricingHighToLow": 390
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "01-ai/yi-34b",
      "hfSlug": "01-ai/Yi-34B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-07T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Yi 34B (base)",
      "shortName": "Yi 34B (base)",
      "author": "01-ai",
      "description": "The Yi series models are large language models trained from scratch by developers at [01.AI](https://01.ai/). This is the base 34B parameter model.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": "none",
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "01-ai/yi-34b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 391,
        "newest": 391,
        "throughputHighToLow": 391,
        "latencyLowToHigh": 393,
        "pricingLowToHigh": 391,
        "pricingHighToLow": 391
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "01-ai/yi-34b-chat",
      "hfSlug": "01-ai/Yi-34B-Chat",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-07T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Yi 34B Chat",
      "shortName": "Yi 34B Chat",
      "author": "01-ai",
      "description": "The Yi series models are large language models trained from scratch by developers at [01.AI](https://01.ai/). This 34B parameter model has been instruct-tuned for chat.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "01-ai/yi-34b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 392,
        "newest": 392,
        "throughputHighToLow": 392,
        "latencyLowToHigh": 395,
        "pricingLowToHigh": 392,
        "pricingHighToLow": 392
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "01-ai/yi-6b",
      "hfSlug": "01-ai/Yi-6B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-07T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Yi 6B (base)",
      "shortName": "Yi 6B (base)",
      "author": "01-ai",
      "description": "The Yi series models are large language models trained from scratch by developers at [01.AI](https://01.ai/). This is the base 6B parameter model.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Yi",
      "instructType": "none",
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "01-ai/yi-6b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 393,
        "newest": 393,
        "throughputHighToLow": 393,
        "latencyLowToHigh": 394,
        "pricingLowToHigh": 393,
        "pricingHighToLow": 393
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "gryphe/mythomist-7b",
      "hfSlug": "Gryphe/MythoMist-7b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-07T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "MythoMist 7B",
      "shortName": "MythoMist 7B",
      "author": "gryphe",
      "description": "From the creator of [MythoMax](/models/gryphe/mythomax-l2-13b), merges a suite of models to reduce word anticipation, ministrations, and other undesirable words in ChatGPT roleplaying data.\n\nIt combines [Neural Chat 7B](/models/intel/neural-chat-7b), Airoboros 7b, [Toppy M 7B](/models/undi95/toppy-m-7b), [Zepher 7b beta](/models/huggingfaceh4/zephyr-7b-beta), [Nous Capybara 34B](/models/nousresearch/nous-capybara-34b), [OpenHeremes 2.5](/models/teknium/openhermes-2.5-mistral-7b), and many others.\n\n#merge",
      "modelVersionGroupId": null,
      "contextLength": 32768,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "gryphe/mythomist-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 394,
        "newest": 394,
        "throughputHighToLow": 394,
        "latencyLowToHigh": 392,
        "pricingLowToHigh": 394,
        "pricingHighToLow": 394
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "nousresearch/nous-hermes-2-vision-7b",
      "hfSlug": "NousResearch/Nous-Hermes-2-Vision-Alpha",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-07T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 2 Vision 7B (alpha)",
      "shortName": "Hermes 2 Vision 7B (alpha)",
      "author": "nousresearch",
      "description": "This vision-language model builds on innovations from the popular [OpenHermes-2.5](/models/teknium/openhermes-2.5-mistral-7b) model, by Teknium. It adds vision support, and is trained on a custom dataset enriched with function calling\n\nThis project is led by [qnguyen3](https://twitter.com/stablequan) and [teknium](https://twitter.com/Teknium1).\n\n#multimodal",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/nous-hermes-2-vision-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 395,
        "newest": 395,
        "throughputHighToLow": 395,
        "latencyLowToHigh": 391,
        "pricingLowToHigh": 395,
        "pricingHighToLow": 395
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "openrouter/cinematika-7b",
      "hfSlug": "OpenRouter/cinematika-7b-v0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-06T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Cinematika 7B (alpha)",
      "shortName": "Cinematika 7B (alpha)",
      "author": "openrouter",
      "description": "This model is under development. Check the [OpenRouter Discord](https://discord.gg/fVyRaUDgxW) for updates.",
      "modelVersionGroupId": null,
      "contextLength": 8000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "airoboros",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openrouter/cinematika-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 396,
        "newest": 396,
        "throughputHighToLow": 396,
        "latencyLowToHigh": 396,
        "pricingLowToHigh": 396,
        "pricingHighToLow": 396
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://openrouter.ai/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "nousresearch/nous-capybara-7b",
      "hfSlug": "NousResearch/Nous-Capybara-7B-V1.9",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-12-05T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Capybara 7B",
      "shortName": "Capybara 7B",
      "author": "nousresearch",
      "description": "The Capybara series is a collection of datasets and models made by fine-tuning on data created by Nous, mostly in-house.\n\nV1.9 uses unalignment techniques for more consistent and dynamic control. It also leverages a significantly better foundation model, [Mistral 7B](/models/mistralai/mistral-7b-instruct-v0.1).",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "airoboros",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/nous-capybara-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 397,
        "newest": 397,
        "throughputHighToLow": 397,
        "latencyLowToHigh": 397,
        "pricingLowToHigh": 397,
        "pricingHighToLow": 397
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "jebcarter/psyfighter-13b",
      "hfSlug": "jebcarter/Psyfighter-13B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-29T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Psyfighter 13B",
      "shortName": "Psyfighter 13B",
      "author": "jebcarter",
      "description": "A merge model based on [Llama-2-13B](/models/meta-llama/llama-2-13b-chat) and made possible thanks to the compute provided by the KoboldAI community. It's a merge between:\n\n- [KoboldAI/LLaMA2-13B-Tiefighter](https://huggingface.co/KoboldAI/LLaMA2-13B-Tiefighter)\n- [chaoyi-wu/MedLLaMA_13B](https://huggingface.co/chaoyi-wu/MedLLaMA_13B)\n- [Doctor-Shotgun/llama-2-13b-chat-limarp-v2-merged](https://huggingface.co/Doctor-Shotgun/llama-2-13b-chat-limarp-v2-merged).\n\n#merge",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "jebcarter/psyfighter-13b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 398,
        "newest": 398,
        "throughputHighToLow": 398,
        "latencyLowToHigh": 398,
        "pricingLowToHigh": 398,
        "pricingHighToLow": 398
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "openchat/openchat-7b",
      "hfSlug": "openchat/openchat-3.5-0106",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenChat 3.5 7B",
      "shortName": "OpenChat 3.5 7B",
      "author": "openchat",
      "description": "OpenChat 7B is a library of open-source language models, fine-tuned with \"C-RLFT (Conditioned Reinforcement Learning Fine-Tuning)\" - a strategy inspired by offline reinforcement learning. It has been trained on mixed-quality data without preference labels.\n\n- For OpenChat fine-tuned on Mistral 7B, check out [OpenChat 7B](/models/openchat/openchat-7b).\n- For OpenChat fine-tuned on Llama 8B, check out [OpenChat 8B](/models/openchat/openchat-8b).\n\n#open-source",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "openchat",
      "defaultSystem": null,
      "defaultStops": [
        "<|end_of_turn|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openchat/openchat-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 399,
        "newest": 399,
        "throughputHighToLow": 399,
        "latencyLowToHigh": 399,
        "pricingLowToHigh": 399,
        "pricingHighToLow": 399
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "intel/neural-chat-7b",
      "hfSlug": "Intel/neural-chat-7b-v3-1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-25T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Neural Chat 7B v3.1",
      "shortName": "Neural Chat 7B v3.1",
      "author": "intel",
      "description": "A fine-tuned model based on [mistralai/Mistral-7B-v0.1](/models/mistralai/mistral-7b-instruct-v0.1) on the open source dataset [Open-Orca/SlimOrca](https://huggingface.co/datasets/Open-Orca/SlimOrca), aligned with DPO algorithm. For more details, refer to the blog: [The Practice of Supervised Fine-tuning and Direct Preference Optimization on Habana Gaudi2](https://medium.com/@NeuralCompressor/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3).",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "neural",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "### User:"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "intel/neural-chat-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 400,
        "newest": 400,
        "throughputHighToLow": 400,
        "latencyLowToHigh": 400,
        "pricingLowToHigh": 400,
        "pricingHighToLow": 400
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "anthropic/claude-instant-1.1",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude Instant v1.1",
      "shortName": "Claude Instant v1.1",
      "author": "anthropic",
      "description": "Anthropic's model for low-latency, high throughput text generation. Supports hundreds of pages of text.",
      "modelVersionGroupId": null,
      "contextLength": 100000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": "claude",
      "defaultSystem": null,
      "defaultStops": [
        "\n\nHuman:"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-instant-1.1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 401,
        "newest": 401,
        "throughputHighToLow": 401,
        "latencyLowToHigh": 401,
        "pricingLowToHigh": 401,
        "pricingHighToLow": 401
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": []
    },
    {
      "slug": "teknium/openhermes-2.5-mistral-7b",
      "hfSlug": "teknium/OpenHermes-2.5-Mistral-7B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenHermes 2.5 Mistral 7B",
      "shortName": "OpenHermes 2.5 Mistral 7B",
      "author": "teknium",
      "description": "A continuation of [OpenHermes 2 model](/models/teknium/openhermes-2-mistral-7b), trained on additional code datasets.\nPotentially the most interesting finding from training on a good ratio (est. of around 7-14% of the total dataset) of code instruction was that it has boosted several non-code benchmarks, including TruthfulQA, AGIEval, and GPT4All suite. It did however reduce BigBench benchmark score, but the net gain overall is significant.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "teknium/openhermes-2.5-mistral-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 402,
        "newest": 402,
        "throughputHighToLow": 402,
        "latencyLowToHigh": 402,
        "pricingLowToHigh": 402,
        "pricingHighToLow": 402
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "liuhaotian/llava-13b",
      "hfSlug": "liuhaotian/llava-v1.6-vicuna-13b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-16T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "LLaVA 13B",
      "shortName": "LLaVA 13B",
      "author": "liuhaotian",
      "description": "LLaVA is a large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding, achieving impressive chat capabilities and setting a new state-of-the-art accuracy on Science QA.\n\n#multimodal",
      "modelVersionGroupId": null,
      "contextLength": 2048,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "liuhaotian/llava-13b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 403,
        "newest": 403,
        "throughputHighToLow": 403,
        "latencyLowToHigh": 403,
        "pricingLowToHigh": 403,
        "pricingHighToLow": 403
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "nousresearch/nous-capybara-34b",
      "hfSlug": "NousResearch/Nous-Capybara-34B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-15T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Capybara 34B",
      "shortName": "Capybara 34B",
      "author": "nousresearch",
      "description": "This model is trained on the Yi-34B model for 3 epochs on the Capybara dataset. It's the first 34B Nous model and first 200K context length Nous model.",
      "modelVersionGroupId": null,
      "contextLength": 200000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "airoboros",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/nous-capybara-34b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 404,
        "newest": 404,
        "throughputHighToLow": 404,
        "latencyLowToHigh": 404,
        "pricingLowToHigh": 404,
        "pricingHighToLow": 404
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "openai/gpt-4-vision-preview",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-13T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-4 Vision",
      "shortName": "GPT-4 Vision",
      "author": "openai",
      "description": "Ability to understand images, in addition to all other [GPT-4 Turbo capabilties](/models/openai/gpt-4-turbo). Training data: up to Apr 2023.\n\n**Note:** heavily rate limited by OpenAI while in preview.\n\n#multimodal",
      "modelVersionGroupId": null,
      "contextLength": 128000,
      "inputModalities": [
        "text",
        "image"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-4-vision-preview",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 405,
        "newest": 405,
        "throughputHighToLow": 405,
        "latencyLowToHigh": 405,
        "pricingLowToHigh": 405,
        "pricingHighToLow": 405
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": []
    },
    {
      "slug": "lizpreciatior/lzlv-70b-fp16-hf",
      "hfSlug": "lizpreciatior/lzlv_70b_fp16_hf",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-12T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "lzlv 70B",
      "shortName": "lzlv 70B",
      "author": "lizpreciatior",
      "description": "A Mythomax/MLewd_13B-style merge of selected 70B models.\nA multi-model merge of several LLaMA2 70B finetunes for roleplaying and creative work. The goal was to create a model that combines creativity with intelligence for an enhanced experience.\n\n#merge #uncensored",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "airoboros",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "lizpreciatior/lzlv-70b-fp16-hf",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 406,
        "newest": 406,
        "throughputHighToLow": 406,
        "latencyLowToHigh": 406,
        "pricingLowToHigh": 406,
        "pricingHighToLow": 406
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "openrouter/auto",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-08T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Auto Router",
      "shortName": "Auto Router",
      "author": "openrouter",
      "description": "Your prompt will be processed by a meta-model and routed to one of dozens of models (see below), optimizing for the best possible output.\n\nTo see which model was used, visit [Activity](/activity), or read the `model` attribute of the response. Your response will be priced at the same rate as the routed model.\n\nThe meta-model is powered by [Not Diamond](https://docs.notdiamond.ai/docs/how-not-diamond-works). Learn more in our [docs](/docs/model-routing).\n\nRequests will be routed to the following models:\n- [openai/gpt-4o-2024-08-06](/openai/gpt-4o-2024-08-06)\n- [openai/gpt-4o-2024-05-13](/openai/gpt-4o-2024-05-13)\n- [openai/gpt-4o-mini-2024-07-18](/openai/gpt-4o-mini-2024-07-18)\n- [openai/chatgpt-4o-latest](/openai/chatgpt-4o-latest)\n- [openai/o1-preview-2024-09-12](/openai/o1-preview-2024-09-12)\n- [openai/o1-mini-2024-09-12](/openai/o1-mini-2024-09-12)\n- [anthropic/claude-3.5-sonnet](/anthropic/claude-3.5-sonnet)\n- [anthropic/claude-3.5-haiku](/anthropic/claude-3.5-haiku)\n- [anthropic/claude-3-opus](/anthropic/claude-3-opus)\n- [anthropic/claude-2.1](/anthropic/claude-2.1)\n- [google/gemini-pro-1.5](/google/gemini-pro-1.5)\n- [google/gemini-flash-1.5](/google/gemini-flash-1.5)\n- [mistralai/mistral-large-2407](/mistralai/mistral-large-2407)\n- [mistralai/mistral-nemo](/mistralai/mistral-nemo)\n- [deepseek/deepseek-r1](/deepseek/deepseek-r1)\n- [meta-llama/llama-3.1-70b-instruct](/meta-llama/llama-3.1-70b-instruct)\n- [meta-llama/llama-3.1-405b-instruct](/meta-llama/llama-3.1-405b-instruct)\n- [mistralai/mixtral-8x22b-instruct](/mistralai/mixtral-8x22b-instruct)\n- [cohere/command-r-plus](/cohere/command-r-plus)\n- [cohere/command-r](/cohere/command-r)",
      "modelVersionGroupId": null,
      "contextLength": 2000000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Router",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openrouter/auto",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 407,
        "newest": 407,
        "throughputHighToLow": 407,
        "latencyLowToHigh": 407,
        "pricingLowToHigh": 407,
        "pricingHighToLow": 407
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://openrouter.ai/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "google/palm-2-chat-bison-32k",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-03T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: PaLM 2 Chat 32k",
      "shortName": "PaLM 2 Chat 32k",
      "author": "google",
      "description": "PaLM 2 is a language model by Google with improved multilingual, reasoning and coding capabilities.",
      "modelVersionGroupId": null,
      "contextLength": 32760,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "PaLM",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/palm-2-chat-bison-32k",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 408,
        "newest": 408,
        "throughputHighToLow": 408,
        "latencyLowToHigh": 409,
        "pricingLowToHigh": 408,
        "pricingHighToLow": 408
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "google/palm-2-codechat-bison-32k",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-03T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: PaLM 2 Code Chat 32k",
      "shortName": "PaLM 2 Code Chat 32k",
      "author": "google",
      "description": "PaLM 2 fine-tuned for chatbot conversations that help with code-related questions.",
      "modelVersionGroupId": null,
      "contextLength": 32760,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "PaLM",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/palm-2-codechat-bison-32k",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 409,
        "newest": 409,
        "throughputHighToLow": 409,
        "latencyLowToHigh": 408,
        "pricingLowToHigh": 409,
        "pricingHighToLow": 409
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "teknium/openhermes-2-mistral-7b",
      "hfSlug": "teknium/OpenHermes-2-Mistral-7B",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-11-01T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenHermes 2 Mistral 7B",
      "shortName": "OpenHermes 2 Mistral 7B",
      "author": "teknium",
      "description": "Trained on 900k instructions, surpasses all previous versions of Hermes 13B and below, and matches 70B on some benchmarks. Hermes 2 has strong multiturn chat skills and system prompt capabilities.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "teknium/openhermes-2-mistral-7b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 410,
        "newest": 410,
        "throughputHighToLow": 410,
        "latencyLowToHigh": 410,
        "pricingLowToHigh": 410,
        "pricingHighToLow": 410
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "open-orca/mistral-7b-openorca",
      "hfSlug": "Open-Orca/Mistral-7B-OpenOrca",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-10-30T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Mistral OpenOrca 7B",
      "shortName": "Mistral OpenOrca 7B",
      "author": "open-orca",
      "description": "A fine-tune of Mistral using the OpenOrca dataset. First 7B model to beat all other models <30B.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "chatml",
      "defaultSystem": null,
      "defaultStops": [
        "<|im_start|>",
        "<|im_end|>",
        "<|endoftext|>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "open-orca/mistral-7b-openorca",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 411,
        "newest": 411,
        "throughputHighToLow": 411,
        "latencyLowToHigh": 411,
        "pricingLowToHigh": 411,
        "pricingHighToLow": 411
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "nousresearch/nous-hermes-llama2-70b",
      "hfSlug": "NousResearch/Nous-Hermes-Llama2-70b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-10-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 70B",
      "shortName": "Hermes 70B",
      "author": "nousresearch",
      "description": "A state-of-the-art language model fine-tuned on over 300k instructions by Nous Research, with Teknium and Emozilla leading the fine tuning process.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/nous-hermes-llama2-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 412,
        "newest": 412,
        "throughputHighToLow": 412,
        "latencyLowToHigh": 412,
        "pricingLowToHigh": 412,
        "pricingHighToLow": 412
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "xwin-lm/xwin-lm-70b",
      "hfSlug": "Xwin-LM/Xwin-LM-70B-V0.1",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-10-15T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Xwin 70B",
      "shortName": "Xwin 70B",
      "author": "xwin-lm",
      "description": "Xwin-LM aims to develop and open-source alignment tech for LLMs. Our first release, built-upon on the [Llama2](/models/${Model.Llama_2_13B_Chat}) base models, ranked TOP-1 on AlpacaEval. Notably, it's the first to surpass [GPT-4](/models/${Model.GPT_4}) on this benchmark. The project will be continuously updated.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "airoboros",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "xwin-lm/xwin-lm-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 413,
        "newest": 413,
        "throughputHighToLow": 413,
        "latencyLowToHigh": 413,
        "pricingLowToHigh": 413,
        "pricingHighToLow": 413
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "migtissera/synthia-70b",
      "hfSlug": "migtissera/Synthia-70B-v1.2b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-09-22T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Synthia 70B",
      "shortName": "Synthia 70B",
      "author": "migtissera",
      "description": "SynthIA (Synthetic Intelligent Agent) is a LLama-2 70B model trained on Orca style datasets. It has been fine-tuned for instruction following as well as having long-form conversations.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "airoboros",
      "defaultSystem": null,
      "defaultStops": [
        "USER:",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "migtissera/synthia-70b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 414,
        "newest": 414,
        "throughputHighToLow": 414,
        "latencyLowToHigh": 414,
        "pricingLowToHigh": 414,
        "pricingHighToLow": 414
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "meta-llama/codellama-34b-instruct",
      "hfSlug": "meta-llama/CodeLlama-34b-Instruct-hf",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-08-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: CodeLlama 34B Instruct",
      "shortName": "CodeLlama 34B Instruct",
      "author": "meta-llama",
      "description": "Code Llama is built upon Llama 2 and excels at filling in code, handling extensive input contexts, and following programming instructions without prior training for various programming tasks.",
      "modelVersionGroupId": null,
      "contextLength": 8192,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "llama2",
      "defaultSystem": null,
      "defaultStops": [
        "</s>",
        "[INST]"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/codellama-34b-instruct",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 415,
        "newest": 415,
        "throughputHighToLow": 415,
        "latencyLowToHigh": 415,
        "pricingLowToHigh": 415,
        "pricingHighToLow": 415
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "phind/phind-codellama-34b",
      "hfSlug": "Phind/Phind-CodeLlama-34B-v2",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-08-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Phind: CodeLlama 34B v2",
      "shortName": "CodeLlama 34B v2",
      "author": "phind",
      "description": "A fine-tune of CodeLlama-34B on an internal dataset that helps it exceed GPT-4 on some benchmarks, including HumanEval.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "phind/phind-codellama-34b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 416,
        "newest": 416,
        "throughputHighToLow": 416,
        "latencyLowToHigh": 417,
        "pricingLowToHigh": 416,
        "pricingHighToLow": 416
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "nousresearch/nous-hermes-llama2-13b",
      "hfSlug": "NousResearch/Nous-Hermes-Llama2-13b",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-08-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Nous: Hermes 13B",
      "shortName": "Hermes 13B",
      "author": "nousresearch",
      "description": "A state-of-the-art language model fine-tuned on over 300k instructions by Nous Research, with Teknium and Emozilla leading the fine tuning process.",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "alpaca",
      "defaultSystem": null,
      "defaultStops": [
        "###",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "nousresearch/nous-hermes-llama2-13b",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 417,
        "newest": 417,
        "throughputHighToLow": 417,
        "latencyLowToHigh": 416,
        "pricingLowToHigh": 417,
        "pricingHighToLow": 417
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://nousresearch.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "huggingfaceh4/zephyr-7b-beta",
      "hfSlug": "HuggingFaceH4/zephyr-7b-beta",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-08-02T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Hugging Face: Zephyr 7B",
      "shortName": "Zephyr 7B",
      "author": "huggingfaceh4",
      "description": "Zephyr is a series of language models that are trained to act as helpful assistants. Zephyr-7B-β is the second model in the series, and is a fine-tuned version of [mistralai/Mistral-7B-v0.1](/models/mistralai/mistral-7b-instruct-v0.1) that was trained on a mix of publicly available, synthetic datasets using Direct Preference Optimization (DPO).",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Mistral",
      "instructType": "zephyr",
      "defaultSystem": null,
      "defaultStops": [
        "<|user|>\n",
        "</s>"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "huggingfaceh4/zephyr-7b-beta",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 418,
        "newest": 418,
        "throughputHighToLow": 418,
        "latencyLowToHigh": 418,
        "pricingLowToHigh": 418,
        "pricingHighToLow": 418
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://huggingface.co/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "anthropic/claude-instant-1",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude Instant v1",
      "shortName": "Claude Instant v1",
      "author": "anthropic",
      "description": "Anthropic's model for low-latency, high throughput text generation. Supports hundreds of pages of text.",
      "modelVersionGroupId": null,
      "contextLength": 100000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-instant-1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 419,
        "newest": 419,
        "throughputHighToLow": 419,
        "latencyLowToHigh": 422,
        "pricingLowToHigh": 419,
        "pricingHighToLow": 419
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": []
    },
    {
      "slug": "anthropic/claude-1",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude v1",
      "shortName": "Claude v1",
      "author": "anthropic",
      "description": "Anthropic's model for low-latency, high throughput text generation. Supports hundreds of pages of text.",
      "modelVersionGroupId": null,
      "contextLength": 100000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": "claude",
      "defaultSystem": null,
      "defaultStops": [
        "\n\nHuman:"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-1",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 420,
        "newest": 420,
        "throughputHighToLow": 420,
        "latencyLowToHigh": 419,
        "pricingLowToHigh": 420,
        "pricingHighToLow": 420
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": []
    },
    {
      "slug": "anthropic/claude-1.2",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude v1.2",
      "shortName": "Claude v1.2",
      "author": "anthropic",
      "description": "Anthropic's model for low-latency, high throughput text generation. Supports hundreds of pages of text.",
      "modelVersionGroupId": null,
      "contextLength": 100000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": "claude",
      "defaultSystem": null,
      "defaultStops": [
        "\n\nHuman:"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-1.2",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 421,
        "newest": 421,
        "throughputHighToLow": 421,
        "latencyLowToHigh": 421,
        "pricingLowToHigh": 421,
        "pricingHighToLow": 421
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": []
    },
    {
      "slug": "anthropic/claude-instant-1.0",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Anthropic: Claude Instant v1.0",
      "shortName": "Claude Instant v1.0",
      "author": "anthropic",
      "description": "Anthropic's model for low-latency, high throughput text generation. Supports hundreds of pages of text.",
      "modelVersionGroupId": null,
      "contextLength": 100000,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Claude",
      "instructType": "claude",
      "defaultSystem": null,
      "defaultStops": [
        "\n\nHuman:"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "anthropic/claude-instant-1.0",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 422,
        "newest": 422,
        "throughputHighToLow": 422,
        "latencyLowToHigh": 420,
        "pricingLowToHigh": 422,
        "pricingHighToLow": 422
      },
      "authorIcon": "https://openrouter.ai/images/icons/Anthropic.svg",
      "providers": []
    },
    {
      "slug": "google/palm-2-chat-bison",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: PaLM 2 Chat",
      "shortName": "PaLM 2 Chat",
      "author": "google",
      "description": "PaLM 2 is a language model by Google with improved multilingual, reasoning and coding capabilities.",
      "modelVersionGroupId": null,
      "contextLength": 9216,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "PaLM",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/palm-2-chat-bison",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 423,
        "newest": 423,
        "throughputHighToLow": 423,
        "latencyLowToHigh": 423,
        "pricingLowToHigh": 423,
        "pricingHighToLow": 423
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "google/palm-2-codechat-bison",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-07-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Google: PaLM 2 Code Chat",
      "shortName": "PaLM 2 Code Chat",
      "author": "google",
      "description": "PaLM 2 fine-tuned for chatbot conversations that help with code-related questions.",
      "modelVersionGroupId": null,
      "contextLength": 7168,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "PaLM",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "google/palm-2-codechat-bison",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 424,
        "newest": 424,
        "throughputHighToLow": 424,
        "latencyLowToHigh": 424,
        "pricingLowToHigh": 424,
        "pricingHighToLow": 424
      },
      "authorIcon": "https://openrouter.ai/images/icons/GoogleGemini.svg",
      "providers": []
    },
    {
      "slug": "meta-llama/llama-2-13b-chat",
      "hfSlug": "meta-llama/Llama-2-13b-chat-hf",
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-06-20T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "Meta: Llama 2 13B Chat",
      "shortName": "Llama 2 13B Chat",
      "author": "meta-llama",
      "description": "A 13 billion parameter language model from Meta, fine tuned for chat completions",
      "modelVersionGroupId": null,
      "contextLength": 4096,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "Llama2",
      "instructType": "llama2",
      "defaultSystem": null,
      "defaultStops": [
        "</s>",
        "[INST]"
      ],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "meta-llama/llama-2-13b-chat",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 425,
        "newest": 425,
        "throughputHighToLow": 425,
        "latencyLowToHigh": 425,
        "pricingLowToHigh": 425,
        "pricingHighToLow": 425
      },
      "authorIcon": "https://t0.gstatic.com/faviconV2?client=SOCIAL\\u0026type=FAVICON\\u0026fallback_opts=TYPE,SIZE,URL\\u0026url=https://ai.meta.com/\\u0026size=256",
      "providers": []
    },
    {
      "slug": "openai/gpt-3.5-turbo-0301",
      "hfSlug": null,
      "updatedAt": "2025-03-28T03:20:30.853469+00:00",
      "createdAt": "2023-05-28T00:00:00+00:00",
      "hfUpdatedAt": null,
      "name": "OpenAI: GPT-3.5 Turbo (older v0301)",
      "shortName": "GPT-3.5 Turbo (older v0301)",
      "author": "openai",
      "description": "GPT-3.5 Turbo is OpenAI's fastest model. It can understand and generate natural language or code, and is optimized for chat and traditional completion tasks.\n\nTraining data up to Sep 2021.",
      "modelVersionGroupId": null,
      "contextLength": 4095,
      "inputModalities": [
        "text"
      ],
      "outputModalities": [
        "text"
      ],
      "hasTextOutput": true,
      "group": "GPT",
      "instructType": null,
      "defaultSystem": null,
      "defaultStops": [],
      "hidden": false,
      "router": null,
      "warningMessage": null,
      "permaslug": "openai/gpt-3.5-turbo-0301",
      "reasoningConfig": null,
      "features": {},
      "endpoint": null,
      "sorting": {
        "topWeekly": 426,
        "newest": 426,
        "throughputHighToLow": 426,
        "latencyLowToHigh": 426,
        "pricingLowToHigh": 426,
        "pricingHighToLow": 426
      },
      "authorIcon": "https://openrouter.ai/images/icons/OpenAI.svg",
      "providers": []
    }
  ]
}